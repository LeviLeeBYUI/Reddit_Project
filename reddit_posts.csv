subreddit,title,score,id,url,created_utc,body
datascience,"Weekly Entering & Transitioning - Thread 13 Jan, 2025 - 20 Jan, 2025",5,1i06k3y,https://www.reddit.com/r/datascience/comments/1i06k3y/weekly_entering_transitioning_thread_13_jan_2025/,1736744505.0," 

Welcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:

* Learning resources (e.g. books, tutorials, videos)
* Traditional education (e.g. schools, degrees, electives)
* Alternative education (e.g. online courses, bootcamps)
* Job search questions (e.g. resumes, applying, career prospects)
* Elementary questions (e.g. where to start, what next)

While you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new)."
datascience,Influential Time-Series Forecasting Papers of 2023-2024: Part 1,96,1i4yyoe,https://www.reddit.com/r/datascience/comments/1i4yyoe/influential_timeseries_forecasting_papers_of/,1737294977.0,"This article explores some of the latest advancements in time-series forecasting.

You can find the article [here](https://aihorizonforecast.substack.com/p/influential-time-series-forecasting).

Edit: If you know of any other interesting papers, please share them in the comments."
datascience,AI is difficult to get right: Apple Intelligence rolled back(Mostly the summary feature),257,1i4f1go,https://www.reddit.com/r/datascience/comments/1i4f1go/ai_is_difficult_to_get_right_apple_intelligence/,1737227935.0,"Source: https://edition.cnn.com/2025/01/16/media/apple-ai-news-fake-headlines/index.html#:\~:text=Apple%20is%20temporarily%20pulling%20its,organization%20and%20press%20freedom%20groups.

Seems like even Apple is struggling to deploy AI and deliver real-world value.  
Yes, companies can make mistakes, but Apple rarely does, and even so, it seems like most of Apple Intelligence is not very popular with IOS users and has led to the creation of r/AppleIntelligenceFail.

It's difficult to get right in contrast to application development which was the era before the ai boom. "
datascience,Where to Start when Data is limited,7,1i50i4u,https://towardsdatascience.com/effective-ml-with-limited-data-where-to-start-194492e7a6f8,1737299326.0,"Hey, I’ve been putting together my thoughts and some research around how to get the most out of small datasets when performance requirements mean conventional analysis isn’t enough. 

Would love to hear some feedback and thoughts."
datascience,Should I Try to postpone my FAANG Interview?,0,1i5576y,https://www.reddit.com/r/datascience/comments/1i5576y/should_i_try_to_postpone_my_faang_interview/,1737311263.0,"So I got contacted by a FAANG Recruiter for a Data Scientist Role I applied for a month and a half ago. But as I have started to prep, I realize I am not ready and need 1 to 2 months before I would be able to do well on all the technical interviews (there are 4 of them). My SQL is rusty because I have been using Pyspark so much that I didn't really need to do medium to hard SQL queries at work (We're also not allowed in most cases since SQL is slower). So I would just do everything in Pyspark. But now, as I start practicing my SQL I realize it's very basic, and it's going to take some time before I can get it on the level my pyspark is at.

I've noticed that I feel like there is no chance of me performing well enough on this interview, and it sucks because the recruiter said that the hiring manager was looking at my resume and really wants to interview me as soon as possible since he thinks I have strong experience for the role (They made me bypass the phone screens because of it). I have no doubt I would be able to do the role, but interviews are another beast. According to the prep guide, my Stats, ML Theory, SQL, and Python all have to be perfect. Since I joined my current company as an intern, I didn't have to do as many in-depth technicals as I have to do here. I've interviewed at a couple other big companies last year and didn't make it to the final round for one simply because I needed more time to prepare. The FAANG recruiter wants me to do the first 2 interviews within the next two weeks, and I'm worried about what it would do to my confidence if I failed this interview since this is pretty much my dream Data Scientist role. My mind is already telling me just to make the best of this and use it as a learning experience, but another part of me is wondering if I should just cancel it altogether or try to delay it as much as possible. I have a mock interview with a Company Data Scientist they set up for me in a few days, but part of me feels defeated already and it sucks...

I honestly am not sure what to do as I need a lot more time. I've heard others say it took them as long as 2-6 months before they were ready to crush their FAANG interview and I know I am not there yet..."
datascience,What salary range should I expect as a fresh college grad with a BS in Statistics and Data Science?,105,1i3y1qs,https://www.reddit.com/r/datascience/comments/1i3y1qs/what_salary_range_should_i_expect_as_a_fresh/,1737169081.0,"For context, I’m a student at UCLA, and am applying to jobs within California. But I’m interested in people’s past jobs fresh out of college, where in the country, and what the salary was. 

Tentatively, I’m expecting a salary of anywhere between $70k and $80k, but I’ve been told I should be expecting closer to $100k, which just seems ludicrous. "
datascience,Are there any ways to earn a little extra money on the side as a data scientist?,82,1i3x2cf,https://www.reddit.com/r/datascience/comments/1i3x2cf/are_there_any_ways_to_earn_a_little_extra_money/,1737165883.0,"Using data science skills (otherwise I'm sure there are plenty). 

I know there is data annotation, but I'm not sure that qualifies as data science."
datascience,Do these recruiters sound like a scam?,10,1i40izz,https://www.reddit.com/r/datascience/comments/1i40izz/do_these_recruiters_sound_like_a_scam/,1737177777.0,"Hi all, unsure of where else to ask this so asking here. 

I had a recruiter (heavy Indian accent) call/email me with an interesting proposition. They work for the candidate rather than the company. If they place you in a job within 45 days they ask for 9% of your first year's salary.

They claim their value add is in a couple of things. First they promise that they have advanced ATS software that will help tweak professional qualifications. Second, they say they will apply to approximately 50 JDs per day (I am skeptical this many relevant jobs are even being posted).

I have never had luck with Indian recruiters before but I have had good experiences professionally in offshoring some repetitive tasks for cheap. This process sounds like it fits the bill. The part where it gets sketchy is they want either access to my LinkedIn/Gmail or they want me to create second LinkedIn/Gmail accounts that they would have control over. Access to my gmail is a nonstarter obviously. But creating spoof LinkedIn/Gmails feels a little sketchy. 

If we're living in a universe where these guys are simply trying to provide the service they've described, I'm all in. I just don't want to get soft-rolled into some sort of scam."
datascience,SOS: Developer Community in South Florida ,0,1i4gk4a,https://www.reddit.com/r/datascience/comments/1i4gk4a/sos_developer_community_in_south_florida/,1737232040.0,"Hey folks, 

I’m new to south Florida and am looking to get connected with the developer community here. 

I am an entrepreneur and would love connecting with other like minded individuals. 

Any guidance or advice?

- CM"
datascience,Huggingface smolagents : Code centric Agent framework. Is it the best AI Agent framework? I don't think so,2,1i3zajz,/r/ArtificialInteligence/comments/1i3z9ni/huggingface_smolagents_code_centric_agent/,1737173285.0,
datascience,I've been given the choice between being a Data Scientist or an Analytics Manager. Which would you choose and why?,187,1i33mt0,https://www.reddit.com/r/datascience/comments/1i33mt0/ive_been_given_the_choice_between_being_a_data/,1737073226.0,"I'm coming from a Data Analyst position, and I've essentially been given the choice between being a Data Scientist and or an Analytics Manager. I thought Data Scientist was my dream job, but the Manager position would pay more, and I've been dreaming about working my way up to Director or CDO... Does Analytics Manager make the most sense in this case?

Update for context: I'm 25, have a master's in data analytics, and have been working in the same industry for 7 years but in different roles. I've been an Analyst for 1.5+ years, and previously was a Data Manager, and a Researcher."
datascience,guys is web crawling and scraping +1 for data science or it doesn't matter. ,36,1i3cgo0,https://www.reddit.com/r/datascience/comments/1i3cgo0/guys_is_web_crawling_and_scraping_1_for_data/,1737105217.0,"by web crawling and scraping i mean advanced scraping with multiple websites for prices and products then building further things around it like strategic planning and buisness analytics. 

edit: is it a necessary skill or not. +1 it means its a great add on to ur skill stack"
datascience,How long did it take you to get a new role when looking for a new job?,40,1i3a45a,https://www.reddit.com/r/datascience/comments/1i3a45a/how_long_did_it_take_you_to_get_a_new_role_when/,1737094521.0,"I'm feeling very miserable at my job as well as feeling uneasy with the ethics of my company so I desperately am looking for a new role, but this job market is concerning. I have a BS in Math and MS in DS, been at my job as a data scientist for 1.5 years, worked for 3 years between BS and MS in analyst roles. Is there hope to have something new soon? How many apps per day should I be sending? "
datascience,"Free Learning Paths for Data Analysts, Data Scientists, and Data Engineers – Using 100% Open Resources ",227,1i2vj0x,https://i.redd.it/ustzy4gseede1.jpeg,1737051786.0,"Hey, I’m Ryan, and I’ve created 

https://www.datasciencehive.com/learning-paths 

a platform offering free, structured learning paths for data enthusiasts and professionals alike.

The current paths cover:

	•	Data Analyst: Learn essential skills like SQL, data visualization, and predictive modeling.
	•	Data Scientist: Master Python, machine learning, and real-world model deployment.
	•	Data Engineer: Dive into cloud platforms, big data frameworks, and pipeline design.

The learning paths use 100% free open resources and don’t require sign-up. Each path includes practical skills and a capstone project to showcase your learning.

I see this as a work in progress and want to grow it based on community feedback. Suggestions for content, resources, or structure would be incredibly helpful.

I’ve also launched a Discord community (https://discord.gg/Z3wVwMtGrw) with over 150 members where you can:

	•	Collaborate on data projects
	•	Share ideas and resources
	•	Join future live hangouts for project work or Q&A sessions

If you’re interested, check out the site or join the Discord to help shape this platform into something truly valuable for the data community.

Let’s build something great together.

Website: https://www.datasciencehive.com/learning-paths
Discord: https://discord.gg/Z3wVwMtGrw "
datascience,Google Titans : New LLM architecture with better long term memory,5,1i3a227,/r/ArtificialInteligence/comments/1i3a1ub/google_titans_new_llm_architecture_with_better/,1737094288.0,
datascience,Microsoft MatterGen: GenAI model for Material design and discovery ,2,1i3clrk,/r/ArtificialInteligence/comments/1i3clk7/microsoft_mattergen_genai_model_for_material/,1737105866.0,
datascience,Introducing mlsynth.,21,1i2vmuv,https://www.reddit.com/r/datascience/comments/1i2vmuv/introducing_mlsynth/,1737052050.0,"Hi DS Reddit. For those of who you work in causal inference, you may be interested in a Python library I developed called ""machine learning synthetic control"", or ""mlsynth"" for short.

As I write in its [documentation](https://mlsynth.readthedocs.io), mlsynth is a one-stop shop of sorts for implementing some of the most recent synthetic control based estimators, many of which use machine learning methodologies. Currently, the software is hosted from my GitHub, and it is still undergoing developments (i.e., for computing inference for point-estinates/user friendliness).

mlsynth implements the following methods: [Augmented Difference-in-Differences](https://doi.org/10.1287/mksc.2022.1406), CLUSTERSCM, [Debiased Convex Regression](https://doi.org/10.1287/inte.2023.0028)  (undocumented at present), the [Factor Model Approach](https://doi.org/10.1177/00222437221137533), [Forward Difference-in-Differences](https://doi.org/10.1287/mksc.2022.1406), [Forward Selected Panel Data Approach](https://doi.org/10.1016/j.jeconom.2021.04.009), the [L1PDA](https://doi.org/10.1002/jae.1230), the [L2-relaxation PDA](https://doi.org/10.13140/RG.2.2.11670.97609), [Principal Component Regression](https://doi.org/10.1080/01621459.2021.1928513), [Robust PCA Synthetic Control](https://academicworks.cuny.edu/gc_etds/4984), [Synthetic Control Method (Vanilla SCM)](https://doi.org/10.1198/jasa.2009.ap08746), [Two Step Synthetic Control](https://doi.org/10.1287/mnsc.2023.4878)  and finally the two newest methods which are not yet fully documented, [Proximal Inference-SCM](https://arxiv.org/abs/2108.13935) and [Proximal Inference with Surrogates-SCM](https://arxiv.org/abs/2308.09527)  

While each method has their own options (e.g., Bayesian or not, l2 relaxer versus L1), all methods have a common syntax which allows us to switch seamlessly between methods without needing to switch softwares or learn a new syntax for a different library/command. It also brings forth methods which either had no public documentation yet, or were written mostly for/in MATLAB.

The documentation that currently exists explains installation as well as the basic methodology of each method. I also provide worked examples from the academic literature to serve as a reference point for how one may use the code to estimate causal effects.

So, to anybody who uses Python and causal methods on a regular basis, this is an option that may suit your needs better than standard techniques."
datascience,Books on Machine Learning + in R,22,1i2qj4j,https://www.reddit.com/r/datascience/comments/1i2qj4j/books_on_machine_learning_in_r/,1737038919.0,"I'm interested in everyone's experience of books based specifically in R on machine learning, deep learning, and more recently LLM modelling, etc.  If you have particular experience to share it would really useful to hear about it.

As a sub-question it would be great to hear about books intended for relative beginners, by which I mean those familiar with R and statistical analysis but with no formal training in AI. There is obviously the well-known *""Introduction to Machine Learning with R""* by Scott V Burger, available as a [free pdf](https://edisciplinas.usp.br/pluginfile.php/8527271/mod_resource/content/0/Burger%2C%20Scott%20V%20-%20Introduction%20to%20machine%20learning%20with%20R_%20rigorous%20mathematical%20analysis-OReilly%20%282018%29.pdf).  But it hasn't been updated in nearly 7 years now, and a quick [scan of Google](https://www.google.co.uk/search?tbm=shop&hl=en-GB&psb=1&ved=2ahUKEwi6jeS9vPqKAxXdQ0ECHRvSDwAQu-kFegQIABAK&q=Machine+Learning+in+R&oq=Machine+Learning+in+R&gs_lp=Egtwcm9kdWN0cy1jYyIVTWFjaGluZSBMZWFybmluZyBpbiBSSABQAFgAcAB4AJABAJgBAKABAKoBALgBA8gBAJgCAKACAJgDAJIHAKAHAA&sclient=products-cc) shows quite a number of others.  Suggestions much appreciated."
datascience,Start freelancing with 0 experience?,41,1i2jytl,https://www.reddit.com/r/datascience/comments/1i2jytl/start_freelancing_with_0_experience/,1737013947.0,"I hear many people have the ambition to start freelancing as soon as they can, ideally before having significant job experience. 
I like the attitude, but I tried myself a few years ago and got burned. So I wanna share my experience. 
   
I am a Data Scientist and tried to start freelancing with just one year job experience in 2017. Did the usual stuff. Set up an Upwork profile, applied to jobs at nights and during weekends and waited for a reply. 
Crickets. I **applied to 11 jobs** and didn't get any. Looking back at that experience I see a few mistakes
1 I didn't have a portfolio of projects that matched the jobs I applied to. 
2 I only used Upwork, without leveraging LInkedIn, Catalant, Fiverr and others. 
3 I gave up too early. Just 11 applications over one month is not enough. I recommend applying to 20-30 jobs per week if possible.
4 I set an unreasonable hourly rate. I set my hourly rate same as my daily job, Freelancing is a market where you are the product. When there is no demand for you (because nobody knows you) it's a smart move to set the price low. Once demand picks up, increase the price accordingly. 

Overall, I think experience is not the number one factor that a client looks for when hiring a freelancer. It's way more important to give the client confidence that you can do the job. So you should always work with that goal in mind, from the way you build your profile, to all the communication with your client. 
Last bit of advice. I found success in my local market at first. In Italy there is not many Data professionals that are also freelancers, and that helped me. People like to work with familiar faces and speaking the same language, sharing the same culture, goes a long way building confidence.

Curious to know your point of view too. "
datascience,looking for arts sales data to understand arts pricing dynamics or madness,0,1i34tao,https://www.reddit.com/r/datascience/comments/1i34tao/looking_for_arts_sales_data_to_understand_arts/,1737076708.0,"I would like to explore datasets of arts sale and auctions, please if anyone has a good source please post below in the link. Just curious to explore if there are any patterns in art prices or just maddness which data science can't understand why a banana and tape would sell for 6 million or perhaps I can learn more about arts from this dataset. 

thanks in advance



Thanks "
datascience,Can someone help me understand what is the issue exactly?,0,1i3bwdj,/r/aws/comments/1i3bvho/can_someone_help_me_understand_what_is_the_issue/,1737102536.0,
datascience,Solution completeness and take home assignments for interviews?,4,1i2mh17,https://www.reddit.com/r/datascience/comments/1i2mh17/solution_completeness_and_take_home_assignments/,1737025307.0,"What is the general consensus about take home interviews and then completeness of solution.

I have around a week and it took me already 2 days just to work with with the data just so I can
1) clean it
2) enhance it with external data
3) feature engineer it
4) establish baselines to capture lift

The whole thing is supposed to be finished around the span of a week. As i was scoping it out the whole thing is essentially potentially 3-4 models in a framework given the complex nature of the work.

How critical is the completeness and assumptions being made regarding these take home assignments. I didnt get a take home that large in scope. Its difficult task but very doable just laborious in the sense that it requires to be well thought out. "
datascience,What do you think about building the pipeline first with bad models to start refining quickly?,38,1i28x7i,https://www.reddit.com/r/datascience/comments/1i28x7i/what_do_you_think_about_building_the_pipeline/,1736978111.0,"we have to build a computer vision application, I detect 4 main problems, 



get the highest quality training set, it is requiring lots of code and it may require lots of manual work to generate the ground truth

train a classification model, two main orthogonal approaches are being considered and will be tested

train a segmentation model

connect the dots and build the end to end pipeline

  
one teammate is working in the highest quality training set, and three other teammates in the classification models. I think it would be incredibly beneficial to have the pipeline as soon as possible integrated with the extremely simple models, and then iterate taking into account error metrics, as it gives us goals and this lets them test their module/section of the work also taking into account variation of the final metrics.

  
this would also help the other teams that depend on our output, web development can use a model, it is just a bad model, but we'll improve the results, the deployment work could also start now.

  
what do you guys think about this approach? for me it looks like its all benefits and zero problems but I see some teammates are reluctant on building something that definitely fails at the beginning and I'm not definitely the most experienced data scientist."
datascience,Who is the most hungry for AI / ML talent right now,127,1i1z6pj,https://www.reddit.com/r/datascience/comments/1i1z6pj/who_is_the_most_hungry_for_ai_ml_talent_right_now/,1736953054.0,"I run a job search engine for Data Scientists. This week we added monitoring of the highest paid job openings in the last week. This is what I saw. It seems one company in particular wants to outbid everyone else. And this is not because of lack of competition - we monitor more than 30.000 companies including all of Fortune 100 and most of Fortune 1000. We index more than 60k data science jobs every month. 

Source: [jobs-in-data.com](https://jobs-in-data.com)

https://preview.redd.it/sqxgf9u786de1.png?width=2438&format=png&auto=webp&s=476af7f8ec1456a3d3f0e27f2fea61d4519daa9c

"
datascience,aspirations of starting a data science consultancy ,35,1i20otn,https://www.reddit.com/r/datascience/comments/1i20otn/aspirations_of_starting_a_data_science_consultancy/,1736957009.0,"Has anyone ever here thought of how to use their skills to start their own consultancy or some kind of business? Lately ive been kinda feeling that it would be really nice to have something of my own to work one involving analytics. Working for a company is great experience, but part of me would really like to have a business that I own where I help small businesses who have data make sense of it with low hanging fruit solutions.

Just a thought, but I’ve always thought of some sort of consultancy where clients are some sort of local business that collects data but doesn’t use it effectively or does not have the expertise on how to turn their data into insights that can be used. 

For example, suppose you had three clients:

1. Local gyms which have lots of membership data - my consultancy could offer services to measure engagement, etc and use demographic information to further understand gym goers - don’t know what “action” they could take but a thought 

2. Local shop has expenses they track and right now it’s all over the place. A dashboard that can help them view everything in one place

Something where, it’s tasks which are trivial for the average data scientist, but generate a lot of value for local businesses.

But maybe you can go deeper? I’m not sure how genAI works and haven’t played around with like any of these tools, but I’ve thought of ways these can be incorporated too.

Idk, I just find working in the industry sole draining and I just want to be able to have something that I can call my own, work on my own schedule, and it lead to a lot more revenue than working for a company. 

If anyone has any thoughts on what they have done, or how they have tried to do something, please let me know. Ideally I’d try and start this after 3-4 years of experience where I’ve built some niche industry experience. "
datascience,WASM-powered codespaces for Python notebooks on GitHub,11,1i275yh,https://www.reddit.com/r/datascience/comments/1i275yh/wasmpowered_codespaces_for_python_notebooks_on/,1736973521.0,"During a hackweek, we built this project that allows you to run [marimo](https://github.com/marimo-team/marimo) and Jupyter notebooks directly from GitHub in a Wasm-powered, codespace-like environment. What makes this powerful is that we mount the GitHub repository's contents as a filesystem in the notebook, making it really easy to share notebooks with data.

**All you need to do is prepend** [`https://marimo.app`](https://marimo.app) **to any Python notebook on GitHub.** Some examples:

* Jupyter Notebook: [https://marimo.app/github.com/jakevdp/PythonDataScienceHandb...](https://marimo.app/github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/02.08-Sorting.ipynb)
* marimo notebook: [https://marimo.app/github.com/marimo-team/marimo/blob/07e8d1...](https://marimo.app/github.com/marimo-team/marimo/blob/07e8d14109f7312f19916fd13e4046a561a740f8/examples/third_party/polars/polars_example.py)

Jupyter notebooks are automatically converted into marimo notebooks using basic static analysis and source code transformations. Our conversion logic assumes the notebook was meant to be run top-down, which is usually but not always true \[2\]. It can convert many notebooks, but there are still some edge cases.

We implemented the filesystem mount using our own FUSE-like adapter that links the GitHub repository’s contents to the Python filesystem, leveraging Emscripten’s filesystem API. The file tree is loaded on startup to avoid waterfall requests when reading many directories deep, but loading the file contents is lazy. For example, when you write Python that looks like

    with open(""./data/cars.csv"") as f:
        print(f.read())
    
    # or
    
    import pandas as pd
    pd.read_csv(""./data/cars.csv"")

behind the scenes, you make a request \[3\] to *https://raw.githubusercontent.com/<org>/<repo>/main/data/cars.csv*

Docs: [https://docs.marimo.io/guides/publishing/playground/#open-notebooks-hosted-on-github](https://docs.marimo.io/guides/publishing/playground/#open-notebooks-hosted-on-github)

\[2\] [https://blog.jetbrains.com/datalore/2020/12/17/we-downloaded-10-000-000-jupyter-notebooks-from-github-this-is-what-we-learned/](https://blog.jetbrains.com/datalore/2020/12/17/we-downloaded-10-000-000-jupyter-notebooks-from-github-this-is-what-we-learned/)

\[3\] We technically proxy it through the playground [https://marimo.app](https://marimo.app) to fix CORS issues and GitHub rate-limiting.

**Why is this useful?**

Vieiwng notebooks on GitHub pages is limiting. They don't allow external css or scripts so charts and advanced widgets can fail. They also aren't itneractive so you can't tweek a value or pan/zoom a chart. It is also difficult to share your notebook with code - you either need to host it somehwere or embed it inside your notebook. Just append `https://marimo.app/<github_url>`"
datascience,"Advanced Imputation Techniques for Correlated Time Series: Insights and Experiences?

",8,1i29a6d,https://www.reddit.com/r/datascience/comments/1i29a6d/advanced_imputation_techniques_for_correlated/,1736979031.0,"**Advanced Imputation Techniques for Correlated Time Series: Insights and Experiences?**

Hi everyone,

I’m looking to spark a discussion about **advanced imputation techniques** for datasets with multiple distinct but correlated time series. Imagine a dataset like **energy consumption** or **sales data**, where hundreds of stores or buildings are measured separately. The granularity might be hourly or daily, with varying levels of data completeness across the time series.

Here’s the challenge:

1. Some buildings/stores have **complete or nearly complete data** with only a few missing values. These are straightforward to impute using standard techniques.
2. Others have **partial data**, with gaps ranging from days to months.
3. Finally, there are buildings with **100% missing values** for the target variable across the entire time frame, leaving us reliant on correlated data and features.

The time series show **clear seasonal patterns** (weekly, annual) and dependencies on external factors like weather, customer counts, or building size. While these features are available for all buildings—including those with no target data—the features alone are insufficient to accurately predict the target. Correlations between the time series range from moderate (\~0.3) to very high (\~0.9), making the data situation highly heterogeneous.

# My Current Approach:

For stores/buildings with **few or no data points**, I’m considering an approach that involves:

1. **Using Correlated Stores**: Identify stores with high correlations based on available data (e.g., monthly aggregates). These could serve as a foundation for imputing the missing time series.
2. **Reconciling to Monthly Totals**: If we know the **monthly sums** of the target for stores with missing hourly/daily data, we could constrain the imputed time series to match these totals. For example, adjust the imputed hourly/daily values so that their sum equals the known monthly figure.
3. **Incorporating Known Features**: For stores with missing target data, use additional features (e.g., holidays, temperature, building size, or operational hours) to refine the imputed time series. For example, if a store was closed on a Monday due to repairs or a holiday, the imputation should respect this and redistribute values accordingly.

# Why Just Using Correlated Stores Isn’t Enough:

While using highly correlated stores for imputation seems like a natural approach, it has limitations. For instance:

* A store might be closed on certain days (e.g., repairs or holidays), resulting in zero or drastically reduced energy consumption. Simply copying or scaling values from correlated stores won’t account for this.
* The known features for the missing store (e.g., building size, operational hours, or customer counts) might differ significantly from those of the correlated stores, leading to biased imputations.
* Seasonal patterns (e.g., weekends vs. weekdays) may vary slightly between stores due to operational differences.

# Open Questions:

* **Feature Integration**: How can we better incorporate the available features of stores with 100% missing values into the imputation process while respecting known totals (e.g., monthly sums)?
* **Handling Correlation-Based Imputation**: Are there specific techniques or algorithms that work well for leveraging correlations between time series for imputation?
* **Practical Adjustments**: When reconciling imputed values to match known totals, what methods work best for redistributing values while preserving the overall seasonal and temporal patterns?

From my perspective, this approach seems sensible, but I’m curious about others' experiences with similar problems or opinions on why this might—or might not—work in practice. If you’ve dealt with imputation in datasets with heterogeneous time series and varying levels of completeness, I’d love to hear your insights!

Thanks in advance for your thoughts and ideas!

"
datascience,Leaving Public Sector for Private,20,1i1wnxj,https://www.reddit.com/r/datascience/comments/1i1wnxj/leaving_public_sector_for_private/,1736945403.0,"Posting for a friend:

Currently in a an ostensibly manager level DS position in local government. They are in the final stages of interviewing for a Director level role at a private firm. Is the compensation change worth it (posted below) and are there any DS specific aspects they should consider? 

Right now they are an IC who occasionally manages, but it seems this new role might be 80-90% managing. Is that common for the private sector? I told them it doesn't seem worth it (I'm biased as I am also in the public sector), but they said the compensation combined with more interesting work might be worth it.

Public Sector:
Manager
135k
Pension (secure but only okay payout)
Student Loan Forgiveness

Private Sector:
Director
165k
10-15% Bonus
401k 4% Match

"
datascience,What Challenges Do Businesses Face When Developing AI Solutions?,0,1i2m3mv,https://www.reddit.com/r/datascience/comments/1i2m3mv/what_challenges_do_businesses_face_when/,1737023704.0,"Hello everyone,

I’m currently working on providing cloud services and looking to better understand the challenges businesses face when developing AI. As a cloud provider, I’m keen to learn about the real-world obstacles organizations encounter when scaling their AI solutions.

For those in the AI industry, what specific issues or limitations have you faced in terms of infrastructure, platform flexibility, or integration challenges? Are there any key challenges in AI development that remain unresolved? What specific support or solutions do AI developers need from cloud providers to overcome current limitations?

Looking forward to hearing your thoughts and learning from your experiences. Thanks in advance!"
datascience,E-values: A modern alternative to p-values,104,1i1bjhi,https://www.reddit.com/r/datascience/comments/1i1bjhi/evalues_a_modern_alternative_to_pvalues/,1736876152.0,"In many modern applications - A/B testing, clinical trials, quality monitoring - we need to analyze data as it arrives. Traditional statistical tools weren't designed with this sequential analysis in mind, which has led to the development of new approaches.

E-values are one such tool, specifically designed for sequential testing. They provide a natural way to measure evidence that accumulates over time. An e-value of 20 represents 20-to-1 evidence against your null hypothesis - a direct and intuitive interpretation. They're particularly useful when you need to:

- Monitor results in real-time
- Add more samples to ongoing experiments
- Combine evidence from multiple analyses
- Make decisions based on continuous data streams

While p-values remain valuable for fixed-sample scenarios, e-values offer complementary strengths for sequential analysis. They're increasingly used in tech companies for A/B testing and in clinical trials for interim analyses.

If you work with sequential data or continuous monitoring, e-values might be a useful addition to your statistical toolkit. Happy to discuss specific applications or mathematical details in the comments.​​​​​​​​​​​​​​​​

P.S: Above was summarized by an LLM.

Paper: Hypothesis testing with e-values - https://arxiv.org/pdf/2410.23614

Current code libraries:

Python:

- expectation: New library implementing e-values, sequential testing and confidence sequences (https://github.com/jakorostami/expectation)

- confseq: Core library by Howard et al for confidence sequences and uniform bounds (https://github.com/gostevehoward/confseq)


R: 

- confseq: The original R implementation, same authors as above

- safestats: Core library by one of the researchers in this field of Statistics, Alexander Ly. (https://cran.r-project.org/web/packages/safestats/readme/README.html)

"
datascience,Fuck pandas!!! [Rant],476,1i0x2pm,https://www.kaggle.com/code/sudalairajkumar/getting-started-with-python-datatable,1736825814.0,"I have been a heavy R user for 9 years and absolutely love R. I can write love letters about the R data.table package. It is fast. It is efficient. it is beautiful. A coder’s dream.
 
But of course all good things must come to an end and given the steady decline of R users decided to switch to python to keep myself relevant.

And let me tell you I have never seen a stinking hot pile of mess than pandas. Everything is 10 layers of stupid? The syntax makes me scream!!!!!! There is no coherence or pattern ? Oh use [] here but no use ({}) here.
Want to do a if else ooops better download numpy. 
Want to filter ooops use loc and then iloc and write 10 lines of code.

It is unfortunate there is no getting rid of this unintuitive maddening, mess of a library, given that every interviewer out there expects it!!! There are much better libraries and it is time the pandas reign ends!!!!! (Python data table even creates pandas data frame faster than pandas!)

Thank you for coming to my Ted talk
I leave you with this datatable comparison article while I sob about learning pandas 

"
datascience,Dash Python Incosistence Performance,6,1i18xcv,https://www.reddit.com/r/datascience/comments/1i18xcv/dash_python_incosistence_performance/,1736869506.0,"I'm currently working on a project using Dash Python. It was light and breezy in the beginning. I changed a few codes while maintaining the error at 0, test-running it once in a while just to check if the code change affected the website, and nothing bad happened. But after I left it for a few hours without changing anything, the website wouldn't run anymore and showed me an ""Internal Server Error"". This happened way too many times, and it stresses me out, as I have to update most of the backend ASAP. Does anyone has any similar experience and manage to solve it? I'd like to know how."
datascience,Seeking Advice on Amazon Bedrock and Azure,7,1i13e03,https://www.reddit.com/r/datascience/comments/1i13e03/seeking_advice_on_amazon_bedrock_and_azure/,1736851459.0,"Hello everyone. I’m currently exploring AI infrastructure and platform for a new project and I’m trying to decide between Amazon Bedrock and Azure (AI Infrastructure & AI Studio). I’ve been considering both but would love to hear about your real-world experiences with them.

Has anyone used Amazon Bedrock or Azure AI Infrastructure and Azure AI Studio? How would you compare the two in terms of ease of use, performance, and overall flexibility? Are there specific features from either platform that stood out to you, or particular use cases where one was clearly better than the other?

Any advice or insights would be greatly appreciated. Thanks in advance! "
datascience,Mastering The Poisson Distribution: Intuition and Foundations,149,1i0dbaj,https://medium.com/@alejandroalvarezprez/mastering-the-poisson-distribution-intuition-and-foundations-d96bae3de61d,1736772966.0,
datascience,Where do you go to stay up to date on data analytics/science?,307,1i03pk7,https://www.reddit.com/r/datascience/comments/1i03pk7/where_do_you_go_to_stay_up_to_date_on_data/,1736735034.0,"Are there any people or organizations you follow on Youtube, Twitter, Medium, LinkedIn, or some other website/blog/podcast that you always tend to keep going back to? 

My previous career absolutely lacked all the professional ""content creators"" that data analytics have, so I was wondering what content you guys tend to consume, if any. Previously I'd go to two sources: one to stay up to date on semi-relevant news, and the other was a source that'd do high level summaries of interesting research papers. 

Really, the kind of stuff would be talking about new tools/products that might be of use, tips and tricks, some re-learning of knowledge you might have learned 10+ years ago, deep dives of random but pertinent topics, or someone that consistently puts out unique visualizations and how to recreate them. You can probably see what I'm getting at: sources for stellar information."
datascience,exit cmd.exe from R (or python) without admin privilege,0,1i1951j,https://www.reddit.com/r/datascience/comments/1i1951j/exit_cmdexe_from_r_or_python_without_admin/,1736870071.0,"I run:

system(""TASKKILL /F /IM cmd.exe"")

I get

Erreur�: le processus ""cmd.exe"" de PID 10333 n'a pas pu être arrêté.

Raison�: Accès denied.

Erreur�: le processus ""cmd.exe"" de PID 11444 n'a pas pu être arrêté.

Raison�: Accès denied.


I execute a batch file> a cmd open>a shiny open (I do my calculations)> a button on shiny should allow the cmd closing (and the shiny of course)

I can close the cmd from command line but I get access denied when I try to execute it from R. Is there hope? I am on the pc company so I don't have admin privilege"
datascience,Humana Senior DS Position merry-go-round,25,1i0c3x8,https://www.reddit.com/r/datascience/comments/1i0c3x8/humana_senior_ds_position_merrygoround/,1736768520.0,Anyone in the US apply to the Humana revolving Senior DS position over the last 5 months? They continuously post this position and never seem to fill it. Wondering if anyone has gotten an actual interview. I make it to the prescreen rounds  every single time I apply and then it just gets reposted.  
datascience,Advice on stabilizing an autoencoder's representation?,2,1i0m1ts,/r/learnmachinelearning/comments/1haqmu6/advice_on_stabilizing_an_autoencoders/,1736795972.0,
datascience,Mistral released Codestral 25.01 : Free to use with VS Code and Jet brains,0,1i0wxxt,/r/OpenAI/comments/1i0wwxm/mistral_released_codestral_2501_ranks_1_on_lmsys/,1736825403.0,
datascience,"How we matured Fisher, our A/B testing library",64,1hzpcuv,https://medium.com/@alejandroalvarezprez/how-we-matured-fisher-our-a-b-testing-package-6f2294746a56,1736696534.0,
datascience,Sky-T1-32B: Open-sourced reasoning model outperforms OpenAI-o1 on coding and maths benchmarks ,0,1i0czn6,/r/ArtificialInteligence/comments/1i0cyyw/skyt132b_opensourced_reasoning_model_outperforms/,1736771828.0,
datascience,Seeking Advice on GPU Comparison: GreenNode vs FPT,0,1i0bhi3,https://www.reddit.com/r/datascience/comments/1i0bhi3/seeking_advice_on_gpu_comparison_greennode_vs_fpt/,1736765919.0,"I’m currently exploring GPU options for my projects and I’m curious if anyone here has experience using GPUs from GreenNode or FPT. I’m looking for real feedback on how they compare in terms of performance, pricing, and overall experience.

Has anyone used GPUs from either of these providers? How do they stack up against each other in terms of power efficiency, speed, and reliability? Are there any specific use cases where one outperforms the other?

I’d love to hear your thoughts, personal experiences, or any suggestions you might have on which GPU might be better for intensive workloads. Thanks in advance!"
datascience,"200 applications - no response, please help. I have applied for data science (associate or mid-level) positions. Thank you ",423,1hyploh,https://www.reddit.com/gallery/1hyploh,1736575525.0,
datascience,Feeling stuck in my career. Please help,61,1hyte5x,https://www.reddit.com/r/datascience/comments/1hyte5x/feeling_stuck_in_my_career_please_help/,1736592284.0,"I'm in a weird position, where I feel like I'm stuck in my career. I really enjoy mathematics, ML/AI, implemented a lot of algorithms from scratch in C, developed new models for business purposes, presented at some internal/small conferences, and developed entire ML infrastructures for startups, but having no real opportunities to grow more.

At the moment I'm making over 100k$ working remotely from eastern Europe for a FAANG in the US (they have an office here, but my entire data science team is based in the US and I'm working on the same things as them).

When applying to companies in the US/UK I'm receiving zero callbacks (willing to relocate), although companies from the same areas are reaching out with remote offers of \~100k$/year. Those don't have the benefits of my current company, and are not attractive opportunities. I'm looking to relocate and get 200k$+. Current internal transfers to the US are closed, as they are looking to expand in east Europe. I've also asked for more difficult projects, but those are only available for US, not for my region.

The projects that are open to me at the moment offer zero satisfaction and I want to solve more complex problems and continue to expand my skills, but I'm stuck for the only thing that my studies are in eastern Europe and that I don't hold a PhD, even though I've already worked on novel models in industry, and speaking with friends and colleagues that hold a PhD, my skills are on par.

I'm at a point where I feel like skills and projects don't mean absolutely anything, and the only thing that has any weight for getting a job are diplomas and people you know... Maybe I'm exaggerating, but from all of my experiences I'm starting to feel like people from my region without studies abroad are seen only as cheap labor that should never be given the chance to work on real problems and be paid accordingly (a shitty company directly told me that, while another told me explicitly that my skills don't matter and they're only offering bad projects with bad pay in my region). It's like, there's a limit to the level of difficulty I can work on and the pay I can receive, regardless of how much I outcompete others...

At the moment, I'm working on a side research project that I'll be sending to some top tier conferences, and then try getting a PhD in the west... but that will take years, and if I already have the skills it's so frustrating to be stuck for so long just for a diploma and a title...

Or maybe my skills are really not on par, and I'm only good compared to the people in my region? Here's my resume if anyone would be willing to offer me some feedback."
datascience,SQL Squid Game: Imagine you were a Data Scientist for Squid Games (9 Levels),521,1hy7g0m,https://datalemur.com/sql-game,1736524298.0,
datascience,How to communicate with investors?,13,1hyaw2t,https://www.reddit.com/r/datascience/comments/1hyaw2t/how_to_communicate_with_investors/,1736532961.0,"I'm working at a small scale startup and my CEO is always in talks with investors apparently. I'm currently working in different architectures for video classification as well as using large multimodal models to classify video. They want to show how no other model works on our own data (obviously) and how recent architectures are not as good as our own super secret model (videoMAE finetunned on our data...). I'm okay with faking results/showing results that cannot be compared fairly. I mean I'm not but if that's what they want to do then fine, doesn't really involve more work for me.

Now what pisses me off is that now I need to come up with a way to get an accuracy per class in a multilabel classification setting based solely on precision and recall per class because different models were evaluated by different people at different times and I really only have those 2 metrics per class - precision and recall. I don't even know if this is possible, it feels like it isn't, and is an overall dumb metric for our use case. All because investors only know the word ""accuracy""....

Would it not be enough to say: ""This is the F1 score for our most important classes, and as you can see, none of the other models or architectures we've tried are as good as our best model... By the way, if you don't know what F1 means, just know that higher scores are better. If you want, I can explain it in more detail..."" as opposed to getting metrics that do not make any sense...?

I will not present it to the investors, I only need to come up with a document, but wouldn't it be enough for the higher ups in my company to say what I said above in this scenario? "
datascience,Simple Full stack Agentic AI project to please your Business stakeholders,0,1hyxec6,https://www.reddit.com/r/datascience/comments/1hyxec6/simple_full_stack_agentic_ai_project_to_please/,1736606856.0,"Since you all refused to share how you are applying gen ai in the real world, I figured I would just share mine.

  
So here it is:  [https://adhoc-insights.takuonline.com/](https://adhoc-insights.takuonline.com/)  
There is a rate limiter, but we will see how it goes.



Tech Stack:

Frontend: Next.js, Tailwind, shadcn

Backend: Django (DRF), langgraph

LLM: Claude 3.5 Sonnet

I am still unsure if l should sell it as a tool for data analysts that makes them more productive or for quick and easy data analysis for business stakeholders to self-serve on low-impact metrics.

So what do you all think?"
datascience,Companies are finally hiring,1561,1hxalxo,https://www.reddit.com/r/datascience/comments/1hxalxo/companies_are_finally_hiring/,1736421422.0,"I applied to 80+ jobs before the new year and got rejected or didn’t hear back from most of them. A few positions were a level or two lower than my currently level. I got only 1 interview and I did accept the offer. 

In the last week, 4 companies reached out for interviews. Just want to put this out there for those who are still looking. Keep going at it. 

Edit - thank you all for the congratulations and I’m sorry I can’t respond to DMs. Here are answers to some common questions. 

1. The technical coding challenge was only SQL. Frankly in my 8 years of analytics, none of my peers use Python regularly unless their role is to automate or data engineering. You’re better off mastering SQL by using leetcode and DataLemur

2. Interviews at all the FAANGs are similar. Call with HR rep, first round is with 1 person and might be technical. Then a final round with a bunch of individual interviews on the same day. Most of the questions will be STAR format. 

3. As for my skillsets, I advertise myself as someone who can build strategy, project manage, and can do deep dive analyses. I’m never going to compete against the recent grads and experts in ML/LLM/AI on technical skills, that’s just an endless grind to stay at the top. I would strongly recommend others to sharpen their soft skills. A video I watched recently is from The Diary of a CEO with Body Language Expert with Vanessa Edwards. I legit used a few tips during my interviews and I thought that helped "
datascience,How good are your linear algebra skills?,80,1hxt0wl,https://www.reddit.com/r/datascience/comments/1hxt0wl/how_good_are_your_linear_algebra_skills/,1736472663.0,"Started my masters in computer science in August. Bachelors was in chemistry so I took up to diff eq but never a full linear algebra class. I’m still familiar with a lot of the concepts as they are used in higher level science classes, but in my machine learning class I’m kind of having to teach myself a decent bit as I go. Maybe it’s me over analyzing and wanting to know the deep concepts behind everything I learn, and I’m sure in the real world these pure mathematical ideas are rarely talked about, but I know having a strong understanding of core concepts of a field help you succeed in that field more naturally as it begins becoming second nature.

Should I lighten my course load to take a linear algebra class or do you think my basic understanding (although not knowing how basic that is) will likely be good enough?"
datascience,SAS - SQL question: inobs= vs outobs=,5,1hy8jhq,https://www.reddit.com/r/datascience/comments/1hy8jhq/sas_sql_question_inobs_vs_outobs/,1736527127.0,"Just a quick question here regarding PROC SQL in SAS.  Let's say I'm just writing some code and I want to test it.  Since the database I'm querying has over a million records, I don't want it to process my code for all the records.  

My understanding is that I would want to use the inobs= option to limit how much of the table is queried and processed on the server.  Is this correct?

The outobs= option will return however many records I set, but it process every record on the table in the server.  Is this correct?"
machinelearning,[D] Self-Promotion Thread,2,1i4oujz,https://www.reddit.com/r/MachineLearning/comments/1i4oujz/d_selfpromotion_thread/,1737256529.0,"Please post your personal projects, startups, product placements, collaboration needs, blogs etc.

Please mention the payment and pricing requirements for products and services.

Please do not post link shorteners, link aggregator websites , or auto-subscribe links.

--

Any abuse of trust will lead to bans.

Encourage others who create new posts for questions to post here instead!

Thread will stay alive until next one so keep posting after the date in the title.

--

Meta: This is an experiment. If the community doesnt like this, we will cancel it. This is to encourage those in the community to promote their work by not spamming the main threads."
machinelearning,[D] Monthly Who's Hiring and Who wants to be Hired?,37,1hq5o1z,https://www.reddit.com/r/MachineLearning/comments/1hq5o1z/d_monthly_whos_hiring_and_who_wants_to_be_hired/,1735615814.0,"**For Job Postings** please use this template

>Hiring: \[Location\], Salary:\[\], \[Remote | Relocation\], \[Full Time | Contract | Part Time\]    and \[Brief overview, what you're looking for\]

**For Those looking for jobs** please use this template

>Want to be Hired: \[Location\], Salary Expectation:\[\], \[Remote | Relocation\], \[Full Time | Contract | Part Time\]  Resume: \[Link to resume\] and \[Brief overview, what you're looking for\]

&#x200B;

Please remember that this community is geared towards those with experience."
machinelearning,[D] I invented GANs,47,1i56crv,https://i.redd.it/j01k4ets20ee1.jpeg,1737314106.0,No you didn’t…
machinelearning,[P] Noteworthy LLM Research Papers of 2024 (Part Two): July to December,14,1i51cks,https://magazine.sebastianraschka.com/p/ai-research-papers-2024-part-2,1737301590.0,
machinelearning,[P] Speech recognition using MLP ,9,1i4rz3r,https://www.reddit.com/r/MachineLearning/comments/1i4rz3r/p_speech_recognition_using_mlp/,1737266802.0,"So we have this assignment where we have to classify the words spoken in the audio file. We are restricted to using spectrograms as input, and only simple MLPs no cnn nothing. The input features are around 16k, and  width is restricted to 512, depth 100, any activation function of our choice. We have tried a lot of architectures, with 2 or 3 layers, with and without dropout, and with and without batch normal but best val accuracy we could find is 47% with 2 layers of 512 and 256, no dropout, no batch normal and SELU activation fucntion. We need 80+ for it to hold any value. Can someone please suggest a good architecture which doesn't over fit?"
machinelearning,[D] Suggestions for topics for a PhD level ML focused programming course?,19,1i4ltt6,https://www.reddit.com/r/MachineLearning/comments/1i4ltt6/d_suggestions_for_topics_for_a_phd_level_ml/,1737247026.0,"Some background: I work as a data scientist/ML engineer for a small startup. I also adjunct for the department from which I got my PhD(in statistics).

For the last few years, I’ve been teaching a series of statistical programming courses for masters students, and early PhD‘s. This semester, my class unfortunately got canceled due to low enrollment, which I was told is due to poor recruitment last fall and poor advertising.  We are thinking to offer that course every other year. I would like to propose a third course in the series with more advanced topics.

First course: programming fundamentals for both R and Python. Some basic analytical stuff for each.

Second course: Python based analysis course (many R courses exist already) which touches on statistical routines from basics to mixed modeling and Bayesian analysis.  Also we go through the classic models with PyTorch as well as a few transformer based applications.  Also work in some explainable AI techniques 

Third course: optimization, variational inference, other Bayesian deep learning approaches, MLops concepts, ????

The thing is I need to work in a fair amount of stochastic approaches because it’s a statistics department after all. 

Hope that’s clear. I would like to provide relevant information especially to PhD students who would like to live at the cutting edge with an emphasis on experimentation and implementation.  I know there is a lot out there but at work I need to focus on my specific tasks.

Thanks so much for any advice!"
machinelearning,[D] I hate softmax ,221,1i44h5v,https://www.reddit.com/r/MachineLearning/comments/1i44h5v/d_i_hate_softmax/,1737194715.0,"This is a half joke, and the core concepts are quite easy, but I'm sure the community will cite lots of evidence to both support and dismiss the claim that softmax sucks, and actually make it into a serious and interesting discussion.

What is softmax? It's the operation of applying an element-wise exponential function, and normalizing by the sum of activations.
What does it do intuitively? One point is that outputs sum to 1. Another is that the the relatively larger outputs become *more* relatively larger wrt the smaller ones: big and small activations are teared apart.

One problem is you never get zero outputs if inputs are finite (e.g. without masking you can't attribute 0 attention to some elements).
The one that makes me go crazy is that for most of applications, magnitudes and ratios of magnitudes are meaningful, but in softmax they are not: softmax cares for differences.
Take softmax([0.1, 0.9]) and softmax([1,9]), or softmax([1000.1,1000.9]). Which do you think are equal? In what applications that is the more natural way to go?

Numerical instabilities, strange gradients, embedding norms are all things affected by such simple cores. Of course in the meantime softmax is one of the workhorses of deep learning, it does quite a job.

Is someone else such a hater? Is someone keen to redeem softmax in my eyes?"
machinelearning,[D] Refactoring notebooks for prod,22,1i4ho23,https://www.reddit.com/r/MachineLearning/comments/1i4ho23/d_refactoring_notebooks_for_prod/,1737235091.0,"I do a lot of experimentation in Jupyter notebooks, and for most projects, I end up with multiple notebooks: one for EDA, one for data transformations, and several for different experiments. This workflow works great until it’s time to take the model to production.

At that point I have to take all the code from my notebooks and refactor for production. This can take weeks sometimes. It feels like I'm duplicating effort and losing momentum.

Is there something I'm missing that I could be using to make my life easier? Or is this a problem y'all have too?

\*Not a huge fan of nbdev because it presupposes a particular structure"
machinelearning,[D] Which ML Certification is the Best and Most Valuable for the Job Market?,0,1i56e4g,https://www.reddit.com/r/MachineLearning/comments/1i56e4g/d_which_ml_certification_is_the_best_and_most/,1737314199.0,"

  **1. Google Professional Machine Learning Engineer**

* Focuses on designing, building, and productionizing machine learning models.
* Covers topics like deploying ML models and using Google Cloud tools effectively.
* **2. AWS Certified Machine Learning – Specialty**
   * Demonstrates expertise in building, training, tuning, and deploying ML models.
   * Includes AWS-specific tools like SageMaker and AI services.

1. **3. Microsoft Certified: Azure AI Engineer Associate**
   * Focuses on designing and implementing AI and machine learning solutions.
   * Uses Azure Machine Learning and other Azure AI tools.

I’d like to know which of these certifications is the most valuable in the job market right now. Which one do employers value the most, and which one would help me land a better job or boost my career?

I’m also curious about your experiences if you’ve taken any of these certifications. How challenging are they, and how much do they align with real-world ML projects?

Thanks in advance for your advice!"
machinelearning,[R] VortexNet: Neural Computing through Fluid Dynamics ,19,1i4fvqn,https://samim.io/p/2025-01-18-vortextnet/,1737230204.0,
machinelearning,[R] Tensor and Fully Sharded Data Parallelism,5,1i4n01i,https://www.reddit.com/r/MachineLearning/comments/1i4n01i/r_tensor_and_fully_sharded_data_parallelism/,1737250575.0,"In this series, we continue exploring distributed training algorithms, focusing on tensor parallelism (TP), which distributes layer computations across multiple GPUs, and fully sharded data parallelism (FSDP), which shards model parameters, gradients, and optimizer states to optimize memory usage. Today, these strategies are integral to massive model training, and we will examine the properties they exhibit when scaling to models with 1 trillion parameters.

[https://martynassubonis.substack.com/p/tensor-and-fully-sharded-data-parallelism](https://martynassubonis.substack.com/p/tensor-and-fully-sharded-data-parallelism)"
machinelearning,[R] Causal Inference Meets Deep Learning: A Comprehensive Survey,22,1i455gs,https://spj.science.org/doi/10.34133/research.0467,1737197680.0,
machinelearning,[P] Building an Reinforcement Learning Agent to play The Legend of Zelda,149,1i3t4c3,https://www.reddit.com/r/MachineLearning/comments/1i3t4c3/p_building_an_reinforcement_learning_agent_to/,1737154326.0,"A year go I started trying to use PPO to play the original Legend of Zelda, and I was able to train a model to beat the first boss after a few months of work. I wanted to share the project just for show and tell. I'd love to hear feedback and suggestions as this is just a hobby project. I don't do this for a living. The code for that lives in the [original-design branch](https://github.com/DarkAutumn/triforce/tree/original-design) of my [Triforce repo](https://github.com/DarkAutumn/triforce). I'm currently tinkering with new designs so the main branch is much less stable.

Here's a video of the agent [beating the first dungeon](https://www.youtube.com/watch?v=yERh3IJ54dU), which was trained with 5,000,000+ steps. At 38 seconds, you can see it learned that it's invulnerable at the screen edge, and it exploits that to avoid damage from a projectile. At 53 seconds it steps up to avoid damage from an unblockable projectile, even though it takes a -0.06 penalty for moving the wrong way (taking damage would be a larger penalty.) At 55 seconds it walks towards the rock projectile to block it. And so on, lots of little things the model does is easy to miss if you don't know the game inside and out.

As a TLDR, [here's an early version of my new (single) model](https://youtu.be/3AJXfBnmgVk). This doesn't make it quite as far, but if you watch closely it's combat is already *far* better, and is only trained on 320,000 steps (~6% of the steps the first model was trained on).

This is pretty far along from my [very first model](https://www.youtube.com/watch?v=KXPMwehTOf0).

# Original Design

I got the original project working using stable-baselines's PPO and default neural network (Shared NatureCNN, I believe). SB was great to get started but ultimately stifling. In the new version of the project I've implemented PPO from scratch with torch with my own simple neural network similar to stable-baseline's default. I'm playing with all kinds of changes and designs now that I have more flexibility and control. Here is my rough original design:

## Overall Strategy

My first pass through this project was basically ""imagine playing Zelda with your older sibling telling you where to go and what to do"". I give the model an objective vector which points to where I want it to go on the screen (as a bird flies, the agent still had to learn path finding to avoid damage and navigate around the map). This includes either point at the nearest enemy I want it to kill or a NSEW vector if it's supposed to move to the next room.

Due a few limitations with stable-baselines (especially around action masking), I ended up training unique models for traversing the overworld vs the dungeon (since they have entirely different tilesets). I also trained a different model for when we have sword beams vs not. In the video above you can see what model is being used onscreen.

In my current project I've removed this objective vector as it felt too much like cheating. Instead I give it a one-hot encoded objective (move north to the next room, pickup items, kill enemies, etc). So far it's working quite well without that crutch. The new project also does a much better job of combat even without multiple models to handle beams vs not.

## Observation/Action Space

**Image** - The standard neural network had a really tough time being fed the entire screen. No amount of training seemed to help. I solved this by creating a [viewport around Link](https://github.com/DarkAutumn/triforce/blob/dea241219ff17b386e368bc25adfbc171207888a/notebooks/torch_viewport.ipynb) that keeps him centered. This REALLY helped the model learn.

I also had absolutely zero success with stacking frames to give Link a way to see enemy/projectile movement. The model simply never trained with stable-baselines when I implemented frame stacking and I never figured out why. I just added it to my current neural network and it seems to be working...

Though my early experiments show that giving it 3 frames (skipping two in between, so frames curr, curr-3, curr-6) doesn't *really* give us that much better performance. It might if I took away some of the vectors. We'll see.

**Vectors** - Since the model cannot see beyond its little viewport, I gave the model a vector to the closest item, enemy, and projectile onscreen. This made it so the model can shoot enemies across the room outside of its viewport. My new model gives it multiple enemies/items/projectiles and I plan to try to use an attention mechanism as part of the network to see if I can just feed it all of that data.

**Information** - It also gets a couple of one-off datapoints like whether it currently has sword beams. The new model also gives it a ""source"" room (to help better understand dungeons where we have to backtrack), and a one-hot encoded objective.

**Action Space**

My original project just has a few actions, 4 for moving in the cardinal directions and 4 for attacking in each direction (I also added bombs but never spent any time training it). I had an idea to use masking to help speed up training. I.E. if link bumps into a wall, don't let him move in that direction again until he moves elsewhere, as the model would often spend an entire memory buffer running headlong straight into a wall before an update...better to do it once and get a huge negative penalty which is essentially the same result but faster.

Unfortunately SB made it really annoying architecturally to pass that info down to the policy layer. I could have hacked it together, but eventually I just reimplemented PPO and my own neural network so I could properly mask actions in the new version. For example, when we start training a fresh model, it cannot attack when there aren't enemies on screen and I can disallow it from leaving certain areas.

The new model actually understands splitting swinging the sword short range vs firing sword beams as two different actions, though I haven't yet had a chance to fully train with the split yet.

**Frameskip/Cooldowns** - In the game I don't use a fixed frame skip for actions. Instead I use the internal ram state of game to know when Link is animation locked or not and only allow the agent to take actions when it's actually possible to give meaningful input to the game. This greatly sped up training. We also force movement to be between tiles on the game map. This means that when the agent decides to move it loses control for longer than a player would...a player can make more split second decisions. This made it easier to implement movement rewards though and might be something to clean up in the future.

## Other interesting details

**Pathfinding** - To facilitate rewards, the original version of this project used A* to pathfind from link to what he should be doing. [Here's a video of it in action](https://www.youtube.com/watch?v=HFsHpex4OvM). This information wasn't giving to the model directly but instead the agent would only be given the rewards if it exactly followed that path or the transposed version of it. It would also pathfind around enemies and not walk through them.

This was a nightmare though. The [corner cases were significant](https://github.com/DarkAutumn/triforce/blob/original-design/triforce/critics.py#L343-L502), and pushing Link towards enemies but not *into* them was really tricky. The new verison just uses a wavefront algorithm. I calculate a [wave from the tiles we want to get to outwards](https://github.com/DarkAutumn/triforce/blob/main/triforce/wavefront.py), then make sure [we are following the gradient](https://github.com/DarkAutumn/triforce/blob/dea241219ff17b386e368bc25adfbc171207888a/triforce/critics.py#L281-L329). Also calculating the A* around enemies every frame (even with caching) was super slow. Wavefront was faster, especially because I give the new model no special rewards for walking around enemies...faster to compute and it has to learn from taking damage or not.

Either way, the both the old and new models successfully learned how to pathfind around danger and obstacles, with or without the cheaty objective vector.

**Rewards** - I programmed very dense rewards in both the [old](https://github.com/DarkAutumn/triforce/blob/original-design/triforce/critics.py) and [new](https://github.com/DarkAutumn/triforce/blob/dea241219ff17b386e368bc25adfbc171207888a/triforce/critics.py) model. At basically every step, the model is getting rewarded or punished for something. I actually have some ideas I can't wait to try out to make the rewards more sparse. Or maybe we start with dense rewards for the first training, then fine-tune the model with sparser rewards. We'll see.

**Predicting the Future** - Speaking of rewards. One interesting wrinkle is that the agent can do a lot of things that will eventually deal damage but not on that frame. For example, when Link sets a bomb it takes several seconds before it explodes, killing things. This can be a massive reward or penalty since he spent an extremely valuable resource, but may have done massive damage. PPO and other RL propagates rewards backwards, of course, but that spike in reward could land on a weird frame where we took damage or moved in the wrong direction.

I probably could have just *not* solved that problem and let it shake out over time, but instead I used the fact that we are in an emulator to just see what the outcome of every decision is. When planting a bomb, shooting sword beams, etc, we [let the game run forward](https://github.com/DarkAutumn/triforce/blob/dea241219ff17b386e368bc25adfbc171207888a/triforce/state_change_wrapper.py#L140-L192) until impact, then rewind time and reward the agent appropriately, continuing on from when we first paused. This greatly speeds up training, even if it's expensive to do this savestate, play forward, restore state.

**Neural Networks** - When I first started this project (knowing very little about ML and RL), I thought most of my time would be tuning the shape of the neural network that we are using. In reality, the default provided by stable-baselines [and my eventual reimplemnentation](https://github.com/DarkAutumn/triforce/blob/dea241219ff17b386e368bc25adfbc171207888a/triforce/models.py#L19-L255) has been enough to make *massive* progress. Now that I have a solid codebase though, I really want to revisit this.  I'd like to see if trying CoordConvs and similar networks might make the viewport unncessary.

## Less interesting details/thoughts

**Hyperparameters** - Setting the entropy coefficinet way lower helped a TON in training stable models.  My new PPO implementation is way less stable than stable-baselines (ha, imagine that), but still converges most of the time.

**Infinite Rewards** - As with all reinforcement learning, if you give some way for the model to get infinite rewards, it will do just that and nothing else. I spent days, or maybe weeks tweaking reward functions to just get it to train and not find a spot on the wall it could hump for infinite rewards.  Even just neutral rewards, like +0.5 moving forward and -0.5 for moving backwards, would often result in a model that just stepped left, then right infinitely.  There has to be a real reward or punishment (non-neutral) for forward progress.

**Debugging Rewards** - In fact, building a rewards debugger was the only way I made progress in this project.  If you are tackling something this big, do that very early.

**Stable-Retro is pretty great** - Couldn't be happier with the clean design for implementing emulation for AI.

**Torch is Awesome** - My early versions heavily used numpy and relied on stable-baselines, with its multiproc parallelization support. It worked great. Moving the project over to torch was night and day though. It gave me so much more flexibility, instant multithreading for matrix operations. I have a pretty beefy computer and I'm *almost* at the same steps per second as 20 proc stable-retro/numpy.

## Future Ideas

This has already gone on too long. I have some ideas for future projects, but maybe I'll just make them another post when I actually do them.

## Special Thanks

A special thanks to [Brad Flaugher](https://bradflaugher.com/) for help with the early version of this, Fiskbit from the Zelda1 speedrunning community for help pulling apart the raw assembly to build this thing, and MatPoliquin for maintaining Stable-Retro.

Happy to answer any questions, really I just love nerding out about this stuff."
machinelearning,[D] Am I actually a machine learning engineer?,110,1i3qxy4,https://www.reddit.com/r/MachineLearning/comments/1i3qxy4/d_am_i_actually_a_machine_learning_engineer/,1737148506.0,"For the past few years I've had a job with the official title ""machine learning engineer"", but as I hunt for other jobs online, I wonder if that's actually accurate. Based on the experience requirements and responsibilities listed, it doesn't seem to match up with what I do.

I have a master's with a focus in ML (though that was pre LLM-boom, so things have changed a lot) but struggled to find work in my area pertaining to that out of college. Post-COVID when everyone went remote I got my current job. In it, I work on a team building and deploying software that utilize machine learning to accomplish tasks. However, I'm never the one actually building the learning models (there's a researcher on our team who does that); just creating the systems around them. I'm actually pretty happy in my ""machine learning adjacent"" role, but should I be searching for different job titles to find something similar?"
machinelearning,[R] Any paper recommendations for Bayesian methods in ML and causal inference?,27,1i3ym76,https://www.reddit.com/r/MachineLearning/comments/1i3ym76/r_any_paper_recommendations_for_bayesian_methods/,1737170980.0,"Hey guys,

So I am very new to Bayesian methods and am curious about it from a data science and modelling point of view and how it could determine causal relationships.

I don't really know where to start, but I've read some papers on Bayesian Networks and have heard interesting things about Bayesian Deep Learning so would be happy to see any recommendations on those topics.

I would also be happy to hear about any papers you may have recently read, but am looking for anything you guys have found interesting and not an application on any specific domain, just interested in learning the theory for now (unless you suggest that I pick a domain first).

Many thanks"
machinelearning,[R] Liquid Neural Networks exhibit robust navigation in OOD environments.,7,1i458ut,https://cap.csail.mit.edu/sites/default/files/research-pdfs/Robust%20flight%20navigation%20out%20of%20distribution%20with%20liquid%20neural%20networks.pdf,1737198072.0,
machinelearning,[P] Launch a Federation of robots that collaboratively train an object manipulation model,5,1i44wlr,https://www.reddit.com/r/MachineLearning/comments/1i44wlr/p_launch_a_federation_of_robots_that/,1737196643.0,"Using [Flower](https://flower.ai/)  and [LeRobot](https://github.com/huggingface/lerobot), I put together a  [quickstart example](https://github.com/adap/flower/tree/main/examples/quickstart-lerobot) that demonstrates how to train a diffusion model collaboratively across 10 individual nodes (each with its own dataset partition!). This example uses the`push-t` dataset, where the task is to move a letter T object on top of another that is to remain static.

The example it's pretty easy to run, and can do so efficiently if you have access to a recent gaming GPU. Although the diffusion model only takes 2GB of VRAM (of course you can decide to scale it up), the compute needed to train them isn't negligible. For context, running the example until convergence takes 40mins on a dual RTX 3090 setup. It takes about 30rounds of federated learning (FL) to do so although the example runs for 50 rounds by default.

[Evaluation of the global model at different rounds. After just a few rounds of collaboratively AI training the model successfully completes the task \(and it does so pretty fast!!!\)](https://i.redd.it/lp13jn70dqde1.gif)

  
The example runs each node/robot in simulation by default (i.e. each node is a Python process and there is some clever scheduling to run the jobs in a resource-aware manner). But it is straight forward to run it as a real deployment where each node is, for example, a different device (e.g. NVIDIA Jetson). If someone is interested in doing this, checkout the links added at the bottom of the example readme

  
Learn more about the Action Diffusion policy method -> [https://arxiv.org/abs/2303.04137](https://arxiv.org/abs/2303.04137)

"
machinelearning,[D] Dynamic Neuron-Controller-Based Transformer Architecture: Feedback Wanted,13,1i40viz,https://www.reddit.com/r/MachineLearning/comments/1i40viz/d_dynamic_neuroncontrollerbased_transformer/,1737179120.0,"**Dynamic Neuron-Controller-Based Transformer Architecture by Shanmukh Ram**

# Abstract

This white paper presents an innovative architecture that integrates dynamic neuron-controller systems with transformer models to create a continuously adaptive and resource-efficient AI framework. The proposed architecture utilizes neuron or batch controllers to dynamically adjust the weights and operations of a shared transformer architecture in real time.

By responding to signals generated by individual or grouped neurons, the system continuously adapts to changing demands. This adaptability enables efficient multi-tasking and optimizes resource sharing, ensuring high performance across diverse contexts. These features establish the architecture as a groundbreaking innovation in AI, unlocking advancements in applications such as general intelligence, personalized systems, and multi-agent collaboration.

# 1. Introduction

# 1.1 Background

Transformer architectures have revolutionized natural language processing and other domains, owing to their scalability, attention mechanisms, and ability to model long-range dependencies. However, transformers remain largely static post-training, with fine-tuning or retraining required to adapt to new tasks or shifting environments.

# 1.2 Motivation

Real-world applications often involve dynamic and unpredictable environments. Traditional transformer models, though powerful, are inefficient in adapting to real-time changes without significant retraining. This gap motivates the design of a system where neurons act as adaptive controllers, dynamically modifying the transformer’s behavior to optimize performance across varying tasks and inputs.

# 2. Proposed Architecture

# 2.1 Core Components

The architecture consists of the following core components:

1. **Neuron-Controllers**:
   * Independent neurons or batches of neurons act as dynamic agents within the system, controlling and optimizing the transformer’s performance. These controllers receive input signals from various sources, including real-time environmental data, user feedback, or task-specific objectives. Upon processing these inputs, the controllers generate precise control signals to dynamically modify transformer parameters such as attention weights, layer activations, or embeddings. For instance, in a natural language processing task, the controllers might adjust attention weights to focus on critical phrases in a document, ensuring more accurate summarization. Similarly, in image recognition tasks, layer activations could be optimized to emphasize edges or textures, improving classification accuracy.
   * These targeted adjustments significantly enhance the system’s ability to adapt to diverse tasks while maintaining high performance and efficiency. This dynamic adjustment ensures the system remains highly adaptive, continuously optimizing its responses to suit specific tasks or contexts.
2. **Shared Transformer Framework**:
   * A modular transformer architecture forms the backbone of the system, meticulously crafted to support real-time adjustments to its operational parameters. This modularity allows each core component, such as attention heads, transformer layers, or embeddings to be dynamically reconfigured based on control signals generated by neuron-controller batches. By enabling real-time adaptability, the system ensures that computational resources can be scaled efficiently or concentrated on specific areas of importance, depending on the complexity and requirements of the task. For instance, attention heads may be activated selectively for high-priority inputs, while layers or embeddings can be modified dynamically to fine-tune task-specific outputs. This approach not only enhances scalability but also optimizes performance, making the architecture capable of handling both simple and complex tasks with remarkable efficiency.
3. **Feedback Loop**:
   * The architecture integrates a continuous feedback mechanism wherein the transformer's outputs are systematically analyzed and fed back to the neuron-controllers. This iterative process allows the neuron-controllers to refine their strategies based on real-time performance metrics and contextual outcomes. By dynamically adjusting control parameters, the system ensures alignment with evolving task objectives and operational efficiency. This feedback loop not only enhances adaptability but also fosters a robust learning environment where both controllers and the transformer progressively improve in tandem.
   * This loop refines the controllers’ strategies in real time, ensuring constant performance improvement and alignment with task objectives.
   * By iteratively optimizing both the controllers and the transformer, the system achieves a closed-loop learning environment.
4. **Coordinator Mechanism**:
   * A centralized or decentralized coordinator mechanism is designed to ensure seamless interactions among multiple neuron-controller batches. This mechanism prioritizes resource allocation and balances task assignments, mitigating potential conflicts that may arise when neuron batches manage separate transformers or collaborate on shared tasks. By enabling effective coordination, the architecture prevents inefficiencies and ensures that all tasks are executed optimally, maintaining synergy across the entire system.

# 2.2 Key Features

1. **Dynamic Weight Adjustment**:

Dynamic weight adjustment represents the core capability of the system where controllers fine-tune specific transformer weights in real time. These adjustments are informed by contextual signals, which include environmental data, user feedback, and task-specific objectives. For example, in autonomous driving, the controllers can adjust attention weights to prioritize critical inputs like pedestrian detection over less immediate data, such as road signage in clear weather. In healthcare applications, layer activations might be fine-tuned dynamically to focus on anomalies in medical imaging, ensuring accurate diagnostics. When an input signal is received, the neuron-controllers analyze it and generate precise commands to recalibrate the transformer's internal parameters, such as attention weights or activation thresholds. This process ensures that the architecture adapts seamlessly to the demands of diverse tasks and dynamic environments. The ability to perform these real-time optimizations not only enhances task-specific performance but also maximizes resource efficiency, as only the necessary components of the transformer are engaged at any given time. This dynamic adaptability is crucial for handling complex, real-world scenarios where static models would fail to perform optimally, thereby positioning this system as a significant advancement in AI adaptability and responsiveness.

1. **Batch-Based Control**:
   * Groups of neurons manage different tasks or modules, each acting as specialized agents to oversee specific functionalities within the system. This allows simultaneous optimization across multiple frameworks by dynamically distributing computational resources and responsibilities. For example, one group of neurons may control language modeling tasks while another focuses on vision-based analysis, enabling these processes to run concurrently without interfering with each other. This approach enhances efficiency and ensures that the transformer system remains scalable and adaptable, bringing the value of multitasking without compromising performance.
2. **Task-Specific Adaptation**:
   * Each neuron batch can specialize in controlling a subset of the transformer for task-specific performance by dynamically focusing on the specific layers, attention mechanisms, or embeddings that are most relevant to the task. For example, in a multi-task learning setup, one neuron batch could fine-tune the transformer’s attention weights for language modeling, while another batch might adjust embedding layers for visual data processing. This specialization ensures that the system can effectively handle diverse tasks in parallel without sacrificing efficiency or performance. By leveraging this dynamic specialization, the architecture optimizes resource utilization, minimizes interference between tasks, and enhances the accuracy and responsiveness of each transformer subset to its assigned task.
3. **Multi-Agent Collaboration**:
   * Neuron batches play a pivotal role in enhancing the system's overall performance by engaging in collaborative or competitive dynamics tailored to complex, multi-dimensional tasks. For example, in a multi-modal AI system, one neuron batch could specialize in processing textual data, while another focuses on visual inputs. Collaboration between these batches ensures that insights from both modalities are integrated effectively, leading to more accurate and coherent outcomes, such as in video summarization or multimedia content analysis. Similarly, competition among neuron batches could prioritize critical tasks, ensuring time-sensitive objectives like anomaly detection in real-time surveillance are addressed promptly. These batches act as specialized agents, dynamically adjusting their behaviors to maximize task outcomes based on the broader system’s objectives. For instance, collaboration between neuron batches may involve sharing insights or control signals to optimize resource allocation across different sections of the transformer. In contrast, competitive dynamics could arise in scenarios where distinct neuron batches vie to prioritize their assigned tasks, ensuring critical objectives receive adequate focus.
   * By allowing both collaboration and competition, the architecture fosters a balance between efficiency and task-specific precision. This mechanism integrates seamlessly with the feedback and coordination systems, ensuring that neuron batches remain aligned with the overarching goals of the system while dynamically optimizing their strategies. The value of this approach lies in its ability to handle multi-tasking demands with enhanced adaptability and responsiveness, making it an essential component of the architecture's design.

# 3. Implementation

# 3.1 Input Signals

Neuron-controllers process a variety of inputs, such as:

* **Environmental Data**: Real-time data streams from external sensors or APIs.
* **Feedback Signals**: Outputs from transformers or user interaction data.
* **Predefined Objectives**: Task-specific goals encoded during training.

# 3.2 Dynamic Controllers

Neuron-controllers utilize advanced reinforcement learning (RL) techniques and optimization algorithms to determine the most effective adjustments for the transformer. These adjustments include recalibrating attention weights to focus on the most relevant features of the input, selectively activating or deactivating layers to optimize computational efficiency, and dynamically modifying positional encodings or embeddings to enhance the transformer's contextual understanding. By analyzing input signals and system feedback in real-time, neuron-controllers ensure that the architecture remains highly adaptive and aligned with task-specific objectives, enabling superior performance across diverse and complex tasks.

# 3.3 Transformer Modularity

The transformer is designed with modularity in mind:

* **Adapters**: Lightweight modules inserted into transformer layers to enable task-specific adjustments.
* **Sparse Activation**: Only parts of the transformer are activated based on control signals.
* **Mixture of Experts (MoE)**: Controllers determine which expert modules to activate for a given input.

# 3.4 Feedback Mechanism

A feedback loop evaluates the transformer’s output and updates the neuron-controllers’ strategies, creating a continuous learning environment.

# 4. Applications

# 4.1 Multi-Task Learning

Dynamic controllers empower a single transformer architecture to manage multiple tasks simultaneously by dynamically redistributing resources to optimize for each task's specific requirements. These controllers act as task-specialized agents, analyzing the contextual demands of each input and directing computational focus to the most relevant sections of the transformer such as attention heads, embeddings, or specific layers. For example, when handling a combination of natural language processing and vision-based tasks, the dynamic controllers can assign priority resources to textual embeddings for language inputs while activating vision-specific modules for image data.

This simultaneous multi-task optimization ensures that each task benefits from the transformer's shared architecture without compromising performance. The ability to dynamically allocate resources not only reduces computational redundancy but also enhances scalability, allowing the system to adapt seamlessly to complex, real-world scenarios. By maintaining task-specific precision while sharing computational infrastructure, this architecture represents a significant step forward in creating efficient and robust AI systems capable of managing diverse workloads.

# 4.2 Personalized Systems

Dynamic controllers allow the transformer to adapt its behavior to individual users or specific contexts, enabling highly tailored and responsive applications. By analyzing real-time user data, such as preferences, historical interactions, or contextual inputs, these controllers dynamically modify the transformer's parameters to deliver personalized outputs. For example, in a virtual assistant application, the controller might adjust the transformer's attention mechanisms to prioritize the user's current needs or focus on topics of interest based on prior interactions. This capability ensures that the system evolves alongside the user, providing a more engaging and effective experience. The ability to personalize outputs in real-time is critical for applications in education, healthcare, and customer service, where individualized solutions add significant value.

# 4.3 Collaborative AI

Neuron-controller batches enhance the system's ability to handle complex, multi-dimensional problems by fostering collaboration among multiple transformers. For instance, in a multi-modal AI system integrating text, images, and audio, one batch of neuron-controllers could process and extract key textual information, another batch could analyze visual data, and a third could handle audio signals. Collaboration ensures that insights from each modality are synthesized into a unified understanding, significantly improving outcomes such as multimedia content analysis or real-time event summarization.

This collaborative potential enables the system to leverage diverse data types effectively, ensuring comprehensive and accurate results. These controllers dynamically allocate resources and share insights between transformers, enabling them to work together seamlessly. For instance, in multi-modal AI applications that integrate text, images, and audio, one transformer might specialize in processing textual data while another focuses on visual analysis.

Through real-time communication and coordination, the system ensures that insights from each modality contribute to a cohesive and accurate result. This collaborative approach not only improves task performance but also enables the system to tackle problems that require integrated knowledge from multiple domains.

# 4.4 General Intelligence

The architecture's dynamic adaptability, real-time resource allocation, and collaborative mechanisms represent a significant step toward achieving general artificial intelligence. By allowing neuron-controller batches to manage diverse tasks and contexts dynamically, the system creates a foundation for cross-domain learning and decision-making. Unlike traditional AI systems that require retraining for new tasks, this architecture can rapidly adapt to novel scenarios, demonstrating a level of flexibility and generalization that closely mirrors human intelligence. The ability to integrate knowledge across tasks and respond effectively to unforeseen challenges positions this architecture as a cornerstone in the pursuit of general AI.

# 5. Societal Impacts

# 5.1 Positive Outcomes

* **Efficiency**: Reduced computational costs through dynamic resource sharing.
* **Adaptability**: Better handling of real-world variability and user-specific needs.
* **Innovation**: New AI applications and use cases become feasible.

# 5.2 Risks

* **Unpredictability**: Dynamic systems may produce unforeseen behaviors.
* **Security**: Systems must be robust against adversarial inputs or misuse.
* **Ethical Concerns**: Continuous learning raises questions about accountability and transparency.

# 6. Future Directions

The dynamic neuron-controller-based transformer architecture opens up several avenues for research and practical advancements. The focus must be on refining the foundational mechanisms to further enhance scalability, adaptability, and safety.

# 6.1 Enhancing Controller Intelligence

Research should prioritize the development of neuron-controllers capable of understanding higher-level abstractions, contextual nuances, and complex task hierarchies. By integrating advanced algorithms such as meta-learning and neural architecture search, these controllers can evolve into highly intelligent agents that adapt seamlessly to diverse and unforeseen challenges. This advancement will make the system more robust in managing a wider array of applications.

# 6.2 Scaling to Larger Architectures

Efforts must be directed toward designing and managing larger systems that integrate multiple controllers and transformers. However, scaling such architectures presents significant challenges, including increased computational overhead, potential bottlenecks in communication between controllers, and the risk of degraded performance in highly complex systems. Addressing these limitations is crucial to unlock the full potential of this approach and ensure seamless scalability in real-world applications. Techniques such as distributed computing, modular design, and sparse activations will be critical to maintain performance and efficiency at scale. This scaling capability will empower the architecture to handle increasingly complex tasks across industries, from healthcare diagnostics to autonomous systems.

# 6.3 Safety and Robustness

Ensuring the safety and reliability of dynamically adaptive systems is paramount. Specific strategies to achieve this include the integration of robust adversarial defense mechanisms to counter malicious inputs, the development of fail-safe protocols to handle unexpected failures, and the implementation of comprehensive ethical oversight frameworks. Additionally, employing techniques such as explainability in AI and real-time monitoring systems can ensure transparency and accountability, further reinforcing the trustworthiness of these architectures. This requires the implementation of fail-safes, ethical oversight mechanisms, and robust adversarial defenses.

By addressing these concerns, the architecture can operate confidently in critical applications, including finance, defense, and public safety. For example, in finance, the system could dynamically adapt to market changes by prioritizing critical data streams for fraud detection or risk assessment. In defense, collaborative neuron-controller batches could integrate intelligence from multiple data modalities such as satellite imagery, intercepted communications, and real-time ground reports to provide actionable insights for decision-makers. Similarly, in public safety, the architecture could manage resources dynamically during emergencies, such as optimizing response times for disaster management or ensuring accurate predictions for crowd control. Safety-focused research will also ensure that the system remains compliant with evolving regulations and ethical standards.

# 8. Conclusion

The proposed dynamic neuron-controller-based transformer architecture represents a paradigm shift in AI development. By enabling real-time adaptability, efficient resource sharing, and multi-tasking capabilities, this system has the potential to revolutionize AI applications across industries. While challenges remain, the opportunities for innovation and societal benefit are immense, making this a promising direction for future research and development."
machinelearning,[D] Few-shot Learning with prototypical networks - help to understand the concept ,5,1i45h9r,https://www.reddit.com/r/MachineLearning/comments/1i45h9r/d_fewshot_learning_with_prototypical_networks/,1737199033.0,"Hi, probably quite simple questions for those who know the concept but still tricky for me to realize.

Let's say I have a dataset with 200 labeled samples and I have 10 classes. However, not all 200 examples contain all 10 classes, but only some of them while the rest samples contain a combination of them. Meaning that a sample might be labeled for classes 0, 1, 5, 8, while another for 0, 3, 7, and so on. Which also means that the prevalence of the classes varies a lot.

How do I split my dataset for few-shot learning with prototypical networks? Do I need to train and validate on samples that include all classes, so the network learns to compute prototypes for every class? Also, given that the prevalence of the classes varies, do I need to balance the sampling so it sees each class equally on the number of training and validation episodes?

During testing do I need to include on my test set a few labeled samples for each class? Can I do inference without any labeled samples? Is that zero-shot learning? Also, can I train a model that generalizes to unseen classes during training? 

Thanks in advance for your time and help!"
machinelearning,[D] Fine tuning FinBert,0,1i4c5ao,https://www.reddit.com/r/MachineLearning/comments/1i4c5ao/d_fine_tuning_finbert/,1737220250.0,"I want to solve use case for categorising transactions from bank statements. 

Can fine tuning finbert a good choice?"
machinelearning,[P] How to Highlight Entire Articles Based on Keywords in a Multi-column Newspaper PDF,0,1i4cybu,https://www.reddit.com/r/MachineLearning/comments/1i4cybu/p_how_to_highlight_entire_articles_based_on/,1737222373.0,"Hi everyone,

I'm working on a project where I need to search for a keyword within a newspaper PDF and highlight the entire article that contains the keyword. The challenge arises because:

1. **Multiple Articles Per Page:** Each page may have multiple articles, and I need to distinguish which parts of the page belong to which article.
2. **Multi-column Layout:** Articles are often spread across multiple columns, which makes it tricky to identify the full content of an article when it spans across these columns.

My goal is to:

* Search for a keyword in the text.
* Identify and highlight the entire article that contains the keyword, even if the article spans across multiple columns or pages.

I’m currently using **PyMuPDF4LLM** to process the PDFs and extract text, but I’m not sure how to accurately map the text to specific articles and handle multi-column text.

Has anyone worked on something similar or have suggestions on how to approach this problem?

I’m attaching a sample page of the newspaper for context.

https://preview.redd.it/07gc46adhsde1.png?width=692&format=png&auto=webp&s=f0f6cd925013c67ea5b0ad2cef72a84cc2430c35

"
machinelearning,[D] Looking for a specific youtube video,0,1i4aqxu,https://www.reddit.com/r/MachineLearning/comments/1i4aqxu/d_looking_for_a_specific_youtube_video/,1737216478.0,There is a video of an asian guy who is explaining backpropogation on pen and paper using the minst dataset can anyone send me the url to the video? Thanks
machinelearning,[D] Recommendations of noteworthy AI papers for starters in 2025,67,1i39iuh,https://www.reddit.com/r/MachineLearning/comments/1i39iuh/d_recommendations_of_noteworthy_ai_papers_for/,1737092193.0,"Hi I’m devising up a list of papers to recommend students just starting out in compsci.

What are some must-read papers to give that is not too deep?

These days all the statistic learning theories are within reach with online courses but I want them to grow to read academic papers.

I’m starting off with ilya Sutskever's reading list.

A brief explanation of why you’re recommending the paper would be welcome too!"
machinelearning,Grokking at the Edge of Numerical Stability [Research],128,1i34keg,https://www.reddit.com/r/MachineLearning/comments/1i34keg/grokking_at_the_edge_of_numerical_stability/,1737075960.0,">Grokking, the sudden generalization that occurs after prolonged overfitting, is a surprising phenomenon challenging our understanding of deep learning. Although significant progress has been made in understanding grokking, the reasons behind the delayed generalization and its dependence on regularization remain unclear. In this work, we argue that without regularization, grokking tasks push models to the edge of numerical stability, introducing floating point errors in the Softmax function, which we refer to as Softmax Collapse (SC). We demonstrate that SC prevents grokking and that mitigating SC enables grokking without regularization. Investigating the root cause of SC, we find that beyond the point of overfitting, the gradients strongly align with what we call the naïve loss minimization (NLM) direction. This component of the gradient does not alter the model's predictions but decreases the loss by scaling the logits, typically by scaling the weights along their current direction. We show that this scaling of the logits explains the delay in generalization characteristic of grokking and eventually leads to SC, halting further learning. To validate our hypotheses, we introduce two key contributions that address the challenges in grokking tasks: StableMax, a new activation function that prevents SC and enables grokking without regularization, and ⊥Grad, a training algorithm that promotes quick generalization in grokking tasks by preventing NLM altogether. These contributions provide new insights into grokking, elucidating its delayed generalization, reliance on regularization, and the effectiveness of existing grokking-inducing methods.

Paper: [https://arxiv.org/abs/2501.04697](https://arxiv.org/abs/2501.04697)

(not my paper, just something that was recommended to me)  
"
machinelearning,[P] Are there any formal references to this dataset?,1,1i3rrkx,https://www.reddit.com/r/MachineLearning/comments/1i3rrkx/p_are_there_any_formal_references_to_this_dataset/,1737150696.0,"Hi all!

I'm working on a project about Multitouch Attribution Modeling using Tensor flow to predict conversion over different channels.

In the project, we are using this dataset ([https://www.kaggle.com/code/hughhuyton/multitouch-attribution-modelling](https://www.kaggle.com/code/hughhuyton/multitouch-attribution-modelling)). However, we cannot find any formal reference (published paper or something similar) to make a proper citation. I have searched on Google a lot… really, a lot.

Does anyone know what is the origin of the data or if is it referenced somewhere?

Thanks for the help."
machinelearning,Automate Deep learning model with camera(inception -Tensorflow) [P],2,1i3enos,https://www.reddit.com/r/MachineLearning/comments/1i3enos/automate_deep_learning_model_with_camerainception/,1737114704.0,So i have been working with a deep learning project the aim is to detect objects. My main goal was to detect plastic from water and pick it up using a conveyor belt attached with a boat so i took code from GitHub and made sufficient changes and now the model is working but one problem is i have to manually add photo and change its name to test.jpeg(which i have given) so in my model the boat have a camera how will i make a project that can took the photo automatically when it detects a object and automatically load to my already made model and for all this process which development board will be sufficient.i hope someone answers my question 🙂
machinelearning,[D] share your most frequent embarrassingly parallel tasks,10,1i39cia,https://www.reddit.com/r/MachineLearning/comments/1i39cia/d_share_your_most_frequent_embarrassingly/,1737091537.0,"Hey all,

I’m curious about the most common embarrassingly parallel tasks you encounter in the wild. In the ML and DS world, I’ve noticed many workflows tend to follow this general pattern:

* Pull a bunch of data from cloud storage
* Process that data through a series of functions
* Run an analysis, use the data for training, or pass it into a model for inference

What workloads do you have that follow this process or something similar? I’ve been tinkering with a cloud abstraction to make large-scale parallel processing easier, and I’m trying to identify common use cases to build tutorials around.

Any ideas, advice, or feedback would be super helpful"
machinelearning,[D] Concerns about review process at TPAMI,6,1i3baxp,https://www.reddit.com/r/MachineLearning/comments/1i3baxp/d_concerns_about_review_process_at_tpami/,1737099768.0,"I submitted a paper to TPAMI on June 25, 2024. It was a significant extension of our work that was accepted as an oral presentation at AAAI 2023. I know the reviews at TPAMI are rigorous and can take months, but I was just wondering what the longest time it has taken in your experience, since it has been 6 months and 3 days with no news. Also, would the reviewers take into account works that were published after the submission date? I am just worried that with the (understandably) slow reviews, I will be asked by the reviewer why I am not comparing against method XYZ, and asked to compare against said method, which could potentially outperform mine due to how fast the field progresses, and make revision and acceptance complicated."
machinelearning,[P] How to import and deploy a pre-trained text-to-image model on Google Cloud for a high-traffic e-commerce project?,0,1i3tr80,https://www.reddit.com/r/MachineLearning/comments/1i3tr80/p_how_to_import_and_deploy_a_pretrained/,1737156112.0,"Hello, I am working on an e-commerce project and I need a text-to-image model. I want to deploy this model on Google Cloud Platform (GCP), but this process seems quite new and complicated for me. Since I have limited time, I would like to know which of the following scenarios is more suitable:

Using ready-made GitHub models: For example, pre-trained models like Stable Diffusion. Can I import and use these models on GCP? If possible, can you share the recommended steps for this?

Google Cloud Marketplace: Would it be easier to buy a ready-made solution from GCP Marketplace? If so, what are the recommended APIs or services?

My goal:

To take inputs from user data (e.g. a string array) in the backend and return output via a text-to-image API.

Since I have an e-commerce project, I need a scalable solution for high traffic.

Information:

Backend: Requests will come via REST API.

My project allows users to create customized visuals (e.g. product designs).

Instead of training a model from scratch, I prefer ready-made solutions that will save time.

My questions:

Which way is more practical and faster? A ready-made model from GitHub or a solution from Google Cloud Marketplace?

If I prefer a model from GitHub, what steps should I follow to import these models to GCP?

How can I optimize a scalable text-to-image solution on GCP for a high-traffic application?

What platforms am I asking about:

If you have experience with Stable Diffusion or similar models, can you share them?

I would like to get suggestions from those who have started such a project on Google Cloud."
machinelearning,[P] Virtual Orientation session on EY Open Science AI & Data Challenge 2025,0,1i3han7,https://www.reddit.com/r/MachineLearning/comments/1i3han7/p_virtual_orientation_session_on_ey_open_science/,1737123412.0,"[Join the upcoming Open Science AI & Data Challenge Virtual Orientation session on January 22nd 2025.](https://form.ey.com/243104302127945) Let's work together to cool down our cities and create healthier, more sustainable urban environments. Learn how the [2025 EY Open Science AI & Data Challenge](https://challenge.ey.com/2025) will help tackle the problem of urban heat islands through the application of AI and technology-based solutions. Winners are eligible for cash prizes and attendance at an exciting awards ceremony. [Register today!](https://challenge.ey.com/register)"
machinelearning,[P] I made a script to create GSM problems of any complexity.,12,1i31dwr,https://www.reddit.com/r/MachineLearning/comments/1i31dwr/p_i_made_a_script_to_create_gsm_problems_of_any/,1737066918.0,"[Project github link](https://github.com/dattasid/grade-school-math-procedural)

[Here is a example](https://github.com/dattasid/grade-school-math-procedural/blob/main/datasets/examples/price_normal.md).

[Here is a example](https://github.com/dattasid/grade-school-math-procedural/blob/main/datasets/examples/price_easy.md) which uses simpler language, for testing if it is the confusing language that causes a model to fail.

Edit: Detailed post keeps getting removed. Please ask questions, hope someone finds this tool helpful."
machinelearning,[D] Titans: a new seminal architectural development?,85,1i2l0ey,https://arxiv.org/html/2501.00663v1,1737018747.0,"What are the initial impressions about their work? Can it be a game changer? How quickly can this be incorporated into new products?
Looking forward to the conversation!"
machinelearning,[R] Multimodal Visualization-of-Thought: Enhancing MLLM Reasoning Through Visual Thinking,15,1i2q6t9,https://www.reddit.com/r/MachineLearning/comments/1i2q6t9/r_multimodal_visualizationofthought_enhancing/,1737037918.0,"The key innovation here is combining large language models with image generation to create a system that can ""visually think"" while solving problems. The approach, called Multimodal Visualization-of-Thought (MVoT), generates relevant visualizations during its reasoning process, similar to how humans might sketch diagrams to better understand a problem.

Main technical points:
- System architecture integrates LLMs for reasoning with image generation models
- Uses **spatial-semantic alignment** to ensure generated visuals match reasoning steps
- Implements an iterative process where each reasoning step can trigger visualization
- Maintains consistency between visual and textual representations through multimodal chain-of-thought

Results:
- 12% improvement on visual reasoning benchmarks compared to baseline approaches
- Particularly strong performance on tasks involving spatial relationships
- Generated visualizations showed clear alignment with reasoning steps
- Works with different combinations of language and image generation models

I think this approach could meaningfully improve AI systems' ability to reason about physical and spatial problems. By incorporating visual thinking into the reasoning process, we might see better performance on tasks that humans typically solve through visualization - from physics problems to architectural design. However, the computational overhead of generating images during reasoning could limit practical applications.

I think the most interesting aspect is how this mimics human cognitive processes - we often sketch or visualize to understand complex problems. This could lead to AI systems that reason in more intuitive and interpretable ways.

TLDR: New method combines language models with image generation to create AI systems that can ""think visually"" while reasoning, showing 12% improvement on visual reasoning tasks.

[Full summary is here](https://aimodels.fyi/papers/arxiv/imagine-while-reasoning-space-multimodal-visualization-thought). Paper [here](https://arxiv.org/abs/2501.07542)."
machinelearning,"Best way to classify NSFW text - BERT, small LLM like llama 3.2 3B or something else? [D]",83,1i2h315,https://www.reddit.com/r/MachineLearning/comments/1i2h315/best_way_to_classify_nsfw_text_bert_small_llm/,1737002280.0,"I'm working on a project where I need to classify text as either nsfw or sfw. I know there are some BERT-based classifiers out there that are specifically trained for this kind of task. I've also seen people using smaller LLMs.  
What's the best approach for this? Since the underlying complexity of detecting NSFW text isn't that high, I'm thinking maybe a full blown LLM is overkill. What are your recommendations?"
machinelearning,CIFAR 100 with MLP mixer. [P],13,1i2nu5q,https://www.reddit.com/r/MachineLearning/comments/1i2nu5q/cifar_100_with_mlp_mixer_p/,1737030619.0,Recently took part in a hackathon where was tasked with achieving a high accuracy without using Convolution and transformer models. Even though mlp mixers can be argued being similar to convolution they were allowed. Even after a lot of tries i could not take the accuracy above 60percent. Is there a way to do it either with mlp or with anything else to reach somewhere near the 90s.
machinelearning,[P] How I found & fixed 4 bugs in Microsoft's Phi-4 model,303,1i23zbo,https://www.reddit.com/r/MachineLearning/comments/1i23zbo/p_how_i_found_fixed_4_bugs_in_microsofts_phi4/,1736965368.0,"Hey r/MachineLearning! Last week, Microsoft released Phi-4, a 14B open-source model that rivals OpenAI's GPT-4-o-mini. I managed to find & fix 4 bugs impacting its output quality. You might remember me previously from [fixing 8 bugs](https://www.reddit.com/r/MachineLearning/comments/1bipsqj/p_how_i_found_8_bugs_in_googles_gemma_6t_token/) in Google's Gemma model! :)

I'm going to walk you through how I found & fixed the bugs. Phi-4's benchmarks were amazing, however many users reported weird or just wrong outputs. Since I maintain the open-source project called '[Unsloth](https://github.com/unslothai/unsloth)' (fine-tuning LLMs 2x faster with 70% less VRAM) with my brother, I firstly tested Phi-4 for inference and found many errors. Our GitHub repo: [https://github.com/unslothai/unsloth](https://github.com/unslothai/unsloth)

This time, the model had no implementation issues (unlike Gemma 2) but did have problems in the model card. For my first inference run, I randomly found an extra token which is obviously incorrect (2 eos tokens is never a good idea). Also during more runs, I found there was an extra assistant prompt which is once again incorrect. And, lastly, from past experience with Unsloth's bug fixes, I already knew fine-tuning was wrong when I read the code.

These bugs caused Phi-4 to have some drop in accuracy and also broke fine-tuning runs. Our fixes are now [under review by Microsoft](https://huggingface.co/microsoft/phi-4/discussions/21) to be officially added to Hugging Face. We uploaded the fixed versions to [https://huggingface.co/unsloth/phi-4-GGUF](https://huggingface.co/unsloth/phi-4-GGUF)

Here’s a breakdown of the bugs and their fixes:

***1. Tokenizer bug fixes***

The Phi-4 tokenizer interestingly uses <|endoftext|> as the BOS (beginning of sentence), EOS (end of sentence) and PAD (padding) tokens. The main issue is the EOS token is wrong - it should be <|im\_end|>. Otherwise, you will get <|im\_end|><|endoftext|> in generations.

***2. Fine-tuning bug fixes***

The padding token should be a designated pad token like in Llama (<|finetune\_right\_pad\_id|>) or we can use an untrained token - for example we use <|dummy\_87|>, fixing infinite generations and outputs.

***3. Chat template issues***

The Phi-4 tokenizer always adds an assistant prompt - it should only do this if prompted by add\_generation\_prompt. Most LLM serving libraries expect non auto assistant additions, and this might cause issues during serving.

**We dive deeper into the bugs in our blog:** [**https://unsloth.ai/blog/phi4**](https://unsloth.ai/blog/phi4)

# Do our Fixes Work?

Yes! Our fixed Phi-4 uploads show clear performance gains, with even better scores than Microsoft's original uploads on the [Open LLM Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/?search=phi-4).

https://preview.redd.it/d8hew26e06ce1.png?width=2366&format=png&auto=webp&s=173c23feacc625566271470839fe7a5e25eb860e

Some redditors even tested our fixes to show greatly improved results in:

* Example 1: [Multiple-choice tasks](https://www.reddit.com/r/LocalLLaMA/comments/1hwzmqc/comment/m665h08/)

https://preview.redd.it/qx50pkq706ce1.png?width=1579&format=png&auto=webp&s=437da2cabdbf98ef5a8b8cbdc5592907a20e2316

* Example 2: [ASCII art generation](https://www.reddit.com/r/LocalLLaMA/comments/1hwzmqc/comment/m65wr3e/)

https://preview.redd.it/sw1o3a3yt4de1.png?width=2326&format=png&auto=webp&s=fc6bfc45d14134d45f332ba58bbd1de049f5776b

We also made a Colab notebook fine-tune Phi-4 completely for free using Google's free Tesla T4 (16GB) GPUs: [https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi\_4-Conversational.ipynb](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4-Conversational.ipynb)

Thank you for reading this long post and hope you all found this insightful! If you have any questions, please feel free to ask! :)

**How I found the bugs:**

1. I first downloaded the original Phi-4 from [https://huggingface.co/microsoft/phi-4](https://huggingface.co/microsoft/phi-4), and tested inference out. Weirdly I found `<|im_start|>assistant<|im_sep|>` to be appended at the even with `add_generation_prompt = False` in Hugging Face, so I theorized there was a chat template problem. Adding assistant prompts by default can break serving libraries.
2. And yes, [https://huggingface.co/microsoft/phi-4/blob/f957856cd926f9d681b14153374d755dd97e45ed/tokenizer\_config.json#L774](https://huggingface.co/microsoft/phi-4/blob/f957856cd926f9d681b14153374d755dd97e45ed/tokenizer_config.json#L774) had by default added the assistant prompt - I first fixed this!
3. I then found `<|endoftext|>` to be used for the BOS, EOS and PAD tokens, which is a common issue amongst models - I ignored the BOS, since Phi-4 did not have one anyways, but changed the PAD token to `<|dummy_87|>`. You can select any of the tokens since they're empty and not trained. This counteracts issues of infinite generations during finetuning.
4. For Llama-fication, I used torch.allclose to confirm all tensors are in fact equivalent. I also used some fake random data to check all activations are also mostly similar bitwise. I also uploaded the model to the HF [Open LLM Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/?search=phi-4) to confirm if the original Phi-4 arch and the new Llama-fied models are equivalent.
5. Finally I verified all finetuning runs with Unsloth in a [Colab Notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4-Conversational.ipynb) to confirm all runs were correct.

"
machinelearning,"[R] Virgo: A Preliminary Exploration on
Reproducing o1-like MLLM",7,1i2qmdf,https://www.reddit.com/r/MachineLearning/comments/1i2qmdf/r_virgo_a_preliminary_exploration_on_reproducing/,1737039166.0,"**TL;DR:** A reasoning multimodal model built from Qwen2-VL-72B. Surprisingly, beats QVQ in evals.

**Paper:** [https://arxiv.org/pdf/2501.01904](https://arxiv.org/pdf/2501.01904)

**Abstract:**

>Recently, slow-thinking reasoning systems, built upon large language models (LLMs), have garnered widespread attention by scaling the thinking time during inference. There is also growing interest in adapting this capability to multimodal large language models (MLLMs). Given that MLLMs handle more complex data semantics across different modalities, it is intuitively more challenging to implement multimodal slow-thinking systems.  
To address this issue, in this paper, we explore a straightforward approach by fine-tuning a capable MLLM with a small amount of textual long-form thought data, resulting in a multimodal slow-thinking system, Virgo (Visual reasoning with long thought). We find that these long-form reasoning processes, expressed in natural language, can be effectively transferred to MLLMs. Moreover, it seems that such textual reasoning data can be even more effective than visual reasoning data in eliciting the slow-thinking capacities of MLLMs. While this work is preliminary, it demonstrates that slow-thinking capacities are fundamentally associated with the language model component, which can be transferred across modalities or domains. This finding can be leveraged to guide the development of more powerful slow-thinking reasoning systems. We release our resources at [this https URL](https://github.com/RUCAIBox/Virgo).

**Highlights:**

>\[W\]e obtain approximately 5K long thought instruction instances distilled from two open slow-thinking reasoning systems: DeepSeek-R1-Lite-Preview \[2\] (abbreviated as R1) and QwQ-32B-preview \[3\] (abbreviated as QwQ). The statistics of the collected instruction data are categorized by domain as follows: math (3.7K), science (0.9K), code (0.2K) and puzzle (0.1K). \[...\]

>After collecting instruction data for long-form reasoning, we fine-tune the base MLLM to emulate slow-thinking reasoning behavior. \[...\]

>The second approach we explore is the direct distillation of multimodal long thought data from slow-thinking MLLMs (e.g., QVQ). \[...\]

>As another alternative approach, we design a multi-stage tuning method for self-distillation. Specifically, we first fine-tune the selected MLLM (i.e., Qwen2-VL-72B-Instruct) on the textual long thought instruction set DT, obtaining model M0. Next, we use M0 to generate the visual long thought instruction set by self-distillation DSD, which can be subsequently used for fine-tuning the original MLLM.

**Visual Highlights:**

https://preview.redd.it/2o4v0y2tcdde1.png?width=1123&format=png&auto=webp&s=b3ac8bbb69248d8c326a73553cbccb0c5ab12d46

https://preview.redd.it/j3wyeg0ucdde1.png?width=967&format=png&auto=webp&s=98b2ca3dedb6c99c078491e67e53df6343f074c3

https://preview.redd.it/m6385vuucdde1.png?width=1191&format=png&auto=webp&s=4447b132fb7484d1375403916c3dcd8a9c2b8e17

[Looks a bit chaotic, if you ask me](https://preview.redd.it/q2dgxrlvcdde1.png?width=929&format=png&auto=webp&s=0f8ec5a05dc7feee71ebe57cb0ae2cb18dfd2051)

"
machinelearning,[D] Best Text-to-Sound-Effects model (MIT license or equivalent),8,1i2n50v,https://www.reddit.com/r/MachineLearning/comments/1i2n50v/d_best_texttosoundeffects_model_mit_license_or/,1737027976.0,"Hi there !
I've been looking around for a MIT (commercially available) model for Text-to-Sound-Effects (Text-to-Audio) and haven't found much, besides the traditional stable-Audio-Open (with its special license)

Do you know any other ?
"
machinelearning,[D] How to analysis memory and computation cost by parts in LLM fine-tune?,0,1i389km,https://www.reddit.com/r/MachineLearning/comments/1i389km/d_how_to_analysis_memory_and_computation_cost_by/,1737087716.0,"[Flash-attention paper](https://arxiv.org/pdf/2205.14135) show that “most operation in Transformers are botlenecked by memory accesses”

[Cut cross entropy](https://arxiv.org/abs/2411.09009) show that “The cross-entropy loss is responsible for up to 90% of the memory footprint of modern LLM training”


How to get these data, is there a tool or platform which can show the cost by parts in LLM, like embedding, attention, layer normalazation, loss computation?

Purpose: After know that, we will know which part we should accelerate at first and can pay more attention on it. 

Thanks for any suggestion"
machinelearning,[P] AutoResearch: A new open-source LLM-driven research automation tool,5,1i2lk5n,https://www.reddit.com/r/MachineLearning/comments/1i2lk5n/p_autoresearch_a_new_opensource_llmdriven/,1737021315.0,"Hello, everyone

I recently developed a new open-source LLM-driven research automation tool, called AutoResearch. It can automatically conduct various tasks related to machine learning research, the key function is:

[Topic-to-Survey Automation](https://jlx0.github.io/auto_research/_examples_gallery/top_to_survey.html) \- In one sentence, **it converts a topic or research question into a comprehensive survey of relevant papers.** It generates keywords, retrieves articles for each keyword, merges duplicate articles, ranks articles based on their [impacts](https://jlx0.github.io/auto_research/target_code/auto_research.search.core.html#auto_research.search.core.AutoSearch.score_threshold), summarizes the articles from the topic, method, to results, and optionally checks code availability. It also organizes and zips results for easy access.

When searching for research papers, the results from a search engine can vary significantly depending on the specific keywords used, even if those keywords are conceptually similar. For instance, searching for ""LLMs"" versus ""Large Language Models"" may yield different sets of papers. Additionally, when experimenting with new keywords, it can be challenging to remember whether a particular paper has already been checked. Furthermore, the process of downloading papers and organizing them with appropriate filenames can be tedious and time-consuming.

This tool streamlines the entire process by automating several key tasks. It suggests multiple related keywords to ensure comprehensive coverage of the topic, merges duplicate results to avoid redundancy, and automatically names downloaded files using the paper titles for easy reference. Moreover, it leverages LLMs to generate summaries of each paper, saving researchers valuable time and effort in uploading it to ChatGPT and then conversing with it in a repetitive process.

Additionally, there are some basic functionalities:

* [Automated Paper Search](https://jlx0.github.io/auto_research/_examples_gallery/search_papers.html) \- Search for academic papers using keywords and retrieve metadata from Google Scholar, Semantic Scholar, and arXiv. Organize results by relevance or date, apply filters, and save articles to a specified folder.
* [Paper Summarization](https://jlx0.github.io/auto_research/_examples_gallery/summarize_a_paper.html) \- Summarize individual papers or all papers in a folder. Extract key sections (abstract, introduction, discussion, conclusion) and generate summaries using GPT models. Track and display the total cost of summarization.
* [Explain a Paper with LLMs](https://jlx0.github.io/auto_research/_examples_gallery/explain_a_paper.html) \- Interactively explain concepts, methodologies, or results from a selected paper using LLMs. Supports user queries and detailed explanations of specific sections.
* [Code Availability Check](https://jlx0.github.io/auto_research/_examples_gallery/get_github_link.html) \- Check for GitHub links in papers and validate their availability.

This tool is still under active development, I will add much more functionalities later on.

I know there are many existing tools for it. But here are the **key distinctions and advantages** of the tool:

* [Free and open-source](https://github.com/JLX0/auto_research/)
* Pure Python code-base, which enables convenient deployment, such as [Google Colab notebook](https://colab.research.google.com/drive/1Xj0xTpHvpnPfmK9tYnI8Ep7oRKrQ9gn7?usp=sharing)
* [API documentation](https://jlx0.github.io/auto_research/target_code/auto_research.html#module-auto_research) are available
* No additional API keys besides LLM API keys are required (No API keys, such as Semantic Scholar keys, are needed for literature search and downloading papers)
* Support multiple search keywords.
* Rank the papers based on their [impacts](https://jlx0.github.io/auto_research/target_code/auto_research.search.core.html#auto_research.search.core.AutoSearch.score_threshold), and consider the most important papers first.
* Fast literature search process. It only takes about 3 seconds to automatically download a paper.

**------Here is a quick installation-free** [**Google Colab demo**](https://colab.research.google.com/drive/1Xj0xTpHvpnPfmK9tYnI8Ep7oRKrQ9gn7?usp=sharing)**------**

Here is the [official website of AutoResearch](https://jlx0.github.io/auto_research/).

Here is the [GitHub link to AutoResearch](https://github.com/JLX0/auto_research/).

**------Please star the** [**repository**](https://github.com/JLX0/auto_research/) **and share it if you like the tool!------**

Please DM me or reply in the post if you are interested in collaborating to develop this project!"
machinelearning,[R] Seeking a Knowledgeable Co-Author for Time Series Foundation Models Research,0,1i33y8v,https://www.reddit.com/r/MachineLearning/comments/1i33y8v/r_seeking_a_knowledgeable_coauthor_for_time/,1737074146.0,"Hello,

I am conducting research that I plan to submit to the AHLI Conference on Health, Inference, and Learning (CHIL) (H5-index 26, h5-median 43). However, the submission deadline is approaching quickly—February 10.

My advisor has suggested adding other professors as co-authors, but they would primarily review and provide feedback rather than directly contributing to the writing. Therefore, I am reaching out to see if anyone with expertise in time series foundation models would be interested in collaborating as a co-author.

The research involves comparing time series foundation models across different datasets. The experiments are nearly complete, but I need support in writing the theoretical foundation for each model. If you have the necessary knowledge, time, and interest in contributing meaningfully to this work, please send me a private message so we can discuss this opportunity further.

Thank you!"
machinelearning,"Kaggle dataset: one of the input features has a >0.99 correlation with the target, yet most/all notebooks (20+) do not care? [D]",94,1i210hp,https://www.reddit.com/r/MachineLearning/comments/1i210hp/kaggle_dataset_one_of_the_input_features_has_a/,1736957850.0,"There is this dataset (won't link here as I don't want my kaggle and reddit associated) with a few input features (5-6) used to predict one target value.

But one of the features is basically perfectly linearly correlated with the target (>0.99).

An example would be data from a trucking company with a single model of trucks:

Target: truck fuel consumption / year Features: driver's age, tires type, truck age, DISTANCE TRAVELED / year

Obviously in average the fuel consumption will be linearly proportional with the nb of miles traveled. I mean normally you'd just use that to calculate a new target like fuel/distance.

Yet not a single person/notebook did this kind of normalization. So everyone's model has >.99 accuracy, as that one feature drowns out everything else.

Is that something other people noticed: more and more the code looks fine (Data loading, training many types of models), maybe thanks to LLMs. But the decision making process is often quite bad?"
machinelearning,"Good People of this reddit who worked with multiple adapters on the same model, guide me with your wisdom [D]",4,1i2mcy1,https://www.reddit.com/r/MachineLearning/comments/1i2mcy1/good_people_of_this_reddit_who_worked_with/,1737024846.0,How do you deal with multiple adapters created for different tasks? I understand task id based dynamic loading of the appropriate adapter is obvious but is there a better way? I am especially asking for whisper
machinelearning,[D] Platform for Multimodal Dataset Upload?,0,1i2t0gj,https://www.reddit.com/r/MachineLearning/comments/1i2t0gj/d_platform_for_multimodal_dataset_upload/,1737045440.0,"What do you guys use to upload Multimodal Dataset?

I want it to be convenient for the people who use it. For the text, huggingface dataset is the best convenient solution, but I cant find any convenient solution for Multimodal (Image + Video + Audio + Text) datast.

Thanks in advance."
machinelearning,"[D] How often are you babysitting your models? 🤔
",0,1i351hc,https://www.reddit.com/r/MachineLearning/comments/1i351hc/d_how_often_are_you_babysitting_your_models/,1737077393.0,"Hey yall! I'm curious, how often are you kicking off a new training runs?   
Once a week? Twice a week? Everyday?   
Would love to hear about your experience! "
machinelearning,[R] Imagine while Reasoning in Space: Multimodal Visualization-of-thought,31,1i279gb,https://www.reddit.com/r/MachineLearning/comments/1i279gb/r_imagine_while_reasoning_in_space_multimodal/,1736973785.0,"Abstract:

Chain-of-Thought (CoT) prompting has proven highly effective for enhancing complex reasoning in Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs). Yet, it struggles in complex spatial reasoning tasks. Nonetheless, human cognition extends beyond language alone, enabling the remarkable capability to think in both words and images. Inspired by this mechanism, we propose a new reasoning paradigm, Multimodal Visualization-of-Thought (MVoT). It enables visual thinking in MLLMs by generating image visualizations of their reasoning traces. To ensure high- quality visualization, we introduce token discrepancy loss into autoregressive MLLMs. This innovation significantly improves both visual coherence and fidelity. We validate this approach through several dynamic spatial reasoning tasks. Experimental results reveal that MVoT demonstrates competitive performance across tasks. Moreover, it exhibits robust and reliable improvements in the most challenging scenarios where CoT fails. Ultimately, MVoT establishes new possibilities for complex reasoning tasks where visual thinking can effectively complement verbal reasoning.

Arxiv link: https://arxiv.org/pdf/2501.07542"
machinelearning,[R] Transformer²: Self-Adaptive LLMs,182,1i1l8d4,https://www.reddit.com/r/MachineLearning/comments/1i1l8d4/r_transformer²_selfadaptive_llms/,1736901669.0,"Paper: https://arxiv.org/abs/2501.06252

**Abstract**

Self-adaptive large language models (LLMs) aim to solve the challenges posed by traditional fine-tuning methods, which are often computationally intensive and static in their ability to handle diverse tasks. We introduce Transformer², a novel self-adaptation framework that adapts LLMs for unseen tasks in real-time by selectively adjusting only the singular components of their weight matrices. During inference, Transformer² employs a two-pass mechanism: first, a dispatch system identifies the task properties, and then task-specific ""expert"" vectors, trained using reinforcement learning, are dynamically mixed to obtain targeted behavior for the incoming prompt. Our method outperforms ubiquitous approaches such as LoRA, with fewer parameters and greater efficiency. Transformer² demonstrates versatility across different LLM architectures and modalities, including vision-language tasks. Transformer² represents a significant leap forward, offering a scalable, efficient solution for enhancing the adaptability and task-specific performance of LLMs, paving the way for truly dynamic, self-organizing AI systems. 

Blog Summary: https://sakana.ai/transformer-squared/

GitHub: https://github.com/SakanaAI/self-adaptive-llms"
machinelearning,[R] MathReader: A Text-to-Speech System for Mathematical Documents Using OCR and Fine-tuned T5,16,1i1xgp2,https://www.reddit.com/r/MachineLearning/comments/1i1xgp2/r_mathreader_a_texttospeech_system_for/,1736947990.0,"Interesting new text-to-speech system that tackles mathematical content by combining OCR and language models. The key innovation is treating mathematical notation as a specialized language that needs translation, using a multi-stage pipeline to convert equations into natural speech.

Technical approach:
* Custom OCR model trained specifically on mathematical documents
* T5-based language model fine-tuned for math-to-text translation
* Three-stage pipeline: recognition → translation → synthesis
* Integration with LaTeX parsing for handling complex mathematical typography

Key results:
* 95% accuracy in mathematical expression recognition
* Successful handling of complex notation including fractions, integrals, matrices
* User testing showed preference over existing math TTS systems
* Natural language output matches human descriptions

I think this could be impactful for making technical education more accessible. Being able to convert mathematical documents to clear speech opens up some possibilities for learning and working with technical content. The combination of OCR and NLP seems maybe like a robust approach that could extend beyond just mathematics to other technical domains with specialized notation.

I see some limitations around context-dependent notation and complex proofs, but these seem like natural areas for future work rather than fundamental flaws in the approach.

TLDR: New TTS system combines specialized OCR and language models to convert mathematical documents to natural speech, achieving 95% accuracy in math recognition and producing human-like descriptions.

[Full summary is here](https://aimodels.fyi/papers/arxiv/mathreader-text-to-speech-mathematical-documents). Paper [here](https://arxiv.org/abs/2501.07088)."
machinelearning,[R] Explainable GNNs in Job Recommender Systems: Tackling Multi-Stakeholder Challenges,4,1i21t17,https://www.reddit.com/r/MachineLearning/comments/1i21t17/r_explainable_gnns_in_job_recommender_systems/,1736959904.0,"Can explainable AI balance competing needs in job recommendation systems? Models like OKRA, powered by GNNs, deliver stakeholder-specific insights - text explanations for candidates, skill alignment for recruiters, and visualizations for companies. They address biases (e.g. rural underrepresentation) and challenges like integrating explanations with source data (CVs, vacancies). 

Future directions focus on refining explanation coherence, fairness metrics, and real-world validation, pushing explainable multi-stakeholder AI towards equitable, context-aware job matching.

We unpack *""Explainable Multi-Stakeholder Job Recommender Systems""* by *Roan Schellingerhout* here: [https://www.shaped.ai/blog/decoding-job-recommendations-the-future-of-explainable-multi-stakeholder-ai](https://www.shaped.ai/blog/decoding-job-recommendations-the-future-of-explainable-multi-stakeholder-ai)"
machinelearning,Best AutoML for Supervised Regression of Tabular Data [P],2,1i26qvt,https://www.reddit.com/r/MachineLearning/comments/1i26qvt/best_automl_for_supervised_regression_of_tabular/,1736972414.0,"I have a simple dataset that I want to train a prediction model on for a pretty low stakes project (more for fun), but I have no experience training ML models. Simple linear regression didn't have great performance when I tried it and I suspect there is a more complex interaction between the variables.

Training Dataset: 25K observations of 5 numerical predictor variables with one 1 numerical outcome variable.

What is the best AutoML platform that I can run this with minimal code, just to see if ML models can perform better than simple regression can? Thanks!"
bigdata,"Hey friends, you’ve got to check out this amazing tool that tracks VC investments in real-time! 🌐💸 It’s super useful for seeing which companies are getting funding and even offers detailed insights into industries and key players. A fantastic resource if you're diving into the VC world!",1,1i5693h,https://v.redd.it/txsqgn9x10ee1,1737313856.0,
bigdata,"Hey friends, if you're curious about the VC world, I just found this amazing live investment tracker that shows all the VC funding happening globally! It's super insightful for data analysis on companies and decision makers. A game-changer if you're looking to learn the ins and outs of venture capit",1,1i4vwb3,https://v.redd.it/0oilvar6kxde1,1737283678.0,
bigdata,Solidus AI Tech - Among Binance's Top 5 Alpha Projects!,5,1i4j95u,https://www.reddit.com/r/bigdata/comments/1i4j95u/solidus_ai_tech_among_binances_top_5_alpha/,1737239474.0,"Everything starts again TRUMP launching her own token before she becomes president and BTC is a good start and we should not forget artificial intelligence projects

Solidus AI Tech u AITECH has solidified its leadership in Web3 and AI innovations and gained the trust of global investors by being ranked among Binance's Top 5 Alpha Projects.

https://preview.redd.it/30gbjjvswtde1.png?width=1750&format=png&auto=webp&s=514c3218a7027b993cafefd80544c267f6c6999d

Why This Matters

Visibility and Recognition: AITECH's recognition by Binance puts the project on the radar of global investors and increases investor confidence.

Adoption and Growth: Such recognition can accelerate Solidus AI Tech's adoption and support growth in its ecosystem.

Leadership: Being featured on a major platform like Binance helps Solidus AI Tech position itself as a leader in Web3 AI innovations.

What's Next ?

This achievement increases the potential for Solidus AI Tech to attract more collaboration and investment in its future projects. The Solidus AI Tech community celebrates this significant milestone and looks forward to the future."
bigdata,"Hey friends, have you ever thought about tapping into the VC goldmine? I found this awesome app that tracks real-time funding announcements and connects you with decision-makers at funded startups. It's even got AI insights on what they might want! If you're curious about it too, let me know!",0,1i4jguq,https://v.redd.it/hpohwttjytde1,1737240081.0,
bigdata,Cancer Immunotherapy & Big Data/AI Technology,2,1i3dkwk,https://www.reddit.com/r/bigdata/comments/1i3dkwk/cancer_immunotherapy_big_dataai_technology/,1737110300.0,"Cancer touches millions of lives, and the journey to better treatments is one we take together. On January 23rd, 2025, at 11:00 AM EDT / 09:30 PM IST, join us for a thought-provoking webinar, The Intersection of Cancer Immunotherapy & Big Data/AI Technology. 

Link to Register: [https://www.senzmate.com/publish/webinar-7/](https://www.senzmate.com/publish/webinar-7/)"
bigdata,"Free Learning Paths for Data Analysts, Data Scientists, and Data Engineers – Using 100% Open Resources ",5,1i2vmec,https://i.redd.it/at0sz4bhfede1.jpeg,1737052018.0,"Hey, I’m Ryan, and I’ve created 

https://www.datasciencehive.com/learning-paths 

a platform offering free, structured learning paths for data enthusiasts and professionals alike.

The current paths cover:

	•	Data Analyst: Learn essential skills like SQL, data visualization, and predictive modeling.
	•	Data Scientist: Master Python, machine learning, and real-world model deployment.
	•	Data Engineer: Dive into cloud platforms, big data frameworks, and pipeline design.

The learning paths use 100% free open resources and don’t require sign-up. Each path includes practical skills and a capstone project to showcase your learning.

I see this as a work in progress and want to grow it based on community feedback. Suggestions for content, resources, or structure would be incredibly helpful.

I’ve also launched a Discord community (https://discord.gg/Z3wVwMtGrw) with over 150 members where you can:

	•	Collaborate on data projects
	•	Share ideas and resources
	•	Join future live hangouts for project work or Q&A sessions

If you’re interested, check out the site or join the Discord to help shape this platform into something truly valuable for the data community.

Let’s build something great together.

Website: https://www.datasciencehive.com/learning-paths
Discord: https://discord.gg/Z3wVwMtGrw "
bigdata,Exploring Database Isolation Levels,1,1i2yqv1,https://www.thecoder.cafe/p/exploring-database-isolation-levels,1737059971.0,
bigdata,"High-key, if you’ve got a service to sell, I totally recommend pitching to fresh VC-funded startups! I hit $5k in monthly recurring revenue in just a month using this clever app to find decision-makers and dropping them a DM. Trust me, it’s way easier than it sounds!",0,1i366ao,https://v.redd.it/qn2b2705tgde1,1737080871.0,
bigdata,Connect Power BI to PowerPoint and Google Slides with Rollstack (www.Rollstack.com),4,1i25j32,https://i.redd.it/r5w80ov8l7de1.png,1736969263.0,
bigdata,Evolving Data Models: Backbone of Rich User Experiences (UX) for Data Citizens,4,1i1wid5,https://moderndata101.substack.com/p/evolving-data-models-backbone-of,1736944848.0,
bigdata,Free Webinar: Accelerate AI Value with Teradata and Google Cloud,1,1i1qzdd,https://www.reddit.com/r/bigdata/comments/1i1qzdd/free_webinar_accelerate_ai_value_with_teradata/,1736920647.0,"📅 Date: 01/15/2025  
⏰ Time: 7:30 AM PT / 4:30 PM CET  
🔗 Register here: [https://www.brighttalk.com/webcast/19856/632920?utm\_source=TDDev&utm\_medium=brighttalk&utm\_campaign=632920](https://www.brighttalk.com/webcast/19856/632920?utm_source=TDDev&utm_medium=brighttalk&utm_campaign=632920)

As a data professional, you want to build solutions that help your company and customers.

There is significant value in unstructured data stored in formats such as text, audio, and more, which you can leverage to achieve this goal.

Advanced Large Language Models (LLMs), like Google’s Gemini, can simplify the process of introducing structure into unstructured data, enabling individuals and organizations to derive insights that better serve their customers.

Join Janeth Graziani, Developer Advocate, Teradata and Merlin Yamssi, Lead Solutions Consultant AI/ML CoE, Google Cloud, as they explore, demo, and discuss how data analysts, engineers, and scientists, can leverage Teradata VantageCloud and Google Cloud to accelerate your AI innovation from development to production.

Janeth and Merlin are excited to share how you can:

\- Get faster results from your AI/ML initiatives by quickly building and training ML models with Vertex AI and the powerful in-database analytics functions of ClearScape Analytics  
\- Easily build and deploy powerful gen AI solutions with Teradata VantageCloud Lake, Vertex AI, and Gemini  
\- Transform customer complaint management through advanced generative AI for precise and automated classification. Janeth will give a complaints classification demo which leverages Teradata Vantage and Google Gemini.

Kate Russell, technology journalist, will moderate this webinar and make sure your questions are addressed by our experts.

https://reddit.com/link/1i1qzdd/video/wokg2qjpk3de1/player

"
bigdata,Just announced: Tableau Conference #TC25 Registration is Open! Who is going? ,1,1i1b9pe,https://www.linkedin.com/posts/tableau-software_tc25-datafam-activity-7284917234756435969-3nu-,1736875452.0,
bigdata,Hey friends! I just stumbled upon this awesome tool that gathers info on VC funded startups and helps you find contacts of key decision-makers. It’s a game changer for anyone looking to pitch services! Let me know if you're curious to give it a whirl!,0,1i0v37l,https://v.redd.it/5cddx66s8vce1,1736819780.0,
bigdata,I learned how big data fuels AI on platforms like Instagram and Pinterest,2,1hxdk90,https://www.reddit.com/r/bigdata/comments/1hxdk90/i_learned_how_big_data_fuels_ai_on_platforms_like/,1736431711.0,"I wrote an article about how **AI influences social media**, deciding what we see in our feeds, ads, and content. Key points:

* **Facebook and Instagram** use Meta AI to figure out what shows up in your feed based on what you like, comment on, or share.
* **TikTok’s Monolith AI** studies what you watch and interact with to fine-tune your For You Page.
* **LinkedIn** suggests jobs, articles, and connections that match your career goals.
* **YouTube** recommends videos and even picks when ads pop up during what you watch.
* **Pinterest’s PinSage AI** suggests pins and products based on your searches and saves.

It’s remarkable how much AI controls our online experience, but sometimes it can feel a little too spot-on.

If you want to tweak what you see:

* Check your privacy settings regularly to see what data is being used.
* Use tools like “Not Interested” to refine your feed.
* Be mindful of what you interact with—it directly affects future recommendations.

If you’re curious about how it all works, here is the full article: [https://aigptjournal.com/explore-ai/ai-guides/ai-in-social-media-platforms/](https://aigptjournal.com/explore-ai/ai-guides/ai-in-social-media-platforms/)

Have you noticed how accurate your feeds are lately? Do you find it helpful, or is it over the top?"
bigdata,Federated Modeling: When and Why to Adopt,3,1hxacjv,https://moderndata101.substack.com/p/federated-modeling-when-and-why,1736420337.0,
bigdata,"Optimizing Retrieval Speeds for Fast, Real-Time Complex Queries",6,1hvjyig,https://www.reddit.com/r/bigdata/comments/1hvjyig/optimizing_retrieval_speeds_for_fast_realtime/,1736226116.0,"Dear big data geniuses:

  
I'm using snowflake to do complex muliti-hundred line queries with many joins and window functions. These queries can take up to 20 seconds. I need them to take <1 second. The queries are fully optimized on snowflake and cant be optimized further. What do you recommend?"
bigdata,How to create HIVE Table with multi character delimiter? (Hands On) ,4,1hurwxn,https://youtu.be/jgM3ds4_n4o,1736141542.0,
bigdata,"50+ Incredible Big Data Statistics for 2025: Facts, Market Size & Industry Growth",6,1hthw2p,https://bigdataanalyticsnews.com/big-data-statistics/,1736007688.0,
bigdata,25 Best Project Management software in 2025,0,1htc6wj,https://bigdataanalyticsnews.com/best-project-management-tools/,1735988681.0,
bigdata,About go get into Big Data ,8,1hsv9pr,https://i.redd.it/9k202a0j2uae1.jpeg,1735933831.0,"About to get into Big Data 

Hey there 

I’m 29 with background experience in farming, biology and nature with some skills related to tech and computers, looking forward to learn more about #BigData as I want to develop another career. 

What are your recommendations, tips, advices, etc.? 


p.s. Also my first time posting in Reddit, greetings from México🌮🌶️🇲🇽"
bigdata,"Hey folks! If you're in VC or a business analyst, you’ve got to check out this tool. It streams live data of VC-funded startups globally and gives you quick access to tons of company history (there's even a CSV or API option). Let me know if you want to give it a shot!",1,1hsyr6i,https://v.redd.it/5itajn3tsuae1,1735942713.0,
bigdata,[Poll] Has anyone used dbt's AI (dbt copilot) yet? What has your experience been?,2,1hs7pyr,/r/DataBuildTool/comments/1hs7pdf/has_anyone_used_dbts_ai_dbt_copilot_yet_what_has/,1735860170.0,
bigdata,guidance for finish and review my first mini-project,4,1hqgfr8,https://www.reddit.com/r/bigdata/comments/1hqgfr8/guidance_for_finish_and_review_my_first/,1735657345.0,"Hello guys , could anyone help me with reviewing and guide me thoughout my mini-project for big data ? ,this involves designing a (textual) information search engine and analyzing user reviews of your search engine.

here is the link : [https://www.kaggle.com/code/cherryblade29/notebook1e9ba773b0](https://www.kaggle.com/code/cherryblade29/notebook1e9ba773b0)"
bigdata,How automation and AI advanced data-driven reporting in 2024 [LinkedIn Post] ,2,1hq0ym3,https://www.linkedin.com/posts/rollstack_automating-data-driven-content-with-ai-activity-7279551358913953792-ax8p,1735601913.0,
bigdata,"Hey friends, if you're looking for a simple way to make some sales, you should consider selling to new startups that just landed venture capital! I found this awesome app that tracks real-time funding announcements, gathers verified emails of decision-makers, and even summarizes their buying hints w",0,1hpq5vk,https://v.redd.it/3c9m16qcc0ae1,1735573971.0,
bigdata,Hadoop vs. Spark: Which One Should Beginners Learn First?,5,1houh90,/r/BigDataEnginee/comments/1houfut/hadoop_vs_spark_which_one_should_beginners_learn/,1735472946.0,
bigdata,Welcome to r/BigDataEngineer: Let’s Build and Grow Together!,0,1hotwap,/r/BigDataEnginee/comments/1hotvvd/welcome_to_rbigdataengineer_lets_build_and_grow/,1735470480.0,
bigdata, Big data Hadoop and Spark Analytics Projects (End to End) ,27,1hkfzpa,https://www.reddit.com/r/bigdata/comments/1hkfzpa/big_data_hadoop_and_spark_analytics_projects_end/,1734927955.0,"Hi Guys,

I hope you are well.

Free tutorial on Bigdata Hadoop and Spark Analytics Projects (End to End) in **Apache Spark, Bigdata, Hadoop, Hive, Apache Pig, and Scala with Code and Explanation.**

***Apache Spark Analytics Projects:***

1. [Vehicle Sales Report – Data Analysis in Apache Spark](https://projectsbasedlearning.com/apache-spark-analytics/vehicle-sales-report-data-analysis/)
2. [Video Game Sales Data Analysis in Apache Spark](https://projectsbasedlearning.com/apache-spark-analytics/video-game-sales-data-analysis/)
3. [Slack Data Analysis in Apache Spark](https://projectsbasedlearning.com/apache-spark-analytics/slack-data-analysis/)
4. [Healthcare Analytics for Beginners](https://projectsbasedlearning.com/apache-spark-analytics/healthcare-analytics-for-beginners-part-1/)
5. [Marketing Analytics for Beginners](https://projectsbasedlearning.com/apache-spark-analytics/marketing-analytics-part-1/)
6. [Sentiment Analysis on Demonetization in India using Apache Spark](https://projectsbasedlearning.com/apache-spark-analytics/sentiment-analysis-on-demonetization-in-india-using-apache-spark/)
7. [Analytics on India census using Apache Spark](https://projectsbasedlearning.com/apache-spark-analytics/analytics-on-india-census-using-apache-spark-part-1/)
8. [Bidding Auction Data Analytics in Apache Spark](https://projectsbasedlearning.com/apache-spark-analytics/bidding-auction-data-analytics-in-apache-spark/)

***Bigdata Hadoop Projects:***

1. [Sensex Log Data Processing (PDF File Processing in Map Reduce) Project](https://projectsbasedlearning.com/bigdata-hadoop/sensex-log-data-processing-pdf-file-processing-in-map-reduce-part-1/)
2. [Generate Analytics from a Product based Company Web Log (Project)](https://projectsbasedlearning.com/bigdata-hadoop/generate-analytics-from-a-product-based-company-web-log-part-1/)
3. [Analyze social bookmarking sites to find insights](https://projectsbasedlearning.com/bigdata-hadoop/analyze-social-bookmarking-sites-to-find-insights-part-1/)
4. [Bigdata Hadoop Project - YouTube Data Analysis](https://projectsbasedlearning.com/bigdata-hadoop/youtube-data-analysis-part-1/)
5. [Bigdata Hadoop Project - Customer Complaints Analysis](https://projectsbasedlearning.com/bigdata-hadoop/customer-complaints-analysis-part-1/)

I hope you'll enjoy these tutorials."
bigdata,Searching For Hive Alternatives,2,1hkkq2k,https://www.reddit.com/r/bigdata/comments/1hkkq2k/searching_for_hive_alternatives/,1734948441.0,"My current setup is Hive on Tez, running on YARN with data stored in HDFS.  
I feel like this setup is a bit outdated, and that the performance is not great. However I can't find alternatives.  
Every technology I found so far fails in one of the requirements that I'll mention.

I have the following requirements:

1. Be able to handle huge analytical batch jobs, with multiple heavy joins
2. Scalable (Petabytes)
3. Fault-tolerant, jobs must finish
4. On-premise

Would like to hear your suggestions!"
bigdata,"Don't make the CFO wait. Use Rollstack to automate recurring reports (QBRs, Annual Reports, MBRs, etc.,) ",0,1hkukvg,https://i.redd.it/w0tmr9h1an8e1.png,1734980002.0,
bigdata,Will Data Science be a big deal in 2025?,0,1hj6p76,https://www.reddit.com/r/bigdata/comments/1hj6p76/will_data_science_be_a_big_deal_in_2025/,1734774582.0,"# 1. Getting to know Data Science

# Explaining Data Science

Think of data science as a high-tech detective blending stats, math, and code skills to sniff out cool clues and crack tough puzzles in humongous data piles.

# Why Data Science Rocks Today

Nowadays, with all our lives so wrapped up in data, data science is pretty much a magic element. It's what makes your Netflix picks so spot on, forecasts trends, and helps companies make super-smart choices.

# 2. What's Hot in Data Science

# All About Big Data Analytics

Imagine big data as an all-you-can-eat info spread. Data scientists are like skilled foodies who know how to fill their plates picking out the tasty bits of knowledge that can spice up business plans and spark new ideas.

# Machine Learning and AI Uses

Self-driving automobiles and digital helpers are causing a revolution in our tech interactions, and data scientists are the wizards working magic to make it happen.

# Ways to Present Data

Data visualization turns snooze-fest tables into enthralling masterpieces. It allows a quick grasp of intricate data and shares knowledge with others super .

# 3. What Makes Data Science So In-Demand

# The Rise of Making Choices Based on Data

Since data's become the hot commodity, companies are super eager for data pros. They need these smart folks to transform basic digits into powerful wisdom to guide top-level choices and help their biz expand.

# AI and Automation Demand More Data Pros

The demand for data scientists to create and improve algorithms for AI and automation is soaring. These skills are becoming red-hot in the employment sphere.

# Meeting the Bar for Regulatory Stuff

In our super connected era where keeping data safe is huge, companies want data scientists to help them wade through the complex rules to make sure they play fair and keep data use on the up-and-up.

# 4. The Tough and Good Stuff in Data Science

# Keeping Data Safe and Sound

With data mishaps popping up in the news, data scientists have the tough job. They've got to dig out the good stuff from the data while making sure none of the secret info gets into the wrong hands. They're juggling keeping things fresh and new with making sure everything stays locked down tight.

# Lack of Data Science Experts

As more people want data experts than there are available, this creates a tough spot but also a huge chance for folks aiming to jump into this area offering great jobs and fat paychecks.

# Data Science Rocks Various Sectors

Whether it's in health or money stuff, data science is causing a stir across different work areas. It's leading cool things like making meds just for you spotting cons, and figuring out groups of buyers, proving just how much it can do and how cool it can be.

# 5. What Data Science Might Look Like in 2025

# What to Expect in the Data Science Work Scene

Heading into 2025, folks can expect the data science job scene to keep on climbing. With companies in all sorts of businesses getting how critical data-informed decisions are, there's gonna be a huge ask for data science whizzes. Anyone in data science is looking at some pretty sweet career moves and loads of chances to snag a job.

# Tech Upgrades Making Waves in What's Next

Tech upgrades are huge in deciding [what's next for data science](https://www.usdsi.org/data-science-insights/future-of-data-science-10-predictions-you-should-know). All the cool stuff like artificial intelligence learning machines, and big-time data studies will push forward new stuff for data scientists to do in 2025. Jumping on the tech bandwagon is super important to not fall behind in data science's fast-paced world.

# 6. Tech Stuff Changing the Data Scene

# Blending Blockchain with Crunching Numbers

Blockchain is about to make a big splash in the number-crunching game. It's gonna ramp up security and make sure everything is clear and trackable when it comes to moving digits around. Merging this tech with the brainy science of data could start a whole new game for keeping our online facts straight and real when everything is linked up.

# Making Sense of Internet of Things (IoT) Stats

Okay so all these Internet of Things gadgets are spitting out crazy amounts of info that's got some real golden nuggets hidden in there. By 2025, the brainiacs working with numbers will gotta dig in with some fancy figuring-out tricks to pull out the gems from this data gush. Getting a grip on this IoT number crunching is key for groups looking to smarten up their choices and spark some fresh ideas.

# 7. What You Gotta Have to Be a Data Scientist in 2025

# Know Your Coding and Gadget Game

Data scientists waiting for 2025 got to know their stuff with a bunch of coding languages and gadgets. You gotta be tight with Python, R, SQL, and TensorFlow. Being a wizard with these allows you to mess with big complex data, cook up some solid predictive stuff, and pull out the kind of know-how that makes businesses rock and roll.

# "
bigdata,"Build Real-Time Systems with NATS and Pathway, Scalable Alternatives to Apache Kafka and Flink",11,1hhsukf,https://www.reddit.com/r/bigdata/comments/1hhsukf/build_realtime_systems_with_nats_and_pathway/,1734614782.0,"Hey everyone! I wanted to share a tutorial created by a member of the Pathway community that explores using [NATS](https://docs.nats.io/) and [Pathway](https://pathway.com/) as an alternative to a Kafka + Flink setup.

The tutorial includes step-by-step instructions, sample code, and a real-world fleet monitoring example to show how you can simplify data pipelines while still handling large volumes of streaming data. It walks through setting up basic publishers and subscribers in Python with NATS, then integrates Pathway for real-time stream processing and alerting on anomalies.  
  
**App template link (with code and details):**  
[https://pathway.com/blog/build-real-time-systems-nats-pathway-alternative-kafka-flink](https://pathway.com/blog/build-real-time-systems-nats-pathway-alternative-kafka-flink) 

**Key Takeaways:**

* **Seamless Integration:** Pathway’s native NATS connectors allow direct ingestion from NATS subjects, reducing integration overhead.
* **High Performance & Low Latency:** NATS delivers messages quickly, while Pathway processes and analyzes data in real time, enabling near-instant alerts.
* **Scalability & Reliability:** With NATS clustering and Pathway’s distributed workloads, scaling is straightforward. Message acknowledgment and state recovery help maintain reliability.
* **Flexible Data Formats:** Pathway handles JSON, plaintext, and raw bytes, so you can choose the data format that suits your needs.
* **Lightweight & Efficient:** NATS’s simple pub/sub model is well-suited for asynchronous, cloud-native systems—without the added complexity of a Kafka cluster.
* **Advanced Analytics:** Pathway supports real-time machine learning, dynamic graph processing, and complex transformations, enabling a wide range of analytical use cases.

Would love to know what you think—any feedback or suggestions."
bigdata,MASTER DATA SCIENCE ACCELERATE YOUR FUTURE,2,1hhq92i,https://www.reddit.com/r/bigdata/comments/1hhq92i/master_data_science_accelerate_your_future/,1734605056.0,"https://preview.redd.it/iebxtn3dbs7e1.jpg?width=800&format=pjpg&auto=webp&s=36f9d0083def416dadc2e309f6e0544dab469776

    Organizations need data-driven leaders. With the USDSI® Certification, master data science skills that unlock insights, fuel decisions, and accelerate business growth. Become the data expert companies trust.
    "
bigdata,I built an end-to-end data pipeline tool in Go called Bruin ,7,1hhc8b5,https://www.reddit.com/r/bigdata/comments/1hhc8b5/i_built_an_endtoend_data_pipeline_tool_in_go/,1734557142.0,"Hi all, I have been pretty frustrated with how I had to bring together bunch of different tools together, so I built a CLI tool that brings together data ingestion, data transformation using SQL and Python and data quality in a single tool called Bruin:

[https://github.com/bruin-data/bruin](https://github.com/bruin-data/bruin)

Bruin is written in Golang, and has quite a few features that makes it a daily driver:

* it can ingest data from many different sources using [ingestr](https://github.com/bruin-data/ingestr)
* it can run SQL & Python transformations with built-in materialization & Jinja templating
* it runs Python fully locally using the amazing [uv](https://github.com/astral-sh/uv), setting up isolated environments locally, mix and match Python versions even within the same pipeline
* it can run data quality checks against the data assets
* it has an open-source [VS Code extension](https://bruin-data.github.io/bruin/vscode-extension/overview.html) that can do things like syntax highlighting, lineage, and more.

We had a small pool of beta testers for quite some time and I am really excited to launch Bruin CLI to the rest of the world and get feedback from you all. I know it is not often to build data tooling in Go but I believe we found ourselves in a nice spot in terms of features, speed, and stability.

Looking forward to hearing your feedback!

[https://github.com/bruin-data/bruin](https://github.com/bruin-data/bruin)"
bigdata,The Art of Discoverability and Reverse Engineering User Happiness,2,1hg9u75,https://moderndata101.substack.com/p/the-art-of-discoverability-and-reverse,1734439533.0,
bigdata,String to number in case of having millions of unique values,1,1hgdqtn,https://www.reddit.com/r/bigdata/comments/1hgdqtn/string_to_number_in_case_of_having_millions_of/,1734451126.0,"Hello,  
I am currently working on preprocessing big data dataset for ML purposes. I am struggling with encoding strings as numbers. I have a dataset of multiple blockchain transactions and I have addresses of sender and receivers for these transactions. I use pyspark.

I've tried String Indexer but it throws out of memory errors due to number of unique values. How should I approach it? Is hasing with SHA256 and casting to big int good approach? Wouldn't big numbers influence ML methods too much? (i will try different methods ex. random forests, gan, some based on distance etc)"
bigdata,Data Science Projects for Beginners | Infographic,1,1hg8twp,https://www.reddit.com/r/bigdata/comments/1hg8twp/data_science_projects_for_beginners_infographic/,1734435744.0,"One way to excel above your competitors in the race for top data science jobs is by showcasing your practical experience and a strong portfolio to demonstrate your data science skills and knowledge practically. Check out our detailed infographic to learn about popular [data science projects](https://www.usdsi.org/data-science-insights/role-of-major-components-in-data-science-projects) for beginners that you can work on to apply your theoretical data science knowledge practically and build a strong portfolio. 

https://preview.redd.it/qn8ilmoxbe7e1.jpg?width=1080&format=pjpg&auto=webp&s=ff704d8e8a7fe6909dae083229e1c34771b95507

"
bigdata,Step-by-Step Tutorial: Setting Up Apache Spark with Docker (Beginner Friendly),2,1hfup8a,https://www.reddit.com/r/bigdata/comments/1hfup8a/stepbystep_tutorial_setting_up_apache_spark_with/,1734386073.0,"Hi everyone! I recently published a video tutorial on setting up Apache Spark using Docker. If you're new to Big Data or Data Engineering, this video will guide you through creating a local Spark environment.

📺 Watch it here: [https://www.youtube.com/watch?v=xnEXAD9kBeo](https://www.youtube.com/watch?v=xnEXAD9kBeo)

Feedback is welcome! Let me know if this helped or if you’d like me to cover more topics."
bigdata,Free Ungated Whitepaper: Personalized healthcare reporting with data and AI,2,1hfn1h0,https://www.rollstack.com/case-studies/personalized-healthcare-data-reporting-for-client-success,1734366719.0,
bigdata,Data-Driven Recruitment The WorkWolf Revolution,0,1hdzmhe,https://www.reddit.com/r/bigdata/comments/1hdzmhe/datadriven_recruitment_the_workwolf_revolution/,1734169453.0,"Discover how WorkWolf is transforming the recruitment game by reducing bias and enhancing efficiency with data-driven solutions. As the future of work becomes more data-centric, HR professionals must adapt to ensure ethical and fair hiring practices. [WorkWolf Revolution](https://www.usdsi.org/data-science-insights/data-driven-recruitment-using-workwolf-to-reduce-bias-and-increase-efficiency)

https://preview.redd.it/yvoj2h33cs6e1.jpg?width=1080&format=pjpg&auto=webp&s=58d3f24e9d25fbc390dab129366db0ebb290f53b

"
bigdata,30 Best IDE Software for Developers in 2025,0,1hdckux,https://bigdataanalyticsnews.com/top-ides-for-programmers/,1734097729.0,
bigdata,"DATA VISUALIZATION IN R: CHEATSHEET AHEAD OF 2025 | INFOGRAPHIC

",0,1hdbw7e,https://www.reddit.com/r/bigdata/comments/1hdbw7e/data_visualization_in_r_cheatsheet_ahead_of_2025/,1734095544.0,"Understanding data science has never been this convenient as it amalgamates with the R programming language. [Data science in R](https://www.usdsi.org/data-science-insights/data-visualization-in-r-cheatsheet-ahead-of-2025) is turning tables for deeper data-driven business insights to guide a better business landscape ahead. 

https://preview.redd.it/kehq19q88m6e1.jpg?width=1200&format=pjpg&auto=webp&s=545aa2e49a1d1c962d8e8067575aaffe1ed33ab6

"
bigdata,Data Science Roadmap 2025,4,1hch7ch,https://www.reddit.com/r/bigdata/comments/1hch7ch/data_science_roadmap_2025/,1733994686.0,"Explore the evolutionary journey of data science as it intertwines human intelligence with cutting-edge technology. This roadmap delves into essential skills, tools, and adaptations required to thrive in the ever-changing analytics landscape of 2025. [Data Science Roadmap 2025](https://www.usdsi.org/data-science-insights/data-science-roadmap-2025-a-darwinian-evolution-of-analytics)

https://preview.redd.it/06sw992fwd6e1.jpg?width=1920&format=pjpg&auto=webp&s=d82a7a1fd59ac6a5022323e7b4d717b0feacfa3a

"
bigdata,How Do You Do Data?,0,1hcai3m,https://www.reddit.com/r/bigdata/comments/1hcai3m/how_do_you_do_data/,1733969122.0,"Just curious about the types of infrastructure you folks use. Specifically, what kind of chips are you using to train/fine-tune/run your deep models?

I appreciate you filling out this  survey.

[https://forms.gle/uiAmfG9K7MpFvQtK7](https://forms.gle/uiAmfG9K7MpFvQtK7)"
bigdata,For those like me who like to have music on the background while working ,0,1hc5gm9,https://www.reddit.com/r/bigdata/comments/1hc5gm9/for_those_like_me_who_like_to_have_music_on_the/,1733954734.0,"I often need background music to help me increase my productivity while working. I created these playlists which I update regularly They help me stay calm, focused and productive. Perfect academia playlists! 



Ambient, chill & downtempo trip (a tasty mix of ambient, downtempo, IDM, trip-hop, electronica, jazz house music and more. Chill, hypnotic, trippy and atmospheric grooves for focus, relaxation, and deep listening) [https://open.spotify.com/playlist/7G5552u4lNldCrprVHzkMm?si=6fiOfJmeRi2CrnhNwHzyzg](https://open.spotify.com/playlist/7G5552u4lNldCrprVHzkMm?si=6fiOfJmeRi2CrnhNwHzyzg) 



Mental food (A bit of the same atmosphere as the previous one) [https://open.spotify.com/playlist/52bUff1hDnsN5UJpXyGLSC?si=37JEertEQkG9aba7xETmow](https://open.spotify.com/playlist/52bUff1hDnsN5UJpXyGLSC?si=37JEertEQkG9aba7xETmow) 



Something else (atmospheric, poetic, calm, soothing, cinematic and ambient soundscapes with a touch of mystery. Relaxing instrumental music for focus, relaxation, introspection, reading, writing, studying, meditation and mindfulness practice.) [https://open.spotify.com/playlist/0QMZwwUa1IMnMTV4Og0xAv?si=XEQqfz8OQaSDS\_JvzkUYUw](https://open.spotify.com/playlist/0QMZwwUa1IMnMTV4Og0xAv?si=XEQqfz8OQaSDS_JvzkUYUw) 



Pure ambient (calming ambient music designed to enhance focus, relaxation, study, meditation, sleep, and mindfulness) [https://open.spotify.com/playlist/6NXv1wqHlUUV8qChdDNTuR?si=RE0d-iHuQd-5hGtboUq4OQ](https://open.spotify.com/playlist/6NXv1wqHlUUV8qChdDNTuR?si=RE0d-iHuQd-5hGtboUq4OQ) 



Chill lofi day (mix of smooth lofi hip-hop beats, chillhop, jazzhop and soothing vibes. Chill background music for studying, working, reading or just unwinding) [https://open.spotify.com/playlist/10MPEQeDufIYny6OML98QT?si=NZ\_vPqdYQc-idTOg-kt5Vg](https://open.spotify.com/playlist/10MPEQeDufIYny6OML98QT?si=NZ_vPqdYQc-idTOg-kt5Vg) 


French Producers (dedicated to new independent French producers.  Several electronic genres covered but mostly chill) [https://open.spotify.com/playlist/5do4OeQjXogwVejCEcsvSj?si=4WN5523VRA6uaAvN5RDGLQ](https://open.spotify.com/playlist/5do4OeQjXogwVejCEcsvSj?si=4WN5523VRA6uaAvN5RDGLQ) 



Jrapzz (the latest in modern jazz with a mix of Nu-Jazz, Jazzhop, Acid Jazz, Jazz UK, Ambient Jazz, Jazztronica, Jazz House, Nu-Soul, Hip-Hop Jazz, rather chill) [https://open.spotify.com/playlist/3gBwgPNiEUHacWPS4BD2w8?si=pZ1LxONJSYqQRR483Q55tA](https://open.spotify.com/playlist/3gBwgPNiEUHacWPS4BD2w8?si=pZ1LxONJSYqQRR483Q55tA) 



Cool stuff (chill indie pop & rock fresh finds, from emerging independent artists and few recognized talents) [https://open.spotify.com/playlist/2mgbWuWrYSVPrPNHbQMQec?si=FVMlFI5gTiWPkaJUWPUJtA](https://open.spotify.com/playlist/2mgbWuWrYSVPrPNHbQMQec?si=FVMlFI5gTiWPkaJUWPUJtA) 



Enjoy! 


\- 


H-Music"
bigdata,Governance for AI Agents with Data Developer Platforms,2,1hbsznu,https://moderndata101.substack.com/p/governance-for-ai-agents-with-ddp,1733922232.0,
bigdata,Data Science Command the Future of Businesses in 2025?,2,1hbocvq,https://www.reddit.com/r/bigdata/comments/1hbocvq/data_science_command_the_future_of_businesses_in/,1733902639.0,"Data science has been transforming businesses for a long time now. But are these technologies capable of changing the future of the world? Download our comprehensive resource to understand the impact of data science on the world's future. To [download](https://www.usdsi.org/data-science-insights/resources/can-data-science-command-the-future-of-businesses-in-2025), click below.

https://preview.redd.it/x9f6awrqa66e1.jpg?width=1050&format=pjpg&auto=webp&s=0bf5a1720f7671c964936a13a2921a876a025fe1

"
bigdata,2025 Guide to Architecting an Iceberg Lakehouse,3,1hb2w3b,https://medium.com/data-engineering-with-dremio/2025-guide-to-architecting-an-iceberg-lakehouse-9b19ed42c9de,1733840675.0,
bigdata,"Hey, I collected IMO the best product analytics tools for 2025",5,1hb0upu,https://www.reddit.com/r/bigdata/comments/1hb0upu/hey_i_collected_imo_the_best_product_analytics/,1733834425.0,"Helloo, I made a blogpost about the possible best product analytics tools (warehouse native and traditionals). Feel free to add any experience or comment. Thank youu

https://medium.com/@pambrus7/6-product-analytics-tool-for-2025-ab9766510551"
bigdata,Has anyone tried this analytics automation tool yet? (Rollstack) What did you think? ,4,1haepvt,https://www.linkedin.com/posts/nathanbc_tableau-datafam-businessintelligence-activity-7271932754571718656-oOaf?utm_source=share&utm_medium=member_desktop,1733764394.0,
analytics,Monthly Career Advice and Job Openings,3,1i51oay,https://www.reddit.com/r/analytics/comments/1i51oay/monthly_career_advice_and_job_openings/,1737302445.0,"1. Have a question regarding interviewing, career advice, certifications?  Please include country, years of experience, vertical market, and size of business if applicable.
2. Share your current marketing openings in the comments below. Include description, location (city/state), requirements, if it's on-site or remote, and salary.

Check out the community sidebar for other resources and our Discord link"
analytics,Looking for community feedback,16,1dj1a5b,https://www.reddit.com/r/analytics/comments/1dj1a5b/looking_for_community_feedback/,1718744143.0,"Hey r/analytics community,

As this group continues to grow I want to make sure majority are finding it useful.

I'm looking for your ideas of where we can improve this group and what do you love about it, leave your comments below."
analytics,"What master's should I pursue: CS, Math, Stats, Economics, or MBA? ",21,1i4nlb2,https://www.reddit.com/r/analytics/comments/1i4nlb2/what_masters_should_i_pursue_cs_math_stats/,1737252428.0,"Data Analyst with 3 years of experience and currently working as one. 

I have a Bachelor's in mathematics from Cal State Northridge. 

I'm looking to go for a master's in any field that will help look more impressive for promotions and to increase my knowledge further with data. I also would like to look more appealing(apart from any work experience and projects) for future prospective jobs. "
analytics,How do you guys create data presentations after analysis?,4,1i4tkr1,https://www.reddit.com/r/analytics/comments/1i4tkr1/how_do_you_guys_create_data_presentations_after/,1737273371.0,"I have to frequently create data presentations to explain my findings. I've tried a few tools and a I have to do lot of things are pretty manually. So, just wanted to know if you guys have any tricks or do you also manually insert data in powerpoint charts or add screenshots. 

And how do you decide on the story? Isn't this is hard process, to use right brain after all that left.

Would love to know your workflow or any tools you guys use?"
analytics,Need recommendation and sources ,3,1i4tpjq,https://www.reddit.com/r/analytics/comments/1i4tpjq/need_recommendation_and_sources/,1737273939.0,"Hello guys I'm a finance graduate and also want to breat into data analytics with finance. Although I have a basic knowledge of python. I don't know which courses should I do...
Please help"
analytics,"Without a degree, now planning to shift into Data Analyst ",13,1i4aavf,https://www.reddit.com/r/analytics/comments/1i4aavf/without_a_degree_now_planning_to_shift_into_data/,1737215271.0,"So initially i did my Bachelors but due to one zero credit subject which i failed held me back and i didn't get my degree, due to family pressure and finances I Had to return my own country where I got a job as supervisor in a company, and soon promoted to assistant manager on the side I did SEO and other analytical stuff which i was always interested about.

Now im planning to take a jump in my career im 26 and i don't want to be late on the boat, Im thinking of going through basic SQL, fundamentals, Power Bi, Tableu, thinking of doing some projects to add to my portfolio, thinking of also doing few months apprenticeship in data analyst meanwhile thinking of networking in Linkedin and finally applying for a data analyst job to get my career to begin, am i missing anything ? Do let me know ? Thanks in advance"
analytics,"Business Analysts in Aus - what course did you take, what would you do differently?",1,1i4skez,https://www.reddit.com/r/analytics/comments/1i4skez/business_analysts_in_aus_what_course_did_you_take/,1737269094.0,"I am a project manager keen to learn BA skill. Can you become a BA without formal qualifications?  If you need qualifications to work, what courses would you recommend? If you were to start over - what would you change about the way you came to become a BA."
analytics,"Want to transition into more into a data management titled role, what resources or training could help transition into this role with only document management experience",2,1i4h8fn,https://www.reddit.com/r/analytics/comments/1i4h8fn/want_to_transition_into_more_into_a_data/,1737233921.0,c
analytics,Data analysis tools,10,1i42obl,https://www.reddit.com/r/analytics/comments/1i42obl/data_analysis_tools/,1737186662.0,"Please bear with me I have a question, I'm an IT BA and recently I'm considering moving to another company, but I realized a lot of job postings require certain DA tools knowledge like power BI, Tableau...etc. And I was thinking I could start working on them to learn and stuff but my issue is that my day to day job doesn't include working with data in anyform, since I do systems and software business analysis I don't seem to find a purpose in learning these tools. I mainly work with requirements and technical specifications and visualization of the projects scope, I do have to track all that and keep backlogs of everything but again I don't think DA tools would help with any of that.

But I still feel like I wanna aquire this skillset just in case.

My question is, is there a way to incorporate these tools to fit within my work scope, or should I consider learning other tools? Or should I just learn them for the heck of it!

Guide me please 🥺 

"
analytics,Am I a decent candidate for a analytics job? ,6,1i3pen0,https://www.reddit.com/r/analytics/comments/1i3pen0/am_i_a_decent_candidate_for_a_analytics_job/,1737144387.0,"Recent graduate with biomedical informatics degree, relevant courses to Data Analytics taken - Biomed Data Analytics l and ll. also did a capstone project where took a bunch of data from an excel and used python to clean, analyze, and put it through machine learning to predict an outcome. Although my major isn’t something specific like data science, i’m wondering if i should waste my time applying for data analyst positions, or any other “analyst” positions with what I have. Thank you "
analytics,Data headcount vs company size,3,1i3tdpa,/r/BusinessIntelligence/comments/1i3t9gk/data_headcount_vs_company_size/,1737155057.0,
analytics,is it worth it?,2,1i3w394,/r/dataanalysiscareers/comments/1i3w257/is_it_worth_it/,1737162899.0,
analytics,Is this considered Data Analytics?,0,1i3tyno,https://www.reddit.com/r/analytics/comments/1i3tyno/is_this_considered_data_analytics/,1737156699.0,"Hi! I have a degree in Economics with a major in Applied Statistics and am interested in pursuing a career as a data analyst, with the eventual goal of transitioning into data science.

I recently started a new role where my tasks include creating report charts (using Q for significant testing and then visualizing the data in PowerPoint), cleaning datasets, and performing QA to ensure accuracy in reports.

However, I don’t currently use SQL or Python in my job. Given these responsibilities, do you think this experience will help me progress toward a career in data science, or would it be better to explore other opportunities?"
analytics,QlikSense Developer [$45 per hour] Needed in SF Bay Area,0,1i3ve37,https://www.reddit.com/r/analytics/comments/1i3ve37/qliksense_developer_45_per_hour_needed_in_sf_bay/,1737160790.0,"Hi Folks, 

I am looking for a mid-level QlikSense Developer \[$45 per hour\] to work for an AI startup.

This is a hybrid role - at times you have to come in person. 

If interested please get in touch with me [Chris@Analyze.Agency](mailto:Chris@Analyze.Agency)"
analytics,Mid-level and a bit stuck,35,1i2wy2q,https://www.reddit.com/r/analytics/comments/1i2wy2q/midlevel_and_a_bit_stuck/,1737055375.0,"I’m a mid-level data analyst with 6 years experience and a SQL, PowerBI, PowerQuery, Excel stack. 

I recently quit my job because of the workload (they had me doing 10-14 hours a day, insane) and now I feel kinda stuck in terms of where to go. 

I’ve been applying to mid-level positions but it feels like my tech stack isn’t enough anymore. Lots os positions include Python, R, database management, etc. I feel like I need to expand my stack but I’m a bit lost as to what I should focus on. 

In your experience, what are some areas which have good demand for  mid-level professionals?"
analytics,Google Data Analytics worth it?,31,1i2wbgh,https://www.reddit.com/r/analytics/comments/1i2wbgh/google_data_analytics_worth_it/,1737053794.0,"Hi, is the above really worth it? I'm currently studying L4 Data Analytics via work but the material is much better I think on Coursera (trialling the 7 day free version). 

Is the cert still worth it? YouTube tells me one thing but I wanted thoughts from real people in the field.

Thanks "
analytics,Desperate for Advice ,7,1i356je,https://www.reddit.com/r/analytics/comments/1i356je/desperate_for_advice/,1737077814.0,"Started uni in 2021 as a Finance major --> 

**1st year**: Didn't do much.

**2nd year**: Joined 2 finance clubs my 2nd year thinking I was going to pursue Investment Banking. Realized that a 90+ hour work week was not for me, so I decided not to pursue that path.

**3rd year**: Took a data analytics class and intro comp sci class during the Fall semester. Turns out I enjoyed technical work more than making stock pitches so decided to add a Business Analytics major and a Comp Sci minor. Took 3 business analytics classes and 1 cs class during the Winter semester and realized most BA courses were poorly structured and often unavailable due to lack of professors. Figured taking Comp Sci classes would be a better investment of my time and money.

**4th year**: Took 3 cs classes last semester (F2024) and currently taking 2 this semester. 

Currently have a 3.75 GPA and will be graduating next year in may (W2026)

Have used Python (Pandas, NumPy, Scikit-learn), SQL, PowerBI, R, Java, Excel, PowerPoint for class assignments/projects (nothing too complicated).

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

Due to family constraints, I was not able to work during my time at uni and, as a result, have no internship experience. Things have changed this year though so I am now able to pursue internships. Since I am at the end of my 4th year, I have F2025, W2026, and possibly S2026 to gain internship experience.

So I guess I'm looking for advice on how to move forward towards getting an internship within data analytics. I know a solid portfolio is super important, so that should be 1st step, but I don't know what projects to do and where to even begin. Ideally I'd want to leverage my finance background to land a data analyst/business intelligence role within the finance sector so any ideas for projects would be very appreciated. Also what skills should I learn/refine, what books/resources should I be reading/using to put myself in a better position to land an internship. Honestly just looking for general tips on the steps I need to take atm. 

Thank you :)

"
analytics,Do personal projects help in getting a data analyst role?,24,1i2tt60,https://www.reddit.com/r/analytics/comments/1i2tt60/do_personal_projects_help_in_getting_a_data/,1737047470.0,"I’m currently working as a data analyst which only requires some basic Excel and Power BI. I want to break into a role that works with SQL and Python as well (i’ve been self-learning about them). I’ve only been invited to job interviews of the roles that only require Excel & Power BI, which are what i’ve been doing in my current role. "
analytics,Any websites where I can download books for analytics ,1,1i3bqsj,https://www.reddit.com/r/analytics/comments/1i3bqsj/any_websites_where_i_can_download_books_for/,1737101800.0,My uni requires me to buy books its kinda expensive is there any place or source to get these for free 
analytics,"Degree in English with no previous data anlytics experience, starting learning statsitics and planning to move to tools, any recommendations for building up a resume?",1,1i380hi,https://www.reddit.com/r/analytics/comments/1i380hi/degree_in_english_with_no_previous_data_anlytics/,1737086841.0,entry job
analytics,Chances of getting a job with a cs degree and projects ,5,1i2xvyt,https://www.reddit.com/r/analytics/comments/1i2xvyt/chances_of_getting_a_job_with_a_cs_degree_and/,1737057763.0,I live in Orlando and am open to in office (but it’s not exactly a tech hub so remote would be preferable). Moving is not really an option due to marriage/kids/house. I’m 2 classes away from graduating and want to know if I should even bother or just change careers with how depressing the CS and all related career forums have been. Am I cooked? Does the CS degree hold any weight? I thought this was an entry level field but others say no so then what is? I think my personal goal is at most a year of job searching. Is this realistic in this job market? 
analytics,PlumbingJobs.com ~ Sharing the analytics of my job board site (summary of how it's going after the third month),5,1i2z986,https://www.reddit.com/r/analytics/comments/1i2z986/plumbingjobscom_sharing_the_analytics_of_my_job/,1737061300.0,"On October 12th 2024, I launched PlumbingJobs.com, and this is my first update (January 2025) in what I hope will be a long journey.

To stay accountable and track progress, I’ll be sharing monthly updates about the site's stats, achievements, challenges, and my plans moving forward. While these posts are mostly to document the journey, I hope they’ll also be helpful to others, especially members of r/analytics who might be interested in learning the web analytics of a job board website.

If this post isn’t a good fit for this subreddit, I’m happy to remove it or move updates elsewhere.

The goal for PlumbingJobs.com is clear: to become the #1 job board for plumber jobs, featuring hand-picked opportunities the plumbing industry.

Let’s dive right in:

# Statistics update ~ 4th Quarter of 2024

|\-|October|November|December|
|:-|:-|:-|:-|
|Jobs Posted:|2|16|43|
|Paid Post:|0|2|2|
|Free Post:|0|1|2|
|Visitors:|72|138|1,164|
|Avg. Time Per Visit:|1 min. 24 sec|2 min. 15 sec|3 min. 41 sec|
|Pageviews:|196|308|2,590|
|Avg. Actions:|1.1|2.3|2.3|
|Bounce Rate:|87%|73%|40%|

I'm not a very technical guy and I don't know how to code. So the best way for me was learning to build it using Wordpress through YouTube. Also, I believe in the power of a great domain name, and the stats from the first three months have only reinforced that belief:

* **49.2% of traffic** comes directly from users typing the URL into their browsers.
* **48% of traffic** is from search engines like Google and Bing.
* The remaining **1.8%** comes from social media and other backlinks.

# Tech-Stack

Wordpress - Website + CMS

Gravity Forms - Form + PayPal payments integration

GeneratePress - WP Them

WP Grid Builder - For Grids & Cards

Clicky - Traffic Analytics

ChatGPT - Rewriting the job ad

Make - automating the flow

# Pricing Tiers and Early Wins

I offer three pricing tiers for job listings:

* **Free Listing**: Basic exposure for job openings.
* **Silver Listing** ($45): Greater visibility and placement on the site.
* **Gold Listing** ($95): Premium visibility and enhanced promotion.

To my surprise, my very first sale in October was a **Gold Listing**! That initial $95 sale was the motivation I needed to keep building. Later that month, I sold a **Silver Listing**, bringing my total revenue for October to $140. The same revenue was generated in December 2024, showing consistent early interest.

# Steps Taken in December

To boost SEO and add value to the site, I created a Plumbing Directory, featuring:

* Plumbing companies across the U.S.
* Their stories, contact information, logos, addresses, business hours, and more.

This directory serves as free marketing for these businesses and increases the likelihood they’ll discover my site and support it by posting job openings.

# Plans Moving Forward

1. **Social Media Marketing**: I plan to automate posts using AI to expand reach and drive more traffic to the site.
2. **Consistency in Job Postings**: I’m committed to posting 2–3 plumbing jobs daily to keep the site fresh and useful for plumbers seeking work.

Looking forward to grow this niche job board slowly but surely this 2025. If you have any questions, concerns, come across glitches - feel free to reach out, happy to chat.

Thank you all again, and see you in a month.  
[Romel@plumbingjobs.com](mailto:Romel@plumbingjobs.com)"
analytics,Legit Contractor Companies?,4,1i2vuna,https://www.reddit.com/r/analytics/comments/1i2vuna/legit_contractor_companies/,1737052595.0,"I get contacted by recruiters all the time and many of them seem like a scam. They barely speak English or they send a poorly worded email that goes right to spam. I was considering doing contract work, but it is difficult to determine which companies are legit. Does anyone have some suggestions for Companies that hire analytics, data science, and data architects that are legitimate and actually have contracts? "
analytics,Aws vs Google data certificates ,2,1i2y2j0,https://www.reddit.com/r/analytics/comments/1i2y2j0/aws_vs_google_data_certificates/,1737058223.0,Most posts I see are saying that the Google cert is pretty worthless. What about an AWS cert for an entry level candidate in business or data analytics? Maybe the data engineer cert or solutions architect? Or are the days of certs behind us in this job market? 
analytics,Perplexity with complex data aggregation,0,1i32xb0,https://www.reddit.com/r/analytics/comments/1i32xb0/perplexity_with_complex_data_aggregation/,1737071205.0,"I’m working on a project that uses AI to calculate complex statistics that don’t exist anywhere online—percentages and insights that typically take hours to aggregate manually. For example:

* **“What percentage of unicorn startups from 2024 had at least one remote cofounder?”**
* **“What percentage of developed countries with republican leaders have governments that cover 100% of healthcare costs for their citizens?”**

The tool generates these stats automatically, combining information from various sources using a controllable reasoning process.

My question to you is:

* Would this be useful for your daily work? Are there situations where you've been frustrated by perplexity failing to get a statistic you were looking for?
* Would you pay a premium for access to this kind of data, and why?

I’d love to hear your thoughts and ideas! Feel free to ask questions if anything sounds unclear."
analytics,Should I learn Python or SQL as a complete beginner to become Data Analyst?,101,1i26ypb,https://www.reddit.com/r/analytics/comments/1i26ypb/should_i_learn_python_or_sql_as_a_complete/,1736972998.0,"Basically the title, some are suggesting to begin with Python and some say SQL.

Can I/Should I learn both simultaneously?

P.S. I do not have any coding experience."
analytics,Rotman MMA vs McGill MMA,2,1i2tkkl,https://www.reddit.com/r/analytics/comments/1i2tkkl/rotman_mma_vs_mcgill_mma/,1737046864.0,"Hi,

  
So I've recently been given an offer for both McGill MMA and Rotman MMA programs. I was wondering what the pros and cons are for both and if anyone has any tips on which program I should choose to complete my graduate studies.

"
analytics,Best place to find an Oracle Analytics consultant,1,1i2vw45,https://www.reddit.com/r/analytics/comments/1i2vw45/best_place_to_find_an_oracle_analytics_consultant/,1737052703.0,"The businesses main application runs on an Oracle database.  We have Oracle Analytics v5.9.  I'm looking for an expert that could build us an executive dashboard in OA to show previous day, current day, YOY, etc and build us some automated reports.  

Where is the place to find a consultant for this?"
analytics,Generalization of Newton's method,2,1i2p8lx,https://www.reddit.com/r/analytics/comments/1i2p8lx/generalization_of_newtons_method/,1737035145.0,"Hello, all,

This may be a stupid or naive question but here goes: I know the univariate version of Newton's method from having studied numerical analysis in grad school.  I am currently taking the Andrew Ng machine learning course and am about to learn the gradient steepest descent method and its application in ML.  (Learned about gradients and their properties in Calc 3 in college.)  Can someone explain to me why you would use the steepest descent method vs. the generalized multivariate Newton's method in optimization problems?  What am I missing?

Thanks,

K.S."
analytics,Where can I find data or market research on the games Silver Spenders play?,1,1i2kpg6,https://www.reddit.com/r/analytics/comments/1i2kpg6/where_can_i_find_data_or_market_research_on_the/,1737017320.0,"Hello everyone,

I’m looking for information or insights about the ""Silver Spenders,"" a term used to describe people aged 50 and above.

What types of games are they playing, and where can I find or conduct market research on this demographic?

Thanks a lot!"
analytics,had a technical interview 2 days ago and having a panic attack because I haven't heard back,0,1i2nnud,https://www.reddit.com/r/analytics/comments/1i2nnud/had_a_technical_interview_2_days_ago_and_having_a/,1737029954.0,"I don't know why I'm having a panic attack because I think did really fucking bad in the interview, I got so nervous that I had to look up the syntax for the group by function in pandas, so why would I expect anything besides a rejection anyway

they started by asking me some theory stuff (discuss the differences between sets, lists, dicts, what's a tuple, etc) which I did really well on because of my math background. that sort of stuff is my strongest area, I can remember theory much more easily than I can remember precise syntax. then we did some pandas shit and I completely froze up for a second, had to google group by and something else, but I told them that I was like really panicking in the moment and freezing up. I was able to do some of the other stuff they asked for, transform a column and turn it into a new column, I optimized the work with a lambda function. I don't fucking know. then some more theory stuff, what's an array in numpy? which I sort of answered, it's a multidimensional vector or tensor, I also said I was pretty sure every element had to be of the same type, but I wasn't able to speak to the more technical components since I don't directly work with numpy often 

then there was a sql question, I did ok on the first question though it took a bit of prompting, second question I didn't understand it was something about primary keys and regular keys and I was like yeah I completely forgot what a regular key is, then the third question was to write a query which was easy

I told them at the end I don't think I did well. one of the interviewers said I did better than I think and the other said I was in ""the top percentile,"" I really don't know what the hell that's supposed to mean in context

now it's been two days and I haven't heard anything, I'm so fucking over this I;ve been looking for eight + months for a job and ive done so many interviews and nobody will fucking hire me and id on't know what to do because I can't get EXPERIENCE if nobody fucking HIRES ME"
analytics,How to drive business outcomes with data and AI products (price optimization),5,1i286j9,https://www.reddit.com/r/analytics/comments/1i286j9/how_to_drive_business_outcomes_with_data_and_ai/,1736976163.0,"We must not forget that our job is to create value with our data initiatives. So, here is an example of how to drive business outcome.

CASE STUDY: Machine learning for price optimization in grocery retail (perishable and non-perishable products).

BUSINESS SCENARIO: A grocery retailer that sells both perishable and non-perishable products experiences inventory waste and loss of revenue. The retailer lacks dynamic pricing model that adjusts to real-time inventory and market conditions.

Consequently, they experience the following.

1) Perishable items often expire unsold leading to waste.

2) Non-perishable items are often over-discounted. This reduces profit margins unnecessarily.

METHOD: Historical data was collected for perishable and non-perishable items depicting shelf life, competitor pricing trends, seasonal demand variations, weather, holidays, including customer purchasing behavior (frequency, preferences and price sensitivity etc.).

Data was cleaned to remove inconsistencies, and machine learning models were deployed owning to their ability to handle large datasets. Linear regression or gradient boosting algorithm was employed to predict demand elasticity for each item. This is to identify how sensitive demand is to price changes across both categories. The models were trained, evaluated and validated to ensure accuracy.

INFERENCE: For perishable items, the model generated real-time pricing adjustments based on remaining shelf life to increase discounts as expiry dates approach to boost sales and minimize waste.

For non-perishable items, the model optimized prices based on competitor trends and historical sales data. For instance, prices were adjusted during peak demand periods (e.g. holidays) to maximize profitability.

For cross-category optimization, Apriori algorithm was able to identify complementary products (e.g. milk and cereal) for discount opportunities and bundles to increase basket size to optimize margins across both categories. These models were continuously fed new data and insights to improve its accuracy.

CONCLUSION: Companies in the grocery retail industry can reduce waste from perishables through dynamic discounts. Also, they can improve profit margins on non-perishables through targeted price adjustments. With this, grocery retailers can remain competitive while maximizing profitability and sustainability.

DM me to join the 1% of club of business savvy data professionals who are becoming leaders in the data space. I will send you to a learning resource that will turn you into a strategic business partner.

Wishing you Goodluck in your career."
analytics,Which database certifications should I get for working with databases?,4,1i27wsy,https://www.reddit.com/r/analytics/comments/1i27wsy/which_database_certifications_should_i_get_for/,1736975470.0,"I am really doubtful since there are a lot and I see the database administator role in many of them. Could you please give me a hand out?

"
analytics,Looking for Yearly Sales Dataset for Myntra,2,1i25z4m,https://www.reddit.com/r/analytics/comments/1i25z4m/looking_for_yearly_sales_dataset_for_myntra/,1736970414.0,"I’m looking for a dataset that contains yearly sales figures for Myntra, preferably covering the past few years. 

I’m working on a project that analyzes trends in the Indian e-commerce sector, and this data would be incredibly helpful. If anyone has access to such datasets or knows where I can find them (free sources preferred), I’d really appreciate your help.

"
analytics,JD skills,0,1i2aa2t,https://www.reddit.com/r/analytics/comments/1i2aa2t/jd_skills/,1736981694.0,"I came across this, “Build logistics plan and own logistical coordination for high complexity learning experiences including physical and digital requirements. Manage administrative data and processes for high complexity programs, including LMS entry, learner communications, enrollments, and assignments. Update master training calendar as needed based on program scheduling Monitor performance and effectiveness and perform quality assurance testing on high complexity in-person and digital content, identify and prioritize areas of improvement; design curriculum solutions to improve learner impact Facilitate various topics for high complex in-person and virtual content delivered to leadership and teammate audiences Other duties as assigned”

What do I need to learn to satisfactorily perform these tasks? "
analytics,Frustrated as a Data Analyst: Are we just storytellers?,175,1i196lv,https://www.reddit.com/r/analytics/comments/1i196lv/frustrated_as_a_data_analyst_are_we_just/,1736870187.0,"I’ve worked in five different roles in the data field, and across most companies, I’ve noticed a common trend: data analysts are primarily tasked with producing dashboards or generating figures based on very specific business requests. However, when it comes to tackling broader, more open-ended questions, things seem to get more challenging—especially in companies where Python isn’t part of the toolkit.

In my current company, for example, we’re expected to find new insights regularly, but everything is done using SQL and Tableau. While these tools are fine for certain tasks, doing deeper data exploration with them can feel tedious and limiting. We’re also not encouraged to use statistical knowledge at all, since no one on the team, including our boss, has a statistical background. It feels like there’s no understanding or value placed on applying more advanced techniques. We just need to have exceptional data storytelling skills + put up some nice figures which confirm already known intuitions.

Honestly, I’m feeling a bit frustrated. I can’t help but wonder if this is common across the field or if it’s just the nature of certain industries or companies. Would things be different in a more tech-focused company or in a dedicated data science role?

What’s your experience with this? Is this a frequent issue in your work as well, or does it vary depending on the company or team? I’d love to hear your thoughts."
analytics,Where is the DS career headed?,22,1i1lu49,https://www.reddit.com/r/analytics/comments/1i1lu49/where_is_the_ds_career_headed/,1736903448.0,"Just saw the Rogan / Zuck podcast on how AI is changing most tech careers. I’m just now transitioning in a DS career, getting well versed with the ML algorithms and Gen AI concepts. For the more experienced folks in the field, how is the DS career specifically going to change in the coming years? How can we try to stay on top of all the changes coming in? 

PS: This might be more of a question for the r/datascience sub, but unable to post question there. "
analytics,YouTube channels for background noise?,7,1i1klda,https://www.reddit.com/r/analytics/comments/1i1klda/youtube_channels_for_background_noise/,1736899832.0,"So for IT it's easy to throw on any tech youtubers video for ambient noise relevant to the field and occasionally pick up some useful information. I understand it's easier to make content for IT, but  I'm wondering if there's anything similar for analytics that isn't just a python tutorial or a how to on landing your first job.

Thanks for any suggestions.

Also, if there's a better place to post this I'd be glad to move it there"
analytics,Title: Should I Take an EPR Support internship While Aspiring to Be a Data Analyst?,0,1i1vjy0,https://www.reddit.com/r/analytics/comments/1i1vjy0/title_should_i_take_an_epr_support_internship/,1736941190.0,"Hi everyone, I'm a bsc Computer Science graduate  in 2024. I want to become a Data Analyst. Despite applying to many roles, I haven't landed an opportunity in the IT field yet. I've received a 3-month offer for an EPR support internship and the company is related with marine industry. Should I take it or focus solely on upskilling and searching for data analytics roles?

They are giving me stipend of 10k per month for this internship.
"
analytics,Predictive Analytics Cert?,4,1i1j7vr,https://www.reddit.com/r/analytics/comments/1i1j7vr/predictive_analytics_cert/,1736895947.0,I'm curious if I should get a certificate in Predictive Analytics. No one on my team or in my organization currently offers reporting like this and I would like to start. I manage a small team of analysts specializing in financial and operational reporting and analytics. We do most of our analytics in Tableau & excel but I'm trying to think ahead and there are plenty of use cases for predictive analytics. Any suggestions on who to get certified through? Has it been useful/successful at your organization? Thanks in advance!
analytics,What is the best practice for number of events added to an ecommerce website?,1,1i1s73x,/r/GoogleAnalytics/comments/1i1qul0/what_is_the_best_practice_for_number_of_events/,1736925795.0,
analytics,How can I create a function using values from two different data sources in Looker Studio?,2,1i1njjf,https://www.reddit.com/r/analytics/comments/1i1njjf/how_can_i_create_a_function_using_values_from_two/,1736908679.0,"In my report, Data Source A is giving me the fields A, B and C. 

Data Source B is giving me the fields D, E and F. 

There's a formula behind each of these fields.

I want to create an additional field which would be pretty much (A-B) / D, but that is not possible because they come from two different data sources. 

If I select them and try to choose ""Blend data"", the option is greyed out saying ""You can't blend with an already blended chart"". So I'm currently lost if there's anyway to display this information to my client without manually calculating this.

Alternatively, is there any any to just use the fields as values, instead of replicating the massive formula that's behind each one of them?"
analytics,New grad jobs,7,1i1efq3,https://www.reddit.com/r/analytics/comments/1i1efq3/new_grad_jobs/,1736883447.0,"Is January a bad time to look for jobs? Recently graduated in December but the issue I’m having is that there’s not that many jobs to begin with. LinkedIn is only showing about 20 - 30 jobs. Most of them are for senior roles too.

I’m not sure if I’m competitive enough for this job market tbh. I only have 1 internship utilizing sql, excel, and some data visualizations. The rest of my resume is some other unrelated job and a couple of projects on tableau public. "
analytics,How do people progress from an Academic environment to real world? ,15,1i18boz,https://www.reddit.com/r/analytics/comments/1i18boz/how_do_people_progress_from_an_academic/,1736867902.0,"I recently graduated from an MS in Business Analytics program and had classes in Data Analytics, Stats, Machine Learning, R and Python. The courses covered things but some things were pretty basic. Like we covered SQL but we did not do queries involving multiple joins or CTEs or complex stuff. Rather simple individual queries on a chosen dataset, things like that. It feels like we did learn but did not go too far or deep like people do in industry or real jobs. We did not work with things like Qlik or do ETL. For Excel/Sheets, we had no class and just did some basics, while I have seen some jobs require proficiency. All in all, I feel like classes and class projects might not be enough. Or is this enough to get started? Because I have seen data roles are individual contributor roles where you are kind of on your own. How can an entry level person manage this straight out of college? Is it possible? What did people with experience do or what did your journey look like? "
analytics,Can I use Leadsnavi as a lightweight alternative to GA for web analytics?,11,1i19n03,https://www.reddit.com/r/analytics/comments/1i19n03/can_i_use_leadsnavi_as_a_lightweight_alternative/,1736871377.0,"I have both GA and Leadsnavi on one of my client’s websites. We are using GA for analytics and Leadsnavi for identity resolution and lead generation. The web pages have gotten a little slow and I’m considering switching to a much lightweight analytics tool. I have tried MS clarity but there is not much difference there either.

Leadsnavi has analytics too but I’ve never used it for that, we just use it for identity resolution. I’m considering doing away with both GA and MS clarity and let Leadsnavi handle the analytics too.

Will it be enough or do I need to continue looking for alternative analytics tools?

Note: It was the client’s idea to add Leandsnavi for identity resolution and lead generation, my role is to set up the infrastructure, he uses the tools himself, that’s why I want to know if Leasnavi is good for analytics from a business point of view.

"
analytics,New to SEO: I need some help with deciphering my GSC graph!,1,1i1osow,https://www.reddit.com/r/analytics/comments/1i1osow/new_to_seo_i_need_some_help_with_deciphering_my/,1736912731.0,"Does anyone have any experience with your page showing a sudden decrease in clicks and impressions? I optimised the blog on 26th December, which showed an increase for 1-2 days, but then hit a 0 on the third/fourth day. Position wise is one now."
analytics,Need help deciding which route to take for transition into DA,2,1i1akf5,https://www.reddit.com/r/analytics/comments/1i1akf5/need_help_deciding_which_route_to_take_for/,1736873736.0,"Hi everyone ! 

I bet this is a pretty much always asked question and sorry for asking it again but i would like some answers specific to my situation. 

First lemme say i live in France for some context, so things are a bit different here. 

I have 2 masters in engineering, one in Material Science and the other in Space Systems, from 2 highly recognized schools (+ i did my final year at Imperial College in the UK). 

I have worked 2 years as an R&D engineer in microelectronics, doing 40% of theorical physics and the other basically doing the job of a data analyst. The firm i was in had no data person whatsoever so i kinda became it and built a whole application in VBA to extract, transform, load, analyse and dashboard data coming from our devices tests. Did some python and Power BI dashboarding while i was there. 

 I am saying all this because i keep reading posts where ppl say that a degree is the most imporrtant thing in the field and a bootcamp in case you have the diploma will help but not as much. 

So i have a degree, in a related field, but we kinda did everything you do as a DA (or even DS). A lot of proba, stats, machine learning, math, python and such...

I quit my job a few months ago now and i'm lost between doing a bootcamp (and pay 5k+ for it) to learn more DA skills and have the certification or going the self taught route and build a learning path to be as close as the bootcamp's one, using DataCamp or Maven analytics resources.

On the one hand, self-teaching would save me a lot of money, and there’s a ton of free or affordable resources out there. On the other hand, bootcamps offer access to career coaching and industry networks, which could be invaluable for landing a job. A structured curriculum might also keep me on track and ensure I don’t miss any key concepts, plus they often provide real-world projects that would help me build a portfolio.

So i woul really need your advice here and what you think would be the best choice considering my background and situation. 

  
TL;DR: I’m an engineer with two master’s degrees and two years of data analysis related experience trying to decide between an expensive data science bootcamp and self-teaching. Looking for advice on which route might be better for breaking into data analytics

Thanks a lot ! "
analytics,Drone Data Analysis Projects,2,1i19sg5,https://www.reddit.com/r/analytics/comments/1i19sg5/drone_data_analysis_projects/,1736871766.0,I recently got a DJI Tello drone and I am very passionate about drones. Would analyzing battery performance over time or doing flight data analysis be interesting projects? I was thinking I could use the SDK to get data from the drone and put it in the database. Then from there use SQL and maybe Looker Studio to manipulate the data and create a dashboard or some visualizations. Could these be interesting passions projects? Any recommendations or has anyone done something similar? 
analytics,Projects that got you A job,78,1i0l0i5,https://www.reddit.com/r/analytics/comments/1i0l0i5/projects_that_got_you_a_job/,1736793429.0,"If you don’t mind sharing, what project got you an entry level job? 

Background: I want to transition from teaching. I have a degree in math and computer science. I have completed Google Data Analytics on coursera. I currently have 2 personal projects completed. One is analyzing my finances using python to automate things. The other is analyzing student tests performance with excel. 

I want my 3rd project to be more business facing and impressive. Ive looked on Kaggle for data sets but the data seems basic. Like i can find average, increasing or decreasing trends, max and min but if i was a hiring manager i would not be that impressed. 


Tldr: 
I finished learning the basics and have 2 simple projects. I want to work on a project that would impress people but i am having a hard time finding interesting data sets. What project impressed your hiring manager enough to get you your first job? 

Thanks!"
analytics,How Big is Your Team?,17,1i0v2kv,https://www.reddit.com/r/analytics/comments/1i0v2kv/how_big_is_your_team/,1736819726.0,"I’ve worked in analytics for a few years, starting off as a Sales Operations Analyst to now working as a Business Intelligence Analyst for a Fortune 50 company. 

Throughout the duration of my career, I’ve mostly worked on a team where I’m the only analyst and the only one responsible for data related projects and reporting. From the rhetoric I’ve seen on Reddit and having conversations with other analysts, there doesn’t seem to be many fully developed analytical teams within companies. 

Is this true for most businesses? Do most companies generally keep a small analytic team if not solely relying on one person? "
dataengineering,Monthly General Discussion - Jan 2025,16,1hr6zga,https://www.reddit.com/r/dataengineering/comments/1hr6zga/monthly_general_discussion_jan_2025/,1735750833.0,"This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.

Examples:

* What are you working on this month?
* What was something you accomplished?
* What was something you learned recently?
* What is something frustrating you currently?

As always, sub rules apply. Please be respectful and stay curious.

**Community Links:**

* [Monthly newsletter](https://dataengineeringcommunity.substack.com/)
* [Data Engineering Events](https://dataengineering.wiki/Community/Events)
* [Data Engineering Meetups](https://dataengineering.wiki/Community/Meetups)
* [Get involved in the community](https://dataengineering.wiki/Community/Get+Involved)"
dataengineering,Quarterly Salary Discussion - Dec 2024,50,1h47qv8,https://www.reddit.com/r/dataengineering/comments/1h47qv8/quarterly_salary_discussion_dec_2024/,1733072430.0,"https://preview.redd.it/ia7kdykk8dlb1.png?width=500&format=png&auto=webp&s=5cbb667f30e089119bae1fcb2922ffac0700aecd

This is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.

# [Submit your salary here](https://tally.so/r/nraYkN)

You can view and analyze all of the data on our [DE salary page](https://dataengineering.wiki/Community/Salaries) and get involved with this open-source project [here](https://github.com/data-engineering-community/data-engineering-salaries).

&#x200B;

If you'd like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:

1. Current title
2. Years of experience (YOE)
3. Location
4. Base salary & currency (dollars, euro, pesos, etc.)
5. Bonuses/Equity (optional)
6. Industry (optional)
7. Tech stack (optional)"
dataengineering,Pinterest Data Tech Stack,27,1i50mw6,https://www.junaideffendi.com/p/pinterest-data-tech-stack?r=cqjft&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false,1737299676.0,"Sharing my 7th tech stack series article.

Pinterest is a great tech savy company with dozens of tech used across teams. I thought this would be great for the readers.

Content is based on multiple sources including Tech Blog, Open Source websites, news articles. You will find references as you read.

Couple of points:
- The tech discussed is from multiple teams.
- Certain aspects are not covered due to not enough information available publicly. E.g. how each system work with each other.
- Pinterest leverages multiple tech for exabyte scala data lake.
- Recently migrated from Druid to StarRocks.
- StarRocks and Snowflake primary purpose is storage in this case, hence mentioned under storage.
- Pinterest maintains their own flavor of Flink and Airflow.
- Headsup! The article contains a sponsor.


Let me know what I missed.


Thanks for reading."
dataengineering,"Data Engineers, What Business and Technical Challenges Have You Faced?

",13,1i52gfe,https://www.reddit.com/r/dataengineering/comments/1i52gfe/data_engineers_what_business_and_technical/,1737304450.0,"currently working on projects. However, I don't have job experience yet, so I want to make my solutions realistic and have added value

Could you share some  **business problems** and **technical challenges** you’ve faced while implementing data solutions? 

Thank you in advance 

"
dataengineering,Life of a Data Engineer,741,1i4asfr,https://i.redd.it/26hsel7u0sde1.gif,1737216596.0,
dataengineering,Are most Data Pipelines in python OOP or Functional? ,96,1i4njkr,https://www.reddit.com/r/dataengineering/comments/1i4njkr/are_most_data_pipelines_in_python_oop_or/,1737252276.0,"Throughout my career, when I come across data pipelines that are purely python, I see slightly more of them use OOP/Classes than I do see Functional Programming style. 

But the class based ones only seem to instantiate the class one time. I’m not a design pattern expert but I believe this is called a singleton? 

So what I’m trying to understand is, “when” should a data pipeline be OOP Vs. Functional Programming style? 

If you’re only instantiating a class once, shouldn’t you just use functional programming instead of OOP? 

I’m seeing less and less data pipelines in pure python (exception being PySpark data pipelines) but when I do see them, this is something I’ve noticed. "
dataengineering,How to handle open ended design questions for Data roles and way forward?,14,1i4xbdk,https://www.reddit.com/r/dataengineering/comments/1i4xbdk/how_to_handle_open_ended_design_questions_for/,1737289436.0,"Recently I have seen that in the second or third round companies are asking open ended one liners, how should we approach these? Apart from the Data model, they are also expecting that we make some low level code and APIs and then also explain them about why we chose one service over the other, explain about latency, throughput stuff etc.  
Examples:

1. Design a Rider Management Platform which will provide riders to different e-commerce/quick-commerce websites

2. Design DQ Framework.

3. Design whatsapp/instagram/twitter/Jira etc.

As someone who wants to grow more into this field, I mean like as I grow I want to be on the tech side only like Data Engineer - > Senior Data Engineer - > Lead/Staff DE -> Principal DE. How should we proceed? Because these questions are similar to the System design rounds for Software profiles. Also, I feel that next 5 years DE profile is going to be merged in to Software roles only, like we see in some companies with designation such as Data Software engineer or Software Engineer (Data).

Seeking guidance from Senior folks here.  
"
dataengineering,Azure Data Factory Data Flow vs SQL script in Synapse ,8,1i4yvgd,https://www.reddit.com/r/dataengineering/comments/1i4yvgd/azure_data_factory_data_flow_vs_sql_script_in/,1737294701.0,"Hello guys!  
  
I would like to ask for you help in order to decide whether the current data pipeline usage is good or bad.  
  
In my company we use Azure stack. We gather the data from source systems (mostly Postgres and MariaDB) using Copy activity to acquire and store source data into Azure Data Lake Gen2 in parquet format.   
After that we use Data Flow activity to read the data from Azure Data Lake, do some transformations and then load the data into the Data Warehouse (Synapse Analytics Dedicated SQL Pool).   
What I experienced is that, by using Data Flow activity it takes some minutes (2-3 minutes) to accomplish a very basic data transformation task (such as loading fact data without having to calculate anything). Spark cluster has already been started, and TTL option is set, so it is not about instantiating a Spark cluster. The parquet files' size on the other hand are little (most of the time it does not reach 1 MB). The interesting fact is that when I monitor the Data Flow activity, the processing time is just about some seconds, but when I monitor the whole data pipeline it shows that the Data Flow activity ran for minutes, which is not effective and I think it should be run much faster.  
  
I tried out a new approach, which would be loading the raw data into Synapse Analytics (As Is), and then use SQL script activity to do the same transformation logic but this time the source data would be a staging table in Synapse to be able to execute SQL.  
It was much faster in terms of Data Pipeline execution time and also it became much cheaper approach, because i did not have to use Data Flow activity and Spark cluster.

I'm curious about your opinion about the data pipeline setup. Is there any better approach than using Data Flow activity to do this data transformation? Is it better to use Azure Databricks or Synapse notebook in pyspark for this job? Or what else could you recommend? I would like to learn from your experience. Any suggestion or opinion would be much appreciated!

"
dataengineering,What do you think of Talend?,14,1i4url5,https://www.reddit.com/r/dataengineering/comments/1i4url5/what_do_you_think_of_talend/,1737278654.0,"Qlik acquired Talend and has integrated it into their data studio for ingestion (currently limited to databases afaik).

Since our organization already uses Qlik, this was introduced to us last year. One of our team members spent a few weeks exploring it and concluded that it had its rough edges and was difficult to troubleshoot if something went wrong.

Now, it's being showed down our throats as it has been decided that Talend will be used for ingestions, because management believes UI-based tools equate to faster results. To counter this, I built a few ingestion pipelines for sources that Talend cannot handle (such as Rest APIs) using [dlt](https://github.com/dlt-hub/dlt) that have been working just fine since ~October of last year, but it seems that has fallen on deaf ears.

Has anyone here used the Qlik-integrated version of Talend? What’s your experience with it?"
dataengineering,Data/System Design Resources,4,1i50j2w,https://www.reddit.com/r/dataengineering/comments/1i50j2w/datasystem_design_resources/,1737299391.0,"Any one know where I can find comprehensive resources for Designing an end to end data ingestion pipeline. I want to ensure all things like designing, choosing tools, and scaling. Most YouTube videos aren’t that good and say generic stuff.  Thanks in advance. "
dataengineering,"We added parquet support (shoutout to the great hyparquet package) to our data management/app building tool, interested in feedback on workflow and anything else. Here working on the flights-1m dataset.",10,1i4vij8,https://v.redd.it/km942he6fxde1,1737281986.0,
dataengineering,How to design Python Airflow DAG to run infinite loop programs then start next once it is running?,2,1i54xeq,https://www.reddit.com/r/dataengineering/comments/1i54xeq/how_to_design_python_airflow_dag_to_run_infinite/,1737310600.0,"https://preview.redd.it/6rwcq3rzrzde1.png?width=2560&format=png&auto=webp&s=5d127a10880843ca40b51c42843745b3e87d97fd

I am working on learning Apache Airflow, Kafka, and Spark. I ran into this issue where I want to run this Dag flow of starting up zookeeper, starting up the kafka broker, then starting up my PySpark program for listening in real time. The issue is I cant get the DAG to proceed out of stage 1 because I think it is an infinite looping program for starting up the processes. Any help?"
dataengineering,Getting Foot in the Door as a Data Engineer,2,1i54dy3,https://www.reddit.com/r/dataengineering/comments/1i54dy3/getting_foot_in_the_door_as_a_data_engineer/,1737309309.0,"I'm looking to make the switch to full time data engineering position. I find the field fascinating. I have working over last 7 years spending 1/2 my time as an analyst and 1/2 work non data related tasks. I want to make the switch to a permanent role. Pretty good at SQL, data visualization software's. Got a bit python experience as well. I'm close to south bay Silicon Valley and am open to working in office. Is that enough to get my foot in the door with the current scope of the market? Should I be contacting recruiters or is there a better method here? I feel a tiny bit intimidated, but at the same time, am confident I can learn anything. Is there an approach that you would all recommend?"
dataengineering,Why are DSA questions being asked in interviews if it's not so extensively used on the job?,33,1i4m272,https://www.reddit.com/r/dataengineering/comments/1i4m272/why_are_dsa_questions_being_asked_in_interviews/,1737247717.0,I'm trying to understand how DSA concepts are actually used on the job.
dataengineering,How to learn data engineering? From basics to advance. ,0,1i56w2k,https://www.reddit.com/r/dataengineering/comments/1i56w2k/how_to_learn_data_engineering_from_basics_to/,1737315430.0,I am a power BI developer. I would like to learn data engineering. What would you suggest as the pathway to it. 
dataengineering,Any advice for new Data Engineer?,1,1i56pk8,https://www.reddit.com/r/dataengineering/comments/1i56pk8/any_advice_for_new_data_engineer/,1737314983.0,"I just graduated college 6-8 months ago and will be joining a startup as a junior DE along with other junior, senior and staff DE. Any advice for me? I’m very nervous and having a bit of imposter syndrome. I’ll be using AWS, Databricks, Spark, Airflow and dbt."
dataengineering,Need Help Finding resources for transactional data modeling,3,1i4x07k,https://www.reddit.com/r/dataengineering/comments/1i4x07k/need_help_finding_resources_for_transactional/,1737288202.0,"I want to utilise a supervised ML model to score users based on their transactional data (the data contains both raw transaction data and analysed data - done by the third party ). it would be a supervised model, I have decided to use 30+ dpd in the next 6 months from the last transaction date as the indicator for good/bad behaviour. Any resources or Suggestions would be helpful. posted this on learnmachinelearning as well, but hoping to get resources from here too. Thanks in advance"
dataengineering,Need suggestions about my bachelor graduation project,0,1i53e9o,https://www.reddit.com/r/dataengineering/comments/1i53e9o/need_suggestions_about_my_bachelor_graduation/,1737306831.0,"Hey all, im planning to draft my bachelor graduation project, im interested in data monitoring and data test, quality.

Can you please help suggest any ideas (tech stacks, flow,etc,….) 
Thanks all 🙏"
dataengineering,Annual learning credit,10,1i4qg8h,https://www.reddit.com/r/dataengineering/comments/1i4qg8h/annual_learning_credit/,1737261447.0,"I’ve got an annual learning credit through work (about $500) that I can use for any courses, certifications, etc. 

Would love recommendations for how to use this. I’m in more of an analytics engineering role currently, but want to expand more into the true data eng/platform/infra side. Some of the topics I’d be interested in learning more about include: 

- Kafka -> Spark Streaming -> DataBricks Delta Lake
- AWS for Data Engineering 
- Data Platform/Infra - I’d really love to learn the end-to-end required with deploying an Airflow instance onto a Kubernetes cluster. Would love anything that combines Airflow config with Terraform, EKS, etc. 
- Dev Ops - CI/CD, IaC

EDIT: adding some more info on my background. I’ve been in a few DE/analytics engineering positions in big tech for the past 5ish years, so looking for some more advanced courses beyond the basics/intros. I’ve toyed around with most things in my list above on my own - I know the best way to learn is through projects, but I’m specifically looking for how to spend this learning credit "
dataengineering,Real-world patterns for creating medallion workspaces and ingest data in Fabric,12,1i4klij,https://www.reddit.com/r/dataengineering/comments/1i4klij/realworld_patterns_for_creating_medallion/,1737243368.0,"Hi, I've read several articles about those topics, however I would like to ask Fabric practitioners what is the best approach to these 3 issues. I need to create medallion architecture where I create seperate Lakehouse for bronze and silver layer and Data Warehouse (or Lakehouse) for gold layer. Here are my questions:

**1st - creating separate workspaces for bronze/silver/gold layer in Fabric**

It's recommended to create separate Lakehouses in separate workspaces for each medallion layer - bronze, silver and gold. I'm wondering how it corresponds to another quite common pattern to create separate workspaces for Development, Test and Production (deployment pipeline). How should I combine the two approaches? In my company we split workspaces into DEV/TEST/PROD. I thought about 2 approaches:

*1. create 3 workspaces for bronze/silver/gold layers and within each create Lakehouses for DEV, TEST and PROD.* Here we follow the recommendation of having 3 separate workspaces for each medallion layer. For example: 

BRONZE workspace which includes: Lakehouse DEV, Lakehouse TEST, Lakehouse PROD (in separate folders for example)

SILVER workspace which includes: Lakehouse DEV, Lakehouse TEST, Lakehouse PROD

GOLD workspace which includes: Lakehouse DEV, Lakehouse TEST, Lakehouse PROD

*2. create 9 workspaces for each medallion layer combined with dev/test/prod architecture.* For example:

first workspace: Lakehouse BRONZE Dev

second workspace: Lakehouse BRONZE Test

another workspace: Lakehouse BRONZE Prod

another workspace: Lakehouse SILVER Dev

another workspace: Lakehouse SILVER Test

etc...

Here we also follow recommendation of having separate workspaces for each layer. However, as a result we have 9 workspaces. I'm wondering how those 2 approaches works in case we would use deployment pipeline to manage DEV/TEST/PROD environments. Please advise which approach is best here.

**2nd - data ingestion to bronze layer**

Let's say I created Lakehouse in bronze layer. Now I would like to load data efficiently to this Lakehouse. When it comes to data source it would be SAP data (to be precise data coming from SAP BW Application Server, de facto OLAP Cubes). I can connect to SAP via Dataflow connector. The issue is that I don't want to use Dataflows which are slow are generate overhead (I load huge amount of data). So please advise me how to efficiently load those data directly to Lakehouse Bronze layer from SAP. I have 2 options on my mind:

1. using data pipeline and Copy data activity to ingest data. However, SAP BW Application Server isn't available for data pipeline so I guess this option is about to be dropped

2. using PySpark and Notebooks - I could directly retrieve data from SAP BW Application Server and load it to Lakehouse as .parquet files. Question is if I could make connection to this particular SAP Server from Notebook (PySpark) or not? As far as I know Spark works much faster that Dataflows and is better cost-wise, that's why I think about this option.

**3rd - incremental data load to silver layer**

Now I need to load data from bronze to silver layer. Initial load to bronze layer would embrace, let's say, data for 2 years. Then I would like to upload data to silver layer incrementally for last 3 months. So now as a first step I should load data for 2 last years to bronze layer and then load it to silver layer. Next, delete all 2 years data from bronze layer. In next step load latest data for 3 months to bronze layer and then refresh last 3 months in silver layer. So in bronze layer we would always have data for latest 3 months and in silver layer data for last 2 years (from now) where last 3 months are updated and up-to-date.

My question is if it's good approach to incremental refresh and MOST importantly - should I make it in PySpark or use another approach?"
dataengineering, Beginner seeking advice: best learning resources to build data platform from scratch?,7,1i4k0z0,https://www.reddit.com/r/dataengineering/comments/1i4k0z0/beginner_seeking_advice_best_learning_resources/,1737241692.0,"Hi! Noob looking for advice. My goal is to train myself to be able to build a data platform and analytics platform from scratch. I'm not looking to build something too complicated - think of use cases for small businesses like a saas startup. 

I'd like to hear your suggestions on good learning materials. I'm looking for courses that can help me understand:

* What a data infra typically looks like, what's different components, how they are connected, mainstream tools, etc.
* How to make decisions on what tools / framework to use for each component, what's the trade-offs to be considered, best practices for scaling, etc. (i.e. I don't want to just build something that works, but want to understand the implications behind it)

I work in analytics so am very comfortable with python and sql, but have almost no knowledge on data engineering. And sadly this isn't something I can learn on the job as the data infra in my company seems way too advanced for my use case. Any pointers is appreciated. Thank you in advance!"
dataengineering,If i want to learn data engineering in 2025 from scrap what would be your suggestions?,83,1i43q2y,https://www.reddit.com/r/dataengineering/comments/1i43q2y/if_i_want_to_learn_data_engineering_in_2025_from/,1737191374.0,"I have a strong foundation in Python, as I have been working with Django for the past two years.
But now i want to shift into data suggest from your learning experience what would be better for me."
dataengineering,What is wrong with Synapse Analytics,19,1i4adbr,https://www.reddit.com/r/dataengineering/comments/1i4adbr/what_is_wrong_with_synapse_analytics/,1737215460.0,"We are building Data Mesh solution based on Delta Lakes and Synapse Workspaces.


But i find it difficult to find any use caces or real life usage docs. Even when we ask Microsoft they have no info on solving basic problem and even design ideas. Synapse reddit is dead.

Is no one using Synapse or is knowledge gatekeeped?"
dataengineering,What's the Data Architecture being used at your Company at present.,0,1i5307p,https://www.reddit.com/r/dataengineering/comments/1i5307p/whats_the_data_architecture_being_used_at_your/,1737305851.0,"Hello Guys,

I am new to Data Engineering and would like to know or explore what are all the different architectures being used in different companies at present. Feel free to omit the Company name. 

Kindly mention the **size of the data being handled** at source and at different stages if applicable to make the understanding easier

Kindly mention the following (Feel free edit as per your need)  
1) Data Sources - Mention atleast 3 sources from where the data is mostly pulled from  
2) Data Ingestion - Tools used and in which format data is pulled and which format they are saved  
3) Architecture used - Medallion or any other architecture  
3) Orchestration and Data Transformation  - Tools used  
4) Data Warehouses if any being used and how they are updated  
5) How the data is exposed for Analytics and other purposes  
6) Security and Governance  
"
dataengineering,Help with orchestration[Airflow/Dagster],3,1i4nnb9,https://www.reddit.com/r/dataengineering/comments/1i4nnb9/help_with_orchestrationairflowdagster/,1737252600.0,"We are revamping our scheduler which are cron jobs with Airflow/Dagster.
The requirements are 
1. All piplines across projects should be visible in a single UI.
2. The pipeline code will be a docker image that the orchestrator should pull and run as scheduled.
3. The individual tasks within a pipeline, i.e python functions, dbt models etc. should also be visible in the UI.(lineage within the pipeline)
4. The orchestrator will be in a seperate instance and should execute the docker images in other seperate instances.
5. The orchestrator code should live in the orchestrator instance and must be separated from pipeline code.
6. All logs should be stored in the orchestrator instance. 

We currently use Python for EL and dbt for T.

Questions:
1. Are these requirements appropriate and make sense?
2.Are these possible with Airflow/Dagster? 
3.Which of the two orchestrators would be more suitable for the requirements?
4.What is the best way to go about setting this up that fulfills all these requirements?
5. Are there better ways to go about this that I am overlooking?"
dataengineering,Building Real-time Analytics for an AI Platform,16,1i48phw,https://www.reddit.com/r/dataengineering/comments/1i48phw/building_realtime_analytics_for_an_ai_platform/,1737210637.0,"Hi r/dataengineering!

  
So... my manager just dropped a ""small task"" on my desk yesterday: ""We need real-time analytics for our AI platform"". I've spent the last 24 hours diving deep into data architecture patterns, and I could really use some guidance from folks who've been there.

The situazion is this: I'm working at a company that has built an AI platform managing both containerized model deployments and API integrations (OpenAI, etc.). Every model interaction is stored in MongoDB, with our main collection ""modelCall"" containing prompts, responses, and usage costs. We've accumulated about 3M documents over two years (\~1.5M calls annually).

**Current System:**

* Platform manages AI models (both custom deployments and API integrations like OpenAI)
* MongoDB as primary OLTP database
* Main collection ""modelCall"" stores every model interaction (prompt, response, cost)
* \~3M documents collected over 2 years
* Other collections store user data, budget allocations, etc.

**The Challenge:** I need to add real-time/near real-time analytics capabilities, and I'm trying to figure out the best architecture. Here are my questions:

1. MongoDB seems suboptimal for analytics workloads - am I right about this?
2. Should I:
   * Implement dual writes to both MongoDB and an OLAP system?
   * Use Kafka as an intermediate layer?
   * Use Kafka + data lake format (Iceberg/Delta) + OLAP engine?
3. What's the best practice for write ordering? OLTP first or message queue first?
4. How should I handle potential inconsistencies if OLTP writes succeed but OLAP writes fail?

I'm new to designing data architectures at this scale, and I want to make sure I'm following best practices. Any advice on:

* Architecture patterns
* Technology choices
* Common pitfalls to avoid
* Resources to learn more

Would really appreciate your insights! Thanks in advance!"
dataengineering,[AIRFLOW] How to run one script after another?,6,1i4d4nl,https://www.reddit.com/r/dataengineering/comments/1i4d4nl/airflow_how_to_run_one_script_after_another/,1737222840.0,"I've always wanted to use Airflow to manage pipelines.

I want to manage several scripts in a dependency flow, but I can't find any answers on how to do it.

I thought it would be a continuous series of script dependencies, like a flowchart, but I can only find answers that it can only be done through Tasks.

If I put my scripts in the task it will be huge and impossible to maintain."
dataengineering,data engineering? try dating engineering...,274,1i3n37a,https://i.redd.it/64tgii24klde1.png,1737138440.0,
dataengineering,"I'm Torn Between Data Career Paths

",4,1i4bkuv,https://www.reddit.com/r/dataengineering/comments/1i4bkuv/im_torn_between_data_career_paths/,1737218757.0,"At the beginning of my journey, I aspired to become a data scientist and started self-learning the field. I made some progress by learning statistics and basic machine learning concepts, including supervised and unsupervised techniques. However, I don't feel like I achieved significant expertise.

Later, I joined a data analyst internship, followed by a data engineering internship. After completing these experiences, I was encouraged to pursue a data engineering career. While I’ve worked on improving my skills, I recognize that I still have a lot to learn in terms of tools and concepts to truly excel as a data engineer.

Recently, I was offered a data analyst position, and I’m about to start. I feel that gaining experience in data analysis could help me build on this career path, as data science seems like a natural progression from analysis. However, I’m also drawn to data engineering. Are all these roles interconnected in the end, or should I focus on one specific path to grow my career more effectively?"
dataengineering,First DE Project as Self Taught Developer: Seeking Tools & Best Practices for IoT Data Pipeline,3,1i4cv8z,https://www.reddit.com/r/dataengineering/comments/1i4cv8z/first_de_project_as_self_taught_developer_seeking/,1737222147.0,"After completing ""Fundamentals of Data Engineering"" by Reis & Housley, I'm building my first real DE project and looking for guidance on tool selection and best practices.

**Project Overview:**

* Building pipelines to collect IoT sensor environmental data via API
* Cleaning data and engineering features
* Storing in TimeScaleDB (Postgres) with hypertables
* Generating automated weekly reports comparing 2-year running averages with current week's data
* Using Python and SQL (intermediate Python, learning SQL)

The book emphasizes building custom solutions only when they provide competitive advantage, otherwise leveraging existing tools. This leads to my questions:

1. How do you identify suitable open-source tools for a project like this?
2. Any tips for finding and adapting similar GitHub projects?
3. What are some recommended books/blogs/resources for someone learning DE independently?
4. How would this type of project typically be structured in a professional setting?

I'm self-teaching and using LLMs to help with coding, but I'm more focused on understanding proper frameworks and approaches. Any guidance on professional best practices would be greatly appreciated!"
dataengineering,Book Review: Fundamentals of Data Engineering ,176,1i3jqy0,https://www.reddit.com/r/dataengineering/comments/1i3jqy0/book_review_fundamentals_of_data_engineering/,1737130033.0,"Hi guys, I just finished reading Fundamentals of Data Engineering and wrote up a review in case anyone is interested! 

**Key takeaways:**

1. This book is great for anyone looking to get into data engineering themselves, or understand the work of data engineers they work with or manage better.

2. The writing style in my opinion is very thorough and high level / theory based. 

Which is a great approach to introduce you to the whole field of DE, or contextualize more specific learning.

But, if you want a tech-stack specific implementation guide, this is not it (nor does it pretend to be)

https://medium.com/@sergioramos3.sr/self-taught-reviews-fundamentals-of-data-engineering-by-joe-reis-and-matt-housley-36b66ec9cb23"
dataengineering,Question for AWS RDS to Redshift ,2,1i44qxb,https://www.reddit.com/r/dataengineering/comments/1i44qxb/question_for_aws_rds_to_redshift/,1737195942.0,"
Hi kinda new in AWS.
Question:
When data is in RDS, can we use DMS to have a pipeline that is set to be transferred inside Redshift? Or theres better approach?
Like RDS > DMS > S3
or RDS >Glue > S3

Given we want to have data quality checks /  transformation like schema compliance, converting some zero columns to null basically simple transformations."
dataengineering,"They say ""don't build toy models with kaggle datasets"" scrape the data yourself
",67,1i3o0el,https://www.reddit.com/r/dataengineering/comments/1i3o0el/they_say_dont_build_toy_models_with_kaggle/,1737140791.0,"And I ask, HOW? every website I checked has ToS / doesn't allowed to be scraped for ML model training. 

For example, scraping images from Reddit? hell no, you are not allowed to do that without EACH user explicitly approve it to you.

Even if I use hugging face or Kaggle free datasets.. those are not real - taken by people - images (for what I need). So massive, rather impossible augmentation is needed. But then again.... free dataset... you didn't acquire it yourself... you're just like everybody...

I'm sorry for the aggressive tone but I really don't know what to do."
dataengineering,Mongo-analyser,4,1i42m1k,https://www.reddit.com/r/dataengineering/comments/1i42m1k/mongoanalyser/,1737186369.0,"Hi,

I made a simple command-line tool named Mongo-analyser that can help people analyse and infer the schema of MongoDB collections. It also can be used as a Python library.

Mongo-analyser is a work in progress. I thought it could be a good idea to share it with the community here so people could try it and help improve it if they find it useful.

Link to the GitHub repo: [https://github.com/habedi/mongo-analyser](https://github.com/habedi/mongo-analyser)"
dataengineering,What keyboard do you use?,8,1i419au,https://www.reddit.com/r/dataengineering/comments/1i419au/what_keyboard_do_you_use/,1737180635.0,"I know there are dedicated subs on this topic, but the people there go too deep and do all sorts of things.

I want to know what keyboards data engineers use for their work.

  
Is it membrane or mechanical? Is it normal or ergonomic?"
dataengineering,How much effort should I (and our team) spend helping other teams write queries?,2,1i44wqj,https://www.reddit.com/r/dataengineering/comments/1i44wqj/how_much_effort_should_i_and_our_team_spend/,1737196658.0,"So I'm working at a mid-sized tech startup and we have a small data team. Our core responsibility is to prepare the data warehouse so downstream users (mainly business analysts in commercial teams and finance) can use the data to generate performance charts etc. 

You can imagine the commercial bosses are always not satisfied with the data views we have prepared so the BAs take on some heavy lifting to make a lot of ad hoc charts and tables. The problem is, most of them are not systematically trained to write efficient queries (we use BigQuery) or to properly debug them. So a lot of colleagues reach out to us and ask for help. I'm usually quite ok with helping someone, but there are cases where they have a tight deadline while I also have a deadline to meet for my own work. 

Our team has had some internal rants and discussions about this problem, but we see no way to either increase our HC (in the end, we don't believe it's a junior DE's role to serve the commercial bosses directly either) or make our downstream users better at using our platforms--their job is not sorting out BigQuery but sorting out ""insights.""

What are your thoughts on this?"
dataengineering,"Simple Python ETL job framework? Something that handles recording metrics, logging, and caching/stage restart. No orchestration needed.",22,1i3pa1s,https://www.reddit.com/r/dataengineering/comments/1i3pa1s/simple_python_etl_job_framework_something_that/,1737144083.0,"I'd like to find a Python batch ETL framework that I can inherit from that has opinionated defaults. I'd like to be able to run something like the code below and have the metrics (run time, failures, success, etc) written to postgres, sensible logging, and a way to cache data to restart a job at the transform/load steps.

    class MyETLJob(ETLJob):
        def __init__(self, file_path):
            self.file_path = file_path

        def extract(self):
            with open(filepath) as file:
                data = file.read()
            return data

        def transform(self, data):
            lines = data.split(""\n"")
            return lines

        def load(self, lines):
            for line in lines:
                write_to_database(line)

    job = MyETLJob(""data.txt"")
    job.run()

I don't want any chaining, orchestration, job dependency management, GUIs, etc.

Does anything like this exist?"
dataengineering,Moving from GRC to Data Engineering,5,1i3y6bt,https://www.reddit.com/r/dataengineering/comments/1i3y6bt/moving_from_grc_to_data_engineering/,1737169496.0,"I'm a GRC supervisor but have been learning Data Engineering in my off time. I'd like to make a switch since I really enjoy being able to move Data and learning new things.

I am steeped in cybersecurity but have reasonable skill in linux, SQL, some python, and have Google Associate Cloud Engineer certification. 

Any thoughts on starting a foray into DE would be greatly appreciated."
dataengineering,Does Debezium cap out at 6k ops?,4,1i41neh,https://www.reddit.com/r/dataengineering/comments/1i41neh/does_debezium_cap_out_at_6k_ops/,1737182249.0,"I have been benchmarking some tools in the Postgres CDC and was surprised to find Debezium cannot handle 10k operations per second from Postgres to Kafka. 

https://preview.redd.it/ftu7xh0j7pde1.png?width=1490&format=png&auto=webp&s=f2f16a1c2820a4cb0ac351abe2fb4bc16193698a

The full terraform for Debezium on AWS MSK with MSK Connect is [on GitHub](https://github.com/sequinstream/sequin-vs-debezium-benchmark/tree/eeb8b108e92f90268c3c6e600f3a4bc213c28dab/terraform) and I have a comparison with my company's tool in [our docs](https://sequinstream.com/docs/performance).

Would be very interested if those who know Debezium or have it running more quickly could let me know if there is a way to speed it up! TIA"
dataengineering,AI support bot RAG Pipeline in Dagster Tutorial,9,1i3rs4y,https://youtu.be/MHwwKfCXwDA,1737150738.0,
dataengineering,Should Power BI be Detached from Fabric?,28,1i3f2pe,https://www.sqlgene.com/2025/01/16/should-power-bi-be-detached-from-fabric/,1737116242.0,
dataengineering,How to Approach a Data Architecture Assessment?,20,1i3dvqc,https://www.reddit.com/r/dataengineering/comments/1i3dvqc/how_to_approach_a_data_architecture_assessment/,1737111600.0,"Hi everyone,

I recently joined a firm as a junior data engineer (it's been about a month), and my team has tasked me with doing a data architecture assessment for one of their enterprise clients. They mentioned this will involve a lot of documentation where I’ll need to identify gaps, weaknesses, and suggest improvements.

The client’s tech stack includes Databricks and Azure Cloud, but that’s all the context I’ve been given so far. I tried searching online for templates or guides to help me get started, but most of what I found was pretty generic—things like stakeholder communication, pipeline overviews, data mapping, etc.

Since I’m new to this kind of assessment, I’m a bit lost on what the process looks like in the real world. For example:

What does a typical data architecture assessment include?

How should I structure the documentation?

Are there specific steps or tools I should use to assess gaps and weaknesses?

How do people in your teams approach this kind of task?


If anyone has experience with this type of assessment or has any templates, resources, or practical advice, I’d really appreciate it. 


Thanks in advance!


"
dataengineering,Airbyte on Docker and local CSV,5,1i3ni9g,https://www.reddit.com/r/dataengineering/comments/1i3ni9g/airbyte_on_docker_and_local_csv/,1737139514.0,"I am running Airbyte OSS locally on a windows laptop using Docker for Desktop. I was able to configure it and run a job/connection where it is reading from a Oracle table and writing to a local CSV. I can see that my execution was successful, but am not able to locate the CSV file created by Airbyte. As I am running Docker with WSL2, I though the docker folders would be available under `//wsl$/docker-desktop-data`, but the folder doesn't exist. Appreciate any input on this."
dataengineering,Need help with proper terminology around different ways to display a percentage,3,1i3qi87,https://www.reddit.com/r/dataengineering/comments/1i3qi87/need_help_with_proper_terminology_around/,1737147334.0,"I work with data, and in my data i have two columns ""Rate at origination"" and ""Rate (current)"".  
In my example, they both are, in the real world,  1.25 percent (1.25%)

But, in my table, ""Rate at origination"" is stored as 0.0125, and ""Rate (current)"" is stored as 1.25 (they come from different systems).

I want to explain to someone this difference/problem, but i'm struggling due to lacking the proper terminology.

Basically, I need to explain that they both should be stored in the same ..\_\_?\_\_.. format??  But, I think there's probably a better more precise/accurate term for this.

Help!"
dataengineering,FCMSA or Safer API ,2,1i3sr2y,https://www.reddit.com/r/dataengineering/comments/1i3sr2y/fcmsa_or_safer_api/,1737153303.0,Has anyone worked with the safer or FCMSA API? There is the ability to hit the endpoint by DOT for a snapshot or live data. The snapshot data appears to have less fields than the historical data and there are thousands of fields with nested json. Is there a smarter way to get all three fields and nested fields other than looping through. I am think of having different tables to store the data but the mapping exercise and how to hey all the data and fields seems extremely inefficient. I was going to use python and a RDMS. Any suggestions?
dataengineering,Delta Live Tables opinions,6,1i3h048,https://www.reddit.com/r/dataengineering/comments/1i3h048/delta_live_tables_opinions/,1737122543.0,"What is the general opinion about DLT? When to use and not use DLT? Any pitfalls? The last threads are from years ago.

I can see the benefits but I am honestly bothered by the proprietary nature of it and I am afraid it is going to move more and more into a low code solution."
dataengineering,ActiveData: An Ecosystem for data relationships and context. ,38,1i3935p,https://www.reddit.com/gallery/1i3935p,1737090586.0,"Hi r/dataengineering

I needed a rabbit hole to go down while navigating my divorce. 

The divorce itself isn’t important, but my journey of understanding my ex-wife’s motives are. 

A little background:

I started working in Enterprise IT at the age of 14, I started working at a State High School through a TAFE program while I was studying at school.

After what is now 17 years of experience in the industry, working across a diverse range of industries, I’ve been able to work within different systems while staying grounded to something tangible, Active Directory. 

For those of you who don’t know, Active Directory is essentially the spine of your enterprise IT environment, it contains your user accounts, computer objects, and groups (and more) that give you access and permissions to systems, email addresses, and anything else that’s attached to it. 


My Journey into AI:

I’ve always been exposed to AI for over 10 years, but more from the perspective of the observer. I understand the fundamentals that Machine Learning is just about taking data and identifying the underlying patterns within, the hidden relationships within the data. 

In July this year, I decided to dive into AI headfirst. 

I started by building a scalable healthcare platform, YouMatter, which augments and aggregates all of the siloed information that’s scattered between disparate systems, which included UI/UX development, CI/CD pipelines and a scalable, cloud and device agnostic web application that provides a human centric interface for users, administrators and patients. 

From here, I pivoted to building trading bots. It started with me applying the same logic I’d used to store and structure information for hospitals to identify anomalies, and integrated that with BTC trading data, calculating MAC, RSI and other common buy / sell signals that I integrated into a successful trading strategy (paper testing)

From here, I went deep. My 80 medium posts in the last 6 months might provide some insights here 

https://osintteam.blog/relational-intelligence-a-framework-for-empowerment-not-replacement-0eb34179c2cd

ActiveData:

At its core, ActiveData is a paradigm shift, a reimagining of how we structure, store and interpret data. It doesn’t require a reinvention of existing systems, and acts as a layer that sits on top of existing systems to provide rich actionable insights, all with the data that organisations already possess at their fingertips. 

ActiveGraphs:

A system to structure spacial relationships in data, encoding context within the data schema, mapping to other data schemas to provide multi-dimensional querying 

ActiveQube (formally Cube4D:

Structured data, stored within 4Dimensional hypercubes, think tesseracts

ActiveShell: 

The query interface, think PowerShell’s Noun-Verb syntax, but with an added dimension of Truth

Get-node-Patient | Where {Patient has iron deficiency and was born in Wichita Kansas}

Add-node-Patient -name.first Callum -name.last Maystone 

It might sound overly complex, but the intent is to provide an ecosystem that allows anyone to simply complexity.

I’ve created a whitepaper for those of you who may be interested in learning more, and I welcome any question. 

You don’t have to be a data engineering expert, and there’s no such thing as a stupid question. 

I’m looking for partners who might be interested in working together to build out a Proof of Concept or Minimum Viable Product. 

Thank you for your time 

Whitepaper:

https://github.com/ConicuConsulting/ActiveData/blob/main/whitepaper.md"
dataengineering,I have mixed data types in my JSON source data (strings alongside numbers) which is causing HIVE errors when querying in Athena. Not sure best practices on how to address it,2,1i3q4sn,https://www.reddit.com/r/dataengineering/comments/1i3q4sn/i_have_mixed_data_types_in_my_json_source_data/,1737146330.0,"I have a pretty simple table with a column for quantities along with time stamps, units and sources of those quantities. The majority of my data are double with some int values as well. Initially there wasn’t too much of a problem with those two existing in the same column. The reason why they aren’t all double for example is that the type of the data is described in another column and that may dictate that there are whole number counts. That worked for a while but I did a large (compared to the amount of existing data) data load and now some quantities are strings. Those strings map to a limited set of ordinal rather than the cardinal values that the existing doubles can take. Now I’m getting HIVE errors in Athena. The data is also partitioned by date even in raw form. I suppose I’m wondering why in Athena it seems that there is an error because in the table schema I defined quantity to be strings but when glue crawls and partitions the backfill data it decides to detect the column in that partition as double if there are no string cardinals in that day of data. 


Another question is how to move forward. I get intuitively that rigid SQL rules will not allow a string to be in the same column as a double. Should I drop the string from the float at the source level of ingest? Should I split quantities into columns by type with one being for strings and accept lots of null values in my table? Should I map the strings to int and keep a dictionary somewhere else to know what those Int values represent? Or something else"
dataengineering,Schema for transform/logging,2,1i3o76i,https://www.reddit.com/r/dataengineering/comments/1i3o76i/schema_for_transformlogging/,1737141287.0,"Ok data nerds, who can help me.

I am fixing 60,000 contact records
I have 3 tables: raw, audit log, and transform

My scripts focus on one field at a time 
E.g. Titles that are Mr or Ms 
- Load to table.transform as Mr. or Ms.
- table.auditlog gets a new record for each UID that is transformed with fieldname, oldvalue, new value
- table.tranform also gets a RevisionCounter where every UID new record is incremental so I can eventually query for the latest record 

This is flawed because I'm only querying table.raw 

should I copy all records into transform and just run scripts against max RevisionCounter per UID in transform? 

I'm worried about this table (mySQL) getting so huge really fast - 60,000 records x 30 transforms.... But maybe not?

Clearly someone has figured out the best way to do this. TIA!
- "
dataengineering,DP-203 Cert vs new DP-700 certification for new Data Engineer?,3,1i3k6f9,https://www.reddit.com/r/dataengineering/comments/1i3k6f9/dp203_cert_vs_new_dp700_certification_for_new/,1737131139.0,I am new to Data Engineering field. I just passed DP-900 Azure Data Fundamentals exams. I found out today that DP-203 being phased out in March 2025. Should I rush into taking it before it expires since thats the current industry standard or do you recommend me taking DP-700 Microsoft Fabric cert to future proof myself assuming the industry moves in that direction. Thanks for all your feedback!
