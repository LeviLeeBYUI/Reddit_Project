post_id,comment_id,comment_body,comment_score,created_utc
1i06k3y,m6vku18,"Can I Transition to a Career in Data Science?

I am a 24M who graduated university 1.5 years ago with a bachelor’s degree in mechanical engineering. Currently, I work as a quality engineer for a large aerospace company.

In my role, I use SQL almost daily and have found that I enjoy working with data in my role. I was always extremely comfortable in my mathematics courses as well. I am considering pursuing a career switch to data science and need advice (any is welcome).

I have been in my quality engineer role for about a year and a half, and I am looking to switch jobs in about 7-8 months so that is can correspond with my lease ending where I currently live:

Advice needed:
- Are data science certificates worth it? If so, any recommendations of specific programs or things to look for in a program? I would likely be able to get my employer to pay for it, but want to ensure the program is good because I will then likely not be able to drop it or I would need to pay myself.
- What sorts of specific actions should I be taking to make myself a more marketable candidate? Dive deeper into SQL, refresh myself on Python, etc? Like I said, I am early career so figured a switch is doable, and I could take the next 6 months to really build up my skills. 
- Is 6 or 7 months enough time to make myself marketable for data scientist roles?",3,1736745796.0
1i06k3y,m70i0nf,"have a technical interview at a startup tomorrow. I found out after the invite that they are embattled and struggling, have really low stock price and bad glassdoor reviews for DS positions. probably a free practice interview for me for a job that I think I am unlikely to take unless they instill confidence during the interview",2,1736813786.0
1i06k3y,m7304fs,"Looking for some career/Masters help.

Little bit of background, I'm a 24 year old Bio-analytical Graduate living in Ireland. I was registered to start a Bioinformatics Masters last September which fell through last minute. I ended up enrolling in a Post Graduate Diploma in Data Science with The Data Science Institute which operates through Woolf University.

I have the option to continue my studies into a full Masters but I'm unsure as I'm weary on the status of the University (Rankings, Employer recognition, Etc.). Ideally I'm looking for an online masters as I'm working from home as a caregiver for a family member during the day.

I'm considering taking my PDip. and applying for a different full masters such as the Online Msc. Statistics and Data Science from KU Leuvan. Honestly I'm abit lost at the moment as I've had alot of opportunities fall through in the last year. I suppose I'm asking 2 main questions.

**1.** Is a Data Science masters worth it? What's the Job market like, I'm open to moving anywhere in the world.

**2.** Does the University status matter, my course is accredited in Europe and all credits are ETCS, will employers be looking into that much or are they more likely to be looking at my portfolio of past projects?

Any help or thoughts at all would be much appreciated, I'm thinking over all my options and thought that it might be best to seek some advise.",2,1736854963.0
1i06k3y,m751y50,"I was recently hired as a Data Scientist in a manufacturing company and have been instructed to look into spec'ing out a PC for my work. My current research has led to [this](https://www.dell.com/en-us/shop/desktop-computers/precision-7875-tower-workstation/spd/precision-t7875-workstation/xctopt7875mtus_vp?view=configurations&configurationid=2b9e79c3-7786-4231-a4a1-dd09af30de11) build (I am *encouraged* to order through Dell) and, since I still have some budget left over, I am curious as to which aspect(s) I should opt for improving - if anything.

A little extra information:  
\- Use cases would be a myriad of DS/ML tasks, including shallow- and deep-learning model training on large datasets and database/API development (trivial)  
\- The ""No GPU"" option is currently selected with the knowledge that we have a 4090 lying around from a separate purchase  
\- Ideally the total price stays below $12k (slightly over would be negotiable)  
\- I don't need significant local storage, hence only the 256GB boot drive

My current thoughts are that I can either (a) decrease the RAM from 4x32GB to 2x32GB and upgrade the CPU from 7975WX to 7985WX, (b) select a GPU - 4500 Ada **or** 5000 Ada with the previously mentioned RAM decrease, or (c) upgrade the RAM from 4x32GB to 4x64GB (comes with required upgrade to a 512GB boot drive).",2,1736880028.0
1i06k3y,m6wuc1p,"I have a BA in math, been teaching high school since graduation. How do I go into data science?

There are very few MS stats programs in my area. This sub warns against MS DS programs. And MS CS programs are largely “cash cows” used by international students to get into the country. Is there even a way into the field for me at this point?",1,1736772393.0
1i06k3y,m6x3yo4,"I have a civil engineering degree, and I work in construction, and no one really pays attention to or utilizes any data. I would like to change that but want to get started on the right foot and I am unsure where to start.

I want to start my own access database to track all of the bids we conduct, which bids are awarded to us, track clients, market segments, etc. We have a wealth of information that is somewhat scattered, mostly stored in excel spreadsheets.

Just to try and give an example of what I'm trying to accomplish, here is an example below:

|| || |Estimate #|2025-01-13-001| |Project Name|example project| |Bid Type|Hard Bid | |Bid Date|01/13/2025| |Anticipated Start Date|04/01/2025| |Anticipated Duration|20 weeks| |Estimator|ZEZ| |Value|1,800,000| |Client|ACME Inc.| |Architect|Generic Architect Name Inc.| |Market Segment|Retail| |Project Address|123 Address Lane, City, State, 55555, USA| |Project Square Footage|12,000 SQFT|

All of the above data is common to the whole bid/project, however, this project has more detailed cost and scope information that I want track as well. Construction specifications already have a decent organizational structure to them:

|| || |Div 01 - General conditions|$100,000| |Div 02 - Demo |$50,000| |Div 03 - Concrete|$125,000| |032000 - rebar|$15,000| |033100 - concrete foundations|$65,000| |033200 - concrete slabs|$20,000| |033900 - concrete sidewalks & paving|$25,000| |etc. etc. etc.|$$$$|

I'm pretty sure I need some sort of hierarchical data structure, because all of those sub categories of concrete roll up into the division 3 total cost for concrete. There is also other data, such as the quantity of foundations and the square footage of slabs and sidewalks that I would like to include. Also, multiple subcontractor bids that apply to this scope of work could be another related table.

Can anyone point me in the right direction? I want to try and do it right the first time. Any help is appreciated, thanks!

edit: idk what happened to my table formatting.",1,1736776376.0
1i06k3y,m6xgczp,"I am in the middle of my last year as a PhD student in France, working on computer science, and I am wondering when should be the good time to start looking for opportunities after my PhD.  
I'm pretty much in a weird situation as I am in a private doctoral contract with a company which is an open-ended contract, so after my defence I am technically engaged with it. I wanted to start looking for opportunities in order to leverage and negociate my salary and find better jobs afterwards but I am king of lost in which order I should do the things.

Has anyone been in a similar situation? For PhD people, how did you do you research after your thesis?",1,1736780803.0
1i06k3y,m6xl98f,"I'm currently analysing a joined data set that includes public bus traffic, bus stops, lines, etc and referencing it with road works in the direct vicinity, to quantify resulting issues in bus punctuality/delays. Right now, i'm just comparing averages for peak hours for time slots before, within and after each relevant road work takes place. I can absolutely see higher delays for time periods in which there are road works on or near the bus line, which is quite expected. I would like to delve deeper into this relation and am currently looking for relevant statistical methods to quantify this. Does anyone maybe have any insights?",1,1736782380.0
1i06k3y,m70ajwg,"Hello guys! I’m new here and this is my last attempt to find a way to start on data science (correctly). 
Last year I took all my money and invested in a college, to start learning and in the future start working in the field. 
But sadly for me I just burnt my money bc it seems that a IT college in my country is just garbage and will only frustrate you. (I live in Latin America).
It seems that the only way to get something real is paying for my teachers personal classes.
Now I’m broke and everything I see is ppl selling classes but just superficial bs with tons of ppl complaining about.
I don’t know what to do now. I feel like I’m just running in circles and  I don’t know where to start and where to find knowledge for a roadmap.",1,1736811270.0
1i06k3y,m71llwj,"how to gain deeper understanding of r and python? 

  
Im a masters students so I have to be able make my own simulations/models. I read etexts and follow different tutorials on whichever package/module I'm trying to learn. And copying tutorials does help  especially learning the frameworks, but I cant figure out how to actually apply them.

Some things are easy, like regression models or arima, where you can insert the data into different models. But when it comes simulations or machine learning, I struggle to figure out both the tutorials and applications. For example, monte carlo simulation is sort of easy to understand conceptually, but besides the tutorial I have no idea how to make my own. I dont have any real research background, so its been a struggle. #business major

Maybe I can try making models from scratch to deepen my understanding? But thats sort of like an infinite learning loop. I'm not very strong in mathematics. The hardest math I took in undergrad was trig and I got a pity C. So now my professors casually pull out calculus and i'm lost. I try to find etextbooks in econ to study up on. And R and python have lots of resources too, but I don't really have a plan of attack.

It's not hopeless but it feels hopeless. I don't expect to become a self taught guru, but I do want to not immediately get fired when I get a job or lose my assistantship because I don't have real results.",1,1736826931.0
1i06k3y,m72ig7a,"As a Highschooler (10th Grade) interested in Data Science, what camps or credit courses could I take? What would be a logical next step? What AP's or courses within High School would be best suggested! Other ideas appreciated!",1,1736843858.0
1i06k3y,m73pqfp,"I’m considering taking the IBM Data Science Professional Certificate on Coursera to kickstart my career in data science. For those who’ve taken it, does it provide practical, job-ready skills and enough depth to stand out in the field? Any feedback on your experience would be greatly appreciated!",1,1736865542.0
1i06k3y,m749lht,"Would Coursera certifications make a family-related career break look better on my resume? I'm looking to get back into formal employment after a few years of a gap.

For context, I did an economics PhD, including a data science internship at a startup during the program. Then after graduating, worked as a software engineer for about a year, but then took time off starting late 2020 for family reasons. So I don't have much professional experience, just years and years of academic experience lol (out of the 6 years of PhD, 2 years were classes and 4 years were hands-on causal inference research projects).

How useful/necessary is a portfolio of personal projects for getting applications past the resume drop stage? Is it worthwhile to slap my dissertation chapters onto a website?

Thanks in advance for any help!",1,1736871779.0
1i06k3y,m71r0hy,I have similar questions to these. I've also been looking at data science certificates through different university programs and am unsure if these would be valuable.,1,1736829019.0
1i06k3y,m70zed0,"Yeah doing the interview for practice sake is not an bad option.   
  
I never saw the attraction of joining a startup as 75-90% of fail so equity means nothing, pay is low, have to work more than 50-60 hours consistently, benefits are poor.",1,1736819511.0
1i06k3y,m77ydvt,"I suppose it depends on your use case, but I found 64Gb of RAM to be inadequate when working with language models.",1,1736914263.0
1i06k3y,m6xeke9,"I would start by targeting analyst roles at edtech companies. See if you can land something like that before investing in another degree. (Maybe the company will help pay for a degree.) 

Also I would network with real people and not just base all of your career decisions on the opinions of people on an anonymous message board. Look for industry events in your city or join relevant Slack communities (people usually aren’t anonymous).",1,1736780200.0
1i06k3y,m6yz68v,"Right now is a good time. Ideally, you should be looking for job opportunities at the end of your second to last semester into the middle of your last semester. So the middle of your last year is a good time.",1,1736797012.0
1i06k3y,m77x01g,To quantify? Linear regression is what you're looking for.,1,1736913698.0
1i06k3y,m77wqi4,"[ISLR](https://www.statlearning.com) and [ESL](https://hastie.su.domains/ElemStatLearn/) are what you're looking for. Once you're done with ISLR, consider the [deep learning tracking](https://www.coursera.org/specializations/deep-learning#courses) on Coursera.

ESL is dense so take your time on that.",1,1736913592.0
1i1bjhi,m74r3p9,Paper that explains the math behind the method? Is this using a cumulative gain metric or using properties of the law of the iterated logarithm? This just shows how you use and install it.,34,1736876907.0
1i1bjhi,m752vnr,"Man, the contortions frequentists go through to avoid going Bayes (which inherently achieves all bullet points included above).",52,1736880295.0
1i1bjhi,m74zjdi,"Sounds like another useful tool for the toolbox, going to have to read up on it but really appreciate you sharing!",5,1736879329.0
1i1bjhi,m75188z,Can someone provide more context as to why P values are inappropriate for “sequential analysis”?,6,1736879818.0
1i1bjhi,m75p0x2,"The intention of the E-value is to propose a continuous quantification of evidence that has much better properties than the p-value. 

- it can be interpreted continuously as evidence. For p-values this is highly problematic (but still pervasive…)
- the product of two independent e-values is still an e-value. This allows easy merging of evidence across datasets or studies.
- the average of two arbitrary e-values is still an e-value.
- likelihood ratios are e-values (and so bayes factors as well in simple settings)
- the reciprocal 1/e of an e-value is a special kind of p-value with which we can truly “reject at level p” and still have a kind of Type I error guarantee on the decision.",7,1736886738.0
1i1bjhi,m74rufq,Isn’t this just a simple transform on a sequential p-value? Can you post a decent link to the math underlying it?,5,1736877120.0
1i1bjhi,m74sfgm,"How widely accepted are these new approaches to hypothesis testing among data scientists?

I have seen first-hand how more traditional methods can have major flaws when applied to online transactional data and how challenging the power analysis and test duration calculations can get...  while I'm super intrigued by these new approaches, I'm hesitant to deviate from these more traditional methods I've been taught to use.

These python packages referenced seem pretty new and both label themselves as ""unstable"" so I would be afraid to actually use them, but I may experiment with them and compare results with my more go-to methodologies for fun.",4,1736877285.0
1i1bjhi,m75s1nh,"The “interpretations” section of the wiki page has some depth here:

https://en.m.wikipedia.org/wiki/E-values",9,1736888033.0
1i1bjhi,m77u868,"Hahahahhah welcome to 2025, where math is replaced by python modules. 

STFU, the LLM figured it out.",3,1736912611.0
1i1bjhi,m74rwt5,"Hypothesis testing with e-values by Aaditya Ramdas and Ruodu Wang:

https://arxiv.org/pdf/2410.23614

They use both but primarily a cumulative gain metric since its non-negative martingales so the approach is a mixture supermartingale.

EDIT: LIL is primarily for confidence sequences from what I understand.",-9,1736877138.0
1i1bjhi,m753ovj,"I think it's also using f-, h-, i-, j- or k-value",-3,1736880529.0
1i1bjhi,m757pa4,"I'll admit to being hesitant to use Bayesian methods due to my lack of knowledge and the lack of knowledge of those around me.

All of my formal education was strictly frequentist so it's all I'm comfortable with and I'm concerned I'll mess up the actual implementation or do a piss-poor job of explaining it to those around me. I'd need to get to a level of understanding where I felt comfortable teaching the basics of it to others in my company before I'd be able to use it, and I'm not there yet.

If you have any resources I'd love recommendations!

Edit: also, every time I have attempted to use a Bayesian method it always takes FOREVER to run due to the size of the data we deal with. Is that just an implementation mistake on my part or is that always going to be a problem with Bayesian methods?",9,1736881685.0
1i1bjhi,m75ybkc,"I think that frequentists only object the use of priors that people do not truly believe in.

The fundamental intention of frequentist inference is to present the data in such a manner that anyone can apply their own prior to come to a conclusion. Rather than imposing some prior onto other people.

In the context of hypothesis testing, this means presenting the evidence against the hypothesis in such a manner that anyone can apply their personal prior to come to beliefs about whether the hypothesis is true or not.

This is also happening exactly with the e-value. A likelihood ratio is an e-value; e-values are a generalization of likelihood ratios. So you can simply multiply your prior odds with an e-value to end up with your posterior beliefs about the hypothesis.

This is much harder if someone has already imposed some prior for you: you need to first “strip away” their prior and then apply your own to come to your posterior beliefs.

Ironically, this form of frequentism facilitates true Bayesianism much better than Bayesians who impose their priors onto others…",7,1736889961.0
1i1bjhi,m758nmm,Bayes only works if you have the actual prior probability. You can't just plug in whatever number feels correct. The math equation only holds when it is precisely the true prior probability.,7,1736881964.0
1i1bjhi,m757uwo,I have yet to encounter a Bayesian who doesn't take any opportunity to lie by omission,3,1736881731.0
1i1bjhi,m775ymu,Hey don't insult us!!!,1,1736903951.0
1i1bjhi,m778rzy,E values provide controlled error rates over the whole sequence. Bayesian methods don't address or care about that.,1,1736904924.0
1i1bjhi,m7586n3,"Because with every new data point that comes in, you’re re-running your test on what is essentially the same dataset + 1 additional data point, which increases your chances of getting a statistically significant result by chance.

Let’s say you had a dataset with 1000 rows, but ran your test on 900 of the rows. Then you ran it again on 901 of the rows. And so on and so forth until you ran it against all 1000. Not only were the first 900 rows sufficient for you to run your test, but the additional rows are unlikely to deviate enough to make your result significant if it wasn’t with the first 900. Yet you’ve now run your test an extra 100 times, which means there’s a good chance you’ll get a statistically significant result at least once purely by chance, despite the fact that the underlying sample (and the population it represents) hasn’t changed meaningfully.

Note that this would be a problem even if you kept your sample size the same (e.g., if you took a sliding window approach where for every new data point that came in, you removed the earliest one currently in the sample and re-ran your test.)",19,1736881825.0
1i1bjhi,m75suoh,"In short: for any number of observations n, the probability that your p-value p_n is smaller than alpha, is smaller than alpha.

But the probability that at least one of the P-values p_1, … p_1000, say, is smaller than alpha is much larger!",1,1736888311.0
1i1bjhi,m74s227,"https://arxiv.org/pdf/2410.23614

Will include it in the post",0,1736877180.0
1i1bjhi,m75n7cm,The “interpretations” section on the wiki has some decent explanations: https://en.m.wikipedia.org/wiki/E-values,0,1736886189.0
1i1bjhi,m75ywnu,"In mathematical statistics, e-values are extremely hot and are taken very seriously. It will probably take a decade or so for them to be adopted more widely",1,1736890133.0
1i1bjhi,m74ukwn,Good approach to it. It seems as if it’s currently coming out slowly out of research stage despite being a relatively new research area (different names in the 90s for e-values) but not adopted widely by Data Scientists.,-2,1736877902.0
1i1bjhi,m75swgr,How the fuck is your paper 167 pages.,3,1736888327.0
1i1bjhi,m75p33p,"Statistical Rethinking by McElreath, his lectures are on YouTube as well",11,1736886761.0
1i1bjhi,m75s99d,"Every statistical method have some sort of prior assumption. The mathematical formulation of the model itself is just an assumption of what the real world should be, it is so true that scientists come across questioning and getting previews models better by changing the formulation. Laplace was the one who made Bayes ideia into an formula and Laplace itself used some frequentist approaches, as he invented some as well. Statistics is just an bunch of pre defined assumptions being tossed at an model, and people is still fighting for something so small as freq vs bayes. Just model!",5,1736888111.0
1i1bjhi,m75g76h,"It is both straightforward and common to test the posterior's sensitivity to the assumed prior distribution; it is typical that many reasonable choices of prior lead to materially equivalent conclusions.

If you think frequentist methods are superior... they are often equivalent to Bayesian inference with a specific choice of prior.",4,1736884160.0
1i1bjhi,m75omph,What the hell are you talking about? This isn't even remotely true. Your prior is often treated as a tunable hyper parameter.,2,1736886602.0
1i1bjhi,m75poyz,How do they lie by omission? I usually see the opposite -- bayesian methods force you to be explicit about your distributional assumptions.,2,1736887003.0
1i1bjhi,m75lkyl,"That’s an excellent explanation. I generally got the concept and knew it was to be avoided, and why we have corrections such as Bonferroni, but I properly get it now! Thank you 👍🏽",6,1736885716.0
1i1bjhi,m7732xm,"Are you implying that running a test multiple times with very small changes to the sample could get you a significant p-value by chance, even if the original p-value wasn’t significant?  Is that how it works? I know that in general, a p-value of .05 means there’s a 5% probably the relationship is by chance, and that repeated test on DIFFERENT data will give a false positive at some point if you keep repeating, but the p-value should be relatively stable if using basically the same data, even if it’s repeated many times, right?",0,1736902950.0
1i1bjhi,m76cb8h,"I was about to mention this too, the book is a work of art. Oh, what’s possible with passion and time.",1,1736894123.0
1i1bjhi,m76bba0,"Not sure why you are getting down voted, you are correct. For those overly pedantic about ""prior beliefs"", there are also uninformative-priors that are commonly used. 

In fact, many mathematical equation solvers use this concept in the background to quickly solve systems.",2,1736893816.0
1i1bjhi,m75pqyi,"If you have a math equation, 


A= b* c.


The equation only holds true if you plug in the actual value for c, not your belief about what c is",2,1736887026.0
1i1bjhi,m75zi9d,"Omitting their own other contortions to reach those points ""inherently"".

Sure once you have applied Bayes, it inherently now means that, but the question is when you should or shouldn't.",2,1736890310.0
1i1bjhi,m7776bt,"> Are you implying 

Yea. If the null is true, you’d expect the p-value to be relatively stable, like you said, but it’ll still fluctuate as you add in more data and do repeated tests, and with each additional data point and repeated test, you will increase your likelihood of a Type I error.",1,1736904370.0
1i1bjhi,m77dgyc,"> I know that in general, a p-value of .05 means there’s a 5% probably the relationship is by chance,

This is an incorrect definition of a p-value. P-value tells you nothing about the probability of the null (which is trivially just 0 or 1 anyway in a frequentist paradigm). It is the probability, given that the null is true, of observing a test statistic equal to or more extreme than the one calculated from the data.",1,1736906546.0
1i1bjhi,m76nnw4,Because this sub is pretty low quality unfortunately.,2,1736897799.0
1i1bjhi,m76dzor,"He is being downvoted because it's still plugging wrong numbers into an equation, the equality no longer holds. 


The uninformative priors are still not the correct prior. It's like plugging in the wrong numbers into Pythagorean theorem, it doesn't mean anything anymore.",-3,1736894642.0
1i1bjhi,m75r113,"The equation holds for all A, b, and c that satisfy that relationship, but I don't understand what point you're making about Bayesian modelling. 

In practice, if you don't know what c is, you model it with a probability distribution. Then you get a probability distribution for A (assuming b is known). Sometimes that's the best you can do.",2,1736887587.0
1i1bjhi,m77e6pf,"Isn’t this just another way of saying that if the alternative is false, the probability that the relationship your data shows is by chance, because the extreme result you got wasn’t in line with what the reality is? Genuinely asking as I am relatively new to stats.",1,1736906797.0
1i1bjhi,m76ju46,"I'd encourage you and anyone reading this to do their own research on uninformative priors and not to accept Reddit threads or votes as truth.

Comparing how to solve *statistical* systems to a deterministic equation like the Pythagorean theorem is not only a false analogy but can lead naive internet readers astray.",3,1736896526.0
1i1bjhi,m76nffu,"What do you mean ""it's plugging wrong numbers into an equation?"" You're creating a statistical model, what equation are you referring to? The model specification?",1,1736897720.0
1i1bjhi,m76l5o3,"I've done plenty of research on uninformative priors. I encourage anyone reading to study why Fisher was against the theory of inverse probability.


The equal sign has a meaning, by stating an expression with an equal sign without the actual prior violated the equality.",0,1736896964.0
1i1bjhi,m76ouyr,I'm referring to using values that are not the prior,0,1736898193.0
1i1bjhi,m76p3yd,But we do use values from the prior in all applications...,1,1736898277.0
1i1bjhi,m76s4bk,A belief isn't a probability,0,1736899274.0
1i1bjhi,m76scdc,Okay and...?,1,1736899349.0
1i0x2pm,m71lfce,Try polars,319,1736826864.0
1i0x2pm,m71jxxq,"[] is used to select a column from a DataFrame.  [[]] is used to select multiple columns in a DataFrame.  ({}) is used to create a DataFrame from a dictionary.

Maybe it’s because I learned Python first, but I enjoy Pandas more than R.  I can manipulate the data more easily (for myself) and I’m not really sure what the issue is here.  It sounds like you’re just unfamiliar with it and dislike it because you were already familiar with something else.",674,1736826323.0
1i0x2pm,m71lv8w,"Wait til you find out that the ""linear"" interpolator doesn't do what any thinking person would assume it does.


That said I actually love pandas but the learning curve is a little bit steep at first.",67,1736827027.0
1i0x2pm,m71kjqf,"R is great until you need to put something in production.

As someone who started with R, Pandas does get better and Python is generally better.

Good luck 🍀

E: I should have clarified a few things. My team used Python before I was hired, so I use Python. R is great. Shiny is great. Tidyverse is great.

As many have pointed out, you can run R on prod. I never stated that it is not possible or difficult. However, as someone who works with colleagues that use Python, I don’t expect them to pick up R or maintain my R code. 

To those that are still using R outside of academia and research, congratulations. The job market in my area is Python dominated and I couldn’t afford to ignore it.",201,1736826540.0
1i0x2pm,m71rz4h,"Hmm. I get where you are coming from. But as someone who started with tidyverse then started pandas, I'd say your frustration is coming from not understanding Python - or the lack of fluency in programming in general.

Don't get me wrong, as with any complicated library, pandas has its fair share of inconsistencies and oddities. But fundamentally, it is very clean and mostly Pythonic. I tend to write it in a way that is very similar to how I write tidyverse. If you can write pandas in a concise and clear way, it will be more efficient too.

Of course, you could always try polars and others. But pandas has less ""gotchas"" and is more consistent (pr at least more flexible) than base R or tidyverse. (I have heard great things about data.tables, so perhaps that is a different experience).",51,1736829424.0
1i0x2pm,m71nj70,"I love the tidyverse. Wes McKinney works at Posit now, and I think there is a clear acknowledgement that while python's industry penetration is greater, the tidy syntactic sugar is without equal. Hadley ftw

As many here are saying, polars isn't supposed to be as awful. My experience with it is limited though.",26,1736827647.0
1i0x2pm,m720q6l,"I'm ex R user too and pandas suck.
Try polars, it's better and much faster .",18,1736833464.0
1i0x2pm,m71wi4c,"I think tidyverse is beautiful.
R1’s pipe allows for many tiny packages and functions to link together.

But python method chaining means you end up with massive modules that have to be able to do the whole lot e.g. pandas, scikit learn.

To me it feels bloated and therefore not the best approach. I personally prefer the ease of just creating tiny packages and functions as needed that can just pipe in as required.",17,1736831436.0
1i0x2pm,m71kcly,"Pyspark, Ray Dataset, Torch Dataset, Polars, Dask

come on, keep up",38,1736826468.0
1i0x2pm,m72qpie,"Here's the situation.  python is great.  You can't work with LLMs or really do much with neural networks at all in R.  No one is trashing python's role in deep ML.

But pandas is bad.  matplotlib is bad.  Yes, there are some better alternatives now like polars, but even polars will never match tidyverse syntax due to python's limitations on non-standard evaluation.  And I guarantee that as python user, you'll STILL get stuck with pandas and matplotlib through legacy code and collaboration.

For these reasons, the data science community needs to defend R.  It absolutely has a use case.  Some people are really good at it and super productive.  Yes, you can put it in production!

Maybe I'm crazy, but there almost seems to be a coalition of

\- middle managers trying to simplify their team's tool stack in a misguided way

\- software developers who think it would be very convenient if other (completely different) disciplines would just conform to their standards

\- kaggle bros for whom everything is a problem to be solved with tensorflow

trying to trash R.

As a data scientist, you should not join this coalition!  They are not your friends.  They might come for one of your tools next.

You like python?  It's totally fine.  You don't need to trash R.  Just chill.",18,1736849341.0
1i0x2pm,m72dscy,"Sounds similar to anyone learning a new language, programming or otherwise. 

Just get over it, and get on with it.",10,1736840874.0
1i0x2pm,m71pn8a,"It gets more intuitive the more familiar with objects and modules you become in python. That doesn’t mean it gets better, but things start making sense. You have to instantiate an object to make a multi index slice. Why not just use a tuple, that’s cleaner? Probably a million reasons. Learn the syntax and move on to figuring out your actual ideas. 

I personally think numpy is the perfect learning library. Functional modules all throughout. Matplotlib is the exact opposite and can show you how far we’ve fallen from the light into oop madness.",10,1736828462.0
1i0x2pm,m720j39,I was there in the beginning too. You just gotta learn. Now I love it,5,1736833367.0
1i0x2pm,m73kf2g,Steady decline? Any data to back that up? Seems to gaining ground with how awesome tidymodels is.,4,1736863652.0
1i0x2pm,m71pvlp,Seems like a skill issue,23,1736828555.0
1i0x2pm,m71la5z,"I think you need to take an Intro to Python course. I often recommend that people take an Intro to Python course (up to OOP) before working with pandas or any other data science library. 

Source: I switched from R to Python earlier in my career and I think Python is a more superior language.",16,1736826809.0
1i0x2pm,m71j28f,I love pandas. Don’t know what you’re talking about.,27,1736826002.0
1i0x2pm,m71p3lp,Polars and PyArrow.,8,1736828250.0
1i0x2pm,m736tr1,"""A coder's dream"" - it's more like the non-coder's dream. It's much easier than pandas because you don't have to learn programming, it's more similar to algebra than object oriented programming. But I agree with you R is wonderful for data science. You can't beat the tidyverse.",3,1736858237.0
1i0x2pm,m73q11f,"Glad I’m not the only one, R is love",3,1736865644.0
1i0x2pm,m73xx0j,"Whatever programming language you learn first is going to embed you with very strong opinions of how all languages should be. I work as a software engineer and I've seen (both in others and myself) a lot of grievances when you suddenly have to do something familiar in your more dominant language but now face foreign syntax and errors.

Tools and frameworks are always changing, if you intend to do programming in any field for any reasonable length of time you will need to work around new programming paradigms or you will definitely get left behind",3,1736868216.0
1i0x2pm,m7600e7,Lmao {}[] complication is real as fuck,3,1736890460.0
1i0x2pm,m72ang6,"I was ready to die in this hill since my first R line.

Long live R and fuck python. The only think I need to know is how the fuck did a data driven field ended up in a fucking language with no built in matrixes.

Don’t get me started on why Objects doesn’t do shit for most of the data problem and workflows.",10,1736838946.0
1i0x2pm,m71oeqc,You just get used to it.  People complain about it being too complicated but in reality there are probably like 10 things that cover 99% of operations.  You just learn it and use it.,4,1736827984.0
1i0x2pm,m71vxty,Oh but why is Dinesh from ITs face in this post content?,5,1736831174.0
1i0x2pm,m72m1oc,"(un)fortunately, it will take some time for you to get used to it if you're switching from another language or stack.

But im sure you'll quickly get used to it.

  
Have fun",2,1736846247.0
1i0x2pm,m7387sr,"I have adhd and find it impossible to remember all the python structures. It simply assumes everyone is a software engineer and is NOT user friendly. 

Rather - I’ll say that python is a great software engineering language but a horrible data science language. Because the data science part is an overlay over a normal programming language whose structures need to be respected. 

I’m currently building an AI x analytics company and all the data science code so far is in R.",2,1736858861.0
1i0x2pm,m74rpnr,"There is a lot of bad Pandas code out there because of how many alternatives Pandas provide. I think accessing columns with a period is an abomination (`df.col`), but I know that users like it. I prefer (`df['col']`) as it is more ergonomic to create functions.

As for `df.loc`, this is challenging to understand initially, but once you do, it becomes incredibly powerful.


The following expression returns the column name on the rows in which the column categories contains the word ""pizza"" (case-insensitive).

```python
df.loc[df['categories'].str.contains(""pizza"", case=False), ['name']]
```

If this is something you would do on an ongoing basis, you can write as a function and then pass it to any DataFrame that has the same characteristics.

```python
def contains_substring(any_df: pd.DataFrame, substring: str) -> pd.DataFrame:
    return any_df.loc[df[""categories""].str.contains(""substring"", case=False), [""name""]]
```

Then you could use your function by using the pipe method, `df.pipe(contains_substring)`.

It works in the following fashion `df.loc[condition for rows (required), columns selected]`

As for if else pattern matching, I do believe Polars does it better with their `pl.when().otherwise`, but you can obtain similar results with either Numpy `np.select` or even simpler using base Python, e.g., You want to create a column given an if-else, you could write.

```python
(
    df.assign(
        new_col=(df[col] > 5).map(
            {True: ""Larger than five"", False: ""Not larger than five""}
        )
    )
)
```

Pandas was created to evaluate quick Series (single columns) and leverage the Index/MultiIndex. While the Index is a subject of contention for most people, especially from SQL, R, etc., once you understand how it works, you can leverage its functionality.

Check out Matt Harrison for best practices on how to leverage piping in Pandas.

Also check out Black or Ruff for formatting code so it's nice and clean.",2,1736877082.0
1i0x2pm,m75eyko,Polars is really the best option. Kick pandas to the curb,2,1736883801.0
1i0x2pm,m76y6w9,"OMG - I am 100% with you. R + data.table (not a tidyverse fan) has been a staple for me. I have been dragged into the Python world, and I want to scream every time I need to work w/ it. Thank goodness for AI to fill in the blanks otherwise I'd be spending too much of my life wrestling w/ pandas.",2,1736901293.0
1i0x2pm,m724hio,Pandas makes sense in python because iy uses python structures and syntax. Just familiarize yourself with the basics of python and youll find it a lot more intuitive,2,1736835425.0
1i0x2pm,m72o1tj,"In my experience people who come from development background loves python more. I come from data/ sql background, at first it was just simple view function for me, then i realized python doesn't have several base functions of R. For example you have to either do a for loop or download statistics module in python to calculate a simple mean/average. 
And recently i was working with a dataframe in python. Now we all know the 0-1 indexing difference but it is still challenging. i don't understand why you would put in an extra column to be excluded. When you write df.iloc[:, 0:3], it selects columns 0, 1, and 2, but excludes column index 3.
It also annoys me to write package name before every freaking function in python. So not just fuck pandas but fuck python, long live R imo. 
Sorry for piggybacking on your rant.",3,1736847602.0
1i0x2pm,m71l33w,"The only thing worse than Pandas to work with is R.

Polars or Pyspark is where it's at.",4,1736826735.0
1i0x2pm,m71ndyc,How are you learning Python out of interest?,2,1736827592.0
1i0x2pm,m723tqa,Start new library that’s different than the LANGUAGE they like. Rant that the library isn’t like the language they like after using it for a hot minute as if they’re edgy. What’s the point.,2,1736835072.0
1i0x2pm,m72qsj6,"Nothing beats R data.table. Not pandas, not polars, not tidyverse.  The really useful stuff isn't even implemented (grouping sets or non-equi joins for instance).",2,1736849396.0
1i0x2pm,m7350q2,"My advice. Use DuckDB.

You can outsource the vast majority of pandas data transformations to DuckDB 100% seamlessly any time you need to use pandas (because it allows SQL on top of Pandas data frames).

Plus, you can also use it in R similarly and it has interoperability with Dplyr. So it doesn’t tie you to Python at all (if you prefer R).

Of course, this assumes that you know SQL, but I can’t imagine someone being in data science without knowing SQL.",2,1736857406.0
1i0x2pm,m71n172,It’s not as nice as R but Python is more practical for enterprise use cases. It just integrates much better into the rest of the IT ecosystem.,1,1736827461.0
1i0x2pm,m72mro9,lol haters gonna hate learn to code like a real swe scrub,3,1736846739.0
1i0x2pm,m71okm4,Just remember that it feels much better when you get the acceptance. You will still have to mess with things like graphics but at least you know for sure that it is all worthwhile. Best wishes.,1,1736828048.0
1i0x2pm,m728sxx,"Data.table and tidyverse are beautiful, intuitive and easy to remember syntax. But with copilots, do any of these matter ? Readability can be addressed too with comments",1,1736837860.0
1i0x2pm,m72bxoz,"I see what you are saying but I got one problem with your rant. Pandas is opensource. Somebody put effort and time into writing it. If you don’t like it, use something else.",1,1736839732.0
1i0x2pm,m72f557,Use polars,1,1736841711.0
1i0x2pm,m72heuw,"I've been creating a data frame library in Haskell: https://github.com/mchav/dataframe


Sometimes when I look at the way Pandas does things for comparison I get really confused the look up how the same thing is done in dplyr or Polars. ",1,1736843172.0
1i0x2pm,m72kot2,Switch to Pyspark.,1,1736845341.0
1i0x2pm,m72po0o,just use polars,1,1736848662.0
1i0x2pm,m72rb7i,"OK I see your error there, your first error was to use pandas in the first place",1,1736849735.0
1i0x2pm,m72uj2g,Not seen a juvenile R vs Python/pandas rant in a while. Takes me back.,1,1736851735.0
1i0x2pm,m72x0uo,i thought the problem was that pandas were very bad at fucking,1,1736853221.0
1i0x2pm,m7304mn,"I also came from R and your rant is partially misdirected. Yes, the syntax is just extra steps and bad but it has so many features allowing you to transition easily from R.

Filtering can be done with .query() instead of boolean indexing. Pandas is already vectorized so using numpy means you are using stuff that is not vectorized. R is already vectorized out of the box.

Since you’re coming from R and data.table, I would recommend Polars. It allows you to do similar stuff like dplyr and manipulating your dataframe without ever leaving the manipulation sequence.",1,1736854966.0
1i0x2pm,m733vu9,"Pandas definitely suffers from having grown organically, instead of with clear design in mind.

However, numpy is already a dependency of Pandas, I believe, so when you have Pandas you should be able to just import it, no need to install it again.

Pandas usage is a bit like cooking recipes. You learn one bit at a time when you need it, until you grasp the underlying structure and can derive how to do things. But if you did not use it for a while, you start learning anew, because of it not being very intuitive.",1,1736856867.0
1i0x2pm,m7349w7,"PySpark syntax > Pandas

I hate pandas as well.",1,1736857055.0
1i0x2pm,m737098,Have ChatGPT write it for you. It doesn’t mind the syntax lol,1,1736858321.0
1i0x2pm,m737wtz,seems like you tried learning pandas without learning Python and its data structures first,1,1736858727.0
1i0x2pm,m738lvi,What’s funny is that Pandas was invented to replicate R data frame manipulation in Python,1,1736859032.0
1i0x2pm,m73q6p3,"I’ve had to start learning R for work after primarily using Python for years. What has been really frustrating about R to me is that there are so many different ways to do things- dplyr, purrr, base R etc. 

When I’m stuck and trying to find answers on Stack Overflow or using examples from books there doesn’t seem to be much consistency so it’s been hard to get a clear mental model of how to approach problems. 

Pandas has its own hurdles and weirdness but imo they are self-contained weirdnesses. They are consistent so once you have the mental model developed you’re good and have a consistent way to approach things.",1,1736865697.0
1i0x2pm,m74bdfi,"With you on this one. Cut my teeth in MATLAB, switched to Python and then to R. Transitioning back to Python after 6 years with data.tables and Pandas seems archaic and inefficient (syntactically and computationally) in comparison. 

But given that's where the industry is headed, I am letting out a deep sigh and pushing myself through the transition. <Deeper sigh>",1,1736872310.0
1i0x2pm,m74ibek,R to python is a nightmare as a data scientist. There is little help available compared to R and 70 pc of my time goes in troubleshooting. I am at my wit's end.,1,1736874351.0
1i0x2pm,m74lpdw,Nobody likes Pandas mate,1,1736875344.0
1i0x2pm,m74rp1k,Polars is more efficient,1,1736877077.0
1i0x2pm,m75ihs6,have you even installed linux first?,1,1736884816.0
1i0x2pm,m75ydko,"R is designed for scientists, pandas/python is designed for programmers. As a software engineer working as a data monkey atm, pandas has always been intuitively understandable to me whereas R requires more banging my head against a wall. I think it’s just a matter of background and training.",1,1736889978.0
1i0x2pm,m76envo,"Someone doesn't actually know how to program, they know how to use R.",1,1736894853.0
1i0x2pm,m76omg2,If only Julia got more love...,1,1736898114.0
1i0x2pm,m76r5xj,"Skill issue, tbh. Large learning curve but it makes sense once you learn it.",1,1736898958.0
1i0x2pm,m777xn4,I understand what you are actually saying but can we not fuck pandas?,1,1736904633.0
1i0x2pm,m77i3ps,I find it funny that he is complaining about the syntax of Pandas but loves R.  I couldn't stand learning R because the syntax felt like it was written by someone who never used another programming language before.,1,1736908176.0
1i0x2pm,m77nht9,"liked R for: .Rdata & %>% or |>

haven't seen anything like .Rdata in Python yet. .Rdata save dataframe + function definitions. closest in Python save dataframe only?

R is mostly functional lang (FP) whereas Python is mostly object oriented (OOP). don't mean anything to avg data analyst/scientist writing everything imperatively

* FP pro: http://adv-r.had.co.nz/Functional-programming.html
* FP con: not as popular as OOP, require different approach, OOP easier to understand",1,1736910092.0
1i0x2pm,m77siz2,DuckDB + pandas was a game-changer for me. Querying dataframes directly with SQL syntax is superb.,1,1736911956.0
1i0x2pm,m77vah2,Try h1b,1,1736913022.0
1i0x2pm,m781qfe,Python is better for the real world,1,1736915675.0
1i0x2pm,m72czao,Skill issue ,1,1736840377.0
1i0x2pm,m720kw4,"Started out of college using R, have now completely abandoned it and using python + SQL flavors for database development/data analysis. R is great for what it can do, but productionizing it is so incredibly difficult. I with sympathize your frustration because I felt like if I knew I wasn't going to use R, I would have invested more time into learning python.",1,1736833391.0
1i0x2pm,m71yme7,"As a computer scientist / software engineer, I do **not** like R's multiple function calling semantics. It's very unintuitive for my mental model of computation. E.g.:

* Standard function calls like `sum(x)`
* Special contexts with setter functions like `names(x)`

These change the syntax depending on the implementation of the function.",1,1736832430.0
1i0x2pm,m7257i2,"I learned R before python and pandas. I do like R more but as the kids say this is a skill issue.

Python and pandas at least at the time I transitioned was 100x more extensible to other things than R.

Doing anything out side of analysis was just a massive fucking pain in the ass.

This was like 2012 though.

Edit: fuck multi indexing though that shit is a cluster fuck of implementation.",1,1736835821.0
1i0x2pm,m72iel6,"Really do agree, I  don't like the syntax of Pandas. I really like Python, but kinda dislike Pandas. Thankfully a lot can be done with numpy instead of pandas.

My opinion is to figure out which operations are used the most, and then write a cookbook for those things. Stuff like ""filter on condition"", ""filter on two or more conditions"", ""replace value if condition matches"", ""replace value if condition matches for each in selected\_columns"", ""fill empty values with average of column for each in selected\_columns"", just to name a few so you get the gist.",1,1736843828.0
1i0x2pm,m72x9ha,I support the pandas hate bandwagon,1,1736853359.0
1i0x2pm,m73qt2e,I never had an issue with the brackets. I don't wanna sound like that guy but I think one of your problems can be solved by just going through the basics like lists and dictionaries,1,1736865908.0
1i0x2pm,m71prcc,"Im a statistician and learned R in my undergrad. Since I did a ""minor"" in data science, also learned Python in the end. 

At first, i dont mean to be rude, but you have no idea of what are you talking about. R and Python are just wrappers of low level code like libsvm, liblinear, lightgbm etc. When you say ""fast"", R isnt fast, probably is just the implementation

When you say that pandas have a messy syntax, you are coping hard. There's no ""good"" syntax, its the same thing that I try to learn german and criticize the language because french is perfect 

At least, you learned what matters: in the end of the day, money talks, learn what the market wants or someone will learn it for you

I can finish telling you that what is really blazing fast at the moment is Rust, not Python or R. Polars is the scariest thing that I ever learned from this days. Sounds like cheating.",-4,1736828508.0
1i0x2pm,m71nifc,Skill issue and don't feed the troll,-1,1736827639.0
1i0x2pm,m71wihp,This guy saying it like typing “->” is better than “=“ for setting variables lol,0,1736831441.0
1i0x2pm,m71r9hx,I was just thinking today how glad I am that R isn’t really a thing in industry. The syntax of Python is much more intuitive to me and it’s a more versatile language.,-2,1736829123.0
1i0x2pm,m71p27m,🐻‍❄️,0,1736828235.0
1i0x2pm,m720lng,Seems like a skill issue more than a problem with pandas(where there are many),0,1736833402.0
1i0x2pm,m732jiz,"python is so much better for working with larger data sets it's not even funny. 

R is good for smaller task specific chunks.",0,1736856213.0
1i0x2pm,m71ldmr,Blasphemous!!,-1,1736826846.0
1i0x2pm,m72dg8t,Python/Pandas is more intuitive. Your brain is too fixated on R. There's a reason nobody uses R in production for anything. And don't get me started on the mess that is the R package system.,-2,1736840666.0
1i0x2pm,m71z1lg,Use Github Copilot or any other free AI code completion.,-1,1736832635.0
1i0x2pm,m73i6g3,I can't tell if this is satire or sincere and just painfully embarrassing to read. If you can't figure out something as simple as Pandas then I don't know. Maybe this field isn't for you because pandas is probably the least complicated part of it.,-1,1736862824.0
1i0x2pm,m7278ub,Fuck pandas? The Chinese Communist Party will be knocking \[down\] on your door.,0,1736836967.0
1i0x2pm,m7293af,"Is it a pandas issue or a python issue? Like others have said, try other libraries like polars.",0,1736838019.0
1i0x2pm,m72o2s3,"I agree that pandas has atrocious syntax and overall no coherent pattern. As someone with a lot of experience in C/C++ it was very annoying to go over the so many layers of bs just to do a simple operation on a vector.. many times just making the column into a list/numpy array and writing regular python on it.

But I also think that it is a good package to have, messy as it is. With the help of AI it's quite easy to wrap your head around it.

Programming looks like it's diverging a lot from good standard practices, coherent patterns, and efficiency... But maybe that is not a problem, as AI will be our next compiler and coding will change a lot in the next years.",0,1736847620.0
1i0x2pm,m73yq35,Noob,0,1736868468.0
1i0x2pm,m74d3kc,Pandas is so easy what are you talm bout.,0,1736872823.0
1i0x2pm,m74wmq9,L2p n00b,0,1736878495.0
1i0x2pm,m756yua,"Python and pandas does the job, the issue is with you.",0,1736881466.0
1i0x2pm,m75f2sy,why he mad bro?,0,1736883835.0
1i0x2pm,m75ui0i,"I have seen R called many things, efficient and beautiful have never been those things though.",0,1736888825.0
1i0x2pm,m76k5xd,"Talk is cheap, send fixes",0,1736896634.0
1i0x2pm,m71ze76,Python makes total sense compared to the giant anti pattern that is R. Indexing from 1? Fuck that,-6,1736832805.0
1i0x2pm,m71v68u,".,",-1,1736830827.0
1i0x2pm,m72at8n,"When working in Python, you'll end with a huge amount of pandas tables (intermediary, subset, grouped, filtered, columns dropped...), it will take a toll on memory. But the nice thing is ability to use Notebooks and see / plot things. Notebooks is what makes python great.

What I'm missing is type checking / l'inter (as a lot of issues will fly undetected and will only reveal on run), making a python buletprof for production needs another type of attention.

Today I kind of prefer working in Typescript (Nodejs), somehow made my own classes for data tables (keeping arrays of data for each column, using one for indexing, having a special class for utility methods), the Notebooks for js are sketchy, but still work, I can convert my data to danfos tables and print like in python, plotly works fine (even if you need to write everything, no shortcut integrated commodity plots). For production, my equivalent node code is about x2, x3 faster then python one...",-1,1736839043.0
1i0x2pm,m71k5oa,"Pandas and sql are both dead. In data science you must be able to work with big data which means using pyspark. 

Obviously it’s not dead for those in tech debt. But for anyone trying to be modern it’s all about pyspark.",-20,1736826399.0
1i0x2pm,m71sfc1,"Never been an R user but seen some code and let me tell you. Python is the most well rounded language I have ever seen, streamlit for web applications, kivymd for Android applications. You name it.",-8,1736829617.0
1i0x2pm,m73s9b6,"Your free of reference is wrong. Your comparing R that you were seemingly proficient in with digging you're a novice in. Pandas/python has taken over R because it's easy to use and better in most use cases. 

If you're unable to learn pandas then maybe a different career path is for you mate",-4,1736866393.0
1i0x2pm,m723njq,The groan I emit when I have to work on a pandas script I wrote before I switched to polars can wake the dead.,99,1736834980.0
1i0x2pm,m71n63e,Agreed. Polars has been an improvement for me but data frames in general have their quirks,60,1736827510.0
1i0x2pm,m71o21r,"+1
Polars is the pretty much the only reason I kind of enjoy python after coming from R",50,1736827848.0
1i0x2pm,m71o9tg,"6 months ago to learn Polars, I was building an algorithmic trading project (simple s&p 500 10 years data) forecasting using Polars and I swear there were so many functions it currently doesn't have. I had to use pandas intermediately for such functions and then revert back to Polars. Also my code was so simple, there was not much speed difference.",29,1736827931.0
1i0x2pm,m72b99c,Still no geo support.,5,1736839313.0
1i0x2pm,m71l6n3,"I can see where OP is coming from, but it ultimately stems from not understanding python data structures.",407,1736826772.0
1i0x2pm,m71vpvw,"Same, I learned python first (after C, Java etc)  and find R syntax very weird",41,1736831072.0
1i0x2pm,m71xzoz,I went from R to Python and never went back. IMO pandas is easier to read because python is easier to read. But just my opinion. I know R super users who do impressive things,25,1736832131.0
1i0x2pm,m729uqu,OP might not have used numpy fancy indexing before. It gets intuitive over time.,2,1736838471.0
1i0x2pm,m74iswj,"I learned R first (thanks academia) and python is undoubtedly 100x better.

The only thing I miss is piping from R.",3,1736874495.0
1i0x2pm,m76n2gy,"Yea I am literally writing R right now while Python is my main and as far as I can tell the only difference is R loves these %>%.

And yea, just doubled checked one of the more difficult pandas groupby’s that I have and it’s 2 lines longer because of the split apply combine (which even takes forever to say btw). 

I have no idea what OP is going on about but my assumption is that he just doesn’t know python",1,1736897602.0
1i0x2pm,m76oyuq,"There is hardly any built in way to do anything in R, so I think OP’s complaint about needing numpy is pretty rich. That matrix, table, tibble, and data.frame among others are all, from what I can tell, equally commonplace in R, is pretty annoying imo. I’ve settled on dplyr because it’s easy for me to remember, but I cannot even fathom an argument that it is more intuitive than pandas.

But I think you are right — whatever you learn first is coziest, and having to learn new ways of doing things that were previously completely mindless is annoying no matter which way you are going.",1,1736898229.0
1i0x2pm,m72jnux,"You enjoy the first example more than the second?

I really don't understand it.  Python takes me over twice as long to write because it requires so many more characters and a mess of brackets and quotes.

python

    import pandas as pd
    import numpy as np 
    
    x = np.array([1, 2, 3]) 
    y = np.array([4, 5, 6]) 
    df = pd.DataFrame({'x': x, 'y': y, 'xy': x * y})

R

    library(tidyverse)
    
    df <- tibble(x = c(1, 2, 3), y = c(4, 5, 6), xy = x * y)",-4,1736844655.0
1i0x2pm,m71mj2f,It’s a joke :) I’m sure it’s great once I get used to it. Just personally found it very counterintuitive,-35,1736827271.0
1i0x2pm,m74ouj6,"Could you clarify what you mean about linear interpolation please?

Not saying you're wrong, just not sure which part you're referring to

EDIT: oh are you referring to the ""Ignore the index and treat the values as equally spaced"" part? Yeah that seems quite odd, especially given how central the index is to everything in pandas...",1,1736876258.0
1i0x2pm,m71nuw2,"R isn’t hard to put in production. Engineers just don’t want to put it in production.

Source: Been at a company with smart engineers, and been at a company with lazy engineers.",70,1736827772.0
1i0x2pm,m71niyl,"I keep seeing people saying R is hard to put into production, but I really haven’t seen anyone give a detailed explanation why it’s harder than python these days. Plumber makes it pretty straightforward to build a RESTful service, most cloud services have R support built in, and docker is, well docker.",58,1736827645.0
1i0x2pm,m724oyg,"It’s not that it’s difficult to put into production, but if you already have Python then it is SIGNIFICANTLY higher level of effort to put another thing that does the same thing into production and maintain in the long run. If you’re going to have multiple things do the same thing in production, you better have good justification as to why.",4,1736835537.0
1i0x2pm,m721mqg,"Oh you read somewhere someone wrote R is not for production and decided to contribute to a not relevant discussion by parroting what you read.

R is a programing language and is just as good for production. (deployed numerous ones that are still running to date) This myth stems from lowcode statisticians writing messy R since they are not engineers, nothing more.",6,1736833925.0
1i0x2pm,m73981m,you also have Shiny in Python,1,1736859295.0
1i0x2pm,m73vzyr,"> R is great until you need to put something in production

> I never stated that it is not possible or difficult.

Bruh. What did your first sentence intend to imply if not, at a minimum, that it was difficult?",1,1736867607.0
1i0x2pm,m7267dl,"R users never realize this because they only ever use it as a fancy calculator. 

Python is extendable and goes very far because its community is huge and interested in lots of things. It does OOP amazingly and is a generalists dream language, because its quick and easy to setup— it just works!!

R has a more dedicated and smaller group statisticians who made it more convenient for scripting.
But in terms of production value, it feels closer to Matlab. Its helpful for its “corner” of analyses, but doesn't extend well.
 ",-5,1736836378.0
1i0x2pm,m71wcvv,"Read my post again friend. I never said R is faster than python. I said data table package in python is faster than pandas (and much more better).
This is not my opinion. This is a real based on actual execution speed. (Which is what the linked article shows)",-31,1736831368.0
1i0x2pm,m74l5kk,Yeah. Pandas was based on base R’s data frame. It’s not surprising that BOTH languages (AND their ecosystem’s core developers) are moving on to better tools.,3,1736875183.0
1i0x2pm,m71n9zt,"I'm a hobbyist and work with cuDF and Dask cuDF, and I fit it amazing!",9,1736827551.0
1i0x2pm,m71tbaz,Ibis!,2,1736830003.0
1i0x2pm,m76lbmc,"Ray datasets would not be appropriate for most things people use pandas for. For anything fully in memory, you're getting all this streaming functionality that you don't need and sacrificing a lot of common operations (joins!).

I'm a big ray advocate but it's not a pandas substitute.",1,1736897020.0
1i0x2pm,m729q3b,"airflow, keras, scikit-learn, 3/4 of the ML field, ",-2,1736838395.0
1i0x2pm,m73x3a6,"As someone who teaches both R and Python, it’s truly wild how some people talk about them, and how so many people are quick to attribute complaints about Python to lack of skill or experience.

Both languages have strengths and flaws, and if we can’t discuss and critique them reasonably, then how do we expect the languages and the ecosystem to improve?

Pandas was great and necessary a decade ago when Python didn’t have any alternatives. But even its creator recognizes its limitations and has moved on to projects that try to do things better.

Python comes with a great standard library for general purpose programming, which is why software people love it, but it wasn’t designed for data analysis. The real comparison isn’t R vs Python but R vs Numpy/SciPy/pandas. Python doesn’t come with BLAS and LAPACK out of the box. Python doesn’t come with any form of array computing or linear algebra out of the box.

And shipping the PyData stack is an enormously difficult undertaking that requires fighting Python’s lack of packaging standards and ultimately led to developing completely custom packaging toolchains by the scientific Python community. End users don’t see that struggle (but sometimes experiences its effects whenever pip fails because it can’t resolve the dependency hell). Working in Python often means ending up with dozens of copies of scientific C/Fortran libraries scattered around your system, because so many packages have to vendor their own versions.

Out of this, Python now has a substantially better and more diverse ecosystem of packaging and developer tools than R does, but this was out of necessity because of how bad Python is at packaging in the first place.

I want both R and Python to be better. I want Julia to get there too. It helps to be able to discuss languages’ flaws and strengths like grown ups.",11,1736867953.0
1i0x2pm,m74mmdh,"I'm an R fanboy forced to use Python. Everyone on my team uses Python. Whenever im prototyping or doing some wrangling/data investigation I use R. My team is usually pretty blown away with how quickly I can get work done in R. 

I saw a Data Science live stream competition where there was 1 R user and 1 Python user in the finals. The R user was coding circles around the Python one. 

Dont hate Python but I just view it as less intuitive and for production code after ive proven it out in R. Iterating and experimenting in Python seems clunky to me but i realoze thats just a preference.",2,1736875612.0
1i0x2pm,m73xl94,NumPy is pretty great. Pandas has aged much more poorly.,1,1736868112.0
1i0x2pm,m720k8s,"*I was there in the*

*Beginning too. You just gotta*

*Learn. Now I love it*

\- Crijo

---

^(I detect haikus. And sometimes, successfully.) ^[Learn&#32;more&#32;about&#32;me.](https://www.reddit.com/r/haikusbot/)

^(Opt out of replies: ""haikusbot opt out"" | Delete my comment: ""haikusbot delete"")",0,1736833383.0
1i0x2pm,m72lk38,"There is Python, and then there is Pandas and NumPy. Even while Python is a good language, Pandas and NumPy are arguably not the best realizations for doing the type of analysis that R is superior at.",4,1736845921.0
1i0x2pm,m72fk0g,"Yeah I think it is generally a better language, but exploratory analysis, plotting, and statistics I find R to be outstanding. But that's probably also why I share OP's frustration, I keep using R and delay getting more familiar with pandas.",3,1736841973.0
1i0x2pm,m71nb8a,Do you recommend any? I’ve just finished a 5 hour YT tutorial and unsure where to go next.,2,1736827564.0
1i0x2pm,m71mbs0,Try tidyverse in R,22,1736827196.0
1i0x2pm,m770e17,What does it mean for those of us who learned Java as a first programming language and were embedded with a deep hatred for it?,2,1736902032.0
1i0x2pm,m72w7bb,"Because ecosystem trumps syntax.  It trumps language in general.

I don’t even like Python.  But if I use Python I know I have access to … almost anything if I need it. And I know there are scores of maintained libraries for lots of things — from auto-doc generation to CLI applications — to network analysis — to number theory — to blah blah.

If I have to code I much, much, much prefer Rust (this is coming from someone that spent most of his grad years coding in Mathematica notebooks).
Guess what? There’s a whole, polished ecosystem just for generating Python libraries from rust — right down to error mapping and publication.
(I’m sure Rust for R exists, but I doubt it’s as lovingly maintained. …could be wrong).

TLDR: a beautiful city in the arctic isn’t going to be a bustling metropolis.  A place is its connection to other places.",5,1736852736.0
1i0x2pm,m72r6kx,Pakistani Denzel?,1,1736849651.0
1i0x2pm,m72807f,"The lack of love for Spark in here is really sad to see, and pyspark dataframes are really great to use",1,1736837397.0
1i0x2pm,m75z0co,I can't deal with how extremely they've overloaded `[`. `Y[X]` performing a left join is just bonkers.,1,1736890164.0
1i0x2pm,m72xv5x,"> but productionizing it is so incredibly difficult.


Why? People say this but don't actually say why. ",6,1736853706.0
1i0x2pm,m72loxx,"What do you mean, like R's model of OOP where method dispatch is determined by the class of the argument?",2,1736846010.0
1i0x2pm,m76rr52,I mean you can do both. There is a slight difference in terms of order of operations but in like 99% of cases either works.,1,1736899153.0
1i0x2pm,m71m5ed,I could tell this was going to stir up some emotions haha!,-1,1736827131.0
1i0x2pm,m72xxrp,Explain,1,1736853748.0
1i0x2pm,m72dp93,Doesn’t Quarto/Rmarkdown solve the same problems of notebook?,3,1736840822.0
1i0x2pm,m71oi9u,"Even during pyspark, you use Pandas. Pandas is omnipresent.",6,1736828023.0
1i0x2pm,m71o203,lol not accurate at all.,4,1736827848.0
1i0x2pm,m75si29,"If anything big data is dead for all but the biggest of players. Single large machines are preferable to cluster computing if you can avoid it for complexity and performance reasons, and single machines have gotten very large.",1,1736888195.0
1i0x2pm,m72k9rx,"Try pydantic, uv and ruff and you will never look back on R. They will make all the things you hate right now about Python 10x easier.",35,1736845062.0
1i0x2pm,m72flmu,"What functions did you miss, that you could find in pandas?",12,1736842001.0
1i0x2pm,m731nz2,Polars is new so they’re continually adding to it.,6,1736855772.0
1i0x2pm,m725v91,Interesting. So any interesting findings you got? Related to project. Would love to hear more.,2,1736836186.0
1i0x2pm,m74zsfu,Ever tried building user-defined functions?,1,1736879400.0
1i0x2pm,m73uz8u,There's polars_st. I only recently heard of it so haven't yet tried it.,0,1736867282.0
1i0x2pm,m71qv1k,"this absolutely. once you understand data structures well, the syntax is seriously not hard lol.",145,1736828955.0
1i0x2pm,m71tv0c,"Exactly why people should learn the structures and not memorize code.

ChatGPT isnt helping on this front",95,1736830245.0
1i0x2pm,m71y2to,"I feel, learned Java first before and python feels like a breath of fresh air in syntax comparison, but understanding dict, data frame, strings, etc. helps",18,1736832172.0
1i0x2pm,m7513x1,"I’m a python guy, but I agree with OP that this goes against python’s philosophy. Python is great because most things just make sense (eg you can directly compare strings with ==, dividing 2 ints can return a float, etc)

Passing a list of columns makes perfect sense to me now, but I remember it feeling weird in 2014 when I started",2,1736879783.0
1i0x2pm,m7395ap,"> where OP is coming from

coming from not OOP?",1,1736859262.0
1i0x2pm,m74l1nq,"I think this is true for many people that kinda transition idk DS/BI via other programming knowledge and don’t grind out the foundations as much as they should.


It used to confuse me endlessly because I can from general OOP in Java but I could write it easy enough because code is code. Once I really focused on the fundamentals it’s not that hard. I don’t love everything about Python though.",1,1736875152.0
1i0x2pm,m720wpw,"Dude pandas suck so much there is a whole new protect trying to fix it.
It's polars.",-15,1736833554.0
1i0x2pm,m73hif5,"I have never gotten used to R for a multitude of reasons. The syntax, the fact that it feels very lacking in OOP and the OOP aspects feel like a retrofitted afterthought, that R library imports pollute the global namespace, and the fact that R reminds me very much of Matlab. Which is to say, a crutch for poorly written code, and hell to maintain.

And don’t get me started on <-.",12,1736862574.0
1i0x2pm,m73deb1,"My speed and productivity isn’t really related to how many characters I have to type. 

I don’t think importing a package is even relevant for “speed” as my ide does this for me, whenever I use pandas. 

This just seems like personal preference and whinging. It’s good for team building, but if someone truly held a strong opinion on this, I’d be curious if it’s valuable.",18,1736861004.0
1i0x2pm,m73ntvo,"Honestly number one because everything beyond maybe the package names is at least somewhat intuitive. I know what an array and a dataframe is and can look those up, even if I may have to double check if camelcase or what have you. 

I've programmed for years and the word 'tibble' is not in my regular vocabulary. The fuck is a tibble (rhetorically) and who the hell decided *that* was a good name?",5,1736864876.0
1i0x2pm,m73pevi,"The first one is easier to understand even if you're unfamiliar with the language. And it is way more explicit what you're doing, which follows the Zen of Python 

I am not speedrunning to care if I am writing 10 or 100 characters, and even then we're in 2025, with autocompletion, code snippets, and LLM-assisted completion, creating understandable and easy-to-share code is much more important than the speed of typing it",4,1736865430.0
1i0x2pm,m72lw9o,While the construction is easier I can't get over the hidden side-effects that come with R. library (tydiverse) loads a bunch of stuff that you just have to know exists (like tibble). It's as if I did from XYZ import * in python.,7,1736846146.0
1i0x2pm,m74ios9,"Absolutely 100% the first example.  With R I see the use of both arrows and equal signs for assigning variables, and I my temple starts to throb.  It’s such an ugly language to read, whereas Python is just easy.",1,1736874461.0
1i0x2pm,m76d94l,aint nobody making you write python like that,1,1736894412.0
1i0x2pm,m76pss9,"df = pandas.DataFrame()  

df[‘x’] = [1,2,3]   

df[‘y’] = [4,5,6]   

df[‘xy’] = df[‘x’] * df[‘y’]",1,1736898504.0
1i0x2pm,m723mlc,"Doesn't read like a joke, reads like someone legitimately complaining about pandas compared to R",44,1736834965.0
1i0x2pm,m760wvo,"So say you're merging two dataset with concurrent time series with irregular sampling time, or just not with the same sampling rate. Meaning both dataframe have time stamps that aren't the same, but they are happening during the same broad time range.


You merge on the time columns. Then both series will have NaN in some rows, each respectively on the rows where it was the other serie that had a sample.


You use the interpolate or fill (not sure what's the right name anymore) method to populate these nans. Naturally, you might want to do a linear interpolation to bridge the gap between the known values of a single series.


You select the interpolation method called ""linear"".


Well, it's not actually doing a linear interpolation based on your time index. What it'll do if I remember correctly, is it will do a linear interpolation between the nearest previous and next available measurement and assume constant (as in, on a per-row basis) variation.


I.e. the value calculated there will have nothing to do with the time index value in your dataframe. If you had
1 , NaN , Nan, Nan, 13


you will get
1, 4, 7, 10, 13.


Regardless of whether your time steps are constant or varying.


To get the linear interpolation based on the index you'll need to select, I think, ""index"" for the interpolation mode. Which is extremely easy to overlook.


Lesson: make unit tests people.",2,1736890728.0
1i0x2pm,m71wwt5,"Exactly. I first heard this mantra by one of my former colleagues. When I pressured him why he thinks so, the only reason he was able to come up with: ""It has ugly syntax"". Lol, what? You don't know R then.",20,1736831625.0
1i0x2pm,m7202ym,bingo! I've had tons of R code put into production including in customer facing analysis products.,8,1736833143.0
1i0x2pm,m727yw4,"I am genuinely interested in examples of R in production thats not small scale. 

From what Ive seen, R works in production if: 
1. you don’t care about efficiency 
2. are working in small user base/db’s

Also, blaming R’s unpopularity on lazy engineers seems more likely to be a problem with the language than everyone else. 

Rust is verbose and finicky at first but most engineers I know like it. 

I programmed in R exclusively for 4 years and I would never recommend anyone to implement it for production if they need a serious/large scale website/software. 
I have occasionally used it for small specialized stats related parts and appreciated its convenience. 
But it’s just not as extendable as Python or Java. 

It’s also ugly and idiosyncratic lmbo

with all the new packages I can do a lot with R,  but it’s a pain and finicky. 
Python feels like lego blocks— just import and things work as expected. Standards are easier to follow and fele intuitive ime. debug is helpful and easy to understand. 

R feels totally different for big projects. It feels like standards are very different between packages. And they dont play together well. 
If python is legos, R feels like those wooden block sets that have some cylinders, some squares, a bridge or two. You can make stuff but its not solid and you cant build too high with much confidence. ",-6,1736837376.0
1i0x2pm,m72zj89,"I think it generally has to do with the fact that R’s project-wide package management tools are not generally used by the community. Most data scientists who use R have a bunch of packages installed on their machine in the same folder where R lives, and they start their scripts with `library(tidyverse)`, etc. without even being aware that 1) tidyverse is a meta-package that wraps a dozen other packages, and 2) each of those other packages has a specific version on your machine that engineers will need to replicate in production in order for it to work properly.

Whereas in Python, most projects start with the creation of a virtual environment and `pip install`ing the packages needed for that project specifically, into that project’s virtual environment.

There are other challenges with productionizing R like non-standard evaluation, lack of support for parallelization out of the box, etc., but package management is probably the main complaint.",19,1736854643.0
1i0x2pm,m71r9w8,I take it more as engineers not knowing R and don't want to deal with putting it into production. I wouldn't be surprised if I was the only engineer in my entire line of business that knew R.,44,1736829128.0
1i0x2pm,m726nri,"How are managing your cves for packages, are you managing long term support, can non data scientists pick up R 15 years from now? There’s a ton of things we take for granted in python but which are absolutely essential nowadays",8,1736836632.0
1i0x2pm,m72aigb,"As an MLOps engineer because:
- doesn't distribute pre-compiled packages for most Linux distro
- in the case of the ones that do `apt install r-core-dplyr` takes longer than compiling an avg config of the kernel
- the std libraries of R are a joke, the rest of the ecosystem is a scrambled mess of incongruent stuff which might not work 8 months down the line (not tidyverse, tidyverse is nice)
- Once you get a ""special"" bug it's GG. I recently had troubles installing the arrow package on a fresh R install. What followed was a 36 your journey into even more obscure C compiling error. The average user would have already have been using polars at that point.
- and finally, the one some won't like... A lot of R code is written by people that at that point in time lacked programming experience (sometimes this code is in libraries). This makes it difficult to maintain and to convert into something that can be run in a cluster.",15,1736838862.0
1i0x2pm,m728x73,"It's not just the language, it's that R's coding paradigm doesn't lend itself to be optimized for production purposes. R is primarily used for functional programming. For production you'd want code that can be written in a way that is cohesive and loosely coupled. R can be written that way but it is not as natural or optimized as say Python or Java",2,1736837920.0
1i0x2pm,m72q4ik,"There's more to building a restful API than just having a rest package in a given language:

* Is the language well supported on multiple platforms e.g. Azure, AWS, Digital Ocean, etc? If not, is it because it's too niche and most providers don't want to support it? If so, will the few providers that support it try to screw you on pricing? Will you have no choice but to put up with it because you have no / few alternatives and your data scientists don't want to learn python?
* How good are the testing libraries for the rest APIs?
* How good is debugging for the APIs?
* How good are the network effects for writing the rest APIs? If I find myself with an obscure issue how likely is it that I can find a solution for it?

Do all of those issues have good solutions with R? Maybe. But it would be much easier to do so with python, its data science libraries, as well as its documented and battle-tested web sever libraries e.g. django, flask, fastapi, etc. 

The usage numbers of plumber do not give me confidence. Let's compare to the major web server library in JavaScript: Express. According to their website, plumber is downloaded 100k times per month. That seems pretty decent and not bad right? According to NPM, Express is downloaded +30M times... per week.",1,1736848959.0
1i0x2pm,m72994x,what size were your deployments? How big were the databases and how many users?,1,1736838115.0
1i0x2pm,m729yhf,"They're right. It's not sufficient for it to just be a programming language. R's coding paradigm doesn't lend itself to be optimized for scaled production purposes because R is primarily used for functional programming. For production you'd want code that can be written in a way that is cohesive and loosely coupled. R can be written that way, but it is not as natural or extendable as say Python or Java",-4,1736838532.0
1i0x2pm,m72uzc0,"You may have gone off the rails a bit there.

Python can be a nightmare language as *programming languages* go.  When it comes to production, limiting, testing; reproducibility, sub-dependency resolution, etc.

There’s work to improve some of this, e.g. by astral. But the language is inherently an obfuscating wrapper around what code is doing.  It’s easy to get started, difficult to polish.  Again, as a programming language.

What you *may* mean is that it has a huge ecosystem which allows it to at least hang with other programming languages across many domains.  And that’s true, I think.  Its sheer popularity and the amount of libraries (often not written in Python) is basically python’s super power.",4,1736852006.0
1i0x2pm,m72vf60,"If you’re concerned about speed it’s worth noting that [Polars](https://pola.rs) is the heir apparent to Pandas right now (or [duckdb](https://duckdb.org), for a non-DataFrame, rather sql, based approach)

Polars is also much simpler and more consistent than Pandas in most people’s opinion, though that’s not to say it will grant you syntactic familiarity coming from R.",5,1736852269.0
1i0x2pm,m72ohac,"Yes. data.table is faster. Did I contradict that? If so, my bad. I wasn't clear enough. If you write pandas the way it is meant to be written, then pandas will be more efficient (memory and speed) than pandas written in a poor way.

I have said, however, that R (therefore its libraries such as tidyverse) is more inconsistent than pandas. And this is the surprising part for many R programmers or those who haven't used at least 10 programming languages over 20 years. Because of the way R tends to ""attach"" things like column names, it often confuses between variable names and other ""keys"". If you remember having to use double bangs (!!) in R, then surely you would know the lengths one has to implement workarounds.

edit:

To add, there is no inconsistencies when it comes to the different brackets used. ( [ {
That is why most commenters are pointing out that the rant is unfounded.

There are issues with pandas - plenty. But the specific reasons for the frustrations you are facing are not the package's issues. They are just learning pains associated with learning a new language, Python in this case. It will take time, but you'll get through it.",8,1736847885.0
1i0x2pm,m71qe6a,"At that point, work on projects to get you comfortable with it. Imo, the only way to truly learn what a language has to offer is to do something that forces you to read the docs. 

One of my most favorite projects from school is learning how to simulate a game of blackjack with OOP and then using your simulation to see if “the house always wins” is a true statement or not. Bonus points would be investigating the impact that card counting has on the house. My school’s student government hated me during that year’s casino night lmao. 

Another good OOP project would be recreating Conway’s Game of Life and cellular automata in general.",3,1736828762.0
1i0x2pm,m726imb,"Any Python course will do, especially if the course gives you practice exercises and projects for hands-on learning. I used Codecademy and it was great.",1,1736836553.0
1i0x2pm,m71nco1,"I love pandas after coming from tidyverse. I don't do any more on-the-go analysis though, else, I would be crying over %>%",9,1736827579.0
1i0x2pm,m71ygtj,That’s what I used before switching to Python.,2,1736832355.0
1i0x2pm,m71orxi,"I've used tidyverse and while the syntax is definitely more terse due to R's ability to do delayed evaluation I think the differences are overblown.  ""Wahhh, I have to write .loc instead of filter, how will I ever remember this? I need to use quotations around column names? My lIfE is RuInEd!""",-2,1736828127.0
1i0x2pm,m73z8x7,"I really wish more of the credit for Python’s data analysis ecosystem went to the NumPy+SciPy folks rather than to Python itself. Shipping all of that is a huge undertaking that often requires fighting against Python’s (lack of) packaging standards (compared to R which comes with scientific libraries and ways to easily link C code across packages out of the box). Most users don’t see this though.

Edit: And Guido (in)famously decided he didn’t want to help solve it in Python proper, which is why conda exists and why SciPy and scikit-learn have had to create so many of their own custom build systems.",2,1736868631.0
1i0x2pm,m72922o,"Eh, I don't enjoy working with Spark (or anything Apache; too much Java garbage leaking through the abstractions\*) but it's functionally\* the only game in town for certain classes\* of problem.

\*puns not intended, but still enjoyed",2,1736837999.0
1i0x2pm,m73kstv,It’s just a platitude people spew to sound smart and in-the-know,1,1736863792.0
1i0x2pm,m75t92q,"It's very hard to prevent runtime errors in R. This makes it dangerous to have run unattended.

This is mostly related to lack of static type checking, rudimentary error handling, and the poor packaging story making it hard to ensure your dependencies are the same in dev and prod.

Conveniences for production use like orchestration and logging are also much less developed in the R ecosystem.",1,1736888436.0
1i0x2pm,m76q68f,"I mean even before that. This `names()` call doesnt ""make sense"" if you're thinking in terms of functions. Or standard programming concepts, IMO:

```
roulette_vector <- c(-24, -50, 100, -350, 10)
names(roulette_vector) <- c(""Monday"", ""Tuesday"", ""Wednesday"", ""Thursday"", ""Friday"")
```",1,1736898627.0
1i0x2pm,m71op9v,Just boredom. Seriously.,1,1736828099.0
1i0x2pm,m741re3,"That seems like a big assumption. I don’t know about the author, but those tools don’t do anything about the things I dislike about Python.

Edit: To be clear, they’re good tools, but personally my issues with Python are with Python itself, not its ecosystem, so 3rd party packages won’t help.",11,1736869411.0
1i0x2pm,m73lt1p,"Thanks, I'll check those out!",1,1736864158.0
1i0x2pm,m74lvg7,Never look back until you want to do statistics lol,1,1736875394.0
1i0x2pm,m72r9kj,"I had a similar experience when doing some complex windowed functions on time-series data, I remember it involved exponentially weighted moving averages.",6,1736849705.0
1i0x2pm,m74vi6g,"For me, a recent functionality I found missing was beeing able to do a merge_asof but disallowing exact matches. I think It is an open issue. But polars have many other functionalities that are missing in pandas.",2,1736878170.0
1i0x2pm,m74ekln,"Yeah, no. TBH DuckDB is where it is at for these type of workloads for geo stuff these days anyhow.",0,1736873256.0
1i0x2pm,m720sy5,"As always, it’s how people use the tool that’s the problem, and not the tool itself. ChatGPT is great for me. I usually feed it a line or a snippet (that I got from the internet or ChatGPT itself) and make it explain it. It’s more than happy to talk about the structures, if you ask. Then I go off and write my own.",22,1736833502.0
1i0x2pm,m72sc55,"people should learn structures. ChatGPT is helping on this front.

Both can be true.",11,1736850385.0
1i0x2pm,m729ran,"Polars is not fixing pandas. Polars is a different use case. It works similar to spark, by collecting instructions and optimizing them during collection, so it only has to practically execute it's logic, once the dataframes needs to be loaded into RAM. This is mostly practical for very large table sizes, but it does not replace pandas.",9,1736838414.0
1i0x2pm,m74wopx,"You can definitely just do \`requireNamespace(""dplyr""); dplyr::filter(...)\` if you don't want to add packages to your search path.

Edit: Also, is having <- any worse than Python adding := ?",1,1736878511.0
1i0x2pm,m73nbzy,My job involves lots and lots of MATLAB so I have to contest that part. Admittedly lots of the affection is for the benefits of proprietary documentation and easy debugging. But otherwise you're dead on. I absolutely despise R. The syntax and the godsdamned assignment operator.,0,1736864703.0
1i0x2pm,m73msfl,"besides that the example he uses was also carefully selected to look as bad as possible in python if you avoid the ""xy"" column you don't need numpy and can just use list, inline.

	import pandas as pd
	df = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})

I would argue storing a calculated value is an edge case and rather stupid to do anyway. But yeah list multiplication in python is a problem they should fix so we don't need to use numpy or list comprehensions.",20,1736864509.0
1i0x2pm,m744so6,"All I know is that tibbles hate kingons, and kingons hate tibbles.",3,1736870326.0
1i0x2pm,m73od2b,"Come on.  Is there a fundamental difference between ""tibble"" and ""numpy?""",1,1736865064.0
1i0x2pm,m72xwbf,tidyverse::tibble,7,1736853725.0
1i0x2pm,m74x119,"> `library(tidyverse)` loads a bunch of stuff that you just have to know exists

You should think of `tidyverse` as more like an alternative syntax for R than a collection of functions.",2,1736878611.0
1i0x2pm,m74xmil,"I get it. Likewise, I can't get over the hidden side-effects that come with Python. Mutability everywhere!",2,1736878782.0
1i0x2pm,m750kyv,"I think it’s really the opposite. The Python example requires all 3 bracket types (parens, brackets, and curly brackets), simply to declare a data frame. The R example only uses parens. And no quotes even!

The assignment operator ‘<-‘ is perfectly readable, and it makes sense to have a different operator for variable assignment than setting function arguments (‘ = ‘). 

To me, using a colon in defining a dictionary is less intuitive and frustrating. Why is the assignment operator such a barrier but not the colon? In R, declaring a named list (the closest equivalent to a Python dict) would use the same syntax as declaring a data frame (no curly brackets or colons). It’s clean, and again doesn’t require the clutter of quotes. ",-1,1736879631.0
1i0x2pm,m76nerg,Show me better code to produce that result.,1,1736897714.0
1i0x2pm,m73c26l,"That's a fair criticism, I rarely see any DSs using any sort of package management for R. Libraries like renv and packrat do exist and are pretty much equivalent to python's venv and package management. Doesn't mean people use them though ha. 

I guess I'm sure I entirely follow why NSE is a challenge in productionalization, could you expand on that thought? Same for the parallelization argument. I guess I'm not sure why not providing support OOTB is a problem when we're already likely using several external libraries in a productionalized environment?",4,1736860472.0
1i0x2pm,m74ev0p,"This is both true, but I think it’s also worth acknowledging that Python’s rich ecosystem of package management tools only exists because Python’s packaging is so godawful out of the box.

The same ecosystem doesn’t exist for R because R’s packaging system has supported declarative metadata for much longer (even if it is much more limited than what pyproject.toml is now promising), and it comes with libraries like BLAS and LAPACK so packages don’t need to vendor their own versions.

Plus the fact that CRAN and Bioconductor have curation and review processes that continuously monitor for breaking changes while PyPI has… an exponentially growing number of wheels and no checks whatsoever (beyond signing, which is great, but solves a completely different problem).

So the Python project management ecosystem is pretty great. But that’s by necessity. You certainly miss it when you need the same thing in R, but you can get much further in R before you start needing it, which is part of why R’s ecosystem for workflow tools is significantly less mature.",5,1736873340.0
1i0x2pm,m76rng6,"This is the answer. It's not the language's fault but there does seem to be a higher percentage of engineers (at least in my personal experience) that do not follow ""best practices"" of software when compared to python. Ofc, there are those people in python as well but (again, just my experience!) it seems higher in R.

  
My hunch is that people who learn R do not learn it in a ""Programming Fundamentals"" or similar style class environment and are either A) Stats/data people who were taught by other non-programmers or B) Self-taught. This tends to",1,1736899120.0
1i0x2pm,m72bspa,"This. If we have to play ""find the data scientist"" or ""find the researcher"" based on code, and you have a person who wrote some tool using R, or asks you to use a notebook as a script, or CPP code that is uneeded and not portable, you know who it is.

I am a data scientist as well so don't take it to harshly.",4,1736839645.0
1i0x2pm,m739eef,certainly. in production is dev environment. It's very risky and huge loss revenue if suddenly switching to new language.,1,1736859368.0
1i0x2pm,m72kl54,Are they common in Python data science packages?,2,1736845273.0
1i0x2pm,m74g1cy,"15 years ago, Python’s data science stack was in its infancy and barely useable, and R was easily the better choice for statistics and machine learning. It’s amazing how much the PyData ecosystem has advanced in those 15 years. No one knows what things will look like 15 years from now. We may be using some completely different language.

But personally, I find it significantly easier to teach R to non-programmers than to teach Python to non-programmers when it comes to just getting data analysis done.",1,1736873683.0
1i0x2pm,m72daxt,"CRAN is a much more respectable source of packages then PyPi actually. Serious bar one needs to reach.

We used to install from binary in docker. Helped a lot.",8,1736840575.0
1i0x2pm,m72hsa6,"Why are the base packages of R relevant?  Packages like tidyverse are meant to be used.  Base Python doesn't even have a data frame or a linear regression model, so not sure why we are judging R's base packages lacking but not Python's.",3,1736843417.0
1i0x2pm,m72kjjw,That's interesting - because there is less mutation with functional programming - and small functions keep things loosely coupled - I would have expected that it deploys better.,5,1736845243.0
1i0x2pm,m737klk,"I'd argue that the FP concepts of immutability and referential transparency are better suited to productionalized ML systems than OOP. You generally want functions to always return then same values when fed the same input, and dealing with a bunch of non-obvious state changes that can occur under an OOP paradigm can cause a lot of debugging headaches.",7,1736858576.0
1i0x2pm,m71rabj,"Ok cool, thanks . I’ll look into a few projects like that to get me a bit more familiar. I’m doing a masters atm and have a few different projects that I need to crack on soon within that so will just take them slow and learn what I’m doing.",2,1736829133.0
1i0x2pm,m72a20e,It’s painful for sure but it makes working with big data so much easier. pyspark.dataframe API at least is reaching maturity little by little which makes it significantly less painful.,1,1736838589.0
1i0x2pm,m771wql,"> poor packaging story making it hard to ensure your dependencies are the same in dev and prod.


Isn't that what renv does?",1,1736902544.0
1i0x2pm,m770lkm,Sorry can't see all the code because of the formatting but isn't this just typical getter/setter syntax?,1,1736902103.0
1i0x2pm,m74xrz4,So what do you dislike?,1,1736878826.0
1i0x2pm,m74xly1,Stats and niche models only available in R are the only reason to use it and it's dreadful (to me),0,1736878777.0
1i0x2pm,m73j90f,"There is \`ewm\_mean\`, \`ewm\_mean\_by\`, \`ewm\_var\` and \`ewm\_std\`. Was that insufficient?",3,1736863218.0
1i0x2pm,m750irm,"Isn't that achievable by doing an asof join and post-filtering equal values? Another would be an anti join followed by asof.

And we now have `join_where` which allows you to join on any predicate, so I think you should be able to write a predicate that matches that behavior.",1,1736879613.0
1i0x2pm,m74hdc8,"Yes both are indeed true. As someone from a highly structured C++ environment, python and pandas is maddening. I totally understand where Op is coming from. Without ChatGPT I’d be dead in the water. And that’s after a year of DataCamp tutorials and a bunch of my own projects. It’s super unintuitive. Even just trying to wrap my brain how tf list comprehension works is insane. Everything is backwards!

It’s not as bad as Perl, but thats not saying much.",2,1736874069.0
1i0x2pm,m72fpq5,Polars is also meant for small data. You can work with the eager API and keep all data in RAM. It is meant for most of the pandas use case and more.,9,1736842075.0
1i0x2pm,m72qtdd,">Polars is not fixing pandas. Polars is a different use case.

I have to disagree here. `polars` is the exact same use case as `pandas`. Both deal with tabular data that fits into memory only.

Edit: Let me rephrase this both deal with the use case of tabular data, polars can do more than that.",8,1736849412.0
1i0x2pm,m72btgu,Polars can work like spark or in ram like pandas.,5,1736839659.0
1i0x2pm,m76d1xr,"no way to alias namespaces so better hope that package is named something reasonable. 

pythons walrus operator has a distinct purpose, assign and return. Rs assignment operator does not and appears to be a compatibility vestige encouraged by the cult of wickham",1,1736894350.0
1i0x2pm,m74wxgw,"> But yeah list multiplication in python is a problem they should fix so we don't need to use numpy or list comprehensions.


    import pandas as pd
    df = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})
    df['xy'] = df['x'] * df['y']",4,1736878582.0
1i0x2pm,m73p5sa,"I carved out an exception for package names. And I also don't expect intuition on package names. Is Tidyverse better really? What part of that says ""data manipulation""? 

But within the package, everything is easier if the names somewhat make sense and are generally real words.",3,1736865345.0
1i0x2pm,m7568pe,"Python's colon meaning completely different things in different contexts is certainly something. I always find myself wanting to use = in dicts.

But hey, I'm someone who doesn't even like arithmetic operators being overridden for non-arithmetic applications. ""Hello"" + ""world"" should be an error, IMO. :P",2,1736881254.0
1i0x2pm,m74i40c,"Yes, CVEs are pretty common in Python libraries. I've had to address a few Numpy ones and even dispute some bogus ones. They're common in general software development and typically will pop up in open source libraries and dependencies.",4,1736874289.0
1i0x2pm,m76y57s,"Yes, CVE’s are common in general",1,1736901278.0
1i0x2pm,m76y0ce,"Yeah but python was still the language used everywhere, we know for a fact that python will still exist and be popular in 15 years because it’s not just a data science language, not the same for R. Python might not be the data science language but it will still be in use.

R is easier for non technical people but that’s where production ends because there’s just not enough support for it as a language, it can do one thing really good and that’s about it",1,1736901233.0
1i0x2pm,m72osxg,"I just tried an \`install.packages(""dplyr"", type=""binary"")\` from a debian:latest container and I got  
\`type 'binary' is not supported on this platform\`, so I have to ask...are you running windows in production?",2,1736848098.0
1i0x2pm,m72o9nv,"For ""base packages"" in a language I would like to know do I have all the most common data structures and their manipulation supported, can I pass functions as arguments, does the language supports typing if I want, how easy it is to build and redistribute packages, can I handle interacting with the os and filesystem natively, do I have a way to do sane string interpolation. I suppose that for R ""if there is a will there is a way"", but it's going to be significantly more unpleasant that doing the same task in python.",4,1736847745.0
1i0x2pm,m72wgxq,"It goes beyond functions. In fact, way beyond that. 


When it comes to decoupling you want a language that allows you to effectively deploy all tools within the OOP paradigm: for example, polymorphism, encapsulation, abstraction, you want to be able to decide when to assign relationships between objects based on aggregation vs association, or whether to us use delegation or inhereitence, etc. All these is done to make sure that, to the best extent possible, changes in a class either does not cause cascading effects on other objects, or, cause the intended cascading effects across various objects- which is crucial for scalable production. 


These are just not the things people think about when writing in R. And that's why backend engineers call the code bad.",1,1736852896.0
1i0x2pm,m74hnwt,Yea well functional programming is not the only language that preserves immutability. ,1,1736874156.0
1i0x2pm,m74yv3q,"In Python? I have my personal preferences like hating the whitespace-significant syntax, missing braces, dunder methods being an ugly hack, and Guido's general disdain for functional programming as a paradigm. But I understand those are just language preferences, and others may have different tastes.

On the side of things that are more systemic issues than my personal preferences, the Python packaging ecosystem is a mess. It's taken years to get to pyproject.toml, and we're still multiple years and PEPs away from having useful metadata on PyPI about non-Python dependencies. PyPA and PyPI are still working on the fundamental issues that the SciPy community solved with conda a decade ago. Ultimately, we need CPython core, PyPA, and PyPI to collaborate on a solution, like requiring that new PyPI submissions must meet some basic metadata requirements and pass some basic checks.

But I'm coming at this primarily as a library author/maintainer than a user.

I have a different list of complaints for R.",3,1736879135.0
1i0x2pm,m73n5r4,"I don't think ewm_mean_by existed when I was using it, or maybe it was the time based interpolation with a group by that I had to do first, which was not supported. Sorry it was a while ago, I can't remember the exact details, but I remember that I spent a while trying to get to the bottom of it until I decided to use Pandas.",5,1736864641.0
1i0x2pm,m751zf1,"No, because then you are not joining with the next valid value. The hack is to add a small epsilon to the column of the right table and after joining the epsilon must be substracted to recover the original value. But this is not ideal.",5,1736880038.0
1i0x2pm,m7542ao,Probably the only way would be with join_where followed by a group based filtering. But again It is not as convenient and efficient.,1,1736880635.0
1i0x2pm,m753hnz,"Yeah man. When I was learning Python (my first and so far pnly language) I really struggled with the data types, structures and overall ‘loose’, “incoherent” feeling to the code. 

Perhaps if you’re anything like me, your headspace is logical, systematic and appreciates “a good sense of order” to things. 

I’ve only touched ‘C’ superficially but even looking at the syntax structure it makes me warm inside. 

Regrettably for what I do, data extraction and subsequent wrangling, Python is just superior. 

I hope to spend more time with ‘C’ one day doing some more low level stuff.🤞

Does that sound familiar to your experience?",1,1736880470.0
1i0x2pm,m732nf2,Working with data larger than memory is one of the key features Polars explicitly calls out in its docs.,3,1736856268.0
1i0x2pm,m76i889,"R's <- assignment operator is pretty similar to Python's :=. Its other operators like <<- also have distinct purposes, though should only be used rarely. It's really only the = operator that should be avoided for assignment (because it's less explicit and more contextual). These all predate Hadley's influence on the R ecosystem, so not sure what he has to do with anything.

It's the = operator that's a compatibility vestige if anything.",1,1736895996.0
1i0x2pm,m76ypgh,Which is why I’m in the process of moving all my important code to C and C++.,1,1736901467.0
1i0x2pm,m72s7in,"Why do you need binary? Simply build time? 

I've built docker containers for production apps using both cran and bioconductor packages, and haven't had issues with building them aside from stupid bioconductor version issues so just build from source. I think even on my Mac when installing packages it will build from source.",2,1736850304.0
1i0x2pm,m74h8zb,"I think they were referring to the fact that CRAN and Bioconductor have an actual curation and review process, and they continuously monitor for breaking changes and remove broken packages, while PyPI is a complete free-for-all.

Whether they ship binaries is a different matter.",1,1736874034.0
1i0x2pm,m72omxy,But base Python does not have the most common data structures supported.  It doesn't have vectors or data frames!  You need numpy and pandas.,11,1736847989.0
1i0x2pm,m74gvgb,"To even start comparing R’s and Python’s base/standard packages for data science, we’d have to include NumPy in Python’s standard library. It’s not really R vs Python. It’s R vs NumPy/SciPy.",1,1736873926.0
1i0x2pm,m74628n,"> changes in a class 

That sounds like a disaster waiting to happen... with the OOP model of R, you can extend methods for object classes without making modifications to the class (like what Julia appears to be benefitting from, though there are a different set of interface issues than conventional OOP).",2,1736870711.0
1i0x2pm,m74ircx,"All of this is stuff that’s easily accomplished in R. The reason Python has better tools for deployment is just because it’s a widely-used general purpose programming language rather than a domain-specific language for data analysis like R. Python is deployed for many purposes besides data analysis, so of course those tools need to exist.",2,1736874482.0
1i0x2pm,m751oxz,"Yeah I was thinking haha. I get these complaints and some of them are the reason I switched to rust for some of my projects. The community just has a much more similar visison. But my list of complaints for R is much, much longer.

Although uv & ruff have made making my points  to colleagues much easier, still looking for similar breakthroughs for the ecosystem itself.",1,1736879953.0
1i0x2pm,m753yfh,"Ah right. Now I see. Yeap, I see why that needs to be in the asof. Will see if we can add that.",2,1736880605.0
1i0x2pm,m755jig,"Heh. I love the low level control you get in C, but C is pretty loose itself. Yes, static typing is nice, but once you have (void \*) all over the place, you're basically back to duck typing and crossed fingers.",1,1736881055.0
1i0x2pm,m7321cd,"Because not installing binary (which for an interpreted language requiring binary libraries should be the sane default IMO) for dplyr take \~16 minutes, which is not acceptable for any CICD process involving installing libraries. In comparison \`pip install pandas\` takes 6.6 seconds on the machine I'm typing this from. This is for many a programmer simply not acceptable.",5,1736855959.0
1i0x2pm,m72ua1j,"I don’t know what you’re trying to refer to as a “vector” here, but Python has standard programming data structures.  A DataFrame is not only *not* one of those — it’s not even a data structure.  It’s a broadest idea of functionality that’s connected to a variety of data structures.  (Arrow spec is something many data frames are leaning on, but is a broad and variably implemented spec, with various distinct sub-data structures.)

(I suspect you’re using “vector” to mean something you’d see in a vector database or the like: again that’s *not* a data structure.  That could be backed by lots of things from a stack allocated fixed array to some form of sparse matrix representation, etc.  — for the record, to assist with communication, in the context of “data structures” “vector” typically means a heap allocated, dynamically sized list.)",5,1736851585.0
1i0x2pm,m74gknp,"No here we are talking about writing your own classes, even for analysis.

I think you don't know as much about programming as you think you do, mate",0,1736873839.0
1i0x2pm,m7539p5,"I get it. For me, I largely have the tools to solve my complaints about R myself, especially since ALTREP came out, whereas the things I want solved about Python require a top-down change.",1,1736880407.0
1i0x2pm,m733s76,"I get ya.

I personally don't have an issue with build times. When I have built apps for deployment I just start the build and then push to the internal dockerhub whenever it's done. Waiting 2 minutes or the next day for build/install doesn't matter to me because if there's a wait I just work on something else. Projects on my local machine just install once and then point to a system install in project folders. Only time it might suck is when upgrading a new machine and needing to install all old versions of all libraries again, otherwise eh.",3,1736856818.0
1i0x2pm,m72uy59,I don't mean a vector database.  I mean a one-dimensional array.  A list is different because it's not atomic and you can't do math on it.,4,1736851987.0
1i0x2pm,m74i3qp,"Data frames, multidimensional arrays, and sparse matrices, etc., are absolutely data structures as much as various trees and graphs are data structures. You need NumPy to do any kind of array computing with Python, while R has it out of the box. Yes, it helps to know the implementation details of one defaulting to row-major versus the other using column-major orientation, but that’s not really the point if you just need to do some linear algebra.

That’s not just a matter of syntax.",1,1736874286.0
1i0x2pm,m74kcmf,"You’re both just talking about the expression problem, which R and Python both solve in different ways. The OOP solutions aren’t inherently better than FP solutions. And both still have to deal with breaking API/ABI changes and fixing earlier versions of serialized objects.",3,1736874951.0
1i0x2pm,m72xdn2,"I think you’re confusing syntax with data structures.

You can define math to be done on a dynamically sized, heap allocated list of bytes or a fixed size set of bytes that lives on the stack.

If what you mean is that Python doesn’t have wrappers or operators related to linear algebra like, say, Julia does then that’s a perfectly valid point.  I just want to clarify that “data structures” isn’t what you mean and will mostly cause confusion.

(TLDR: Out of box: Python has common basic data structures — a programming concept for how data is laid out and what it can efficiently do.  It does *not* have syntax or capabilities for much math.)",8,1736853426.0
1i0x2pm,m74y4ln,Thanks for having my back :),2,1736878925.0
1i0x2pm,m737c74,I guess I don't understand.  What is an example of something data science-related you can do in base Python but not base R?,1,1736858471.0
1i0x2pm,m73m7j5,Open a folder with several textual files with informations that you have to regexp from... Let's say an xml dialect.,1,1736864302.0
1i0x2pm,m74lq7y,I never said anything about what R can or can’t do.,1,1736875351.0
1i0x2pm,m73o26z,"You can read files and parse text in base R.  Base R has funcsions \`list.files\`, \`scan\`, \`grep\`, \`regexpr\`, ...",1,1736864958.0
1i13e03,m7314ww,Hbbv,2,1736855501.0
1i18xcv,m749om8,Does the app run locally?,2,1736871805.0
1i18xcv,m74qm0x,"yes, it run locally",1,1736876766.0
1i18xcv,m75abxq,Enter your post on ChatGPT and see what it says. It is helpful in troubleshooting issues.,-1,1736882450.0
1i18xcv,m76h4q8,"I mean..... that's basically what people will do from the beginning, with or without posting a thread on reddit",1,1736895636.0
1i0dbaj,m6xsswb,"Great topic. Studying this distribution can lead to all types of fascinating concepts, including how it relates to Markov processes.",29,1736784692.0
1i0dbaj,m74epmz,Great read,2,1736873296.0
1i0dbaj,m6xvto3,"Indeed, I read a section on that, and although I did not deep-dive it, I made a new connection between the two. If you were to summarise it that relationship, what would be your take?",0,1736785593.0
1i0dbaj,m6xygm4,"In DS, we are most often looking at how historical data about variables predict an outcome. But with Markov chains, eg, typically the most recent state predicts the next state of the system. Poisson processes are a type of Markov process.

Count data has some quirks compared to continuous data (non-negative values), and studying poisson can help us gain intuition around some of those quirks. But when we start to predict counts amid time intervals, which is very common, the characteristics of the system are very unique and look very different from your more common prediction equations. See the relationship between exponential distributions, poisson and Markov chains, eg. Often, for example, these systems can be modeled (and outcomes effectively predicted) with no other variables in the prediction equation.",11,1736786375.0
1i0dbaj,m706huv,Markov process is literally Finite State Machine where one state link to the other. (can be also bidirectional). Poisson is a specific case of Markov process.,3,1736809921.0
1i0dbaj,m706swn,the issue is generally count data is quite sensitive to noise (high variance). Abnormal occurrences can easily screw the frequency.,2,1736810021.0
1i0dbaj,m72a2nw,"In fact, any continuous-time Markov chain is the sum between a Gaussian process and a (compound) Poisson process. And, in addition, the former is a limit of the latter.",2,1736838599.0
1i0dbaj,m7302c2,">Often, for example, these systems can be modeled (and outcomes effectively predicted) with no other variables in the prediction equation.

Up to this point I followed, but here I missed the boat: could you exemplify this statement more?",1,1736854931.0
1i0dbaj,m72zvbk,"Interesting, could you expand on that? You'd help me grasp that with an intuitive example.",2,1736854828.0
1i0dbaj,m734g0j,"Sure... let's say you want to predict the next word in a sentence. For many situations like this, the variable that best predicts the next word is the word that came just before it.

""My sister said there's nothing special about me. But actually I can jump ______"". 

A type of Markov chain can predict that the next word is  ""high"" based on ""jump"", but ""My sister said"" doesn't do much to predict ""high"". The word ""jump"" is by far the most predictive because of the sequence of the words and because jump is a verb. The sequencing of the system and the current word, ""jump"", are most indicative of what comes next.

The state we are in with ""jump"" as a verb in the sequencing means ""high"" is a likely next word. Throwing a bunch of other variables in there to predict what's next doesn't make a lot of sense like with other prediction problems",3,1736857137.0
1i03pk7,m6uz4w9,Papers with Code is pretty useful for finding trending research topics,99,1736737063.0
1i03pk7,m6ux9qz,My advice is to join the American Statistical Association and get involved with the data science group and any other that you are interested in. Best wishes 🙏,146,1736736388.0
1i03pk7,m6v54lb,"I subscribed to [Data Elixir ](https://dataelixir.com/). They have it all! Machine learning, data visualization, analytics, research papers, etc. 

Give it a try. You will not regret it.",82,1736739257.0
1i03pk7,m6v23tk,"For Youtube, i think Ken Jee and StatQuest with Josh Starmer are good enough. Also for blog definitely Kaggle",44,1736738145.0
1i03pk7,m6wpymt,Daily Dose of DS has been pretty great.,5,1736770335.0
1i03pk7,m6xyfwk,"For me, it's a combination of two things:

1. In-person: I try to network with my Data Science peers at in-person events, shoot the breeze with my coworkers, etc.

2. Online: Interactions with people from Statistics Without Borders (and other places that I have or at least tried to volunteer), my LinkedIn connections (I try to avoid the influencers), YouTube channels, randomly looking through Google Scholar, this sub-reddit and some other sub-reddits.

It's impossible to keep up to date in everything, but this provides me a pretty good balance.",5,1736786369.0
1i03pk7,m70kwp7,I'll add TL/DR newsletter and Matt Dancho,3,1736814744.0
1i03pk7,m70dmqb,"Just noticed I could listen to books on Kindle with its voice assistant. Feel like the world has opened up to me now.

I love blogs, medium, pragmatic engineer, TDS, etc, but they aren't ideal to Deep dive into a topic, at least to me.

This is besides the usual, DataCamp, DataLemur/StrataScratch, Udemy, etc.",2,1736812312.0
1i03pk7,m72xfql,"There are lots of great resources that many people have recommended. I would like to advise you to separate the act of finding and studying resources. When you come across interesting articles, podcasts, videos, shortlist them - but have a different dedicated time for studying them. Otherwise, you will get distracted while you are studying and start wondering if you should maybe study some other resource. Short list and prepare your resources ahead of your dedicated study time.",2,1736853459.0
1i03pk7,m6uutqv,kaggle is the way to go,6,1736735510.0
1i03pk7,m6z6wzm,"Some useful papers worth reading come up here, [The Journal Club Pulse](https://www.thejournal.club/c/pulse/)",1,1736799266.0
1i03pk7,m71d5xm,There are some good projects listed in github trending and new progress in Twitter,1,1736823928.0
1i03pk7,m71elqo,"I was a big fan of the Not So Standard Deviations podcast, which I see is still going: [NSSD](https://nssdeviations.com/) .  It was somewhat R-focused when I was tuning in regularly, but was still excellent for non-R-users.",1,1736824416.0
1i03pk7,m71zazo,"It’s not overly technical, but I do like the Analytics Power Hour podcast. Usually some good topics and fun presenters and guest.",1,1736832761.0
1i03pk7,m72anum,"# 1. Industry Blogs and Websites

* **KDNuggets:** Covers topics like machine learning, AI, big data, and analytics tools.
* **Towards Data Science (Medium):** Offers tutorials, case studies, and thought leadership articles.
* **DataCamp Blog:** Focuses on tutorials, career advice, and industry trends.
* **Analytics Vidhya:** Great for hands-on tutorials, competitions, and career resources.

# 2. Academic and Research Publications

* **ArXiv:** Preprints of the latest research in machine learning, statistics, and data science.
* **Google Scholar:** For discovering peer-reviewed articles and academic papers.
* **Kaggle Learn and Discussions:** Combines tutorials with hands-on datasets and discussions

**3. Youtube channels:**

* *StatQuest with Josh Starmer*: Simplifies complex topics.
* *Krish Naik* and *Simplilearn*: Tutorials on tools and techniques.",1,1736838952.0
1i03pk7,m73ty84,"Can recommend Alphasignal to get updates within the space, mostly relevant for MLEs though. Does not have the usual fluff or extreme beginner articles like e.g. Towards Data Science",1,1736866946.0
1i03pk7,m76804x,"I read hacker news (ycombinator) . Sometimes people post new papers or blog posts on the topic, although most of the content is not DS related.",1,1736892816.0
1i03pk7,m6vntde,Towards data science is a good one but many of their articles aren't free,1,1736747281.0
1i03pk7,m6yiwk0,"we do watch a lot of content on the internet and these creators upload the latest stuff going on in the game. 

we watch we update",1,1736792300.0
1i03pk7,m6yk4gf,"On LinkedIn, I follow Eduardo Ordax, Alex Wang, and Tom Yeh. The last one has numerous posts titled ""AI by Hand"" in which he manually does the algorithms calculations on paper! Very informative on that sense.",0,1736792649.0
1i03pk7,m6zrxf8,"Or the royal statistical society, they have a data science and ai section",4,1736805381.0
1i03pk7,m6v5h9f,What online group do you suggest?,-8,1736739386.0
1i03pk7,m6w06fq,Hard agree. Such a good newsletter.,3,1736754342.0
1i03pk7,m6w55vj,It looks awesome but… I cannot see a subscribe button. Am I going crazy? I turned off my add blocker just in case that was erasing it but still nothing,1,1736757535.0
1i03pk7,m71cjcv,"Definitely TL/DR. I get the tech and data science/AI editions daily. They highlight news, blog articles, and academic research.",2,1736823718.0
1i03pk7,m75ectm,"This.
As someone with real ADD issues, this is one of the deepest rabbit holes I struggle endlessly with.",1,1736883624.0
1i03pk7,m6v1pvc,Didn’t know kaggle could be used like that,6,1736738002.0
1i03pk7,m6v5nym,100% People been recommending kaggle,5,1736739454.0
1i03pk7,m6vjt7u,>the data science group and any other that you are interested in,34,1736745303.0
1i03pk7,m6wp5y2,Thanks I'll try that,2,1736769934.0
1i03pk7,m6xbo4r,"It was uBO for me, but maybe try disabling your browser's tracking protection features as well?",1,1736779208.0
1i03pk7,m6xhojl,"But where do I find these groups?! If only there was an association of some sort I could join...

/s",6,1736781236.0
1i03pk7,m6ya18i,I think there's one in America,7,1736789746.0
1i1951j,m74orjl,"Seems like those process ids may be taken by other programs (ie not open), or it’s a simple permission issue. Either way this is an extremely low quality bug report. Please do better",5,1736876234.0
1i1951j,m74pptp,Delete system32,-2,1736876510.0
1i0c3x8,m6wozm5,Lol I’ve had a similar experience with some of their other roles. Makes me wonder if they just post ghost jobs all the time.,40,1736769842.0
1i0c3x8,m6yonms,"Most likely its an H1B tactic. A lot of big companies retain a continuous set of H1B slots by posting roles and never filling them, just in case they identify a candidate they want for a real role that needs H1B sponsorship. If you're approved to hire an H1B for a DS role, it doesn't have to be a specific job on a specific team. You can shift an approved H1B from your ghost role to a real role when you need it (within reason). This process also helps companies justify the H1Bs and fulfill the requirement to confirm that no citizens meet your needs (you interviewed them and didn't hire them). 

This isn't entirely abusive of the system. It is, but the abuse is required to make the system work. When you find a candidate you want (assume the process was actually fair and followed the law with respect to interviewing citizens before looking at H1Bs; this often isn't true, but that's a different problem) and discover that they need sponsorship its too late to apply for the H1B. Takes forever, and you might not get it, which screws both the candidate and the company. You kind of need to have generic approvals on-hand, but there's no official way to do that without gaming the system.",18,1736793958.0
1i0c3x8,m743a6t,Lots of ghost jobs these days,2,1736869872.0
1i0c3x8,m6xg90k,"It’s a game these companies have been playing since the beginning of the pandemic: Look good on paper to shareholders by fudging numbers in ways that won’t get anyone audited, fined, nor arrested. Other end: post it so that internal hires look more transparent when it’s a middle manager’s friends getting pulled into a growing department.

Data is a golden cow right now, so is cybersecurity. Neither actually require any formal background or licensure, so no one is going to question where, when, or who are getting hired right now.",5,1736780765.0
1i0c3x8,m75i1jr,Shit.,1,1736884686.0
1i0c3x8,m71kori,This probably means that you failed to convince someone that you were the person that they wanted Ask yourself why and try again. The next time if you don't get the position you might ask them why. Usually they will tell you.  Better luck next time,-3,1736826590.0
1i0c3x8,m70jtw1,They’re probably just unable to fill the position to a satisfactory degree. The company I work for does the same. They’ve reposted a role for the last two years. Hired one person that didn’t work out and still automatically repost it periodically but the applicants aren’t meeting the requirements and filling the position isn’t a high enough priority to justify trying harder to find someone,2,1736814386.0
1i0c3x8,m72mevj,I have seen these kind of job postings also outside of USA. Here in Germany you don't need to justify that there are no local European that you can hire but they still keep reposting the same job over months/years. This is mostly done by some start-ups but I have seen also bigger companies do it.,1,1736846493.0
1i0m1ts,m72d758,"Set all of the appropriate random seeds to a constant.  Ask ChatGPT which set of seeds may be important for whichever framework you are using.  That will significantly reduce variability, but even then I think training a repeatable autoencoder will be difficult.  It's a latent space that is not directly constrained by the data.

Even then, based on my experience, why the number of apparent clusters is so inconsistent is strange.  Instead of plotting it in 2D, run the different trained outputs through HDBSCAN to have a more uniform count of ""real clusters"".",1,1736840510.0
1i0wxxt,m71ksem,What a terrible name,3,1736826627.0
1i0wxxt,m73eg6m,Jesus Christ do you spam stuff. I hope everybody passing by Down votes your post just because you spam so much,1,1736861411.0
1i0wxxt,m71vojj,"Par for the course for the French, they named their national car ‘Lemon’",0,1736831056.0
1i0wxxt,m73agjb,"Citroën doesn't mean anything, citron means lemon. Citroën was the last name of the founder.",1,1736859815.0
1i0wxxt,m75719r,"The founder had Dutch heritage, Citroen is Dutch for lemon",0,1736881486.0
1i0wxxt,m75quoa,"Still it is the family name of the guy like so many companies at the time. Nothing to do with lemon.

On top of that, it is not the national car company, the closest to that would be Renault (created 20 years before and made famous for transporting french soldier during WWI before Citroen was even founded) but nationalised only after WWII.

For someone posting on a datascience forum you seem to confuse correlation and causality as well as pulling facts out of your hat.",1,1736887509.0
1i0wxxt,m75rdh3,You sound like you’re fun at parties,0,1736887736.0
1i0wxxt,m75rfzi,It's not a party here.,1,1736887767.0
1hzpcuv,m6rrj6f,"I guess it's not an open source project, right? Checked the article but couldn't find a link to the repo, so just want to be sure.",33,1736701787.0
1hzpcuv,m6uivlf,What is wrong with R? It's got a lot more than this and it is a free download too,12,1736731387.0
1hzpcuv,m6z7lno,Here's the thing you can post an R package where everyone knows about it and can download it immediately How are people going to find your package?,0,1736799468.0
1hzpcuv,m70wfzs,test,0,1736818555.0
1hzpcuv,m6wv58h,"It's not open source due to a bunch of dependencies that it has with our internal stack. But it may become so in the future. Being the core dev, I actually plan to generalise it and push it into the world one day - the stats lib at least.",7,1736772756.0
1hzpcuv,m6ww45z,"R is great, I agree - It's my main language in fact. This library does not aim to replace R. Think of it as an R package. This is a python package instead. It helps streamlining workflows to reduce overhead, align practises among data scientists (in a team or organisation) and as an interface that serves methods in an intuitive way. I guess just like sklearn does for ML.",1,1736773184.0
1hzpcuv,m72zari,"I see what you mean. Well, currently my package is not findable anywhere, because it's behind the enterprise's github where I work. It's not a public repo. Just stay assured that python packages are just like R libraries: sharable, packaged code that everybody could use from anywhere.",1,1736854511.0
1hzpcuv,m76wu60,Thanks I do. But I am suggesting that many people that use R could find your work to be valuable.. My guess is that.many of them might not use Python.. This is often the case in statistical work. Well done in any case.,1,1736900842.0
1hyploh,m6jfdg5,"I've recently applied for 4 companies, got interviewed for all 4 and cracked all of them. Here are a few pointers for you. 

1. Mention your skill sets below your summary
2. Make your metrics and achievements bold
3. Try to put in more Data sciennce projects
4. Make sure the specific keywords in the job description is present in your resume.
5. Check your resume score. Your resume should have a parse rate of above 90% and and ATS score of at least 50%

Hope that helps.",496,1736576530.0
1hyploh,m6jjujq,"Well, to be honest this just isn't a strong resume.  I've hired many data scientists, analysts and engineers over the years.  The first thing that stands out to me is that you don't have formal education in stats or modeling. That's not necessarily a problem, but I'm not seeing any explanation for the transition from front end to ML.  This reads as very junior to me and likely someone that is going to need guidance on things like model selection, evaluation and interpretation.  

Thats not to say any of that is true, but as a hiring manager you get 100s of these and you're really just glancing through looking for something to stand out.  

The second thing that makes the resume weak is you arent focusing enough on impact. I'd rather see you detail one super high impact project and what skills that entailed than the generic stuff about your job role.  This is especially important to me in a data science role.  I expect you to understand metrics and how to communicate results. You do a little, but nothing that made me say ""oooo"", i want to hear about this problem and how it was solved.

Edit- as an example the first bullet on developing a predictive model that improved predictions by 25%.  You have a metric but this reads like something anyone could look up.  I want to be able to ask you questions about this but it's too generic.  What type of predictive model did you develop?  25% improvement to what end?  Who needed this info and why?.   You could say something like evaluated several regression models against dataset on patient frailty.  Improved doctors ability to anticipate falls by 25% across xx patients and recieced blah blah award for the work.  I dont know the wording obviously, but something that is specific enough that I can ask questions about it.",204,1736579104.0
1hyploh,m6juc7g,"“Post graduation…” 

Just say you have a graduate certificate",32,1736585748.0
1hyploh,m6l2ja3,"Nuke the professional summary, it's useless, no one cares. Your last 2 experiences are not relevant, remove them and add more details into your DS projects. Also consider adding a section of any data science projects u have done. There's also no such thing as a ""data scientist/analyst"". Pick one title, preferably the one ur contract mentions",23,1736608398.0
1hyploh,m6m0n36,"CV looks very generic, all over the place: data analyst, data scientist, machine learning engineer. And there is no way you can be great in all. Also leaves me confused what problem you can actually help me solve.

So, try to match your cv to the role you are applying. For example if data analyst, then querying the data, visualization, and business acumen. Less is more. Build the case why you are good for the job, not why you are good in everything",21,1736619261.0
1hyploh,m6jfhdc,"Since you don’t have 10+ YOE, your resume should really only be one page. I’d consider cutting down the summary section or eliminating it entirely (since you’re not transitioning into a new type of role nor a new grad) and cut down on the skills section too, it really should only be about 4 bullets max. One possibility is keeping the skills section as is for a “master” resume and modifying it for each application to have the most relevant ones present",65,1736576590.0
1hyploh,m6jjeis,"Some nitpicks:  

When mentioning metrics, you need to put them into context (I.e. magnitude of impact) and choose the most appropriate ones. The reason being, the best people at hiding insignificant results and making them look good to non technical stakeholders by cherry picking metrics are ironically data scientists. Accuracy is not a great metric here. For example, readmission is a rare event and accuracy isn’t great for reporting performance in the setting of class imbalance. The way it’s written in your resume tells me that you still need to work on how to interpret and report your results. 

Were the 70k records pulled from a DB? Did you need to do the data engineering with the initial number of records? (usually in the 100s of thousands for a decent health system to millions in the case of EHR providers) mention this number if you have it too, along with the DEng methods. It’s important to know if you had to join all of the tables and do the queries for the medical records. Anyone who’s done this knows its a huge and tedious task.

I’m not sure what you mean by “positively impacting 95k records.” 

The improving “operational efficiency” bullet sounds like fluff unless you say what it actually impacted and how.

There are inconsistencies in your objective and what you’ve written in your bullets, that if I were reading this would give me pause.

70k medical records is not a “large scale dataset.” Its on the smaller end of medical record datasets. “Deploying advanced ML models” is not helping either. The only ML models I see explicitly mentioned are SVM and logistic regression. These are fine to use, but I would be careful when combining this bit of information with “advanced.” I don’t see what you did to deploy models. Are you using a registry? Inference server? This needs to be mentioned too.",21,1736578841.0
1hyploh,m6jendu,"As I can see in the experience section you have mentioned the results but not the things you have used to achieve it.
Have you scored your resume ? If yes what's the score",9,1736576126.0
1hyploh,m6kbxm7,"You have a misspelling in the first bullet point in your first experience section (accruacy).  When someone in a high-level technical position doesn't run their resume through at least a basic spell check, that's a red flag.

Also, you're aiming for a senior role with less than three years of experience.  I have about a decade of experience in the data world and I see people with more experience than me applying for senior data roles.",23,1736596932.0
1hyploh,m6kve4s,"Honestly you lost me in the first 4 words. You may be very competent but everyone claims to be and few are; better to show it than state it. I would lose the entire summary and bring your skills/tools to the top (grouped by area -programming, DS, PM, etc. )

I also generally find the functional bullets you've listed to lack in sufficient scope or business relevance in the detail you've given. I need to know why these items were important and how quickly you executed on them.",10,1736605790.0
1hyploh,m6my50f,"As a DS who has been offered 20+ jobs over the last 3 years due to OE, my biggest takeaway is that how you find/pick the openings you apply to is the biggest difference maker. You’re going to have a bad time applying to listings on any sites like Indeed, LinkedIn, or any other aggregator. You will have much better luck finding companies that hire a lot of DS or similar type positions in your geographical area and then going to their careers page and finding the openings you want to apply to. Also, try to avoid jobs that are just “Remote”. Let’s say you live in Arizona…find jobs that are “Arizona Remote” or even better “Phoenix Remote”. To find companies to apply to, you can google or ChatGPT things like “Top Employers in Arizona” or “Top Tech Employers in Arizona”. I have also found resources online that provide me with businesses that have a big presence in my area. Usually your nearest metro city or state will have an Economic Partnership website or something similar that has this type of information/data. When you get interviews with a company, save the company name and any relevant notes in an excel doc so that you can reflect on companies that were previously responsive, making your job search much easier when you look for your next job.",5,1736629867.0
1hyploh,m6jx2no,"Being a current data science student with literally nothing on my resume at the moment coding or data science related and seeing this, fills me with dread.

If a resume like this can’t find a job idk how the hell i’m going to find one post graduation. 

My curriculum is a really strong base for developing into a great data scientist, and I’m receiving a Bachelor’s IN data science but I’m still worried. 

What country are you in OP? Do you speak the native language there? Have you followed up after applying?",12,1736587548.0
1hyploh,m6ks2nq,"Lose the professional summary and the buzzwords key skill section at the end. This should be one page.

Your bullet points need more context - it’s all high level. And it’s not done in a way that translates to business value.

 I have seen resumes like this and interviewed some and the prevailing takeaway is “probably would be fine with handholding because they’ve never been the one running the show”

Also if you need a visa that’s probably not happening in the US right now",3,1736604487.0
1hyploh,m6olh6o,"I hire healthcare data scientists and this type of resume is a dime a dozen. You need to differentiate in some way. Building a few xgboost models on structured ehr data is not gonna cut it. I promise chatgpt can do something similar. If you can, either show strategic promise by describing how you influenced change at a business and or have a killer GitHub project then show those 

You appear to be trying to show off how much data science you know but instead you should show how valuable you are to a business. Completely rewrite with a different audience in mind.",5,1736649554.0
1hyploh,m6ouamu,“Highly skilled” and “3+ years of experience” don’t really work together. Let your project outcomes show your skill,4,1736652823.0
1hyploh,m6l2tge,I would get rid of the summary and maybe a cover letter explain how you went from front end to data science without going to school or what not... big leap tbh,3,1736608496.0
1hyploh,m6l6044,"Some really great advice here so far. I’ll add that you should think about your verb choice a bit more in some places. If you have a senior title, you should be leading, steering and managing. If you are an effective IC you should be delivering, launching, and owning. 

Also make sure the key result and strongest verb is emphasized right up front. E.g. “Reduced code complexity 25% by redesigning a website” is much stronger than “Redesigned a website to reduce code complexity 25%”",3,1736609577.0
1hyploh,m6mdz0k,"I'll just say, if you're applying to remote jobs only 200 applications with no response wouldn't be surprising.

You're competing with Data Scientists at FAANG and potentially the world.",3,1736623397.0
1hyploh,m6kfp5u,"Make sure you have an up to date, we'll documented github repo linked on the cv.",2,1736598979.0
1hyploh,m6l20dp,"I had more luck getting interviews by taking initiatives to scale and improve processes.

Basically saying you built a model isnt impressive especially with how easy it is to build a model. Whats harder is improving on a process and quantifying the lift. 

For example in my case i showcased my workflows i incorporated raised our models by 1-3% auc across the board and were more robust. Not to mention I was able to introduce more analytics work that helps with model validation beyond test train splits. I also did open source work for personal projects for a portfolio that addresses gaps in industry. 

Things like this help make you standout than the conventional ds who just spent their time without actually improving processes.

Another example is mention how you lead projects and take ownership of ideas and the quantify how this idea added to the company bottom line. Even better is if you can modernize a team by introducing cloud and simplifying workflows. For example my team rewrites code in java to productionize a model, however i think we should move to docker and go to cloud to reduce code overhead and have more robust models. Stuff like this also enable you to get exposure to the full model life cycle which is something you completely lack in the resume.  You mentioned all the skills like GCP, AWS, but no where in your actual experience did you specify what you did. To me that looks like you basically heard about GCP and now its a skill in your resume when you might not even know what vertex ai or what bigquery even is.

What you are trying to do is basically say, if my current employer didn’t hire me what significant difference would have been if they hired a basic data scientist and trained them instead of you. This showcases how you are more valuable than the competition and often not requires a lot of effort.

Source: i was involved in the hiring process and went over many resumes for candidates before. ATS scores are great but the core idea is what matters not the score.",2,1736608215.0
1hyploh,m6l7xso,"Right now your resume is way too much of a hybrid of DS and frontend stuff. You need to commit to highlighting your DS experience when applying to DS roles. Expand on the two DS roles and cut back on the front end stuff. This is especially important given that you don't have any formal stats training. If you took an ML course for your masters you would definitely want to add that to education section. 

Your resume also has too much bloat.  Cut down to one page. You list git 3 times in the skills section. You list bootstrap under programming languages, which is apparently some front end framework, but in a DS context people will think it means something else and that you're confused! The typical advice that you need to include as many random keywords as possible is bad because it makes your resume look like shit. It needs to be attractive to a human!",2,1736610224.0
1hyploh,m6mfrgd,"I’m not meaning these comments to be rude, I just want to emphasize brevity (which is what your resume lacks).
Immediately turned off by that professional summary. If you’re highly skilled, adept, etc., put it in the relevant experience sections. 
Your skills and technical experience taking a quarter page is unnecessary and irritating. If the posting doesn’t mention it, then nobody is looking for it. Take out the fluff.",2,1736623957.0
1hyploh,m6uyhqp,"take this as you will—i am saying this to be constructive. These are red flags i see when reading this CV:

* No GitHub repo (maybe in blackout section?). I tend to look for people's GitHub repos when hiring a data scientist-like profile. It helps weed out non-contributors and fakes. It is also useful to get an idea of how much people are looking. 

* The claims that you improved accuracy of models by 25% or 40%, increased engagement by 30%, etc... will very likely be seen as bluster. Either you came into companies with extraordinarily weak teams that had never implemented a model, or your model assessment is not factoring in overfitting, or both. It is unthinkable to me to routinely improve models by double digit percentage figures in places that have expert or even semi-expert teams in place. If your companies have had teams that routinely were weak, expect your experience to count less at more sophisticated companies. 

* Lots of phrases that sound good but I am not immediately sure what they mean. ""...optimized ensemble models for feature extraction"" could mean you extracted features that led to improved ensemble model predictions, or that your ensemble models enabled you to extract important features from your data (though to what end is unclear) 

Overall, when I read your CV I don't immediately see a Sr  role in data science or ML. The numbers and the descriptions of the projects simply do not line up with what I expect from a senior role. There is a lot of effort on ensuring people know you know tools in this CV, and almost no effort in ensuring people understand the role you played in shaping these efforts. Bear in mind that deploying a random forest today is as easy as typing RandomForest.fit(X, y), so your CV should ideally reflect a deep insight you managed to generate at your positions (for a data sci role) or a significant advance that allowed you to deploy and build the correct ML pipeline (ML)

Hope this helps! Good luck, there's a job out there for you!",2,1736736827.0
1hyploh,m6vyp97,"As someone who hires in this industry, I don't give a flying fuck about the fake numbers you put in your resume. Leave that for the cock suckers with an MBA, you're a data scientist don't confuse that. 

  
Really, I just want to see your skills, tools, projects, employment history, and education. Nothing else really matters. 

On the professional summary, that's too long. 

  
If someone gave me a resume and was like ""Bro I got a BS in Computer Science, an MS in statistics, I worked my first 2 years as a quant at Wells Fargo, and then 3 years as a Machine Learning Engineer at Pepsico. These are the types of projects I've worked on and I am most familiar with Regression Analysis, Decision Trees (including XGBoost), and clustering."" That's about all I need to know they are worth interviewing. 

  
No inflated bull shit numbers, just raw ""this is who I am, this is the stuff I have worked on"" and once we are in the interview I will ask them about their SQL / Python / How they have applied regression or clustering to a real problem. 

If I give you an open ended project, one that I might assign to someone and expect them to handle it independently in 2-3 weeks, and you do well then good for you. If you do bad then you're no longer a candidate for the role. I'm not even checking your coding skills, it's a high level ""Here is the problem, pitch me on how you would solve the problem / run the anlysis / handle this project."" 3/5 applicants fail at doing this.",2,1736753435.0
1hyploh,m6yv3bc,"This is really personal but I do like to have my CV only one page long. To do this, I would reduce the bullet points of really past experiences and explain just the part you learned the most from that job. 

Also some %s seem too difficult to measure. Hence makes me doubt on the rest (e.g: reduced code complexity by 25%). 

If you have some personal portfolio I would add that as well. 

Finally, keep applying! You only need one yes.",2,1736795829.0
1hyploh,m704zlh,"I don’t see anyone else mentioning this - keep it to one page. Get your achievements across more concisely before their eyes glaze from reading 100 of these. In all honesty the person hiring you might not be a technical person, too, so keep that in mind.",2,1736809429.0
1hyploh,m6l90qa,People on here are ruthless 😂,3,1736610582.0
1hyploh,m6jwpck,We are hiring for data scientists who have 3+ yoe. Are you interested? Location: Ahmedabad.,2,1736587305.0
1hyploh,m6k5koj,"200 applications, but it looks like you don’t take pride in your own resume? 

It looks to me as still relatively junior at least in thought process or business maturity. I’ve managed people who think more senior after 3 years than others with 8+ years experience. Those with the right thought process and business maturity have a way of navigating ambiguity, problems and red tape with relative ease, this often is the kicker for a high performing, autonomous employee.

Your resume should not only showcase your professional career but also show the reader what they’re going to get, it’s a reflection of you and your brand…and work ethic. 

This shows me, basic formatting, generic layouts, minimum effort to get a tick in box and move onto the next activity. 

It doesn’t need to be designed by a UX designer, but show that you care enough to go a little further to present things in a visually impactful manner. Have a look at Etsy or fiver, take some creative direction from those or even consider buying a template. 

Also, Every single application should be tailored to the role. Make sure it addresses critical accountabilities in the role and shows you understand them and have excelled with these in past.",1,1736593061.0
1hyploh,m6kxefg,My resume is a react website which i can print out as a pdf. When I go for a new job i adapt the resume to the corp identity and the job description. My interview rate is higher than 50%. It was also pretty fun to build the cv.,1,1736606547.0
1hyploh,m6lp4f7,"For each accomplishment, list the major tools or packages you used. Don’t repeat yourself between bullets- this gives you a good list of keywords that people will search for",1,1736615672.0
1hyploh,m6lx9dc,"same bro , still searching for the solution",1,1736618208.0
1hyploh,m6lzv6e,Honestly it might be a good idea to think about applying to other roles and then try to move laterally to a role you’re more interested in. I’ve found it easier when my foot is in the door. It’s not giving up it’s just a bump in the road,1,1736619021.0
1hyploh,m6mcgzp,"less is more, cut off the yapping in the introduction, max three bulletpoints, run ATS scan and you'll be good to go. I don't understand why there is so much front end experience in this resume, remember you are looking for ds jobs. Add some interesting personal projects for bonus points!",1,1736622930.0
1hyploh,m6mvq5v,Which country are you applying in?,1,1736629100.0
1hyploh,m6ntdqx,"A lot of my comments might already be covered. Keep it to one page. 

The summary uses too many buzzwords and is repetitive. 

The software engineering roles can be condensed or removed entirely so you can devote more space to data science experience. 

I suggest adding more details describing what you actually did. A lot of your experience is vague or overusing buzz words- for example phrases like ”advanced analytics” and “actionable insights”. To be honest it makes it sound like you’re overstating what you did or just making it up.

Other than that you’ll want to tweak your CV to highlight the most relevant experience for each role. I’m also not sure that your experience, as described, qualifies you for “mid-level”. You might have better luck looking at entry level roles,",1,1736640096.0
1hyploh,m6p1kwj,"Remove summary  , add certifications  , add good projects",1,1736655753.0
1hyploh,m6pg2zj,Um. Drop a bunch of AI and GenAI in there. Hold your nose if you must but a DS without GenAI skills is probably gonna be overlooked often.,1,1736662697.0
1hyploh,m6pg6hx,Also first block is very dense. I’m skimming at best on resumes.,1,1736662750.0
1hyploh,m6prvaz,"Your resume is good. Moreover, you need to create portfolio link and more project. 

You can connect to Manager, CEO, CTO, and Data science (senior) for request. Then, you can forward your resume to that person until they accept you in LinkedIn. 

Thank you.",1,1736669643.0
1hyploh,m6pv4b0,you have almost no data in your resume they’re all round numbers? You don’t mention any of the underlying tool sets that are used in data science????,1,1736671699.0
1hyploh,m6q3a6k,"In my resume, I include a separate ""Key Projects"" section after my summary, which highlights the most impactful/interesting projects I've worked on, and the skills and tools I used to accomplish it. I link it to anything that is sharable on GitHub. Almost every interview I've had, the interviewer has asked me about one of my projects in that section. It makes it easy to stand out since the recruiter or interviewer doesn't need to dig to find something buried two jobs ago. I still include the chronological listing of my job and responsibilities after.",1,1736676878.0
1hyploh,m6q4vlu,If people like you with such a strong CV and experiences struggle for work what does that mean to beginners in the job market?,1,1736677877.0
1hyploh,m6r9mpw,"I was in a similar situation and did the following, which helped me get at least three calls daily:

1. Applied extensively on platforms like Naukri, Hirist, and IIMJobs. LinkedIn didn’t work well for me, but you can still try it.


2. Included an LLM project on my resume, even if I hadn’t worked on one yet. I studied and created a basic project locally to back it up.


3. Listed all the technical skills I know, along with some that I didn’t but could learn quickly.",1,1736696289.0
1hyploh,m6rxner,"Some thoughts:  
1. You mention that you improved accuracy by 25%. But this is vague. Is it 25 percentage points (i.e. from 70 to 95)? Or is it 25% (i.e. 50 to 62.5)? Furthermore, the starting point is important. What if the previous model had a terrible accuracy?  
2. 70,000 EHR records is not that much. I would focus on the some of the impacts of the actionable insights.  
3. The pet insurance, what was the goal of the prediction?   
4. The change from being a developer to a data scientist/analyst is not smooth. Did you suddenly change the course? You can make the change smoother in your CV.",1,1736703572.0
1hyploh,m6u3ud7,"Fwiw, I applied to 200+ jobs before I got my first interview",1,1736726503.0
1hyploh,m6uk8kk,"You have a solid resume. If you aren't getting responses, then idk what will happen with me lol.",1,1736731850.0
1hyploh,m6ulyj4,..,1,1736732433.0
1hyploh,m6w8pdq,"Suggest you to add business impact numbers if you have rather than model performance improvement metrics. Agree that as a data scientist, model performance metrics are chased. But sharing business metric improvement seems more relavant ultimately",1,1736759900.0
1hyploh,m6wb80d,Commenting for later,1,1736761569.0
1hyploh,m6weztv,"Agree with other comments - moving from web developer to data scientist with a one year contract sounds odd. I would have expected you'll need a few years to transition effectively, and it's very odd that a company hired you as a contractor during this initial transition. And then you start as a Senior Data Scientist immediately after that - it just doesn't fit. You also list HTML/CSS etc. at the top of your skills, which makes it look like you are still in transition. 

If you can, stay in your current company to build up some career in DS. Try to change your job title to just ""Senior Data Scientist"" (drop the ""Analyst""). Also, remove frontendy stuff from your resume.",1,1736764033.0
1hyploh,m6wrx1r,"It's a pretty good CV. I would be more detailed about the tech or models you used. As others have said, put a skills section in and highlight what you can do in both DS and Engineering/MLOPS. This is your selling point, you can do both.

Also the market is tough because there are too many CVs due to LinkedIn Easy Apply. Go for roles that have a slightly more involved application form, that puts off people who aren't that interested. Also find companies you like, find the Head of DS on LinkedIn and email them saying you want to work for them, people love that as it shows real interest for the company.",1,1736771261.0
1hyploh,m6xct9a,"First line, instead of 3+ years in ML. Put a decade in the field of data science with specilization in ml.",1,1736779608.0
1hyploh,m6xp76x,to me the only thing that will matter is what the companies are. your best chance of interview is with a company with very similar business model/size/industry to your own.,1,1736783597.0
1hyploh,m6zulqz,Talk more about he specific project you did and tools used. This looks very generic.,1,1736806186.0
1hyploh,m716hdy,Are you a US Citizen?,1,1736821775.0
1hyploh,m73kol2,"I would say, theres a lot of things going on specially on the first part and the last part and i am not seeing these backed up by the experience listed. What i suggest it tone it down a little bit, and focus on giving more details on your present role. You have 2years more or less on that and you were only able to give down 4 bulletpoints. Also your first 2 roles doesnt really contribute on your primary role, so I would combine that into one.",1,1736863749.0
1hyploh,m75qpj0,"A few issues I see here

1) the intro is  wordy and generic. Make it one or two sentences to the point. Stop using so many superlatives. It looks like you are trying too hard

2) this isn't a senior position exprience level. Aim a bit lower with your current experience level and work your way up. Particular because this appears to be a self taught person with no high level formal training 

3) The  HMTL is a big red flag here, very strange transition. I would probably not mention that experience at all

4) You mention large datasets, but I don't see any experience with them in the CV. A million records is an Excel sheet, not a large dataset",1,1736887444.0
1hyploh,m767ssp,"1. Remove or truncate professional summary
2. Add skills section and relevant links to your portfolio
3. Add more color to your DS projects. For example: What tools did you use? How did you unblock yourself when combing through 70K records?
4. Did you deploy any of these models? Can you highlight any DE work that extends beyond the DS scope?",1,1736892754.0
1hyploh,m6jwgri,"
I would remove the software jobs and expand on you data experience.

You need to explain better what you were involved in. Like for example did you work with the data engineering team, did you deploy the models, did you monitor data drift?

Saying something like I affected 95k rows is blow and smoke to me when these sort of companies deal with many millions of rows. What was the relevance to the business and what impact did you have, for example you can also highlight your knowledge of insurance risk data.

I would also highlight soft skills relating to each project.",1,1736587148.0
1hyploh,m6jtsfi,"Lie more. Check other profiles on LinkedIn and use their experiences. You have to be able to answer questions about those lies but that's generally easy if you understand the topic.


Change your 2 oldest jobs to data analyst or junior data scientist and description accordingly. This will be your most important change.
I worked my first 2 years at a dead end office desk jobs where I was working with excel and sending emails. I changed it to data analyst, added some interesting stuff and suddenly my CV was better. 

Unfortunately it's very hard for juniors these days but there's a lot of jobs for experienced workers.


Add fake experience during school years.",-14,1736585384.0
1hyploh,m6l5q3f,Great suggestion…thanks!,0,1736609483.0
1hyploh,m6nmwh5,Stop applying on LinkedIn. Only use it to see employment histories of other people in your profession. Apply to their more recent companies in their history. Apply DIRECTLY ON THE COMPANY’S WEBSITE.,0,1736637899.0
1hyploh,m6or0ak,"Remove “Data Analyst” from your first job. If you’re looking for a Scientist role then an Analyst implies you are less qualified than you are

Also have you been able to tailor your resume to the job you’re applying for? This reads like a very generic application that will get overlooked quickly. For instance, if you’re applying for DS roles then don’t talk much about your frontend dev work. Maybe 1 sentence tops but after that you’re wasting space",0,1736651572.0
1hyploh,m6u684n,"I would not hire you as a Data Scientist as it is clear you are not one. Don’t lie to yourself. You don’t even have a mathematical/quantitative background like Stats, Physics, Operations Research, Econometrics etc",0,1736727288.0
1hyploh,m6jp9pd,I think it’s a strong resume but I’m kinda surprised you don’t have C/C++ listed. Every cs/ds major I know has some experience with C,-11,1736582457.0
1hyploh,m6k9hjv,"Get the address and mail them to The HR rep. Or you can hire a head hunter. 
Bit to mail them call the he department and find out who it is and attn: so and so in the body of the envelope. And make it personal to the person in hr . It will show you tried and the dam computer bots and stop that.",-8,1736595499.0
1hyploh,m6jpv9y,"To piggy back on this comment, agree with all the above, but also those performance numbers are all round numbers and big, which is often a sign GPT has been involved. If it was 19% improvement put that and don't round up to 20%. Just something we've noticed when we do hiring of data scientists.",110,1736582836.0
1hyploh,m6jfj07,Thats a great feedback. Thank you so much. Which site do you use to score the resume ? I have never done that before,47,1736576615.0
1hyploh,m6krmqm,"You got 4 offers? What do you mean by you ""cracked"" the interviews?",9,1736604311.0
1hyploh,m6nf7hq,">Mention your skill sets below your summary

Hard disagree with this point. Resume should be in descending order of importance i.e. from most important at the top to least important at the bottom. Recruiters and HMs almost always care about work experience and education the most. Skills are not because it's not a reliable. If you mentioned a skill, it's hard to tell how good you are at it. If you didn't mention something, does it mean you can't do that?

IMO the best order is experience -> education -> everything else incl. skills. Reverse the first two if you don't have any valuable experience (e.g. recent grad).

Also summaries are often not even read or don't say anything critical most of the time. It just takes up important real estate. I'd rather make a single page resume than keep it.",8,1736635323.0
1hyploh,m6p5193,Can you please explain more about the formatting of the point 1? How to do so without looking messy?,2,1736657260.0
1hyploh,m6kwj42,"Also be aware, ATS score and rank the CV based on peers and competitors. If everyone does that, things are back to square 1.",1,1736606221.0
1hyploh,m6ma7or,Where can you checkt he scores?,1,1736622229.0
1hyploh,m6nj45p,How to check #5?,1,1736636615.0
1hyploh,m6ojj2q,Which ATS parser site did you use to check your score?,1,1736648867.0
1hyploh,m6ox4kh,What's an ats score? How do you check it?,1,1736653917.0
1hyploh,m6primm,what's that ATS score ?,1,1736669423.0
1hyploh,m6q1pk0,I was wondering what projects you did,1,1736675880.0
1hyploh,m6rgp6w,How do you check your resume score?,1,1736698612.0
1hyploh,m6s1ws3,I would've never thought of #5. Thanks for sharing,1,1736704763.0
1hyploh,m6s4ya8,which country do you apply to?,1,1736705612.0
1hyploh,m6tq889,Thanks for the pointers. Are folks spending the time on custom-tailoring and submitting cover letters for each or is submitting them at all a waste of time? I hear conflicting reports...,1,1736722151.0
1hyploh,m6uplvx,"Wait what’s a resume score. Sound so interesting. And thanks for the insights, very useful.",1,1736733686.0
1hyploh,m7106ft,">Try to put in more Data sciennce projects

This is main issue. I will saw have only 1-2 bullet point for FE and developer roles. Also be more specific, don't say predictive machine learning model but mention the model name (like xgboost, cnn, linear regression). Just saying machine learning means nothing.",1,1736819767.0
1hyploh,m73h1pg,"would you say a published reasearch paper shows ones DL/ML ability? Do research papers prove ML proficiency to you? Since it is a ML job, do you think DSA matters?",1,1736862400.0
1hyploh,m6lw3rj,\#4 and \#5 are the most important tips here. ,0,1736617854.0
1hyploh,m6kxxuk,"also those 25% would be nice to be translated to high level revenue/profit/cost. And, 25% improvement seems .... suspiciously high?",32,1736606747.0
1hyploh,m73gzlq,"*This is especially important to me in a data science role. I expect you to understand metrics and how to communicate results. You do a little, but nothing that made me say ""oooo"", i want to hear about this problem and how it was solved.*

would you say a published reasearch paper shows this ability? Do research papers prove ML proficiency to you? Since it is a ML job, do you think DSA matters?",1,1736862377.0
1hyploh,m6jy02i,[deleted],-13,1736588164.0
1hyploh,m6mxd4h,Ya post graduate rather than “post graduate certificate” sounds like they’re reaching to place it on a playing field with post-graduate grad school.,12,1736629619.0
1hyploh,m6ym40z,"What? Hell no, being a SWE means that you can code and not write a shitty, messy notebook. By all means, leave it there... Trust me, I am searching for a DS position and everyone asks if I am a coder and how much of a coder I am, hinting it is more desired than Mathy skills (I was an SWE as well).",1,1736793222.0
1hyploh,m6jfb8v,Thanks for the feedback. My score is 54%.,5,1736576495.0
1hyploh,m6ltxb8,[deleted],3,1736617179.0
1hyploh,m6lnimw,It’s spelled accuracy.,2,1736615171.0
1hyploh,m6kyc61,I'll say unfortunately this CV is not so strong,7,1736606892.0
1hyploh,m6jyq9f,Transition to a different role. People getting rejections often has little to do with their resume at this point. This field is becoming oversaturated. Get into cyber security or Web or mobile development. Just my two cents. ,6,1736588645.0
1hyploh,m6n5hgk,"A degree is just one piece of the puzzle. I don’t have one, yet I’ve secured a mid-level position in data science and AI. The key is hustling—working for free, jumping from company to company for cheap cheap, collaborating on projects for free, networking out the wazoo, etc etc.",1,1736632213.0
1hyploh,m6lin4a,"You're not wrong it's very competitive and there are very few truly entry level roles on data science.  Also, many, many people who are in Data Science positions are either very specialized on a specific domain, or a specific type of DS, like causal inference or expirementation.  

Even more people who post DS roles are actually looking for data engineers or analysts or ML engineers, or even dev ops type roles.  I've seen it all.  

If it were my kid, I wouldn't encourage them to pursue a DS degree.  If you the technical aspect of messing with data, data engineering or comp sci  with a minor in stats.  Otherwise math's or engineering PhD for an entry level position in big tech, or just learn sql, and some data viz tools and go for an analyst role in a field you find interesting and start on the path of becoming a domain expert",1,1736613655.0
1hyploh,m6lako3,"Just curious, there seems to be some disagreement about a summary section up top. I have one, some say you shouldn't and some say you should. Personally, I find it useful so that an HR manager can quickly gauge fit. Why do you think OP should lose the summary?",0,1736611088.0
1hyploh,m6mjvlp,"I reviewed over 100 CVs for a Senior DS role this week. I didn't look at a single github b repo.

The engineers who do the tech test will look, and having a good portfolio is useful...

But it's not useful for getting to the first round, and it's not enough to sway things anywhere I've worked.

Brief, punchy and eye catching CV with details of projects: biz challenge + tech solution + outcomes.

Also, after having to look at that many CVs in our crappy HR portal, I can honestly say that a larger font size and less words is a huge plus!",7,1736625263.0
1hyploh,m6n6tmb,Honestly? Good. I would rather be roasted here than by hiring manager. ,6,1736632635.0
1hyploh,m6mawft,"I don't know why you got downvoted because the general advice of 'care about how you present yourself' is great advice. If you're applying cold, the resume is the only chance you have to make your case; it should be engaging somehow. This resume looks bland and uses too much generic jargon (""adept at cross-functional collaboration"").",1,1736622446.0
1hyploh,m6mh9hc,So you can tailor the pdf before you print it? Do you mind talking more about this? Did you follow a template or tutorial?,1,1736624429.0
1hyploh,m6n6kcz,"Toronto, canada. I am based in Toronto",1,1736632554.0
1hyploh,m717a3o,No canadian citizen based in Toronto,2,1736822034.0
1hyploh,m6kf992,Hard disagree with removing the software jobs. It’s relevant experience.,8,1736598747.0
1hyploh,m6kfb5d,Not relevant for data science or analytics.,2,1736598776.0
1hyploh,m6mgc4j,"Good to know. I designed my resume 5 years ago with nice round numbers to make it easier to read  (obviously not saying 20% if 13%, but from 19% to 20%, or $500 000 instead of $519 304 for example).",19,1736624138.0
1hyploh,m6xopvh,"who doesn't use gpt these days though? i'd say at least half of recruiters are using it to review and rank cv's, really the best approach is to get 5 llms to write in 5 different styles, then get them each to rank all of the 5 outputs. whichever scores highest is most likely to get through llm screening.",4,1736783450.0
1hyploh,m6prm8y,how much do kaggle competitions matter ?,1,1736669487.0
1hyploh,m6jx6tl,Always use fake name and fake contact details for ATS sites. The ATS scoring is in change for your data.,77,1736587626.0
1hyploh,m6jg08t,"Just search for ""Resume ATS score"" or something like that on Google. I don't remember the exact name I used to score my resume.

Also, your skills section is too spread out. Try condensing it. For example you don't have to mention every single ML algo you've worked on.
Also don't have separate columns for CI/CD and others.
For example create a point let's say called ""Dev Tools"" and add Git, docker, kube, CI/CD, etc under there. It would shorted your resume size.

Also people might ask you to keep your resume under 1 page but I won't suggest the same. I'm having 5 YOE and my resume was full 2 pages long.

As long as you have good quality work good skills, you'll get calls you just need to put them on the right spot for people to see.",32,1736576884.0
1hyploh,m6krspd,Yes I got 4 offers,9,1736604377.0
1hyploh,m6q9bpa,"I split my skills section into two columns: expert (1000 hours), intermediate (100+ hours). I was never in the public market (went through an incubator and never changed jobs again lol), but felt good about being open and clear about it.",2,1736680653.0
1hyploh,m6pdhx7,"If you're asking with respect to the skills section, here's my suggestion.

1. Limit the subsection umder skills to 4 to 5 bullet points
2. Try to create umbrella terms for few technologies and tools. For example - in stead of having separate section for IDEs used and let's say CI/CD frameworks used, you can add all of them under let's say ""Dev tools"". This can shrink your bullet points

How I do it.

1. Programming Languages: Here I mention all the RELEVANT programming languages I have hands on experience with (eg - Python, Mysql, Pyspark) 
2. Libraries and Frameworks: I mention the names of libraries and frameworks I have experience with (eg - pandas, numpy, Langchain, etc)
3. Skill sets: I mention the skill set names (eg - data analysis, statistical analysis, data visualization, deep learning, machine learning etc)
4. Dev tools and platforms: The tools and platforms I use to make my life easier (eg - GIT , jupyter, AWS, jira, airflow, etc)

If you feel some of the above points are a little too congested, you can create the final 5th point for this.
Or maybe you can use the last point to add the names of the specific tools and algorithms the specific company you're applying for is looking out for. 

Hope you have gotten a good idea.",5,1736661320.0
1hyploh,m6oy92e,[here](https://enhancv.com/resources/resume-checker/?utm_source=google&utm_medium=cpc&utm_campaign=search_resume_checker_india&utm_content=717284765201&gad_source=1&gclid=Cj0KCQiAyoi8BhDvARIsAO_CDsDtwuy7zTHXPLNjf5vH2ojsnGYW6NuDrWqXvdgrUjGMve8BUgfUAa0aApYnEALw_wcB),1,1736654367.0
1hyploh,m6oyb5u,[here](https://enhancv.com/resources/resume-checker/?utm_source=google&utm_medium=cpc&utm_campaign=search_resume_checker_india&utm_content=717284765201&gad_source=1&gclid=Cj0KCQiAyoi8BhDvARIsAO_CDsDtwuy7zTHXPLNjf5vH2ojsnGYW6NuDrWqXvdgrUjGMve8BUgfUAa0aApYnEALw_wcB),1,1736654390.0
1hyploh,m6oyf1b,There are lots of them online. One is [this](https://enhancv.com/resources/resume-checker/?utm_source=google&utm_medium=cpc&utm_campaign=search_resume_checker_india&utm_content=717284765201&gad_source=1&gclid=Cj0KCQiAyoi8BhDvARIsAO_CDsDtwuy7zTHXPLNjf5vH2ojsnGYW6NuDrWqXvdgrUjGMve8BUgfUAa0aApYnEALw_wcB),1,1736654434.0
1hyploh,m6oy1xh,"ATS or Application Tracking System is an application used by companies to sort the most suited resumes for the job and then those resumes are forwarded onto the HR representatives.

If you have a low ATS score, your resume is at a low risk of getting shortlisted by the application. A high ATS score will most likepy lead to your resume at least pass the application. The resume still can get rejected at any further steps.

Now, why even care about ATS. So when a job opens hundreds and thousands of applicants apply for the role. In order to find the best suited candidate, it's impossible for the recruiters to have a look at the resume individually and hence ATS comes into the picture.

You can goto [here](https://enhancv.com/resources/resume-checker/?utm_source=google&utm_medium=cpc&utm_campaign=search_resume_checker_india&utm_content=717284765201&gad_source=1&gclid=Cj0KCQiAyoi8BhDvARIsAO_CDsDtwuy7zTHXPLNjf5vH2ojsnGYW6NuDrWqXvdgrUjGMve8BUgfUAa0aApYnEALw_wcB) to check your ATS score

Hope that helps",5,1736654286.0
1hyploh,m73j07q,"In one of my interviews I was asked to read and explain a research paper. That was the first time someone asked me to do something like that in an interview scenario. So yes I believe at least having an understanding of research papers help a bit(I also have one under my name so I had some experience)

But now let's talk about publishes research paper in terms of ""does it show DL/ML ability"". I would say yes. I've seen people more interested in the mathematics of DL/ML rather than the implementation part. So a candidate who has let's say published a new finding on let's say Random Forest Classifier. I believe it shows a strong positive note to the recruiter.

Also now coming to DSA, I personally wanted to become an SDE all along but ended up becoming a DATA scientist. So while I was preparing for SDE I learnt a lot of DSA and it did help me a lot. I won't say it's extremely important at least based on my experience. I've had DSA rounds for data science roles but it was never a hard core get the most optimized solution kinda round. They were more ""how do you approach the problem"" kinda rounds. But yes I would say DSA helps a lot. I will probably suggest people to get involved more with Arrays and Strings related questions and not into complex structures like trees or graphs. In general practice DSA if you're weak at approaching problem or problem solving in general. Also, it's a lot fun (at least for me)",1,1736863128.0
1hyploh,m6l3v09,"What would you recommend doing in a case where the company/business area doesn't track implications of models on revenue/profits/cost? I was in a situation where I built a model, and while I can talk about why and the model outcomes, I'll never know if it actually made an impact on the bottom line because that's just not measured or tracked.",14,1736608856.0
1hyploh,m6mdlrv,"Definitely something to ask about, but if you've worked in large corporations the amount of systems processes that are poorly optimized is incredible lol. I've reduced model costs by 95% because it was implemented wrong.

YMMV though.",1,1736623283.0
1hyploh,m73u96e,"Not necessarily?  I'm not sure why but your comment reads as oddly aggressive to me.  Assuming that's not your intention.  

Published research in what area?  As a primary author or as a contributor?",1,1736867046.0
1hyploh,m6lfvsv,Can I know why this guy is downvoted? What's wrong in this?,0,1736612793.0
1hyploh,m6jg4ft,Okay this might be one of the reasons you should use resume worded and the feedback they give is good and then you can use chatgpt to improve upon them. I would suggest to do take care of many points in the feedback in the one go since you can't upload your resume multiple times.,6,1736576950.0
1hyploh,m6m4gia,The last sentence of the intro of the resume says they’re seeking senior roles.,3,1736620446.0
1hyploh,m6jzgkd,"I have a year left in my degree. There’s no “transitioning” outside of declaring a math minor possibly. More looking for advice on navigating the market and how to leverage myself. 

It seems like the market is over saturated because people not formally educated in the math that leads into statistics and thus data science, market themselves as if they were.",3,1736589122.0
1hyploh,m6o2lhy,"It’s a waste of space. “Detailed oriented and results driven professional seeking position X,y,z”

Everybody wants a new job, that’s why you sent me your resume. The summary just says the same thing your experience bullets will say but lacking all context so you have to repeat it later.

Better use is to save the space, then at the bottom put an other section that shows volunteer work, open source projects, awards, etc to give an idea for “fit”.

When I read a resume I’m scanning job titles and then reading the bullet points in order.",2,1736643056.0
1hyploh,m6n4fgo,I had a fancy cv from one of the resume.io builders then I didnt want to pay and rebuild everything with the help of claude sonnet 3.5 as my own cv builder there are a few templates on github but I build from scratch. Its awesome ;),1,1736631884.0
1hyploh,m6nosez,I understand your frustration. I too am applying for DS roles in Germany with no reaponse. Three years back this would have gotten u at least 30-40 responses. The best we can do is keep upskilling and hoping the economy turns for good. ,2,1736638547.0
1hyploh,m6ydsos,"Or a very good prompt. The problem is out of the box we can't tell if someone has just asked ""hey chat GPT write me a good data scientist resume"" Vs ""edit my current resume to highlight my skills"". Also if you're a good prompt engineer you'll make sure that the numbers don't all get rounded up or down or fabricated, so that in itself is often an indicator.",2,1736790826.0
1hyploh,m6pryz5,"Not at all. I honestly don't even look at that, the reason being that no kaggle dataset even remotely resembles data you'd ever see on a job. For extra curricular stuff the order for me goes
- GitHub repo
- Extra qualifications
- Leetcode/kaggle",10,1736669705.0
1hyploh,m6kifyb,Solid,7,1736600342.0
1hyploh,m6neav7,"Depends. JobScan only gives 5 per month for free. After that, it's paid.",4,1736635029.0
1hyploh,m6lwhc5,Thank you 👍,3,1736617969.0
1hyploh,m6v8fkd,True,2,1736740499.0
1hyploh,m6upqjq,Nvm I got ur comment here. Thanks,1,1736733731.0
1hyploh,m6ykpwv,"Getting 4 offers in India is not similar to getting 4 offers in a high-cost living area. Practically, the Indian market is booming and Europe and + the US is sh\*t, because we get paid at least 5 times more... I would not get 4 offers (i.e., you are impressive) but India is not an indication.",1,1736792820.0
1hyploh,m76v92n,Thanks!,1,1736900317.0
1hyploh,m6xjope,Thanks! I am using this website. One suggestion is that I should use better designed resume instead of generic layout like OP. Do you have fancy different color and style?,1,1736781886.0
1hyploh,m6ozpco,"Interesting I just did it and got 53, what's considered good? I don't agree with some of the comments on there like number of words the resume needs to have and where you need to mention specific accomplishment like say improve sales by 20%. Is the expectation that if we have 5-6 bullets per jon all must improve a metric? Usually you only on my experience work on 1-2 things where you can mention metrics",1,1736654958.0
1hyploh,m6lsdnm,"I’ve run into this a lot at my job, and sometimes you as the dev have to infer what happened, and then estimate business impact yourself. 

Sometimes it can take a year or two to see the results of whatever it was based on the business cycle but if you keep tabs on the stakeholders and ask them periodically how things are going, you can sometimes figure out how things were affected. Other times, it’ll be more like cost avoidance estimate because you did something that avoided a costly situation, which is also important to highlight because management tends not to notice those as much.",10,1736616696.0
1hyploh,m6l599w,"Ideally, a/b testing the model when deployment. Another way is causal inference which is an advanced topic",3,1736609325.0
1hyploh,m6lgjgt,"Nothing wrong with asking.  Guy didn't deserve downvotes in my opinion.  I'm not going to do this though.  Sorry folks, it's not very fun reviewing resumes, I just happened to have thoughts on this one. But not something I'm doing in my spare time for free for random people on the internet",7,1736612999.0
1hyploh,m6k53bo,"i have an msc in stats, about to start a phd soon. i would recommend you to get that math minor.

what i meant was that you can transition after you graduate, e.g. through a master's for example. gone are the days you could just get jobs with a degree in a general discipline such as stats or cs. you should have domain information at this point.

and you are completely right. i am a statistician by training, and we ourselves can't even get stats jobs (pure stats such as experimental design) because there are people from other disciplines e.g. psychology, there. it's not a problem by itself, you don't have to have a degree in stats or ds or cs to be good in those areas, but it seems we are confined to academia, which has many problems in its own right.",6,1736592752.0
1hyploh,m6k9neu,"piggybacking off of the other comment - spot on about needing domain information. 

ok, you can build/test/deploy a model, but so can everyone else, right? if you’re new, my advice would be to take your modeling foundations and apply them to a niche that you’re interested in within a more established field. e.g. retail, healthcare, finance, environmental science, etc.

ds has existed in these fields long enough that there will typically be a small set of widely accepted models and conventions with tons of documentation to back them up. showing that you know some of that (e.g. decision trees for retail applications) to some degree will really set you apart for entry level roles.",3,1736595598.0
1hyploh,m72u43j,good prompt engineer == actually reading the output before using it,1,1736851485.0
1hyploh,m6q41ml,"I guess it makes you learn a lot . Because, one is quite engaged with problem while doing kaggle competition. To be honest, I have taken some specializations and courses etc. I forgot a lot of stuff. And, I did a kaggle competition and it was so much learning. I tried out different methods, got to know their pros cons etc. and, I think I'm gonna remember those facts I got from competition for really long time. 

Second thing which I noticed was. Nvidia has explicitly listed their employees who are either kaggle grandmasters or masters on their official site. That made me think I should invest time in kaggle.",5,1736677356.0
1hyploh,m6yywp4,"It was never about getting job in India vs not getting a job at other places. Even though you might say India is not a high-cost living area, but there are a lot more candidates in here. Factor that in you'll realise even Indian market is a tough one.

And respectfully  I don't understand the point of being affected more in a ""high-cost-living"" area. I mean companies pay more because everything is expensive but while operating in those areas they earn more as well. In contrast in Indian market we get paid low because the cost of living is low and companies profit is relatively low as well. If you average things out (like the PPP, number of applicants for a role) , I believe the Indian market is comparable enough. 

Anyways coming back to the point, my focus wasn't on emphasizing that I got 4 jobs, it was to emphasize on the point that I got 4/4 calls because of the way I made my resume and it worked for me. I gave my suggestions irrespective of what country you're applying to.

And it would make my day to know that even 1 person got a call post making changes to their resume based on my feedbacks.",3,1736796934.0
1hyploh,m6p038t,"Anything above 50% is good, every Online ATS company would try to give you a low ATS score in order to upsell their product. I for example got an ATS score of 68% in some websites while in some I got 50%.
One more thing to ensure is that your resume parse score is more than 90%.

For ATS to score your resume, it has to parse your resume. If your parse score is high, be rest assured it's going to be very good with ATS in general.",2,1736655118.0
1hyploh,m6lhiko,"That's understandable but if I post something and if that guy asks me, I will see his resume and do some recommendations but if many people ask me later I would just tell them no.Or they could even deny it for him stating they couldn't do it because they just gave a suggestion. I don't understand why people couldn't just ignore or say no instead of criticising his question. Thanks for the reply.",3,1736613305.0
1hyploh,m6qoilu,It might be a deciding factor for some and maybe for junior or top 1%. But for the average functional data scientist I'm not going to care. I care more about experience but experience is dealing with all the imperfect stuff that real life problems throw at you.,1,1736688590.0
1hyploh,m73izag,"Respectfully, if you're cracking a 5lpa a job it's not the same. I know that's not necessarily what you're getting but this is the average entry level",1,1736863119.0
1hyploh,m73j2yn,"Respectfully, if you're cracking a 5lpa job it's not the same. I know that's not necessarily what you're getting but this is the average entry level

But your advice is great",1,1736863156.0
1hyploh,m6z0fma,"I just wanted to say that many companies open centers in India or Poland and close centers in the US, hence getting a job in the US is more challenging, compared to a highly qualified candidate in India.",0,1736797377.0
1hyploh,m6p1159,Thank you odd I only saw 1 score are you saying in the link you provided there should be more then 1 score?,1,1736655516.0
1hyploh,m73kv8p,"I'm not very sure how's that different, Indian companies despite paying shit try to get as good candidate as possible (not talking about the mass campus recruiters). The interviews are hard asf. But anyways, my experience of cracking interviews wasn't an easy one as well because I was applying for a senior data scientist and positions are relatively less and pay is more as well.

But my friend my aim wasn't to boast that I cracked 4 interviews 😭. It was just to tell people that my resume was shortlisted because I believe I did a few things right. Hope people in here learn something if they find it useful and maybe get calls.",1,1736863816.0
1hyploh,m73juxe,"And I would totally agree, even in India several product based companies usually have only a very few openings for some specific roles and it becomes very hard to even  get a call for those.

But my suggestions is to help people have a better chance of getting shortlisted based on tlmy learnings and experiences",1,1736863445.0
1hyploh,m6pc064,"Nope, there are other websites which can give you the parse rate",1,1736660567.0
1hyploh,m73l6tr,"Again, I have to tell you, I aced a few technical interviews amazingly and didn't pass because of a hiring freeze, a lack of very specific experience, etc. I got more than 4 interviews with a very generic CV (no summary about me).

It just truly sucks in the west. Hopefully I will get an offer soon, but it's really a terrible situation.",1,1736863934.0
1hyploh,m73lksm,"Man I feel for you. But worry not, keep learning and improving. Once the situation changes, you'll have much better chances.

All the very best my friend.",2,1736864076.0
1hyploh,m743563,Thanks!,1,1736869830.0
1hyte5x,m6kbw8p,"Have you thought about building your own startup? You have excellent salary for Eastern Europe and also seem to very smart and motivated. And you seem to be in a comfortable position. This could be the perfect moment to work on your own idea.

It is the path that I took. There is no guarantee for financial reward but I can guarantee you that you will definitely learn a lot (aside from technical skills).",46,1736596911.0
1hyte5x,m6k8db2,"If its of any use, I work in the UK and the number of visa-sponsoring jobs has absolutely plummeted to the point of being fairly rare these days, so I'm not surprised you don't get many callbacks. Not sure about the US, but the job market is crap right now so its not just you. 

As for the PhD my 2 cents is, its not a panacea, do not expect to be flooded with FAANG-level offers once you get it, there is a massive glut of ML PhDs from the last few years that have nowhere to go due to all of the layoffs and hiring freezes, it is extremely competitive out there. Do not look at it as a way to get a salary bump.

Looking at your CV my only comment is that it' looks heavily geared for a research position. There is a lot of  technical vocab but its light on practical impact and business perspective, which might put off some hiring managers.",30,1736594823.0
1hyte5x,m6lblg6,"Not that I think your resume is the main problem, there's definitely a shift in the industry to less jobs and less visa sponsoring for US jobs, but I really had to read between the lines of your resume to see that you're a very smart and accomplished developer. Personally I like to see more on what value your work created and if there's too many lines that don't have the impact attached to them it seems like much of your work wasn't worthwhile which I doubt is true. A lot of recruiters and hiring managers need to see that engineers know how to create value not just do a lot of cool coding and such. A lot of ds isn't even ML. It's all about cost and efficiency savings and improving customer experience. So maybe refocus on those.",4,1736611419.0
1hyte5x,m6likpb,"Eight years experience as a senior DS manager in the US here at a very large company. While I know nothing about the European market for DS, my first impression of your CV is that you’ve tailored it to DS professionals moreso than to recruiters, who are going to see it first and not know much about the technical chops you’ve documented here. You need entry to the interview process first and have to simplify some language for the right audience. Lack of a post-graduate degree might also be a factor. Feel free to send a DM if you want to chat.",5,1736613635.0
1hyte5x,m6k8gk5,"A way forward could be to perhaps find a job in Western Europe and see if you could get more freedom of movement from there. It would likely mean a pay cut for you, though, or at the very least not quickly get you to that 200k you're hoping for. Honestly, though, I wouldn't focus too much on that. If you earn enough to live comfortably and you feel challenged by and happy about your job and overall life trajectory, you're in a pretty good place, if you ask me at least. There are a lot of applied research institutes and some tech organisations/companies that would welcome your expertise, I think, or you could dive into academia.",3,1736594879.0
1hyte5x,m6kaj0m,Can feel you,2,1736596116.0
1hyte5x,m6l5dm4,"Out of context, but I'm really curious about your YouTube channel! Would you mind sharing it?

Also, been experiencing a lot of the same like you recently, the market is just really bad right now and even the amount of relevant job postings are pretty low right now. I'm personally trying to get a PhD right now.",2,1736609366.0
1hyte5x,m6n0scq,Listen I highly suggest you hire a resume writer or career consultant to help polish you up. You can find them on fiverr or google it. Just spend $100-$200 and ease your mind. I can suggest some I worked with and can recommend.,1,1736630727.0
1hyte5x,m6n8r3u,happy to look at your resume if that helps,1,1736633251.0
1hyte5x,m6pp6da,"You have impressive qualifications: most people on this sub don't have CS undergrads and/or experience with C++. You don't need a resume critique: a perfect resume, not that yours is perfect, is unfortunately meaningless if companies aren't willing to provide sponsorship. 

That is of course assuming that you are not a US citizen. A lot of PhD programs in the US sponsor foreigners. Given your salary requirements, you might not want to live off a miniscule PhD stipend (< $50k/year) for 4-6 years. 


Depending on your relationship, have you tried asking your manager(s) on internal opportunities that may have possibility for sponsorship?",1,1736667988.0
1hyte5x,m6pukdv,"How long have you worked after bachelors ? 

Since when did you start ML stuff ? ( in which semester )",1,1736671347.0
1hyte5x,m6tyce2,"I read you resume and i hope you to remember one thing.  
Be descriptive and be kind when you need to talk with people from other industry.  
resume is not just for the people in data science industry.  
For example, ""Neural Network Analyzer"": i am pretty sure recruiter will never understand why its important and what impacts come from this project.",1,1736724737.0
1hyte5x,m70osgw,"Try volunteering your time to work on problems you feel passionate about. Meaning, do them in addition to your current work scope. Network with people or stakeholders and see what pain points they’re facing, then translate them to projects where you can volunteer your time to solve. Make sure they’re really impactful problems to solve. I think the most viable transition remains with your current company. If you can build a reputation that you’re indispensable and can solve really consequential problems, transferring is likely not going to be an issue. I’ve worked in big tech/FAANG managing and building DS orgs for many years.",1,1736816039.0
1hyte5x,m72qb3r,Good luck,1,1736849078.0
1hyte5x,m6k8948,"I’ll try to be as direct as possible. You are too middle of the road. To move on you need to pick a side:
- Be very impactful and that means revenue, market share, cost reduction. Exposure and budget don’t count.
- Work on hotter tech. I am sure you are competent at what you wrote but there are dozens of expert topics like that in every ML conference and companies won’t pay $200k pa for that unless you luck out and find a niche role.",1,1736594752.0
1hyte5x,m6wkm06,"Yeah I absolutely agree with this 
Just go and have your own startup, be your own boss!

Btw are you in the field of ML or AI too?
Can we connect over chat though? I feel like I can get a lot of help from you, if you willing.",3,1736767457.0
1hyte5x,m77w7rr,"Yes I'd like to connect to you as well as I have a MSc DS background with Bachelor's in CS, Maths & Stats. I'm really looking for opportunities where I can work on challenging problems and I would try and learn seriously. 

I'm not getting good opportunities with my expectation of pay as I do not have enough experience. May we please connect if you can help and support?",1,1736913385.0
1hyte5x,m6kesl8,"Also, from an outside perspective you need keywords for filters... Then you need to actually say something... I need details on scale and impact.

Exposure should have been from its impact, I could rewrite almost the whole thing to be more specific to what you actually did, not the fact that you can do the basics of your job.

I need victories, grow, and networking. It might be there but it's hidden.",2,1736598503.0
1hyte5x,m6wkx1d,"So it's not just about my region but is a common situation everywhere! Even in UK
I was planning to shift to Netherlands and study there alongside, find a job!
Can we connect over chat though? I feel like I can get a lot of help from you, if you willing.",1,1736767634.0
1hyte5x,m6knds6,"I understand where you are coming from, but I am doing the exact same work that my colleagues are doing, and they make 300k+

I do not feel respected, challenged or satisfied with my current work... as I'm not given projects based on skill but based on class and politics, and the life trajectory within this place is not nice... I've been proposed to be promoted to team leader, but that would mean just 10% extra money and 2x more work.

I kept asking them to get a publication out, because that would help me a lot in my career, and I do have projects I could publish, but they're completely against it because publications don't come from east europe, but only from US and I'm not part of their club.

They also see math and research as some status thing and not something that anyone can do, regardless of background, if they put in the effort and have some talent.

The only things that are good are the salary for my region, the workload which is not too difficult to handle, and the nice colleagues I have, although they are very much title and status oriented rather than skill oriented people (and such look down on me), but are very nice and helpful when it comes to doing the work they want me to do.",6,1736602568.0
1hyte5x,m6kq12k,"That's an interesting perspective, as the way I see it is showcasing the technical skills, and the fact that I do understand the base mechanisms behind concepts. You call it ""basics of your job"", but a lot of people just call libraries and never wrote a model from scratch, trained models, or came with any novel ideas. 

I read a lot of other CVs too, and in a lot of them it's practically impossible to understand what exactly the person did in terms of coding or problem solving, talking just abstract things about the generalities of the business or vague terms that sound good but don't say anything.

Something extremely hard for me to understand is ""business value"", as most things people do have zero impact on the real world and would be just abstract territorial expansion for the political games of the managers.

I'm not saying you are wrong, because I'm not getting callbacks, but I just don't understand how to modify it... I added the impact with things like, saved 75% compute power, saved thousands of $ in cloud expenses, secured investment of 100k$, brought exposure to the team through internal conference presentation... but I guess I need to add a lot of business buzzwords and make some fancy word salads that don't say anything, right?",5,1736603666.0
1hyte5x,m6wlu8w,"sure thing, happy to help.",1,1736768163.0
1hyte5x,m6kvv87,"yes, metrics the impact is hard. You can work in a big company and work remotely and turn off the light, saving thousand $ weekly for electricity.....

Saying that, you still need to set success metric for any of your delivery (how much the cost of saving as a result of speeding up neural net from C rather than using libraries....). Those success metrics must be discussed with teams at the beginning of project, not when you completed. 

Else, hiring managers look at it and may not fully understand all of your description. They might think you reinvent the wheel without added value to business.",2,1736605972.0
1hyte5x,m6kw5p5,"Yeah I'm trying to help from a manager perspective. Those impacts should be part of the sentences above. It's not word salad per se but saying what makes you better. 

I'm down to help if you show me a post, you really need to tailor to each job. Looks like you can do shit but is it good shit is the question.",2,1736606080.0
1hyte5x,m6ky49a,"I had to read it 4 times to figure out what you've done, let me know about back pain, I'm a good candidate lol.

You need to show it from a higher level, then pepper in the key words with less other specifics.",2,1736606813.0
1hyte5x,m6wmy98,"Thanks 
I have sent you an invite",1,1736768773.0
1hyte5x,m6l14m4,"Thanks a lot for the effort and the help. I'm not trying to be stubborn or insulting, it's just that all this business terminology does not make sense for me personally.

So, I should make things sound more understandable from a higher level, and less technical, even if it does not explain exactly what methods I used, but have some keywords which would point to technologies I know. Something like giving a general fuzzy view of the problem solved or the mathematics, and more accent on business terms and real world intuitions.",1,1736607902.0
1hyte5x,m6lh6nx,"I'm just trying to help. Your shit is not organized, if you can't easily explain what you actually did to make a difference it's hard.

I'd remove personal projects and put like the presenting at summits there. Then have a straight technical section listing what you have used/can use and certs.

The stuff under the company should always try to start with results and then your specific actions.

Reduced company CPU usage by 75% using my skills to figure out where we did something stupid and fix it. Saved us $100k and paidy salary for the year...

Tested, discovered, and presented AI/ML solution that was implemented company wide.

Sorry I'm on mobile and it's Saturday beer O'clock but that's my 2 cents.",4,1736613202.0
1hyte5x,m6p1tcp,"European here, so really not an expert on the American resumes. What I can try to talk about, though, is my understanding of the business side - and mostly it's the attempt to try and convey different viewpoints you might consider your resume from. Please note, that this is entirely subjective, so take it with a giant grain of salt.

One thing that I noted while reading your resume that - from a layman's perspective - I can't always tell at a first glance if you're:

a) a productive data scientist/engineer with in-depth skills who generates the kind of business impact that would tell me it's worth to take 300k a year and invest it into you.

b) a newby using the slang to look bigger than they are.

c) a researcher-type person who's really brilliant and capable but doesn't understand business at all and is mostly interested in the technology.


For any open position there will be hundreds or even thousands of people of category b).

When you apply for a job - and let's assume a person looks at your resume - then you have anywhere between 10 seconds to 2 minutes to grab their attention and let them know that you are indeed the person they're looking for.

-----

To pick one example that caught my eye:
""Designed and implemented the entire data analysis, modelling, visualisation process"" at a startup.

This might mean you developed a fully engineered data process with state of the art, automated backend technology that is still running  today, and the company relies heavily on it to generate a significant chunk of their money from it.

It could also be read as: I wrote three badly documented Jupyter notebooks that need to be executed manually on a CSV file that Data Scientist B curates by hand and sends by email. The notebooks need to be run in sequence but will probably break when Mars meets Saturn - and no one has figured out why. Also, it is a very nice insight but if it didn't exist, then the company wouldn't really notice.

I'm assuming you mean the first version. But do take a moment and consider that I - a business person - just read, let's say: 50 resumes from ""newbie"" Data Scientists who all promote their Coursera skills like they're some kind of Data God. I have another 100 that I need to read and I'm stressed because I have my regular work to do and timelines to meet. So, even if I know that I should read your resume in full, it's probably not going to happen.

Also, while I'm technically minded and smart - I don't really understand what half your technology is about. It's not necessarily that I don't care, but to me most of it is fluff that I need to make sense of. I'll probably ask my more technical colleagues to judge that technical part. So, I'll judge you on the part that I do understand and ignore the rest.


Once I reached the end of your resume, it's relatively clear to me that you probably are quite a smart programmer and data engineer who can probably solve math-heavy problems confidently. ""Probably"" - I'm still assuming and interpreting a lot. If I made it this far, and I'm still assuming, that is not a good sign


A quick summary here, it is not immediately clear to me what type of applicant you are - and it is your job to convince me, taking into account that less competent people might look the same to me on paper, skill-wise.

-----

A point on uncertainties: Taking your startup experience, it is preceded and followed by FAANG experiences, so _I assume_ you are probably not bad at what you do otherwise they wouldn't have (re-)hired you. But I shouldn't have to assume. Assumptions mean that there's uncertainty left - and uncertainty means that I'm not clear on what's going on. From a business perspective, I have to minimise uncertainty and - as a candidate - I need you to help me with that.

I'll probably not go to my boss and tell them that I want to spend 30 hours of company time each for 8 candidates who I _assume_ might be good. I'll probably also not confidently tell my boss, hey this is the person I consider a solid 300k a year investment for our department.

It's your job - more generally with any business partner, really - to remove as much uncertainty and complexity as you can for them. It's also - more specifically - your job as a candidate to write a clear and easy to understand text for them to be able to judge you as a candidate. Make it easy for me to advertise you to my boss. 😉

Now, the tricky part is that everyone has a different viewpoint. So, if you know your resume will be read by a senior data engineer and ""fellow geek"", then yes, highlighting the technical skills will be the focus. The technical person will be able to map your skills onto the technical processes that they have.


If your audience is a person that is less technical (business-focus) they have entirely different processes to consider. What it usually boils down to is business metrics - because everybody can understand and translate metrics (if they're clear). In every company I've been to you have a mix of people who have different experience - technical and business-focussed.

What I personally would try to figure out when reading your resume is:

- What measurable thing did you achieve (money saved, efficiency gained...)?

- How did you achieve that (technical, organisational, management/communication work, ...)?

- how did you interact with others (worked in a team and enabled them through your expertise and communication skills, or provided an insular technical solution without too much business engagement)? Both are valid but might qualify you differently in my mind.

I'd also accept ""softer"", non-quantifiable outcomes, of course, because I know that good metrics are really hard to design. But these are even more difficult to put in words. So, designing the data analytics process is something that I know is valuable even if there's no number attached to it - but I'm still missing crucial information. (I'm not saying, write so that _I_ understand. More like: consider how your resume might be read from different viewpoints).



In another comment you mentioned political grand standing making it difficult for you to judge the value of some of the work. For 300k, I'd expect you be someone who at least tries and does their best to look beyond that political stuff, and still be able to tell me what the value for the department/company was. It's easier said than done, of course. But if you're the kind of person who can do that, you're more likely to be the person who can do that kind of job.



To wrap it up, I'd need you to prove to me from a glance at your resume that you're a person who has the technical skills and can translate that into tangible value for the company. I'd also need you prove to me that this major investment of 300k means you can navigate the complex business landscape of ""my""company - a company that is complex enough to be able to afford 300k, in the first place.


And for that, you also need the right ""word salad."" 😄",3,1736655851.0
1hy7g0m,m6f38h2,"Imagine the Front Man promised you a GenerativeAI job, but tricked you into Product Data Science work with SQL. It's too late to back out – solve the 9 SQL challenges... or else:

[https://datalemur.com/sql-game](https://datalemur.com/sql-game)

r/DataScience, I want to make the levels more Data Science-y with SQL rather than simple Data Analytics stuff, especially for later, harder levels I'll be adding. Any good ideas?",117,1736524430.0
1hy7g0m,m6fhed1,"What am I missing for Q1? I also tried limiting the output columns to just ID or first/last name:

    select * from player  
    where status = 'alive'
    and debt > 400000000
    and (age > 65 or (vice = 'Gambling' and has_close_family = false))",25,1736528557.0
1hy7g0m,m6fiw5s,Making a study session into a game works very well for me. I’ll check this out.,17,1736528994.0
1hy7g0m,m6hauet,"> But in typical data industry fashion, you've been bait-and-switched. Turns out that the role is more about Product Analytics in SQL, and the job's not fully remote, it's hybrid: 5 days in office required, with 2 days optionally remote. 

Ouch... a touch too realistic.",10,1736547778.0
1hy7g0m,m6f6irc,Noice,7,1736525407.0
1hy7g0m,m6fclir,"Just started playing, it looks great! Really good for practice and the music was a nice touch lol",7,1736527175.0
1hy7g0m,m6fdd2f,"This is great! Not sure if I'll have the time to complete, but I'll definitely start!",4,1736527394.0
1hy7g0m,m6gditk,"I haven’t learned SQL yet, but I will have to at some point. I’ll take this as a fun challenge to accompany my learning",5,1736537822.0
1hy7g0m,m6fcfcq,Interesting,4,1736527126.0
1hy7g0m,m6kzl5j,This is awesome!!! Kudos to you my friend ✨,2,1736607350.0
1hy7g0m,m6mpakj,Got killed at level 5. Good challenge,2,1736627014.0
1hy7g0m,m6g3vmm,This is really cool! Nice going.,1,1736535021.0
1hy7g0m,m6ggqn8,"Am I missing something for Q4?

    select 
      team_id, 
      avg(age) as avg_age, 
      (
        case 
    	when avg(age) < 40 then 'Fit'
    	when avg(age) >= 40 and avg(age) <= 50 then 'Grizzled' 
    	else 'Elderly' 
    	end
      ) as age_group, 
      RANK() OVER(
        ORDER BY 
          avg(age)
      ) as rank 
    from 
      player 
    group by 
      team_id 
    having 
      count(*) = 10 
    order by 
      avg_age",1,1736538767.0
1hy7g0m,m6gth63,Wow! This is so good!,1,1736542497.0
1hy7g0m,m6iyxwr,This is smart and fun. Keep up the good work,1,1736568654.0
1hy7g0m,m6tmr66,"Fun challenge! Questions are analogous to common everyday tasks, which is quite useful.",1,1736721094.0
1hy7g0m,m6gcqxx,"How does this verify answers by output or by looking at the SQL?

For Question 3

>  
**Analyze the average completion times for each shape in the honeycomb game during the hottest and coldest months, using data from the past 20 years only. Order the results by average completion time.**

  
Because I believe this achieves the output that the question is asking for but I do not do it by the min/max method in the hint:

    with table_a as (
      
      select *
    , row_number() over (order by avg_temperature) as temp_rn
    
      from monthly_temperatures
      
    )
    
    select b.month
    , b.avg_temperature
    , a.shape
    , avg(a.average_completion_time) as avg_completion_time
    
    from honeycomb_game a
    
    left join table_a b 
    on extract(month from a.date) = b.month
    
    where a.date > current_date - interval '20 years'
    and temp_rn in (1,12)
              
    group by 1,2,3
    
    order by avg_completion_time",0,1736537595.0
1hy7g0m,m6gjazq,"Looks like there are some errors level 3 - ""monthly-temperatures"" isn't the table, looks like it is monthly\_temperatures and instead of ""average-temperature"" it is avg\_temperature",0,1736539515.0
1hy7g0m,m6h3w6y,"For question 9, the requirements feel like they need more explanation?

* What does ""deviated from their assigned position"" mean? Does it mean they accessed some door other than their `assigned_post` between `shift_start` and `shift_end`? What if they accessed the correct door but were late to their shift?
* What does during ""Squid Game"" mean? Is it only the most recent date or is it all dates?

The following naive query to simply find guards who accessed an incorrect door during a game returns zero rows. And this is not even filtering based on `type = 'Squid Game'`. That leads me to believe I'm not picking up enough guards in the join, likely requiring a more lenient WHERE clause. Unless I'm missing something on the page, there seems to be a lot of guessing for what the requirements are.


    select
      g.id,
      g.assigned_post,
      g.shift_start,
      g.shift_end,
      d.access_time,
      d.door_location
    from guard as g join daily_door_access_logs as d
      on g.id = d.guard_id
    where access_time between shift_start and shift_end
      and door_location != assigned_post
      and exists(
        select 1 from game_schedule
        where access_time between start_time and end_time
      )",0,1736545617.0
1hy7g0m,m6ku1pq,I'm already interviewing no thanks😅,-1,1736605263.0
1hy7g0m,m6g3fec,"Philanthropic giving entails shared credit. 

If you look at the classic grocery store example, you can easily call up customer A on a date and see 2 transactions, one of which was 2 apples, a banana, and 5 oranges. Transactions like this are pretty simple. 

Now let's look at non-profits. Steve and Sandy Giverton made a decision for a gift of $500,000 to be given over the course of 5 years. 

Year 1 is a stock exchange which increases in value by the time the funds clear. 

Year 2 is a stock exchange which decreases by the time the funds clear. 

Year 3 is a donor-advised fund, which is legally a separate entity and cannot actually be applied to the original donor. 

Year 4 includes a matching gift from their employer, but no transaction number is given to show who initiated the gift. 

Year 5 is not yet due, but it's a future gift expectancy. 

Let's assume Sandy is the primary donor (hard credit) and Steve receives recognition credit (or soft credit, same thing). Here, you have to model the difference between revenue (actual dollars) and pledges (future dollars). A pledge payment is revenue, but not a pledge itself. 

The stock exchange is actually a transfer that comes from something like Schwab Charitable. The DAF may include credit to a large number of other people on the same transaction. The matching gift comes from yet another entity which does not share the same name as Sandy Giverton's employer.

With this information, the goal would be to do things like count hard credit donors, soft credit donors (while making sure not to count someone who already has hard credit), dollars (hard credit only) and future expectancies. 

While none of this entails machine learning or statistics, it's a really messy situation to model. I've seen DAF gifts that list credit for over 80 people.",7,1736534892.0
1hy7g0m,m6fjmzp,"Your code should work now – I had made a slight mistake!



    SELECT * 
    FROM player 
    WHERE status = 'alive' 
      AND debt > 400000000 
      AND (age > 65 OR (vice = 'Gambling' AND has_close_family IS FALSE));",20,1736529211.0
1hy7g0m,m6fjju9,"I’m having the same problem. My code is also exact to yours , I’m not sure what’s going on.",5,1736529186.0
1hy7g0m,m6fj7vj,Semicolon (;) at the end?,5,1736529089.0
1hy7g0m,m6fjfe4,awesome!,7,1736529150.0
1hy7g0m,m6kzelc,I laughed out loud when I read that part of the game!,2,1736607285.0
1hy7g0m,m6fffze,Yeah try your best!,2,1736527995.0
1hy7g0m,m6geju6,absolutely! also if looking for a free SQL tutorial see this: [https://datalemur.com/sql-tutorial](https://datalemur.com/sql-tutorial),4,1736538124.0
1hy7g0m,m6l650q,thank you!,1,1736609622.0
1hy7g0m,m6kmfb9,yeah you gotta rank desc (where 1 is first),1,1736602156.0
1hy7g0m,m6klkhy,"just remove returning average temperature and your solution is correct, it doesn't ask for it in the problem",1,1736601782.0
1hy7g0m,m6kl8co,"there's hints and a solution, but:

  
squid game is a game type. the question says smth like: the most recent squid game, so you gotta look for the most recent game with type ""squid game"". 

And yeah, deviated means accessed a door other than their assigned\_post between shift\_start and shift\_end. 

And I don't think there's any case of being ""late to a shift"". correct me if I'm wrong but I just dont think that's part of the problem.

  
As for my solution to filtering guards, after finding the dissapearance window (which I'm not going to spoil), i ran this query (where XXXX are dissapearance window times)

    WITH disappearance_window AS (
        SELECT 'XXXX'::time AS start_time, 'XXXX'::time AS end_time
    )
    SELECT g.id AS guard_id, g.assigned_post, g.shift_start, g.shift_end, dal.door_location, dal.access_time
    FROM guard g
    JOIN disappearance_window dw
        ON g.shift_start < dw.end_time AND g.shift_end > dw.start_time
    LEFT JOIN daily_door_access_logs dal
        ON dal.guard_id = g.id
        AND dal.access_time BETWEEN g.shift_start AND g.shift_end
    WHERE g.assigned_post != dal.door_location 
    ORDER BY dal.access_time;",1,1736601632.0
1hy7g0m,m6fobg5,"Thanks!

I'd recommend clarifying in the output section what columns you're expecting (eg include all columns from `player`, or include `id, first_name, last_name`)",12,1736530558.0
1hy7g0m,m6gf69y,Thanks a bunch! The website looks great,1,1736538308.0
1hy7g0m,m6mwbtl,"I see. The part about ""most recent"" is hidden in the flavor text above the actual instructions, which is easy to miss. I did open the hints, but would have been nice to be able to have a better explanation of ""deviation"" nonetheless.",1,1736629288.0
1hyaw2t,m6gwwuv,Show them the money,7,1736543525.0
1hyaw2t,m6h6nff,"I think your approach is good, I just don’t think an investor would want to ask to know more about F1 scores.

If I were you I’d just serve it to them and give a light introduction to it and it’s wide use while not making it feel “elementary”. Then go in to showing your results.",5,1736546462.0
1hyaw2t,m6fy98u,"Ideally, you should come up with cost-profit from precision-recall. However, again no clue in your situation how to get the $ of false/true positive/negative",4,1736533403.0
1hyaw2t,m6i26su,"If you know the dataset size and #labels per class you can do some algebra to figure out TP, FP, FN, and TN. Then calculate accuracy using those numbers. Just verified this works on paper for binary classification but it could be a lot trickier for multi class (assuming there isn't additional info required). If you don't know the size and labels or class, I think you miss critical info to determine accuracy. 

Either way, accuracy doesn't make sense to use as a metric here. Per class precision and recall gives the most info. Summarizing that with harmonic mean gives F1. Then if you want the fairest metric to summarize overall performance, micro-f1 should be used here.

Edit: just realized for multi-class you can just sum per class recall*#labels which gives number of TP per class. Summing that gives you #correct which you would divide by the total to get overall acc as a single number. The binary case was trickier because I assumed you only know prec/recall for label 1. Still, best not use accuracy here.",2,1736556924.0
1hyaw2t,m6hatpz,"Then explain to them what the hell F1 score is, and why it is the metric you chose in the document.",2,1736547772.0
1hyaw2t,m6mhxaq,"You have to let them yap and then find out what is their central worry/fear/desire. 

It sounds like here their main worry is whether the technology they invested in is better than all the other models. They want reassurance to know that they aren't wasting their money. 

If you can tell them, we can't do this because X,Y,Z, but we can do this instead to show you the difference then they would probably be fine.",1,1736624638.0
1hyaw2t,m6sqwxl,"Is it actually the best way to communicate with investors? i.e., to show f1 scores or precision-recall. Do they care about those numbers? I don't have experience in talking to any investor but I always thought it would be great to present live examples where your model beats others.

Secondly, data is equally crucial as the model. So, even if it's a simple enough model it's trained on private data. So, I don't know why you would call it faking results.",1,1736711847.0
1hyaw2t,m6u0p3o,If you have access to numer of observations in each class then you can recreate a confusion matrix out of precision and recall and then compute per class accuracy.,1,1736725499.0
1hyaw2t,m6um346,….,1,1736732476.0
1hyaw2t,m6v745z,"Show them your economic moat including your company's competitive edge, future prospects, revenue generation and profitability.",1,1736739998.0
1hyaw2t,m6vtmie,"My advice is to ""dumb it down"". Highlight the pros of your classification and compare with other software solutions. I don't think the investors are seeking for technical document.",1,1736750428.0
1hyaw2t,m71flx0,">""This is the F1 score for our most important classes, and as you can see, none of the other models or architectures we've tried are as good as our best model... By the way, if you don't know what F1 means, just know that higher scores are better. If you want, I can explain it in more detail...""

That sounds totally fine. If all you're doing is inventing a parameter which is a proxy for the formally-defined variables you actually care about, then as long as F1 tracks those variables and you can defend it to internal technical people if necessary, then I think you're good.  One of the worst things you can do to investors is geek out and muddy the waters for them.",1,1736824767.0
1hyxec6,m6l7xt6,"> Since you all refused to share how you are applying gen ai in the real world

Solid passive aggressive start.

> how AI agents can transform business data analysis

Maybe I’m just dumb, but how is this any more than a marginal UI improvement over existing BI tools without any of the data governance?  It already only takes stakeholders maybe 5 clicks to generate identical graphs in Looker, Tableau, and their ilk. At least with these tools we can have some semblance of feature stores and standardized metrics, I’ve still yet to see how this can be reliably implemented in a gen ai framework. And then there’s that whole pesky hallucination issue. 

> I am still unsure if l should sell it

Good luck, but I wouldn’t get your hopes up. How does your tool differ from the 1000000 other AI powered insights tools on the market? You need a better defined target market beyond all DAs and all business stakeholders.",12,1736610224.0
1hyxec6,m6lfqa5,"Start with low level metrics for business stakeholders.   Easier to develop and validate.  Need to get buy-in from them anyways to justify the use of resources.  Business stakeholders might not know the right questions to ask, which is why you use an LLM to interpret their shitty questions.  Analytics chatbots provide better utility to business stakeholders for this very reason. Analysts can just write the code themselves.  Analysts should still get access because you need to validate the outputs.",4,1736612745.0
1hyxec6,m6l9h5f,"Sorry, l meant sell it to business inside the company, not as an AI tool.

Here is my thinking process, and you are free to correct me. Currently, we only have tools that are great for static metrics(ie, metrics you want to consistently measure over a period of time) eg profit %, revenue etc. But what if you want to ask a once-off ad-hoc request like the one shown in the example prompts? ""Is there a relationship between recipe complexity and user satisfaction?.""  
This requires an analyst to go investigate for a couple of days(factoring in typical cooperate red tape where meets need to be setup, powerpoint presentations to present the results etc etc) and come back with a solution at the very least, but with this app you can just ask and get a reply immediately.",-4,1736610731.0
1hyxec6,m6lei75,You mean to connect company database to this external app?,3,1736612353.0
1hyxec6,m6lfgob,Or just build their own app as a B2B solution,-7,1736612660.0
1hyxec6,m6ll1qf,"Would you want to grant the tool the ability to generate and execute arbitrary code against a company database? Many companies will have rules against this for security reasons, and there’s a high risk of invisible failures/hallucinations as things simply not working as hoped for. Meaning any business user will be contacting you every few seconds. 

So then you’re left with coding up a bunch of tools to cover expected/acceptable use cases and then use langgraph to orchestrate. If you only have ‘one’ user then this may be a feasible task, but if you serve multiple business units with varying needs and databases it might be very time consuming to produce reliable for all of them.

Note that my company has been trying things along these lines and the other problem is that business users actually didn’t necessarily want it. Of course this last point might be specific to my company, but I suspect the first two points are common issues.",2,1736614405.0
1hyxec6,m6lmkjk,"It's very hard to put constraints on code, that why l just wanted to use a query language. It's a very simple setup, but quite powerful in my opinion.",1,1736614877.0
1hxalxo,m67qjvp,"For anyone looking to brush up on their SQL, I found that leetcode SQL50 and DataLemur and superior to any other sites out there. Both are free and took me about a month to get through them both. Practiced about 2 hours a day",648,1736425832.0
1hxalxo,m67nvex,"Yes budgets are usually finalized in November and December. 

The best time to look for work is Q1 of any year.",241,1736424542.0
1hxalxo,m67lzcb,Congrats!! Can I ask what is your experience level?,48,1736423587.0
1hxalxo,m67ndki,let's goooo 2025 is our year,63,1736424294.0
1hxalxo,m69geka,"Things a data scientist should know about job searching:

1. Hiring is cyclical. Usually headcount allocations are made once, at the beginning of the fiscal year, at which point the race is on from the hiring managers perspective to get that role filled because many work places have a “use it or lose it” approach to headcount. These cycles usually follow company fiscal years with quarterly reviews on reallocations and clawbacks. 

2. There’s a second set of cyclic behaviors which are the major holiday periods. My experience has been that i  the US this means nothing big happens from mid November thru early January. Smaller companies will typically have an easier time flexing around this than big companies. Most companies treat these kinds of hiring decisions as being important enough to defer until all the relevant stakeholders are able to meet. This gets even worse when hiring committees get involved, because there’s another layer between interviewers and the final approval that matters. 

3. Track HR and management news sources and stay informed. There are a lot of shitty behaviors that companies are currently engaged in which make any job seekers experience unnecessarily worse. Case in point: advertising openings without having a corresponding requisition — these are just fishing trips to see if by chance a “rockstar” or “10-x-er” or otherwise superhuman candidate applies. Remember: companies rarely change how they choose to treat people unless it’s to go from bad to worse, so if you’re unhappy about the recruiting experience imagine how much worse it can get when folks aren’t trying to sell you.",21,1736446135.0
1hxalxo,m67ptkj,"It felt like this week surpassed all of 2023 for me.

Prior to ""2020"" I don't recall such hiring floods in January.  Seems maybe people adjusted to a new normal? But also, hiring froze last year in March/April and then June, and the bottom fell out in August until December.  So, we'll see how this year progresses.

Companies usually hire in June so they can launch in fall, and they'll hire in March/April so they can launch in summer.  So there's another month and a half of opportunities after February until the summer lull.  But then after September, it's a downhill slip during the last quarter.  By October budgets are frozen solid for the next 6 months unless urgent.

How did people job hunt prior to July 2008?  I don't know of any January flood hiring prior to that time.  It's both a new and old hiring strategy.

What I would tell younger people is that there used to be Dec-17 to Feb-1 shut downs for wage work.  Companies usually started recruiting a month and a half ""after"" the holidays, and sometimes posting ads would pick up dramatically in March/April.  You also never knew how many people left jobs in December or got promoted in January, which opened up opportunities by March/April. But the ""official"" once a year hiring was definitely in the summer. Sometimes companies would hire in the fall for a ""holiday"" campaign for retail customers but that's not like January hiring now, which is a very recent thing.

Basically job agencies adjusted to the behavior of unemployment lines stretching around the corner in January or something, but nowhere did such a large amount of people search for jobs as in the past 6 years, or take time off to search for jobs as in the last 20 years.  So in some way things have changed profoundly. Not sure what.",30,1736425489.0
1hxalxo,m67pl0y,can you be a bit more specific where you are looking for jobs ? and seniority level  ?,11,1736425376.0
1hxalxo,m696s4z,My company is looking for 2 seasoned Data Scientist. PM me for more info.,10,1736443364.0
1hxalxo,m67rn2e,Even for entry level positions?,9,1736426336.0
1hxalxo,m68csu1,Don’t give me hope 🥺,8,1736434335.0
1hxalxo,m67sb4y,I'm junior level and have three interviews in this week and 1 next week. That's more than 7 months of 2024,10,1736426640.0
1hxalxo,m68azi5,"If you were applying before the new year, it could have been that people were on vacation or focused on wrapping things up before the end of the year. It’s normal for hiring to pick up starting mid-January. New budgets, new project cycle, people are back from vacation, etc.",4,1736433732.0
1hxalxo,m680krq,Congrats! A FAANG offer is no easy feat and definitely speaks to your level of experience. I’m honestly just surprised that even people with deep & specialized expertise are struggling to get their resume seen in this market. Cheers to 2025 being better !,8,1736430005.0
1hxalxo,m6avw57,It is kind of funny that you reach the conclusion that companies are finally hiring from your personal anecdote given that this is a data science sub.,6,1736461184.0
1hxalxo,m67ol6r,"I was actively applying between August - December of 2023 and my response rate was only 2% :(. I'm currently not applying for personal reasons, but I will need to start soon. Hopefully the response rate will be better...",3,1736424894.0
1hxalxo,m68r86g,I am thinking of switching my career from mechanical engineering to data science. But I aint that sure whether its a good decision. It seems like that there are a lot of job opportunities in this field in Germany. Do I have a chance of  starting this career path as a fresh starter?,2,1736438809.0
1hxalxo,m690p7x,Does anyone know how the market seems for people with 2 YOE?,2,1736441589.0
1hxalxo,m685vnb,I don’t have much to say other than congrats on the offer! Can you share some more details on what the process was like and your experience?,2,1736431953.0
1hxalxo,m694p09,"We're hiring Data Scientists across all of our sports 

[https://www.reddit.com/user/SwishAnalytics\_Jobs/comments/1hxdlpb/hiring\_data\_scientists\_swish\_analytics\_is\_a/?utm\_source=share&utm\_medium=web3x&utm\_name=web3xcss&utm\_term=1&utm\_content=share\_button](https://www.reddit.com/user/SwishAnalytics_Jobs/comments/1hxdlpb/hiring_data_scientists_swish_analytics_is_a/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",2,1736442754.0
1hxalxo,m690udv,"Yeah, I'm landing all these opportunities like crazy. Strike now while the market is hot!",1,1736441630.0
1hxalxo,m69fyej,"they’ve been, honestly. i get 10+ recruiters a day hitting me up for jobs. i am a MLE tho so could be different.",1,1736446004.0
1hxalxo,m69gfb8,What was the interview process like? Is there still a lot of technical questions for more senior / leadership roles?,1,1736446141.0
1hxalxo,m69ha9j,Weird...Data Science is in absurd demand in my counntry and many others...I struggle to find DS and SDS!,1,1736446390.0
1hxalxo,m69q101,Nice!,1,1736448903.0
1hxalxo,m69wdmm,"New year, new resolution for companies.",1,1736450736.0
1hxalxo,m6a6ab5,Would you mind sharing companies which reached out to you and/or you got interview from?,1,1736453626.0
1hxalxo,m6a749v,What role is going to be in your new company? Are you going to managerial or IC?,1,1736453868.0
1hxalxo,m6ad5z7,Good luck!!,1,1736455639.0
1hxalxo,m6aen0j,I had forgotten what hope looked like... thank you,1,1736456067.0
1hxalxo,m6bnzkk,"Good to hear, not all doom and gloom",1,1736470400.0
1hxalxo,m6c17ko,That’s great news!,1,1736474836.0
1hxalxo,m6coww8,Where are you from?,1,1736483400.0
1hxalxo,m6cubu0,What companies reached out ?,1,1736485732.0
1hxalxo,m6cwowx,"Bois, good days ahead!!",1,1736486828.0
1hxalxo,m6d09pa,What’s your background bro?,1,1736488574.0
1hxalxo,m6d8xj8,RemindMe! 2 days,1,1736493286.0
1hxalxo,m6dyxgn,Thank you for what you put out there for everyone to use,1,1736509267.0
1hxalxo,m6e9jwm,I just got hired here in the Netherlands. I am a US citizen that came to school here because my wife is from here. I start in February and am excited for starting my career.,1,1736514266.0
1hxalxo,m6e9s2b,"Yeah, I've seen this as well. My current company just announced that they're increasing headcount in 2025 and I've had multiple reach outs from recruiters about positions over the Christmas / new year break myself. Definitely feels like I'm things are picking up compared to 23/24.

Happy hunting out there everyone!",1,1736514360.0
1hxalxo,m6emvtq,Thanks for the cheer up and congrats for your new adventure !,1,1736519240.0
1hxalxo,m6ex34m,"Hello, I just finished BS in CS and am looking for advice on how to get a job. I'm very good in Python, did a lot of machine learning and data analysis projects at school. I have solid math, algorithms, statistics, and numerical analysis knowledge. I finished in the University of Victoria in Canada and the curriculum was strong on math and data, I think and that's why I think that my strength would be data. Any advice on what to do next to get  into the field and get a job?",1,1736522563.0
1hxalxo,m6ezncc,some good news finally,1,1736523350.0
1hxalxo,m6f14rd,Great to hear😌,1,1736523800.0
1hxalxo,m6f3qa6,Thank you so much for posting this. It's been hard to hold onto hope in this job market. Best of luck to you in your new role.,1,1736524576.0
1hxalxo,m6hd29i,"Been applying everywhere since October and currently have my final interview at a company on Monday, but this is reassuring to hear. I've barely even been getting any rejection letters.. it's such a drag. Congrats on the faang!",1,1736548482.0
1hxalxo,m6pryii,Wow! Please dm. Can we dicuss?,1,1736669696.0
1hxalxo,m6reebo,"Hey, what cities are you applying in?",1,1736697867.0
1hxalxo,m6ugsc5,"But can I ask what about questions related to projects ? What questions did they ask? Nothing related to data analysis, production ?",1,1736730678.0
1hxalxo,m6vfpkb,feeling some hope again,1,1736743434.0
1hxalxo,m6vg9m5,.,1,1736743678.0
1hxalxo,m67pjs3,Have you done Masters???,1,1736425360.0
1hxalxo,m67v9mz,"Sorry, Im gonna ask a few questions - 
 - how many years of experience do you have?
- are you based in Europe?
- how is the salary?
- can a 2 years experience one apply for FAAANG? How is the probability of getting hired?",1,1736427909.0
1hxalxo,m6d0n04,Likely because the political landscape is changing.  ,0,1736488763.0
1hxalxo,m6qkizc,Interviewing != hiring,0,1736686826.0
1hxalxo,m67sdr5,"[DataLemur](https://datalemur.com/questions) founder here – appreciate the shoutout <3

Edit: woow, lotta love below this – thank you to ~~my alt accounts~~ everyone, glad to know the site/book made a positive impact!",498,1736426673.0
1hxalxo,m67rzwk,Did you apply to a product sense data scientist role?,4,1736426497.0
1hxalxo,m6hji94,Using a bit of sql at work but need to really get good at it. I’ll look into this,2,1736550575.0
1hxalxo,m69xteh,"Hi op, Did you have to do Python Algo questions in your interview?",1,1736451149.0
1hxalxo,m6e9t19,"Do coursera certificates help? not for the certificate but just to learn other topics, refresh, or stay up to date?",1,1736514371.0
1hxalxo,m6jmmnq,Which is the best platform for practicing this?,1,1736580811.0
1hxalxo,m68y7bi,SQL is king baby 😝,1,1736440869.0
1hxalxo,m68ymxc,"Dude thank you, I did a double take here just to make sure it wasn’t getmotivated. Congrats!",1,1736440995.0
1hxalxo,m67wqmz,Exactly. We’ve known for a couple months that as soon as 2025 hit we were going to have the budget to hire a couple more people.,49,1736428508.0
1hxalxo,m6f883y,"this actually makes sense, thank you for this",1,1736525908.0
1hxalxo,m6hds1c,"Most companies have financial year start and end the same as a calendar year. Occasionally there are companies that do not, so their head count budgeting might look different than most.",1,1736548708.0
1hxalxo,m67pz77,"I’m a director at one of the largest financial companies. Not a people leader, it’s just a job grade. I do have two masters and a few certs including AWS. I’ll admit that my resume looks good on paper but the biggest challenge was getting someone to look at it.",80,1736425565.0
1hxalxo,m68bw0q,"Yeah, feb-april is best time for job hopping generally in a technical field. Annual budgets and headcount get approved and managers can finally open the role they've needed for the past 9 months.",17,1736434035.0
1hxalxo,m67q8we,I used LinkedIn to find the jobs which directed me to the companies career pages. I then look at the career pages for any roles that matched my experience. I was looking for more senior level roles. I ended up getting a FAANG offer,34,1736425691.0
1hxalxo,m69cfz4,Appreciate it,1,1736444993.0
1hxalxo,m67xbpe,Sorry I don’t know about entry positions. But my recommendation for anyone having a hard time breaking into data is to take on an entry level position like a call center in a large company. Even better if they will pay you to get licensed (ie FINRA or insurance licenses). There’s usually mobility after a few years and you can pivot internally. Professional maturity is something most recent grads lack plus industry domain knowledge are important for analytics. I worked 8 years as a phone rep and did cold calling sales before I pivoted to analytics. This new career path has done extremely well for me and I really credit my sales experience for that,14,1736428743.0
1hxalxo,m6zqk2x,"Hey 
I am starting out in DS now. Any tips/guidance that you can provide?",1,1736804985.0
1hxalxo,m68wf4q,"2023 summer was VERY rough – someone close to me, whose an absolute killer, took \~6 months to find a tech job even though in 2022 they got 3 offers within 1 month (all for similar comp as what they got in 2023). 2025 should be easier!",3,1736440347.0
1hxalxo,m69chvo,"Depends how many YOE you have. If it's more than 5 then don't. And even if you have less than 5, I can't say with confidence that DS/analytics will be in demand",3,1736445008.0
1hxalxo,m701rug,Can I ask what’s prompting your decision to switch? Could you share a bit about your experience as a mechanical engineer and what’s leading you to consider data science? It might help frame your situation better.,2,1736808397.0
1hxalxo,m6eu0ld,Location?,1,1736521601.0
1hxalxo,m69nf4h,What country is that!,1,1736448155.0
1hxalxo,m6ar8t1,"Citi Bank, Wells Fargo, and SAP reached out. I did not interview with any of them because by the time they reached out, I already had an original offer from a FAANG company and i was waiting on their revised offer",1,1736459766.0
1hxalxo,m6d8zsr,"I will be messaging you in 2 days on [**2025-01-12 07:14:46 UTC**](http://www.wolframalpha.com/input/?i=2025-01-12%2007:14:46%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/datascience/comments/1hxalxo/companies_are_finally_hiring/m6d8xj8/?context=3)

[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdatascience%2Fcomments%2F1hxalxo%2Fcompanies_are_finally_hiring%2Fm6d8xj8%2F%5D%0A%0ARemindMe%21%202025-01-12%2007%3A14%3A46%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201hxalxo)

*****

|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|
|-|-|-|-|",1,1736493322.0
1hxalxo,m67yoef,"I have 16 years of professional experience. 8 in data. 

I am US

My old job was 250k plus remote work. I was hired in 2022 when companies were paying like crazy. I had to leave since they are making everyone go into the office and I didn’t want to relocate for this employer. New job is the same salary and I do have to relocate but it’s worth the experience for me with this new employer. But just to be clear, in my 2nd year of working professionally, I made 32k in a call center. Don’t feel like you’re behind 

I can’t speak for less experienced job seekers but my impression is that unless you’re the top 1% of your peers with exceptional projects, I don’t think FAANG will consider you. I personally know little Python but I’m an expert in SQL, tableau, and Adobe analytics. I have experience with a few other tools as well from my interest in learning more. But for this new job, they hired me because of my relationship management and program management skills. The way I positioned my value to the company is that I am a data program manager with the ability to do deep dive analyses.",24,1736429275.0
1hxalxo,m68eiy5,Normally I don’t endorse LinkedIn influencers since most of them are garbage tbh but Nick Singh’s Ace the Data Science Interview book is (partially) the reason why I am a Data Scientist today (I swear he did not pay me to say this 😅),116,1736434896.0
1hxalxo,m680vz1,"I just wanted to tell you, your website has helped me immensely. Thank you for what you put out there for everyone to use",32,1736430124.0
1hxalxo,m67vw1b,You are a LEGEND! I love how the questions are worded like real world questions from tech companies. The ratings are on point. I tried about 6 different SQL question websites and I thought yours was the most helpful with a more accurate difficult rating for each. I strongly recommend your site to anyone preparing for a FAANG interview,39,1736428167.0
1hxalxo,m68a4yc,Kudos as well. You’ve helped me land my first BI job a few months ago,13,1736433441.0
1hxalxo,m6rwffz,Legend! Your page helped me practice to get my current position!,3,1736703218.0
1hxalxo,m6azyv8,"Although I haven't taken your course yet (just been busy working on my degree), I did try your easy quiz and found my skills rather lacking, despite having gotten good grades in SQL courses. I've ultimately learned more from work in the past 2 years on that subject than in multiple classes, but it was really good to have that reality check.

I may go back and brush up on some skills, but it does at least look like your quiz covered some real scenarios that classes may not. Good work!",4,1736462453.0
1hxalxo,m6ti4mv,recently used your book and site to prep for a meta interview that went super well! the FAANG practice questions are super helpful and reflective of what you might actually get in interviews.,2,1736719702.0
1hxalxo,m68n83c,Really like your interviewing book too,4,1736437612.0
1hxalxo,m6ea20u,Maybe its just with me but when i query something in the exercises the platform constantly puts out an error. Or does not show anything. Is a particular problem maybe?,1,1736514473.0
1hxalxo,m6g1rtz,Thank you bro. Really useful site.,1,1736534416.0
1hxalxo,m6mtvah,DataLemur seems cool!,1,1736628511.0
1hxalxo,m68n14z,Hi and thank you! Great resource,1,1736437551.0
1hxalxo,m69y02l,"Haven't done many problems yet, but I love it. Very intuitive. Cool problems. Keep it up!",1,1736451203.0
1hxalxo,m6bwfqd,"Site errors out on mobile ""Application error client-side exception""",1,1736473232.0
1hxalxo,m6hjoqv,Look up window functions and practice at work. That’s the advanced stuff that I found really helpful.,2,1736550637.0
1hxalxo,m6f2lts,"Yeah data engineer certification seems cool. It has all the information and basics covered ""IBM DATA MANAGEMENT""",3,1736524242.0
1hxalxo,m6847qd,"So, a Sr Data Scientist or what?",20,1736431355.0
1hxalxo,m6aav1c,What kind of masters do you have? Would you recommend it?,3,1736454965.0
1hxalxo,m6hmz7x,I am planning to position myself as a AI/ML manager to leverage my soft skills. What I am lacking now is cert/framework knowledge on AWS. Any recommended AWS cert or if you find its useful for your work?,1,1736551746.0
1hxalxo,m67v5rt,Congrats. What is the duration from first interview to offer ? And hiw many rounds of interviews ?,7,1736427865.0
1hxalxo,m681z6q,Thanks for the advice!,1,1736430533.0
1hxalxo,m69irp0,Why would more years of experience be bad?,1,1736446818.0
1hxalxo,m6eztol,Remote from the US,1,1736523403.0
1hxalxo,m69wyvr,SA,1,1736450905.0
1hxalxo,m6artm9,Seems like you have some fintech/banking background?,1,1736459938.0
1hxalxo,m696s8j,How is the cost of living situation at your new location? Trying to gauge the current market rate.,3,1736443364.0
1hxalxo,m6cnwm9,"For the interview or for the whole data science prep?

Also the book contains only SQL or more for DS related interviews?",4,1736482989.0
1hxalxo,m6eccvr,"DM me – and send me a screenshot + link of where that's happening. That shouldn't be happening at all, and I don't see that right now!",1,1736515395.0
1hxalxo,m6bxxkh,Can you DM me a screenshot? Seems to be working for me RN but happy to repro / debug,1,1736473728.0
1hxalxo,m6aguch,"It should be closer to principal DS I guess. 

This could be a stack ranked list of seniorities:

- Junior
- DS
- Senior
- Staff
- Principal

The idea Is that Sr DS have experience and can handle their own project in full autonomy. Staff DS do that plus influence other team members. Principal DA do that plus influence business stakeholders.

It does vary between companies of course.",30,1736456706.0
1hxalxo,m67wdvh,It was weird timing since my first interview was right before thanksgiving. I got my offer the first week of January and then I countered then accepted the follow up offer last week. The recruiter said they usually respond within 2 days of the first round and 5 days of the final “loop” round so the timing for mine was an outlier,21,1736428368.0
1hxalxo,m69lvgz,It's not bad it's just that you have a higher opportunity cost associated with switching. Engineers can make good money after a few years and aren't easy to replace like data analysts,2,1736447713.0
1hxalxo,m6acny0,south africa? do you mind me asking what type of work or product space is driving the ds demand there?,1,1736455493.0
1hxalxo,m6assod,Yes. I started my career on the phone and did sales. Got into data about 8 years ago.,2,1736460233.0
1hxalxo,m6ev8rt,"book contains a lot of stuff, probability, statistics, ML and cases too.",4,1736521989.0
1hxalxo,m6ewzxi,Mainly just for interviews. Although the book does contain some theory too which is nice.,1,1736522535.0
1hxalxo,m6anokc,"That's a very good description, I like it!

I sometimes feel that in practice Senior DS fall into two very different camps, something like ""recent Seniors"" and ""mature Senors"". But maybe most companies are just too miserly about giving people Staff titles. If Staff typically came before a Tech Lead role, and not after, that would have been a perfect stratification!",5,1736458717.0
1hxalxo,m6ai5hj,"I'm aware of seniority levels and responsibilities entailed. I was merely curious about what your job level. 

That's a slightly strange way to describe seniority though. It's usually moreso level of autonomy and interaction at lateral ranking (Sr influencing and interfacing with other Sr levels, Pr influencing / interfacing with other Principals, etc.)

Sr, Staff, Principal should all be able to influence and interface with business stakeholders. That's a basic job requirement.",1,1736457091.0
1hxalxo,m67x0p8,Holiday season I guess. Good luck at Fang. I believe it is the one that recently changed its name 😀,7,1736428619.0
1hxalxo,m6d9tji,"Data Science capabilities are still new here. Many business are building up their own Data Analytic teams. Skilled data scientists are very rare here. I go through countless interviews trying to find them!

Banking, retail, insurance...the classic triad for data scientists are the sectors in major demand.",2,1736493805.0
1hxalxo,m6beqoh,"Awesome, best of luck",1,1736467340.0
1hxalxo,m6aohhc,To me staff and tech lead are very similar. Maybe tech lead starts having some people manager duties.,5,1736458953.0
1hxalxo,m6ak9wt,"I mean, it's definitely a vague and slightly ambiguous definition.

Yours might work too, but I find it a bit weird to define your seniority based on someone else seniority.",1,1736457716.0
1hxalxo,m6edgmq,cool thanks for the info!,1,1736515825.0
1hxt0wl,m6c9og0,"Linear algebra is the basis of ML. Your data tables are matrices. The math you do with them (scalars, transpose, etc) is the type of math under the hood in ML. You don’t need to be a master of lin alg but you need to understand the concepts. I had a terrible Lin alg prof when I did my MS in Data Science but once I got to my ML classes, it clicked for why we had to learn it. And I was glad I did. That being said we probably spent about 15 hours of class time (3 hours per class 1 time per week for 5 weeks) on Lin alg to give you an idea of how deep to go. (The other 5 weeks of the class was spent reviewing calculus.)",95,1736477764.0
1hxt0wl,m6bvz6p,you should definitely take a linalg course,62,1736473079.0
1hxt0wl,m6ccz46,"As a mathematician, I have to apologize for our pedagogy; we definitely should have taught you linear algebra before differential equations. There are stupid and historical reasons this isn't the case. 

There are free courses out there that cover a good amount. I think MIT has an open course, probably out of Gilbert Strang's book. This likely has good treatment of stuff like abstract vector spaces, linear transformations, and singular value decomposition, which are most of what you need to know for ML.",39,1736478934.0
1hxt0wl,m6cixoa,"Definitely take linear algebra. It's a major cornerstone of data science because it provides the mathematical foundation for most data manipulation, analysis, and machine learning algorithms.

Also, I agree with previous poster that LA makes more advanced econometric and statistics courses easier. 

Honestly, I've forgotten most of the more technical aspects of the linear algebra that I once knew. But I still have the intuition that I apply to basic problem solving every day. Linear algebra opens the door to tools that allow you to model relationships, reduce computational complexity, and facilitate the interpretation of large, complex datasets.",14,1736481093.0
1hxt0wl,m6ec242,"Being able to read linear algebra like your native language, and to use high level matrix packages like CVXPY & NumPy.MatLib is critical.

Knowing how to write an algorithm to compute the SVD or QR decomposition is not as important & not where I would spend my time.

My advice for really learning linear algebra: understand the notation extremely well (especially matrix vector, matrix matrix, vector products), watch 3 Blue 1 Brown's video series on linear algebra, read relevant software docs.",6,1736515277.0
1hxt0wl,m6cyefj,"Tip top, my background is in pure math but my advisor was an applied guy so I can compute a JCF *and* an SVD. I'll be signing autographs from 3-4 on Saturday.

It doesn't always help *directly*, but when it does it really does. We worked on a hybrid computer vision/robotics project a while ago... knowing my linear algebra helped a little with the former, but a ton with the latter. There weren't any libraries to do specifically what we wanted, unlike with the vision part of it. Computing poses for the robot/camera was all just linear algebra, and doing this as efficiently as possible wasn't the bottleneck, so hand-coding them naively using Numpy matrix operations on the robot's joint angle readings worked great.

Edit: I still have to take 2 minutes to work out which way a change of basis matrix should go every time it comes up though, lol. Otherwise it's a coin flip whether I'll get it right or backwards.",16,1736487646.0
1hxt0wl,m6hmccb,I’m terrible at statistics but so are my stakeholders. It has never held me back in my career,3,1736551533.0
1hxt0wl,m6cvdua,"OP, which masters degree are you doing? I’m between OMSCS or data science masters from Berkeley. Curious to hear your thoughts and your experience",2,1736486216.0
1hxt0wl,m6hlrie,"You don’t need a deep understanding of vector spaces the way a mathematician does. Simply understanding matrix multiplication, factorization, inverses, and eigenvalues / eigenvectors would go a long way. The reason is that many statistics and machine learning books use linear algebra to concisely represent transformations on a data matrix X.",2,1736551336.0
1hxt0wl,m6j465z,"Pretty good! You should take some undergrad and grad level classes, LA is very useful, but it’s also a very fun subject! My favorite in undergrad and grad! I wish if I ever get a PhD it’s in a topic in LA!",2,1736570904.0
1hxt0wl,m6kz75c,"I'd suggest taking a pragmatic approach by first considering what you want to do with ML. If you want to go the academic route and really contribute to the field or write optimal software packages, advanced linear algebra knowledge is a must as all your data are essentially matrices. If you want to make cool pipelines in practice, coasting on the current academic meta so to speak, just stick to the absolute essentials (perhaps a couple of lectures online) and focus on accumulating a good working knowledge of current algorithms, their applicability and how to create scalable software with it. Good luck!",2,1736607209.0
1hxt0wl,m6cjhju,Linear algebra is literally the cornerstone of all math involving datasets,2,1736481301.0
1hxt0wl,m6dyg5i,"

You should take a linalg course",1,1736509006.0
1hxt0wl,m6e51dd,Look if it’s tripping you up it’s very fucking simple but the thing is is you haven’t practiced it enough just commit even after the class if you’re like oh I passed it. It’s not enough master it. The great thing about math is it’s black and white.,1,1736512301.0
1hxt0wl,m6fqlac,"Take linear algebra, it’s very very important for ML",1,1736531210.0
1hxt0wl,m6gayrb,I’ve been in a field/discipline that relies heavily on linear algebra for over a decade. I took linear algebra 30 years ago and learned nothing because I didn’t apply it for 20 years. I could really use refresher course. You should definitely take the courses and make LA part of your dna.,1,1736537078.0
1hxt0wl,m6gpzd0,Very. I was a pure math major in undergrad though before my MS. It’s very important and useful!,1,1736541476.0
1hxt0wl,m6hk4ci,Enough to read matrix notation,1,1736550783.0
1hxt0wl,m6mlwtj,"You should definitely spare the time and effort to take LA before digging deeper into ML concepts. It's bread and butter, and it will allow you to focus on the concepts behind the algorithms, otherwise, it will distract you, as you'll keep chasing the LA understanding.


You can do it without, but it's far from ideal.",1,1736625921.0
1hxt0wl,m6n244v,Definitely advise it! My masters actually has a mandatory class at the start of the year for those who didn’t take it during their bachelor. It really makes your life a little easier.,1,1736631153.0
1hxt0wl,m6p3h1c,"Take a linear algebra course that is focused on applications in data science.  There are also courses in linear algebra that are taught as pure mathematics and other courses that are taught as numerical analysis.  You need to know what the SVD is and how to use it, rather than the Jordan Canonical Form (pure mathematics) or the Golub-Reinsch algorithm (numerical analysis).",1,1736656571.0
1hxt0wl,m6v7bp8,Linear algebra is must,1,1736740076.0
1hxt0wl,m6xzj08,Good enough to be dangerous and remember what I need to lookup if i forget,1,1736786685.0
1hxt0wl,m745ftu,"I think ur fine. I had a similar experience in my Masters Linear Models course. Although I did take LA in undergrad I honestly didn’t remember much and felt like I really learned it once I was faced with its applications. If you want a deeper understanding you can seek it out with a course, but from my experience if you don’t nurture that knowledge by continuing it after the course it would just be forgotten.",1,1736870521.0
1hxt0wl,m6entem,and nonlinear algebra,1,1736519563.0
1hxt0wl,m6c1k90,Care to expand on that at all,-15,1736474959.0
1hxt0wl,m6grtw4,I'm curious about the reasons. Does it have to do with the space race in the 1960's by chance?,3,1736542018.0
1hxt0wl,m6p3l5d,Strang has a version of his textbook specifically oriented towards data science.,1,1736656620.0
1hxt0wl,m6cmadb,Oh man. I have an advanced stats class coming up but I don’t remember any linear algebra,4,1736482362.0
1hxt0wl,m6c8fgb,"It’s easier to list the topics that do not involve linear algebra in some way, or do not have natural extensions that involve linear algebra, than those which do.",26,1736477331.0
1hxt0wl,m6dyoss,"Linear algebra deals with matrices. A table can be thought of as a matrix. Therefore, linear algebra deals with data. You won't understand any equation that manipulates data without linear algebra.",3,1736509138.0
1hxt0wl,m6djboa,"Primarily, understanding operations behind matrices, how they interact with each other. I know that’s quite broad, but all this “eigenvalues eigenvectors” chat will just confuse you. I’m not going to scare you away. 

Take a linear algebra course. It’s essential.",2,1736499717.0
1hxt0wl,m6gqawg,"A ton of stuff is built on it. You don’t want to just use the tools, you have to actually understand what’s going on inside to become something more than a run of the mill surface DS.",1,1736541570.0
1hxt0wl,m6htxn1,"I think it really predates that. Matrix notation was largely invented by the quantum mechanics community, while diff eq followed Liebniz notation through 19th Century French mathematicians like Fourier. The differential equations we teach is largely based on finding solutions by hand. Very classical stuff. But I think it's more useful to have a view of differential equations as operators on a function space and solutions as subspaces. 

As I tell students: computers suck at Calculus, but they're great at Linear algebra.",4,1736554124.0
1hxt0wl,m6n0adg,"I'm starting my fourth upper division math/stats class for my DS master's program and I seem to forget most of everything I ever learned about math between classes. YouTube videos, old textbooks, Web searches, etc. are my friends for quick refreshers. I use the integral-calculator.com (""With Steps!"") when I'm stumped on how to approach a sticky integral.",2,1736630567.0
1hxt0wl,m6czmj5,"Yeah, it touches everything from the Hessian matrices in optimization to the covariance matrix in a multivariate normal distribution to the whole setup for neural nets, etc. Maybe hypothesis testing? But my statistical-layman's impression is that you can frame at least some of those tests in terms of generalized linear models, so boom you're right back in linear algebra's house.

Whenever I think linear algebra isn't useful when it comes to a topic in math, stats, or theoretical CS... it usually just turns out that I don't understand that topic deeply enough to see where it comes in yet. Shit, I don't think I can even beat the original Castlevania on NES without linear algebra. (Or the triple holy water trick to freeze Death in place on stage 5 instead of fighting him for real, but knowing that won't get you a data science gig so I digress.)",6,1736488252.0
1hxt0wl,m6cl54v,[deleted],-5,1736481924.0
1hxt0wl,m6fd11d,"I agree with the gist of what you're saying, but imo after a course in linear algebra you should be at a point where eigenvalues and eigenvectors are intuitive. What's the simplest thing a matrix can do to a vector? Scale it! Can we make a whole basis of vectors that get scaled? If yes: dope! If no: boo why can't I work over the complex numbers in real life like in my abstract algebra course, guess I have to learn about the SVD.

They usually have a nice interpretation in applications, too. They're the principal components in your principal components analysis for example.",3,1736527298.0
1hxt0wl,m6r96yb,Huh. I love learning stuff like that! It always helps concepts click together when you know their origin and all the “drama” around them. ,1,1736696145.0
1hxt0wl,m6cmc81,Exactly. My list is the null list.,6,1736482381.0
1hy8jhq,m6g7l2v,"Yes. inobs= is used to limit the number of rows read from a data source, while outobs= is used to limit the number of rows written to a dataset.",6,1736536084.0
1hy8jhq,m6g8798,"Thanks.  Had my confidence shaken about this when somebody, who has much more experience with SAS than I do, told me that they are the same thing.",1,1736536263.0
1hy8jhq,m6ga58o,Nope you’re all over it,2,1736536841.0
1hyhm2a,m6hj38f,"I really hope this is satire. Yes you need to understand math to be a data scientist. If you don’t understand what you’re doing, you’re not a data scientist. That’s like asking if a mechanical engineer needs to know math or a doctor medicine. Why would data science be a special field where no one needs to know how to do the core competencies of the field?",33,1736550437.0
1hyhm2a,m6hin76,Garbage in garbage out,25,1736550288.0
1hyhm2a,m6hjpoo,"Knowing the underlying mathematics ensures that you can do a ""sniff"" test on the LLM's suggestions and tailor its output to your specific needs. In more general terms, view the mathematics you learn as a data scientist as courses in writing. Using the LLM can provides you with an initial starting point that helps you overcome writer's block, but its output will not perfectly align with your purposes. Knowing how to write enables you to make the adjustments required to transform the LLM output from a template to a solution.",6,1736550645.0
1hyhm2a,m6hk840,"Go for it don't learn the math, we won't hire you. There's just so many levels of misconception here I don't even know where to start. You're giving way too much weight to what ML even brings to data science.",6,1736550818.0
1hyhm2a,m6hjn9u,"As a DS you should absolutely have a 100% understanding of what your model is doing and why. If you trust it blindly, then I refer to the first comment about garbage in, garbage out. Your role should be able to explain to your model risk team why it does what it does - even if you leverage something else to get your result. Also this is key for your ability to validate your results during your development… In short, regardless if your doing the development or using something g out of the box, you should be able to explain it. My company won’t even let us use models out of the box from other vendors unless we can see under the hood. It’s a risk for your company and your business cusotmers.",5,1736550622.0
1hyhm2a,m6hlbcw,"Sure, you can train and fit an xgboost model nowadays with little knowledge of the underlying math.

But hey, what does accuracy, AUC, f1 score mean?

How do those model metrics translate to actual organizational/business metrics? In fact, did you use the right loss function when training your model?

How much does model cost to run?

Uh oh, our model’s drifting! How much has it drifted? How much did it chart our organizational metrics? Is it worth training a new one?

Would the model improve if we fed it more data? Would an alternative model be better if we had a different set of data?

Fitting a model is like, a day of work, with half the day being meetings. Real data science jobs are much more about the broder context of business metrics.",5,1736551187.0
1hyhm2a,m6hjwtl,"I really want the math to still be important, but based on the number of data science students who tell me they “hate math”…

Also their eyes glaze over whenever I try to teach them the theory behind the models they’re applying. They just want to look at some F1 scores and collect their $$$ paycheck.",3,1736550711.0
1hyhm2a,m6hl81w,"Let's frame it this way

1. Do you need to know the math to leverage models in data science to create value? 
2. Can you create more value if you knew the math?
3. Do people in the industry actually care if you know the math behind the models so long as you can produce valuable results for them?

For 1, there's a vast range of problems you can value-add even without knowing math. For 2. there are a vast range of problems in which knowing the math can help you devise a better solution and better convince stakeholders. For 3. from my experience, this is a mixed bag where most not caring if you know the math or not so long as you deliver results.",3,1736551155.0
1hyhm2a,m6hm7ts,You have to be able to understand and explain the why.,3,1736551490.0
1hyhm2a,m6hm2m1,"It seems that you're looking for a reason to not continue learning math. Why not use those models you're hoping to rely on, to help you study?",2,1736551441.0
1hyhm2a,m6ko5vf,"For a ""Citizen Data Scientist"" it is not important. 
For a ""Data Scientist"" it is important.

It depends on what level the business actually needs and what level you want to achieve in your career.",1,1736602896.0
1hyhm2a,m6pymvx,Should drop the word ‘scientist’ after data,1,1736673928.0
1hyhm2a,m6v7t8q,"Yes, it's the foundation and engineering behind it. Having a strong foundation helps in implementing it models",1,1736740261.0
1hyhm2a,m6hkc3z,But why ~~male~~ large language models?,11,1736550856.0
1hyhm2a,m6hjfyt,A lot of data scientists are now just doing programming but including LLMs in some way or another. I guess this will revert to the SWE or MLE title sooner or later but it’s currently muddled under the data science umbrella,9,1736550553.0
1hyhm2a,m6ro47q,People who know math barely get hired these days. It's all about soft skills and SWE experience.,2,1736700796.0
1hyhm2a,m6q4blz,This,1,1736677530.0
1hyhm2a,m6hkwmg,That's just a temporary hype associated with the LLM bubble. A lot of these people don't even understand the fundamental limitations of LLMs because they don't understand the MATHS.,9,1736551049.0
1hyhm2a,m6v7h82,100%,1,1736740133.0
1hxplq8,m6fbf5a,Let me know too if you get such resources.,3,1736526832.0
1hxplq8,m6fpjo8,What do you want to forecast? Global emissions or emissions of your car? There are high level and low level approaches. Environmental Agencies publish emission factors such as EPA Emission Factors Hub. There are certain methodologies that companies use to make sure their calculations are correct like Greenhouse Gas Protocol but it’s mostly analytics. I don’t have much time rn to elaborate but I work in climate modelling at F100 so feel free to me ask anything.,3,1736530912.0
1hxplq8,m6m3nn3,"I’d recommend reading the scientific literature to learn more, as I’m unsure if textbooks for a topic like this exist. A quick google scholar check for “global greenhouse gas emissions” results in a variety of approaches that have been used (with detailed descriptions of their models) and references/links to the data they use",2,1736620198.0
1hxplq8,m6pia1y,The one I use (for vehicle emissions) is EPA MOVES,2,1736663907.0
1hxplq8,m6vrh3b,"I think keeping tabs on which academics are involved with modeling at the following labs

https://ncar.ucar.edu/

https://airpact.wsu.edu

Or search terms like “AGU air quality modeling” “EPA air quality modeling”

Might even want to email a professor asking for pointers.",2,1736749231.0
1hxplq8,m6wj50h,"I recently used the STL time series decomposition 
[(Cleveland,1990)](https://www.wessa.net/download/stl.pdf) for my master's thesis to analyse the development of electricity prices. The publication actually also uses CO2 emissions as an example. The method splits a time series into trend, seasonal and residual components. 
[(Stefano et.al, 2023)](https://www.mdpi.com/1996-1073/16/3/1371) have used the components e.g. as input for the Facebook Prophet model to predict Italian energy prices. Maybe that would be a starting point.",2,1736766602.0
1hxplq8,m73t2qk,"At the national or regional level, most studies or institutions like IPCC use off-the-shelf models like GCAM, MESSAGE, GRAPE, BET, Poles REMIND etc. See pp. 1309 of AR5 Annex II [here](https://www.ipcc.ch/site/assets/uploads/2018/02/ipcc_wg3_ar5_annex-ii.pdf). These are models of the entire economy including household sector, different manufacturing industries, services, agriculture and land use, government etc. To simplify, these models try to replicate the entire economies through equations and interdependencies, they validate the model on historical data and then use it to make predictions for the future under possible simplified scenarios like Net Zero achieved by 2050, no policy after 2020, late action starting 2040 etc. 

You can read model documentations to learn more.",2,1736866660.0
1hxplq8,m74fr76,I mean a very simple place to start is with an ARIMA and be sure to look for structural breaks. Use existing time series data on CO2 emissions to forecast.,2,1736873601.0
1hxplq8,m6g8k1l,Looking for global or regional emissions. Like if I wanted to predict GHG emissions in 2030 using previous years. I saw online that CARB board is currently using machine learning but there isn't a lot of info and I was kinda hoping I could find a textbook or a formal guide to learn the approach.,1,1736536367.0
1hxplq8,m73wur2,Thanks. But is there no textbook available. Was kinda hoping for something more comprehensive,1,1736867879.0
1hxplq8,m745s80,"These climate science models fall under the field of Integrated Assessment Modeling, Computable General Equilibrium (CGE modeling) or simulation. There are many textbooks on these. 

But I believe this line of inquiry is not what you are looking for, because in these models, future emissions are assumed trajectories (or scenarios of possible futures). The main outcomes of interest are other factors like temperature rise, GDP impacts, unemployment, inflation, damages from climate change etc. 

If you can provide more explanation on what you're looking for, I can maybe suggest relevant stuff.",1,1736870626.0
1hxplq8,m755m3n,I've done forecasting using fundamental statistical modeling methods. But I've never had any formal training. I was looking for a course that would teach everything I'm supposed to know (don't have any specific needs),1,1736881075.0
1hxplq8,m76kyir,"In that case, ignore the national/regional emissions modeling through IAMs/CGE models. That's a small, specialized field and not relevant to you. However, ML models are useful to predict a range of climate related variables. 

This SaaS company for example, predicts emission for firms. The idea is that verified emissions are only available for a few firms. But this data can be used to train a model to predict emissions based on factors like industry, sector, size of the firm, financial variables etc. They then sell the predicted emissions data to investors. Many companies have such products, but AFAIK, this is the only one with a publicly available description of their method. [Link](https://www.esgbook.com/wp-content/uploads/2025/01/Filling-in-the-Blanks-April-24-compressed_1.pdf)

Perhaps a climate or sustainability course might be good for you. Learn about the field and then using your data science experience, you can figure out how to apply your skills to the relevant problems.",2,1736896898.0
1hx305z,m65z8ww,Did you explain your reasoning or just provide the prescription? Your interviewer may well not understand your approach or know its equivalence.,186,1736392143.0
1hx305z,m662iy1,"If an employer decides not to take you, they'll retrospect and muster anything that could justify their decision.

If they like you, they'll make excuses for you to start asap.",114,1736393378.0
1hx305z,m665ce5,"Height can be modeled with a gaussian distribution with mean 180 and SD 10 even though the support of a normal distribution is all the real numbers.

A t test can work on non normal data if the central limit theorem kicks in. This is usually the case in most applications. Your suggestion seems unnecessarily complex for something that can be done with a t test.",97,1736394471.0
1hx305z,m66dpcq,This is the behavioral component of the technical interview.,10,1736397976.0
1hx305z,m65zkch,"> I suspect many would use a t-test but I believe that would be inappropriate since time is a skewed outcome, **with only positive values**, so a t-test would not fit the data well (i.e., Gaussian outcome).

How does limiting outcomes to positive values only not work with t-tests/Gaussian distributions?",28,1736392261.0
1hx305z,m66iyzo,"Sounds like a straightforward ""CLT, ergo t-test or z-test for two proportions"" situation. The time to whip out a GLM is when you have additional covariates (fixed and random effects) to consider.",14,1736400410.0
1hx305z,m66367e,"In general, yes I have had interviewers be wrong before but typically it’s one of either (i) the interviewer is in a different field than you and uses different terminology, (ii) you didn’t clarify your reasoning fully

In your particular case, I would say it’s nuanced. It’s not an absolute that positive valued data should not follow a Gaussian distribution. Most cases it will be skewed, but you should validate that assumption first. Another thing to consider is that if you’re looking at simple difference in means between two groups the t-test assumptions are pretty relaxed and should hold under mild CLT conditions.",22,1736393627.0
1hx305z,m66reyj,"If you got rejected for this reason, then it was because you were not practical in your answer. Your answer gives me the impression that you overthink and overcomplicate things, which can be an issue if workload is heavy. Strive for simplicity and ""good enough"" solutions and not for perfection. Good luck next time!",20,1736404828.0
1hx305z,m66fn0r,"Interviews shouldn't be quizzes, this sounds like a bad interview experience if this feedback wasn't part of a discussion that happened at the time of the interview.",5,1736398841.0
1hx305z,m66d9b3,Idk about your specific situation. But my experience interviewing is if the interviewer is not a very knowledgeable DS then they are basically looking for you to say their answer. It’s a very hard interview. Interviewing with knowledgeable people is much easier because they can see the nuance in potentially great answers.,8,1736397780.0
1hx305z,m6d88n5,"One lesson I've had to learn in my career is how important it is to convey *experience* and not just *correctness*.

Your intuition isn't wrong, but in A/B testing, t/z-tests are common because sample sizes are usually large enough that CLT eliminates your concerns about a poor distributional fit. Power calculations often require sample sizes in the hundreds of thousands or more. If your sample size is small enough that you need to worry about these issues, the experiment is probably underpowered and has bigger problems.  
    
More broadly, my advice would be to spend time learning which techniques are used in the industry so you can speak the language of the company interviewing you. For me, reading books and technical papers on A/B testing from leading companies really helped me.",3,1736492883.0
1hx305z,m6hki20,"Oh my god, the statistician in me is quaking. I’d actually argue so heavily with that interviewer. You could use a likelihood ratio test. Your answer is also correct. But you could also use a t test because there is a way to derive the difference in means asymptotic distribution",3,1736550912.0
1hx305z,m66i8mz,"Brethren, you should feel proud you understand what you said, cuz I sure dont.


Fuck em, its their loss. ",14,1736400057.0
1hx305z,m67f6fm,"It's not really about best method (or equivalent), it's more about consensus of industry. So, if the industry uses t-test for A/B test, providing an alternative solution creates a headeake for the one who evaluates you. He only needs to know that consensus is t-test, now he needs deeply to know your solution and evaluate against it. You're putting pressure on evaluator, so his default action is to reject (too much thinking needed on his part, assume always him being lazy). We all use shortcuts, we don't like to think.

So, you fel into a trap. Your answer might be correct, but you asked too much from your evaluator (you asked him to think).

The biggest issue is that you might not know industry consensus (you'll learn it on your job, once you're in the industry). This is chicken - egg issue = they are searching for people already in industry, so this builds an high entry barrier for outsiders / newcomers. This will happen everywhere and in all industries. The only way is to insist and apply to jobs till you find one that accepts you. It will be easier later to change towards a better job inside industry once you got to know it",5,1736419725.0
1hx305z,m6605e0,`y` may be strictly positive but `Z` is not,2,1736392478.0
1hx305z,m68df4a,"I've been rejected was told I had not completed a programming question correctly when the literal test rig they had given me to work in said I had gotten the right answer.

You can't take this stuff personally because 1. there is no gaurantee what they are telling you is the truth. There is no rule or law that says the feedback has to be honest and 2. many people doing interviews are being Peter Principled into it because they are Senior or Staff or whatever and its an expectation of the job. But being good enough at DS to get to Staff on your IC work has almost zero to do with if you are good at giving interviews. I see this a lot in SWE too like someone can be a fantastic engineer and just not have any empathy at all and you can't give a good interview without that tbh.",2,1736434536.0
1hx305z,m6cwu6e,This is a smart discussion. What’s y’all’s degrees? Masters?,2,1736486898.0
1hx305z,m6lcfl5,"Yes I am constantly butting heads with hiring managers that fail to understand my brilliance, but such is life as a persecuted genius.",2,1736611689.0
1hx305z,m6lsiir,"All the time.  Hiring managers are people not statistics textbooks.  But what matters is that he looked down on you for knowing a piece of statistics he clearly didn't understand very well.  Do you want to work with a guy like that?

Companies benefit from their job offer being viewed as a gameshow prize that you are graciously offered.  But reality this is a two way conversation.

I have had two (and a half..I bailed on him very quickly) really bad managers in my life.  One destroyed my academic career and the other did the same at a company I really loved to otherwise work in.  Think of this as a dodged bullet.",2,1736616738.0
1hx305z,m66060j,"Ah so they might be thinking of a two proportion z test? The z and t distribution are effectively the same thing when n>=30. Technically the response is binary, yet, I find the imprecise language a bit confusing. 

To answer your question, I have had interviewers be wrong before. One told me there was no calculus in the derivation of linear regression, which is just completely fucking wrong. I’ve done it by hand, many times, on exams. I’ve also been told that xgBoost is empirically better than random forest, which contradicts NFLT. I could probably find more examples.  

I would say you’ve dodged a bullet. It’s frustrating, but let that be someone else’s problem.",5,1736392485.0
1hx305z,m66jxvx,"A few thoughts:

* I would not say that it is equivalent. Though the point estimate practically is (not numerically equal, but very similar), the standard error differs, often by a considerable amount.

* In general, the flexibility and additional capabilities (adding covariates, etc.) of a linear model makes it superior to the t-test.

* There is absolutely no problem with using a linear model in the mentioned context.

* How would you interpret your estimated coefficient following your suggestion?",4,1736400884.0
1hx305z,m66rbdj,"Sounds like they wanted a scripted answer and you went off script. 

I’m sorry that happened to you. I know interviews can be really stressful and time consuming. It sounds like you’re clearly capable of doing standard DS work.",4,1736404772.0
1hx305z,m66hoox,No but have you actually written that out?,1,1736399791.0
1hx305z,m66wkqe,"If you don't mind me asking, what was the programming assessment like? Was it proper DSA stuff or data manipulation in python type?",1,1736407824.0
1hx305z,m66xwol,"I got asked a similar question when doing an interview for a company, but the interviewer worked for a third party company that facilitated the technical interviews. I have to say it seemed like this 3rd party company was directly looking for scripted answers and the whole thing was awkward and uncomfortable. Maybe yours was similar and you can chalk it up to that. The advice on this thread is solid hope you know you’re not the only one going through DS interview hell",1,1736408647.0
1hx305z,m68jacg,I have no idea what any of this means,1,1736436406.0
1hx305z,m69khxx,"""Has anyone had occasions where the interviewer was wrong?""

When the interviewing Technical Lead proudly stated that his Toronto Maple Laughs were the best team in hockey.

He could not be more dead wrong. I proceeded to ""prove"" this with stats - and did! VP laughed, Technical Lead did not.

Interview unsuccessful.",1,1736447315.0
1hx305z,m6btc7q,Any good resources for just getting to your level?,1,1736472197.0
1hx305z,m6dhtg3,"I absolutely agree with your reasoning, and while I have no insight into why this would happen and how to avoid it, I wonder if you may have dodged a bullet there. Would you be happy in a job where all you do are t-tests?",1,1736498745.0
1hx305z,m6e9tn7,"Maybe a stupid question, but why are you assuming your predictor (time spent on app) as binary?",1,1736514378.0
1hx305z,m6w4ez1,You need to work on your communication skills.,1,1736757039.0
1hx305z,m66okc9,"If you want to compute the average time, you can still use a t test by law of large numbers. I think. But you are right about it being skewed.",1,1736403268.0
1hx305z,m68csvf,"One problem with a parametric model, like the log-normal or log-gamma GLM, is that you might run into problems if you parametric assumption is not valid. A simple t-test (or linear model) has less assumptions and without further information I would prefer it.",1,1736434335.0
1hx305z,m663kq9,[removed],-13,1736393783.0
1hx305z,m678lfe,"Hellooo I have a background in causal inference. I actually would proceed with extreme caution using a GLM to make inference on an AB test, because outside of using the GLM to underpin something like an ANOVA, alot of uses of GLM for inference are dodgy = sensitive to your covariate modelling.  It really depends on how you are going to GLM it, GLMs are very flexible and that permits incorrect usage very easily. The classic example of this is where you have an indicator variable / independent variable for the causal thing you are varying (i.e. test condition), but where you also seek to control for a large handful of covariates (time of day, etc etc), and make inference based on the p value of your IV. That p value can swing wildly on the same dataset by dint of what you include as covariates in the model. It's also not clear to me that penalties are appropriate here, given they bias coefficients to 0. Causal inference folks often say that inference depends on the model being correct, which is not knowable ofc - relative to the flexibility of GLMs, ttests are model free in that they only assume the distribution and that's it (and they are also surprisingly robust to distribution violations, where robust by definition means non-inflation of the false alarm rates).

The ""correct"" way to do stuff like this (inference with covariate control) is documented in methods like CUPED, synthetic controls etc, but there you are testing your analyses (GLM modelling) with power calcs that explicitly examine the FA rate and sensitivity, with Monte Carlo simulations based on empirical datasets, and explicitly making a non stationarity assumption. If one thinks ""what's the big deal"" and doesn't understand why people make such a big deal about this kind of analysis, it's exactly because of the useful but dangerous nature of GLMs as pertains to causal inference.",-5,1736415536.0
1hx305z,m65ze9u,"Yup, I said I would use a log normal or gamma generalized linear model because the outcome is skewed and only has positive values. Maybe I should’ve said the simple explanation of a t test first and then indicated why I think that’s not right?",75,1736392199.0
1hx305z,m662lqy,Good point! Thanks,16,1736393408.0
1hx305z,m66cod3,"In your example, height (in cm) is far enough away from zero that you can avoid running into problems with (say) the confidence interval limits becoming negative if you use the standard wald-type CIs (mean +/- 1.96 * se).

Time spent on an app (unit in minutes or hours) might have its mean close enough to zero (and / or high enough standard error) that the lower limit of the wald CIs might be below 0 (which would be nonsensical)

(sure, you could use bootstrap percentile CIs instead of wald CIs)",18,1736397525.0
1hx305z,m665tf9,[deleted],-12,1736394661.0
1hx305z,m664uh0,"I guess the only positive values part is not a reason not to do a t test, but is a constraint of log normal and log gamma models that the outcome is strictly positive. So probably misphrased that as a reason to do a log gamma GLM, whereas it’s a constraint of log gamma GLM

I was more thinking of the fact that truncation or bounded data can be a problem for Gaussian models, but I guess that’s not the same as “positive values only” so I probably misphrased a bit",3,1736394275.0
1hx305z,m6c2wa2,I don't see much of an issue - the worst case is doing the same thing a different way.,1,1736475416.0
1hx305z,m663dzr,Yeah the lesson I’m getting is probably to use the simplest answer possible and then can dive into the more nuanced approach if necessary but have to clearly defend and explain why,12,1736393711.0
1hx305z,m67ddnp,"Interviewers are wrong or don't make sense a lot of time. Especially when interviewing product case where answers are ambiguous.

Problem: They are never being penalized. If they had a bad day, poor luck for interviewee",2,1736418619.0
1hx305z,m68ekcj,It’s this. They’re worried OP is a statistician/mathematician and not a decision-maker who knows when to use fancy models and when to get shit done.,7,1736434909.0
1hx305z,m68ckbw,"It's an interview... we literally tell people to overexplain, don't leave anything to chance, make sure your interviewer is given a view into your thought process. ""Overcomplicate"" it's a GLM OP didn't suggest standing up a data center to run an in-house LLM to do it. 

OP demonstrates that they are genuinely thinking about the problem and its possible non-happy path issues, again literally what we tell people to do, and this is your take? Stick to gooning tbh.",6,1736434258.0
1hx305z,m67dtzl,"It's more like closed-minded interviewer. Even knowledgeable people with ego, and text-book theorist have huge confirmation bias. Either candidates' answers must fit their agenda or out.",2,1736418902.0
1hx305z,m71k8an,"OP this is the real answer. Most companies have a list of questions with generic expected answer key.  In my long time of interviewing, very rare DS, have discussed or debate the nuances. The rest are just parroting mainstream medium and kaggle articles.
It’s specifically true if you interviewed at big tech , FAANG firm where they have a very structured pattern to interviews.",1,1736826425.0
1hx305z,m66x9va,Best response I’ve read so far,-1,1736408255.0
1hx305z,m661elo,Are you using calculus to derive linear regression from the likelihood function? Or do you mean computing the weights from partial derivatives? Calculus is needed in both of those ideas. But perhaps the interviewer instead meant that the analytic solution to linear regression can be computed via matrix algebra without calculus assuming you don’t have any regularization terms.,5,1736392956.0
1hx305z,m66qt8t,"Tbf, there's like, a hundred different ways to derive OLS. Least squares, MLE, MOM, GMM... etc",2,1736404489.0
1hx305z,m6778e6,"> I’ve also been told that xgBoost is empirically better than random forest, which contradicts NFLT.

I don't think it does. NFLT assumes that every optimization problem is equally likely. This is false, to some degree, in practice. From Wikipedia:

> The original no free lunch (NFL) theorems assume that all objective functions are equally likely to be input to search algorithms. It has since been established that there is NFL if and only if, loosely speaking, ""shuffling"" objective functions has no impact on their probabilities. Although this condition for NFL is physically possible, it has been argued that it certainly does not hold precisely.

> The obvious interpretation of ""not NFL"" is ""free lunch,"" but this is misleading. NFL is a matter of degree, not an all-or-nothing proposition. If the condition for NFL holds approximately, then all algorithms yield approximately the same results over all objective functions. ""Not NFL"" implies only that algorithms are inequivalent overall by some measure of performance. For a performance measure of interest, algorithms may remain equivalent, or nearly so.

Unfortunately, NFLT is often misunderstood. NFLT is a good way of explaining that the model you choose should depend on the problem at hand. But it's also true that certain models perform better than others on the optimization problems that we practically encounter.",0,1736414635.0
1hx305z,m678vq0,"> I would not say that it is equivalent. Though the point estimate practically is (not numerizcally equal, but very similar)

The estimates are equivalent - any difference you see is due to it being calculated differently (but equivalently) resulting in a floating point error. You are essentially just saying 0.1+0.2 is not 0.3 because of floating point error.

> The standard error differs, often by a considerable amount.

That's just the difference between the Welch t-test and the Student's t-test. If you in your t-test specify var.equal=TRUE you get the same standard errors.",4,1736415723.0
1hx305z,m67nchc,"It is definitely equivalent. You can test it yourself but here’s a notebook providing examples of how a t test is equivalent to a linear model:

https://lindeloev.github.io/tests-as-linear/#5_two_means

I probably would not interpret the coefficient heavily. I’d focus on the predicted effects and the differences in predictions for A and B.",2,1736424279.0
1hx305z,m69eh5e,"Op wanted to use a model which underlying distribution assumption is more in line with the ""data"", but in reality it does not matter as the Central Limit Theorem is perfectly enough to explain, that a normal t-test would also be sufficient to give the result the interviewers were looking for.",2,1736445575.0
1hx305z,m6c58wt,Any stats textbook that covers GLMs,1,1736476226.0
1hx305z,m6ksf3h,"That’s a great point! If the interviewer didn’t even know that t tests and linear models are equivalent, odds are that the majority of the job are just t tests hah",2,1736604624.0
1hx305z,m6kt5hq,"I am not. The predictor is binary because the predictor is your treatment group compared against control (A/B). The outcome is time spent on app, assumed to be drawn from a long normal or log gamma distribution predicted by experimental group (A/B). What this ends up testing is whether are differences between A and B in time on app

This is equivalent to a t test
https://lindeloev.github.io/tests-as-linear/#5_two_means",2,1736604910.0
1hx305z,m67njay,"Law of large numbers and CLT applies to sample means, not the sample or individual data points though. Any sample doesn’t approach normality, it’s the sample means that do",1,1736424373.0
1hx305z,m663w58,Thanks that’s definitely the read I’m getting is to go with the obvious answer but also articulate and defend the less obvious answer that is more rigorous. But probably use both,1,1736393906.0
1hx305z,m6c54wh,">Causal inference folks often say that inference depends on the model being correct, which is not knowable ofc - relative to the flexibility of GLMs, ttests are model free in that they only assume the distribution and that's it (and they are also surprisingly robust to distribution violations, where robust by definition means non-inflation of the false alarm rates).

Yeah sorry, this is horribly misguided.",1,1736476188.0
1hx305z,m660bga,"It’s reasonable, but likely explaining the inappropriate nature of a naive approach would get you a more positive outcome, as the interviewer may then research your answer further if they know you understand standard ideas

On the other hand, even with a right skewed distribution, a bootstrap sampling of the mean will still be Gaussian as long as the variance is finite and the mean is defined, which is true of both a log normal or log gamma distribution. So you could still use a t-test on the sampling mean. You could highlight this approach and then discuss the benefits of directly calculating the coefficients without the need for sampling with a suitably defined GLM.",135,1736392542.0
1hx305z,m668h8f,"your answer does sound wrong/inexperienced

a t-test would be perfectly fine, just as eg a z-test is used for click through rate (ie a probability), even though probability is strictly between zero and one.

see
https://blog.analytics-toolkit.com/2017/statistical-significance-non-binomial-metrics-revenue-time-site-pages-session-aov-rpu/

the sample mean in an ab test is most probably approximately normally distributed (by central limit theorem, sufficient data etc)",56,1736395740.0
1hx305z,m67cqaa,"CLT makes means distribution is normal. So it's also reasonable to use t-test too. The point is to compare the means distribution, which presumes the difference in means distribution can be a great signal to the difference of 2 test groups.

Makes perfect sense provided A/B testing is usually short-term, also interpretable than any complex generalized linear model. 

Also, the question is ""Any difference between 2 groups"". I'm not sure a generalized linear model can give a concerete answer. 

If OP wanna make it complicated, use distribution distance like KL-divergence or wasserstein or KS-test to measure the divergence of 2 groups.",7,1736418201.0
1hx305z,m69yd2i,"> Maybe I should’ve said the simple explanation of a t test first and then indicated why I think that’s not right?

This is the right approach.  Starting with standard approaches makes it easier to follow your thought process, and more importantly, tells the interviewer that you at least *consider* obvious solutions before doing something more complex.",1,1736451309.0
1hx305z,m6bb1sf,"OP, do you know this page ? 
Common statistical tests are linear models
https://lindeloev.github.io/tests-as-linear/",1,1736466098.0
1hx305z,m66fcnc,I agree. It might not be a good model. But it shouldn't outright be rejected just because we expect time to always be positive.,14,1736398712.0
1hx305z,m66khu1,"The units don't make a difference here, just the relative sizes of the mean and standard deviation. You could measure height in miles and it'd still be well approximated by a Gaussian.",4,1736401162.0
1hx305z,m66f8d9,"You suggested a far more complex approach over a simple and well known solution. This is frowned upon in industry. Imagine if you had to explain it to someone with less training in Statistics. 

My point about the normal distribution is that it can be a good model under reasonable circumstances (mean away from zero). Maybe it's not a good fit for your data, but your post gave me the impression that a positive variable (time) can't ever be modeled with a normal distribution because of the differences in the support. That's not the case.",24,1736398658.0
1hx305z,m664d5n,"Don’t beat yourself up too much. One interviewer can tank an offer and you don’t really know the reason. Maybe the interviewer doesn’t have an in depth theoretical background or maybe they were looking for a textbook answer. Sometimes it’s hard to tell, but you can always try to clarify and ask what type of answer they’re looking for.",4,1736394089.0
1hx305z,m66ryiy,"This is a really good takeaway, unfortunately. A lot of the value add of a DS in industry is in being able to apply simpler techniques broadly and well.",2,1736405134.0
1hx305z,m6v8229,Precise and concise,1,1736740355.0
1hx305z,m6bywxm,You've clearly never heard of a ACTION STATISTICIAN.,1,1736474057.0
1hx305z,m68cvfv,Do you know what an A/B test is and how it is used?,-2,1736434358.0
1hx305z,m6cjs41,This. I have a stats PhD and I’d hire you. Sorry your interviewer was a moron.,2,1736481414.0
1hx305z,m6j52ss,But what are you comparing in the A/B? Aren’t you trying to test whether the sample means differ?,2,1736571312.0
1hx305z,m6611ff,"Lesson learned to explain the simple answer / naive approach first!

And thank you for the thoughtful additional insights!",71,1736392816.0
1hx305z,m67oqn8,"I agree a z-test is appropriate. But that’s because a z-test is for rates/proportions which are averages of binomial data points. If you take a million averages of binomial data (clicks throughs) it will be normally distributed so this is CLT in action as you said and why z test is ok for proportions.

I disagree on you indicating CLT applies to answer I provided and that t test is more correct because distribution will be normal at large N. That is simply not true and a common misconception about CLT. CLT states that the sampling distribution of sample mean will approach normality at large N. It is about the sample means, not the individual or raw data your modeling. So yes, if I was taking the mean of time on app or the mean of click throughs (rates), then any Gaussian model is appropriate. But a time outcome with 1000 data points or a binomial outcome with 2mil data points is still log gamma or binomial distributed at large N, because CLT is about sample mean, not about the sample. The models we employ make distributional assumptions about the sample distribution and its residuals, not about the sampling distribution of the mean.",3,1736424970.0
1hx305z,m67n6uq,"But Central Limit Theorem states that the sampling distribution of the sample mean will approximate a normal distribution. It does *not* state that any sample at a large enough sample size will be normal. A binomial, log gamma (time) or whatever outcome will *not* be normal at a large enough sample size but if you take the mean of 5 million of those binomial, gamma or whatever else distributions, those will be normal. That is CLT.

https://stats.stackexchange.com/questions/204585/independent-samples-t-test-do-data-really-need-to-be-normally-distributed-for-l

Also, a linear model can definitely tell you the difference between two means. A linear model with a two level categorical predictor is statistically and mathematically equivalent to a t test.

https://lindeloev.github.io/tests-as-linear/#5_two_means",5,1736424200.0
1hx305z,m6bekcb,Yup I shared that same link elsewhere in this thread,1,1736467281.0
1hx305z,m670k23,"Of course it shouldn't be rejected outright - as someone else suggested in another comment, in an interview setting I'd probably give the simple answer first with caveats and then add the more complex answer with methods that are likely to work more generally.

Interviews are a lot about trying to understand what the other person wants to hear and whether they'd be open to discussions around that (depends on the personalities involved).",4,1736410278.0
1hx305z,m6703vt,"I get that, I'm just saying that it's possible to run into the issue I mentioned of the CI endpoint crossing the lower bound of 0. How well the sampling distribution can be approximated by a Gaussian is going to depend on the specific problem setting. If your n is large enough the standard error for the mean could shrink enough  that the (alpha/2)%-ile happens to fall above 0 so your CIs are fine. 

Yes, if you change units (height in cm -> height in miles) the shape of the sampling distribution of the mean will eventually resemble a Gaussian, but that's going to depend on whether the specific sample of size n that you have is large enough for the CLT to have kicked in.",4,1736409996.0
1hx305z,m66tyas,"In general, checking if the log(time duration) is “gaussian”, would be my first approach.",6,1736406267.0
1hx305z,m68e1x9,"Nope never heard of that in my many years of working in data science.

Is that where we compare the number of interviews we've proctored for both DS and SWE?",1,1736434742.0
1hx305z,m66a5cx,"I recommend people be practical and bias towards simplicity in their responses for job interviews. Extra points if you’re able to comment on pitfalls of being practical but the point of being practical is that you’ll get 80-99% of the answer with a simpler methodology.

Think of it this way:
- your interviewer has limited time and has other things to think about
- if you’re on the job, you’ll have competing priorities. doing things the statistically optimal way  all the time isn’t sustainable for your career 
- t-tests can be run quickly on large datasets

To echo someone else’s point, t-tests are perfectly fine in this scenario because the central limit theorem just works.",48,1736396435.0
1hx305z,m6cwi00,Naive thought: you will be very frustrated at a company that dismisses your advice and doesn’t let you use your expertise to do your job.,2,1736486738.0
1hx305z,m6dacpq,"CLT absolutely applies to this question. In a t-test, the distributional assumption we are making is that the \*test statistic\* follows a t-distribution under the null hypothesis. We don't care about the distribution of the underlying data, and in the case of a two-sample test, we don't even care about the distribution of the separate sample means.

The test statistic in an A/B test is a *difference* in sample means divided by a standard error. At standard A/B test sample sizes, the combination of CLT (for the numerator) and Slutsky's theorem (for the denominator) make it so a t-test works well in practice.

If you are skeptical, try simulating repeated A/A tests with realistic sample sizes (e.g., 100,000 per variant) with highly skewed (e.g., log-normal) underlying distributions. You will see that the statistical guarantees are generally met. The Type-I error rate will be quite close to the target alpha, and the p-values will follow a Unif(0,1) distribution.",5,1736494121.0
1hx305z,m67riox,"no thats your (common) misunderstanding please review the link i provided, and look at eg 
https://courses.washington.edu/psy315/tutorials/z_test_tutorial.pdf and wikipedia on ztest - comparing the proportions of *two* binomials

we are doing tests on a single sample mean (eg average time on app in user group a /b)

eg does mean time on app increase if we change the colour of the app",8,1736426280.0
1hx305z,m67rozy,"Interesting discussion OP. When you are using a linear model for hypothesis rather than a ttest in an ab context what assumptions do you need to meet, are they the same assumptions as the ttest or the assumptions of linear regression ?",2,1736426360.0
1hx305z,m688i5o,"> It does *not* state that any sample at a large enough sample size will be normal

Sure, CLT only mentioned distribution of means and t-test doesn't guarantee normality of original distribution. That's why I'm saying ""presumes the difference in means distribution can be a great signal to the difference of 2 test groups."".

But do you need the raw distribution to be normal and why? I don't think so. It's quite impractical to have ones, tbf.

That's the simplicity of t-test which makes it very widely used in business experiment

Indeed, your linear model, in the example, can tell the difference between 2 means. But what's the point of modelling if 2 means are already well separated? You even just show the visualization of 2 means and everyone agrees.

It's like saying fitting a model with this data:

|X|Y|
|:-|:-|
|0.1|0 (group a)|
|0.4|0 (group a)|
|0.6|1 (group b)|
|1.1|1 (group b)|

It turns out your model is just \`round(X)\`

You can literally bringing any complex method and trying to rationalize the use of it.",2,1736432875.0
1hx305z,m6wrru4,"Sample size for a sample is irrelevant here. The shape of any distribution does not depend on the units.

For a fixed sample size n and confidence level C, if the C% CI for the mean of a RV X does not include 0 when measured with cm, then it will not include 0 when measured with miles either.

P.S. For the height example, even the population distribution is well-approximated by a Gaussian.",1,1736771192.0
1hx305z,m67njf0,"Not to be rude, but why?",2,1736424374.0
1hx305z,m68ec0c,"Go get some experience, then. I don't talk to amateurs.",-1,1736434833.0
1hx305z,m67f6tn,"Wait but the CLT states that the sampling distribution of the sample mean will be approximately normal given a large enough sample size, *not* the raw data. If you take a mean of binomial data 5 million times, it will be approximately normal. But if you have a sample of 5 million for binomial data, a t test is not and will not be appropriate and you should be using logistic regression.

Thank you for your feedback here but I also disagree about the application of CLT here. It’s a common misconception that if you have a large enough sample size Gaussian models such as t-test or ANOVA can be justified because folks refer to CLT but the theorem pertains to the sample mean, not individual data or the raw mean! So let me know if you think I’m off here but I personally understand it as that’s a misapplication of CLT to suggest you can use Gaussian models for any dataset that is large enough

https://stats.stackexchange.com/questions/204585/independent-samples-t-test-do-data-really-need-to-be-normally-distributed-for-l

FWIW, I understand and often apply your other point of simplicity. But my personal philosophy is to do the more appropriate and more correct model that is more complicated behind the scene and tell the story potentially using the simpler but more incorrect t test.",-8,1736419732.0
1hx305z,m67vrnz,"Right but my impression was the distributional assumptions of a model are pertaining to the sample distribution. But perhaps given that the two proportion z test is valid and is statistically equivalent to logistic regression and a chi square test, maybe it’s the distribution of the sample mean? 

If it’s about the sample distribution or population distribution, a time based outcome will be approximately log normal or gamma normal. But if the model assumptions are for the sample, then a t test can be appropriate just as a z test is appropriate for proportions due to assumption that at large enough N averages of binomials will approximate normal distribution

Found this article on topic
https://www.reddit.com/r/AskStatistics/s/cJK8M4Z8SN",2,1736428116.0
1hx305z,m67ryl4,"The assumptions are the same, yup",2,1736426480.0
1hx305z,m74ouvo,"I was referring to this kind of scenario:
 https://stats.stackexchange.com/questions/78119/what-does-a-confidence-interval-with-a-negative-endpoint-mean

Using the normal approximation may lead to nonsensical CIs for a specific n if the sampling distribution for the parameter of interest for that n is skewed.

Obviously, changing the units isn't going to impact the shape of the distribution (and I don't think I claimed anywhere that it would).

I was simply saying that a skewed sampling distribution + the mean close enough to 0 may lead to nonsensical CI. So maybe the normal approximation isn't the best idea in these scenarios.

Do you have a reference that shows that height is normally distributed?",1,1736876261.0
1hx305z,m67q77h,My assumption is that the log(time duration on app) comes close to a normal distribution that is sufficient to apply a simple t-test. The log transformation is a common statistical approach to reduce skew for non-negative variables with bell-shaped distribution.,1,1736425669.0
1hx305z,m68eqz7,It's genuinely shocking to me that the Dunning-Kruger effect ended up being improperly applied statistics when you make it so very believable.,4,1736434969.0
1hx305z,m67jbxu,I gather 5 million binomial data points. I calculate the mean of those points. That mean is a sample mean and is therefore normally distributed under the CLT. I don’t need to calculate 5 million means.,19,1736422158.0
1hx305z,m67vm2t,"I think you are confusing yourself. Correctness aside, in your example of 5 million samples from a binomial distribution, what would you be using the t-test to test?",5,1736428053.0
1hx305z,m68qkb4,"Maths theories typically go like this: 

Assume X, then Y holds.  ie if X then Y.    
That doesn't mean that if X doesn't hold then Y doesn't hold.

So if we assume our **sample** is normally distributed, then the **sample mean** is also normally distributed and we can apply a t-test (or linear regression t-tests on coefficient..)

If our sample is not normally distributed and the sample is large enough then the sample  mean is approximately normally distributed (assuming CLT conditions hold etc...), and we can still apply a t-test.  

The core requirement is on the sample statistic (the mean, or the coefficient estimate), but the easiest way of achieving that is by making assumptions on the data distribution.",8,1736438609.0
1hx305z,m686vue,"But why conclude about log(time) instead of time itself? In other words, why the need to reach a normal distribution to compare two means? A sample size large enough will be enough to compare the mean of two non-normal distributions.",2,1736432309.0
1hx305z,m67mg0x,"I don’t think that’s correct. CLT is about the sampling distribution of the sample mean. You could simulate it yourself. Take a random binomial number generator. Simulate it 5 million times. That distribution is not normally distributed (at all). But if you take the mean and repeat it 5 million times it will be.

https://en.m.wikipedia.org/wiki/Central_limit_theorem

https://www.scribbr.com/statistics/central-limit-theorem/",2,1736423824.0
1hx305z,m67wilm,"Well that’s insulting hah. Why do you say something so harsh?

To be honest, Rmy impression was the distributional assumptions of a model are pertaining to the sample distribution. But perhaps given that the two proportion z test is valid and is statistically equivalent to logistic regression and a chi square test, maybe it’s the distribution of the sample mean?

If it’s about the sample distribution or population distribution, a time based outcome will be approximately log normal or gamma normal and the click through distribution will be binomial. But if the model assumptions are for the sample, then a t test can be appropriate just as a z test is appropriate for proportions due to assumption that at large enough N averages of binomials will approximate normal distribution

If a two proportion z test is appropriate and equivalent to logistic regression and chi square test, makes me think that it may be the sampling distribution of the mean we are making distributional assumptions about (I always thought it was for sample)

Found this article on topic https://www.reddit.com/r/AskStatistics/s/cJK8M4Z8SN

EDIT: FWIW, just found that z test assumes normality of sampling distribution and that was my mistake",-2,1736428420.0
1hx305z,m67nra2,"Yes and I’m conducting my T-test using the sample mean, which as you said is normally distributed. I am not conducting my T-test using the raw binomial data.

Edit: I don’t need to generate millions of sample means in order for a single sample mean to follow a normal distribution. You’re correct that I CAN generate a bunch of sample means to see the distribution visually form, but the point of statistics is that I can draw inference from a single sample.",10,1736424484.0
1hx305z,m6ady4z,How is what they said insulting and harsh?,6,1736455866.0
1hx305z,m6gof4g,"I apologize if you took offense to this as it was not meant to insult. I'm just trying to simplify everything and get to the root of the issue here and I think the simplest way is to just do the test. So, back to what I was saying, in your example of 5 million samples from a binomial distribution, what would you be using the t-test to test? In other words, what is the test statistic you think we're using?",1,1736541014.0
1hx305z,m67o2j6,"The distributional assumptions for the tests we conduct are about the sample itself. Your justification is appropriate if you were doing a test or model on rates or proportions that are averages of binomial data points. It is not appropriate if you are doing a test on the binomial sample itself because it is a binomial distributed outcome that violates assumptions of t test and general linear model.

We take a mean from the sample for comparison but the assumptions are about the distribution of our sample.",-1,1736424640.0
1hx305z,m67oq2x,"> Your justification is appropriate if you were doing a test or model on rates or proportions that are averages of binomial data points

And that’s what you’d be doing your T-test on. Is the sample mean aka proportion in sample A different than sample B. The point of CLT is it doesn’t matter what the underlying distributions are, because the means of those distributions will approximate to normal.",6,1736424962.0
1hx305z,m6rbyyn,I think you got a lot of very valuable commentary here by creating this post! Condensing this into your next interview will probably help you (and everyone else utilising this information) a lot.,1,1736697071.0
1hx305z,m67uipo,"You’re saying the sample mean is a normally distributed at large N, not the sample itself, and that’s the justification for a two proportion Z test right? If so, I agree. Sorry if I misunderstood",2,1736427596.0
1hx305z,m67vvsu,"Tbh it sounds like you don't really understand t-tests, or more specifically how they are applied to A/B tests.",13,1736428164.0
1hx305z,m67x0a5,"Good discussion to both of you. But just to then summarize, your original point in the post that the t-test is inappropriate in the A/B test is wrong. The t test is appropriate because it assumes the normality of the sample mean, which is satisfied in the example from the interview. 

However your other point about the equivalence between the t test and the linear model is spot on. Interviewers aren’t perfect and it’s just part of the game. This is particularly true with stats since there are so many different ways of answering the same question. Those ways are often equivalent but it can be jarring for a person who learned it one way to see that it’s equivalent to the other. 

I lost a job a long time ago because I actually argued with an interviewer about the complexity of some algorithm. I was definitely right in the specifics but obviously my approach was wrong since I didn’t get the job. Live and learn and move on to the next.",7,1736428614.0
1hx305z,m67xbp1,"Gotcha thanks!

But to be clear, the normality of the sample mean for the sampling distribution is only satisfied provided we have a large enough sample, is it not? E.g., if it was smaller we’d want to use a generalized linear model, permutation t test etc, right? That is my impression, but at larger N you may be permitted to be more flexible due to sampling distribution of sample mean approaching normality

Lmk!",2,1736428743.0
1hx305z,m67yd29,"You are technically correct but the N requirement is generally pretty small. Given the example was “time on app” and not “outcome after extremely expensive surgery” (or something like that), it’s safe to assume that you have a large enough N. 

But, from an interview strategy, asking about the sample sizes is a great way to demonstrate your thinking.",6,1736429154.0
1hx305z,m67yh5r,"In practice you either have enough sample collected to power your test at your desired MDE/fpr, or you don’t. If you have low N, your standard error on your sample mean will be larger, but if the treatment effect is enormous that may not be an issue.

There isn’t a single definition of “how normal is normal enough”. No one is advocating to run an AB test with 4 samples. But whether you need 100, 1000, 1000000 samples is going to depend on the context of your experiment.",4,1736429198.0
1hx305z,m67z9df,"I think a potential misunderstanding of mine may have been in thinking that the distributional assumptions of models such as t test and z test pertained to the sample, rather than the sampling distribution of the sample mean. If it’s about the sample, then a binomial or log gamma distribution would violate distributional assumptions. But if the assumptions of t and z test are about sampling distribution, then yeah CLT would play a role in allowing you to use z test or t test becsuse even if sample doesn’t approximate normality its sample means might",3,1736429500.0
1hx305z,m6b8q0y,"They pertain to the population. In the case of the t-test, what matters (for the error rate) is the distribution of the *test statistic* under the null hypothesis, which has a t-distribution under the usual assumptions (e.g. normality of the population). In the specific case of the t-test, you can use the CLT (and some other results) to show that the test statistic will have approximately the correct distribution at large sample sizes, as long as the population is reasonably well behaved. 

In the case of a linear model, what matters (for inference) is the distribution of the least-squared estimates (under the null hypothesis), which the CLT again says should be asymptotically normal under fairly mild assumptions. You're correct that this won't be exactly true if the population that the sample was drawn from is not normal (that is, the sample mean is only normal if the population is *exactly* normal; and the t-test *does* assume that the *population* is normal), but this can often be *close enough* to true for the test to work well even if the assumptions aren't satisfied.

That said, a GLM might be a perfectly reasonable approach to modelling time data. If the times are long enough to avoid the lower boundary, skew might not be a major issue. For shorter times, it's very common to model them with something like a gamma GLM.",3,1736465308.0
1hx305z,m6b9gnt,"Thanks this is exactly the clarification I was looking for.

So out of curiosity, if the z test is appropriate for proportions which are averages of binomial data, how is that justified? The population is not normal, but the sampling distribution of the sample mean is",1,1736465557.0
1hx305z,m6bbep2,"The distribution of the mean is *not* normal, though it can be close to normal at large sample sizes (as long as you're far enough away from the boundaries). That said, the z-test is still only an approximation, and with computers it's just as easy to work directly with the binomial cdf.",1,1736466216.0
1hx305z,m6bfp1e,"But that’s part of my confusion here with the Z test being valid for binomial data: You had mentioned that the z test and t test distributional assumptions are for population, not the sampling distribution of sample mean. But the population distribution for the binomial click throughs would be binomial right? While the sampling distribution would be approximately normal?

So other commenters on the thread and resources online indicate z test is appropriate for comparing proportions (which it is) at large N. But at large N, the sample means (if resampled over and over) would approach normality but that’s for distribution of sample means, and as you said, it’s about the population distribution not the sample mean distribution right?

Does my confusion make sense?",1,1736467661.0
1hx305z,m6bgn1g,"> You had mentioned that the z test and t test distributional assumptions are for population, not the sampling distribution of sample mean. But the population distribution for the binomial click throughs would be binomial right? While the sampling distribution would be approximately normal?

Correct (at large enough sample sizes, if the true probability is not too close to the boundaries)

> So other commenters on the thread and resources online indicate z test is appropriate for comparing proportions (which it is) at large N. 

Yes.

> But at large N, the sample means (if resampled over and over) would approach normality but that’s for distribution of sample means, and as you said, it’s about the population distribution not the sample mean distribution right?

What matters is the distribution of the test statistic. In the case of the z-test, we're talking about the distribution of the z-statistic, which is required to have a standard normal distribution under the null hypothesis. This is only *exactly* true when the population is normal (hence the assumptions of the test), but you can use the CLT to show that it can still be *approximately* true under weaker conditions, so that the test can still have approximately the correct error rate as long as the sample is large enough and the population is reasonably well behaved.",3,1736467975.0
1hx305z,m6bic7u,"This is clear so much! Thanks for listening and helping

You were so helpful",1,1736468542.0
1hy9am1,m6fk1z1,"It depends what the spreadsheet is for. I find it easier to read a small table whose purpose is a report of something of interest if it starts from B2. I vastly prefer a table of data to start in A1, for a variety of reasons",18,1736529331.0
1hy9am1,m6fk0qb,"Row 1 Column A. When you read the data, it defaults to A1.",11,1736529321.0
1hy9am1,m6fo7aq,"If it is simple display of data then A1. If the goal is for someone to interact with it, or display anything more meaningful than a table, B2 or even C3(im crazy like that.)",5,1736530525.0
1hy9am1,m6fkphr,This is not a meaningful question,12,1736529520.0
1hy9am1,m6fmv0h,"If it starts at row 2 then why would there be an unused row 1 in the first place? Or is one side arguing that column headers are not a ""use"" of the spreadsheet?",2,1736530137.0
1hy9am1,m6fo9pp,I always start AR427,2,1736530545.0
1hy9am1,m6ftcm5,"There is no absolute answer. Most times if I have a process fire off to a spreadsheet, I'm on A1 though. 

Rules and best practices should be based on reason so they're rigid but flexible.",2,1736531995.0
1hy9am1,m6gs9sy,So fun to see the folks who live in excel vs the folks that have never opened excel debate where data goes.,2,1736542147.0
1hy9am1,m6fp4w9,Who by the seven circles of hell is using spreadsheets in data science?,1,1736530794.0
1hy9am1,m6h0czy,"Spreadsheets are simultaneously a tool for data collection, data processing and data visualization. What makes sense for one use case may not make sense for another. If you’re doing data entry in a spreadsheet it literally makes no sense to add complex formatting, you’re just going to make it more difficult to analyze. OTOH, if you’re using it as a sort of dashboard to show analysis results, then it’s important to have visual cues like the one you describe.

This question is not adequately framed, and thus meaningless.",1,1736544557.0
1hy9am1,m6vdb34,"Depends on how many people will be using it and what it is being used for. I work in state government (where spreadsheets are king), doing data for lawyers.  If you have more than 1 person using the spreadsheet and anything in A1, it will get borked frequently. One of my main stats reporting spreadsheets, used by the chiefs, sources data from other workbooks. If I put one of the query functions in A1 I would have to fix it weekly. Lawyers have an uncanny ability to even get past cell protections to delete the contents of A1.",1,1736742402.0
1hy9am1,m6wwylz,"Your friend is a genius! I found that the content starting from B2 can be perfectly bordered! As we all know, the top border of the first row of Excel and the left border of the first column of Excel are invisible. This operation perfectly solves my troubles.",1,1736773550.0
1hy9am1,m6fmay8,"It seems as if they're counting the index/labels as a row/column. This is a mistake in every single software package that supports the structure. Even in programming, like Python, where indices start at 0, the 0th label is still applied as 1 would be in Excel.",0,1736529978.0
1hy9am1,m6gzqjk,"I do as you say, excrpt Data should start at A2, A1 is a link to the source",1,1736544370.0
1hy9am1,m6flgwb,But it's fun. So don't be a fun sponge.,0,1736529739.0
1hy9am1,m6fyybl,Empty row and column before the table starts.,1,1736533604.0
1hy9am1,m6fv4mg,"A recent use case for me was for Q4 sales planning to add propensity and forecast numbers to a bigger document fed by various team. The core audience was our C Suite and Sales leads and we added some transactional fields so they could simulate likely ending positions for the year.

The ML process lived entirely in the AWS VPC with scores moving into SFDC, Tableau and slack where needed. However, it was minimal effort for us to dump scores w/id's into a hidden sheet than it was for another team to do it.

That may not be data science work in the minds of many since the real magic happened outside of excel but my exec team raved about it. The final mile of getting value out of your products is critical. Sometimes, you do suboptimal things to immovate and then work on a better system to persist the features people like.

Ours automatically updated following a batch scoring action. The data from other teams took hours/days to update manually leaving us in a position to consult with leadership.

Could we have built a better mouse trap? Sure, but the process changes every quarter on how data is used so we get it done and move on.",2,1736532505.0
1hy9am1,m6fuup8,I work in government and the use of spreadsheets as ‘databases’ is unfortunately legion. It’s less of a hellscape and more of a purgatory of lowered expectations. ,1,1736532426.0
1hy9am1,m6h15we,"I don’t do any meaningful processing or analysis in spreadsheets. That said, sometimes spreadsheets are useful as deliverables for non-technical stakeholders.",1,1736544797.0
1hy9am1,m6srap0,"It's a fast and easy tool to have a small table (or several) in front of your eyes that you can easily interact with, make simple graphs that update in real time, etc. A better questions is why wouldn't you use a tool that's convenient and does its job?",1,1736711956.0
1hy9am1,m6fsakb,I can't imagine anything less fun than arguing about indexing,2,1736531694.0
1hy9am1,m6fzxg5,Why would this collection of cells be part of the spreadsheet if it contains no data? Spreadsheets are meant to process data.,1,1736533885.0
1hy9am1,m6g308k,My thought exactly,1,1736534772.0
1hxnq3t,m6awe5j,"I think you need a regression discontinuity design.

Basically, you have the app users that can sign up either before or after the removal of the outdated feature.

Even though over time, user outcomes might change,  users that signed up immediately before and after the removal of the onboarding process are likely very similar in their expected outcomes.

So, you want to estimate user outcomes as a function of sign-up time (might have a linear or quadratic trend) - although in this instance there is likely no effect of time, but still worth controlling for.

And then you test for presence of a sharp discontinuity in the trend at the time of the removal of the feature with a dummy variable (before/after removal).",9,1736461338.0
1hxnq3t,m6b2gq2,Posts like this make me realize how much more I need to learn. Following for the discussion!,6,1736463250.0
1hxnq3t,m6m5j2x,"You’re on the right track I believe ! Thinking out loud, you can try use any time series forecast model that forecasts the future evolution of your metric of interest. Then at the time of removing the feature, check if there is a difference between the observed (metrics from dropped feature) vs the forecast (what would have happened if you kept the feature)

It can get more complex, like what type of model to use, which regressors, Bayesian or not, is your metric sensitive enough, etc .. but for business you just might want to go simple and intuitive at first 

Another 2 cents , I would push back against “this can’t be done”. Maybe it’s not your place and I respect that , but to get to the next level of experimentation this needs to be possible .. you can’t keep 2x run time + causal inference whenever you want to touch the onboarding flow, it’s not sustainable IMO",1,1736620778.0
1hxnq3t,m6vgtun,https://google.github.io/CausalImpact/CausalImpact.html,1,1736743928.0
1hxnq3t,m6vh3aw,Do you think a mixed effects model would help?,1,1736744043.0
1hxnq3t,m6avfl3,"You can try doing a Bayesian Structural Time Series analysis. Since you only have 4 weeks of data, you can use it to estimate the time series post-intervention and compare it to the actual results. Not sure how much historical data you have, but the more data you have, the better, as it helps account for seasonality.

https://en.wikipedia.org/wiki/Bayesian_structural_time_series?wprov=sfti1

You could also try propensity score matching. It attempts to find comparable units to use as a basis for comparing the treated group.

https://en.wikipedia.org/wiki/Propensity_score_matching?wprov=sfti1#",1,1736461042.0
1hxnq3t,m6aucaj,You want what is called a difference in differences basically.,0,1736460706.0
1hxnq3t,m6axuww,"This is the only correct post here, though RDD with time as the running variable is tricky. An additional recommendation would be to use daily data if possible, as a lot of precision is required around the discontinuity. Also, do keep in mind the limitations of the estimated parameter (in sum, you can only identify the effect very, very close to the discontinuity, without much capacity for extrapolation towards the latest dates/present/future).",2,1736461791.0
1hxnq3t,m6auudf,I don't think diff-in-diff would work because you cannot verify the parallel trends assumption.,4,1736460860.0
1hxnq3t,m6bcisj,"Parallel trends is not something you can empirically verify, it is an assumption. The statistical tests are not really theoretically justified. In this case, OP has prior information that allows for identification under those assumptions.",-1,1736466593.0
1hxnq3t,m6bf3he,You can empirically observe parallel trends in the pre-intervention data under a proper diff-in-diff design,2,1736467459.0
1hxnq3t,m6btmya,"You still do not understand the actual statistical model. If you are going to employ frequentist reasoning and claim this, parallel trends NEVER holds no matter what statistical tests or eying of a figure suggest.",0,1736472296.0
1hxi5em,m6d0gtp,Anyone know how big the model file is?,2,1736488675.0
1hxi5em,m6dkgny,"29MB for classifier and 44.4MB for regressor, see [https://huggingface.co/Prior-Labs/TabPFN-v2-clf/tree/main](https://huggingface.co/Prior-Labs/TabPFN-v2-clf/tree/main) and [https://huggingface.co/Prior-Labs/TabPFN-v2-reg/tree/main](https://huggingface.co/Prior-Labs/TabPFN-v2-reg/tree/main)",2,1736500451.0
1hx286f,m65t79a,"It looks like you’re working for a university. They follow academic pay scales. Not bad for job associated with academia, but on the lower end for industry standards.",165,1736389967.0
1hx286f,m65syay,"If you have real experience, there are a few data analyst roles posted at Physician Health Partners in downtown Denver.  It's probably hybrid 1 day a week.  But would pay much more than you are making.  PowerBI skills will get you to that interview.  

Oh to answer the original question, yes you are underpaid.",30,1736389877.0
1hx286f,m65ta9g,Seems like a question a data analyst would answer,87,1736389996.0
1hx286f,m65wwvb,"Academia/sneaky nonprofits pay very low relative to industry standards for a lot of roles that are ""entry level"" or ""non-profit supporting"".  The most I've seen a data analyst for a university at is about 75-80k which translates to 2~3yrs of experience + masters or new PhD. My first job out of my undergrad as a data analyst was 72k + 6k bonus potential for a fortune 500.  Many entry level college roles start higher than that now.  You can also refer to the Bureau of Labor Statistics for more info on typical wages per job title as well.  Public universities must publish all wages/titles as well since they're state owned, you can look up Georgia, Texas, Ohio - California's is behind a big paywall unfortunately.",17,1736391291.0
1hx286f,m65woy0,"That's roughly what I earned in my first 2 years. In the 5th year now at 135k. Jumps happen suddenly, especially with job hopping.",15,1736391213.0
1hx286f,m667866,"Definitely underpaid.  I am a manager in a Fortune 500 company and our new analysts from undergrad start at $80-85k.  If you have a whole portfolio in Python, you should be commanding at least $100k",11,1736395227.0
1hx286f,m65yvhg,"Postdoc's get paid 65k and administration always uses that as a reason to pay anyone that doesn't have a phd the same or less. But tbh, Data Manager is an administrative role, so you basically landed this job right out of school, and 65k isn't bad for your first analyst job.",8,1736392005.0
1hx286f,m65snde,Depends on the work you do. What kind of place do you work at and what does your day-to-day look like?,11,1736389770.0
1hx286f,m66i6w6,"My first analyst job out of college was in San Francisco making $65K, granted that was 10 years ago. But I definitely considered that underpaid at the time and found a a lot higher paying places a year later",4,1736400034.0
1hx286f,m65uf7u,"What tech do you use for your reports/analysis/predictive modeling?

Sounds low for MCOL but you are in academia so it’s probably on par for your industry. Switching to a F500 corp would prob get you 80-100k with 1YOE",4,1736390398.0
1hx286f,m660yat,$85k total comp isn’t bad for less than 2 years of exp. Yes there are jobs that pay more but they are in other industries and also this job market is incredibly competitive. I’ve noticed salaries have come down a little bit over the past 2 years.,4,1736392782.0
1hx286f,m65uwlx,Low,2,1736390571.0
1hx286f,m6gbo5r,"University work has all of the crap pay you get in government work, and then the office politics crap of private sector. With as little time as you have right now you are going to have some stiff competition the way the market is, however, I’d expect to break $100 in even a M/LCOL city. 

That said, a mid level position on the west coast I would expect $150. 

And on the (semi) plus side, there are a lot of opportunities for new home construction data analytics in LA. We have a lot of work that’s going to take place in that area, if you have any experience with insurance, auditing, or home construction, I’m sure there are opportunities out there. 

We did a ton of work looking into PG&E a few years ago. I’m sure Socal Edison or the other power companies are going to have a lot of data to work through. I would expect P&C insurance companies will be posting positions here soon. 

Depending on how long things go, you may be able to work remotely. 

If you want to stay in government, I’m also sure the city and county are going to have a hiring spree here in a bit to process the aftermath of this.",2,1736537281.0
1hx286f,m66lr3r,"I don’t know if this has been mentioned already, but it looks like you are being paid at a data analyst rate. Data analyst roles and data scientist roles are not the same when it comes to compensation, at least in my industry. My entry pay was 50k as a junior data scientist - hopefully this helps. ",1,1736401801.0
1hx286f,m66pam5,"Hi I want to Move on from Digital Marketing to Data Science, Can you suggest where we get live project for learning purpose.",1,1736403657.0
1hx286f,m6abqph,That seems pretty average for my area but I am in a LCOL city,1,1736455222.0
1hx286f,m6d1b1o,"This is what I’m making in clinical research in Florida as my first big girl job. If you were a LEAD, you should absolutely get way more than that.",1,1736489111.0
1hx286f,m6v6e9q,Looks like a fair pay,1,1736739731.0
1hx286f,m662eef,"Definitely underpaid, when I was first looking for Analyst roles with just a STEM degree and 2 YOE in a non-analyst role that did data analytics I was getting offers of $60k - $85k and that was back in 2020 - 2021. 

So with a Masters (which usually counts as 2 YOE especially if your masters requires projects, Co-Ops, and/or internships) and 1.5 YOE I would definitely be looking for $85k minimum.

Also, this is assuming you have solid SQL, Python, and  Data Visualization, and some Statistics experience which is something I had.

Keep in mind, my job before an analyst required a decent amount of analytics & database/SQL work along with some statistics so when I started my first actual Data Analyst role I was way more technical than even the senior analyst at my company - that transferable experience translates to higher pay.",1,1736393332.0
1hx286f,m6bj13j,"If you get up in the morning and go to work because of money, you are going to very disappointed.",0,1736468771.0
1hx286f,m66en2o,Who knows? If you are not happy look elsewhere,0,1736398391.0
1hx286f,m65sn8d,[removed],-11,1736389768.0
1hx286f,m65tog7,"That's fair. Yeah, it sucks. Can't wait for an industry job lol.",15,1736390135.0
1hx286f,m6q4jb6,I still in my 3rd year but was looking into getting a job at my university. But i didn’t know university jobs pay pretty low?,1,1736677663.0
1hx286f,m65t0xv,Many thanks!,6,1736389904.0
1hx286f,m65tj2z,"Lol yeah, and this is how I'm collecting the data 😂",70,1736390082.0
1hx286f,m65xjbd,"This is really helpful, thank you!",3,1736391517.0
1hx286f,m667s3i,"Thank you, that's hopeful! 😌",2,1736395454.0
1hx286f,m66oce4,"If you don’t mind me asking, what industry are you in? Also, are you a senior analyst or principal analyst?",2,1736403150.0
1hx286f,m667xjm,"Wow. Yeah, that makes sense. I've been getting bites for positions in the $100-150k range, so hopefully I can land an offer soon. Thank you for the perspective!",7,1736395516.0
1hx286f,m66o99a,I’m assuming these new analysts have zero years of experience and have just a bachelors degree?,1,1736403104.0
1hx286f,m6blfvp,What does a portfolio in Python entail?,1,1736469564.0
1hx286f,m6xzk88,"Can you provide an example of the portfolio?

I’ve been a DA for 3+ years now, and code primarily in Python (background was in math, so it included heavy coding). I make $65k a year… which includes benefits lol

Wondering what I can do to present my resume or portfolio better, because I have a hard time getting interviews, but the interviews that I do get lead to a job offer… then I end up overqualified for the job.",1,1736786695.0
1hx286f,m66isxa,Wow that is so corrupt they use that as an excuse. From my experience in academia that totally adds up.,4,1736400327.0
1hx286f,m65tafv,"I work in Institutional Research, and build dashboards, do predictive modeling, and am the lead analyst for like 4 colleges at a university.",14,1736389998.0
1hx286f,m65urbi,"That sounds amazing. Currently, they have me using R, but I have a whole portfolio in Python. I also use SQL and Tableau on the daily.",6,1736390518.0
1hx286f,m65swlp,I heard jenova AI did 9/11 and killed my grandma,9,1736389860.0
1hx286f,m65svqp,[deleted],0,1736389851.0
1hx286f,m68q7xt,My wife is applying for a job at a university at a higher title than she's ever had and it'd be like a 35% pay cut. It's freaking harvard too lmao,16,1736438505.0
1hx286f,m694e3q,"Just consider the perks you have compared to industry. Maybe better worker protections, benefits, union, workload, etc?  Something to keep in mind",4,1736442665.0
1hx286f,m671qbl,"You can do it. I came from the academic side. Ended up making 5-6x my salary. It takes some time, but you’ll get there. You just have to be persistent in this field.",4,1736411024.0
1hx286f,m6tejkr,"Most public universities in the US have publicly visible salaries. That should give you an idea. Private universities don’t pay much better in non tenure track positions. 

The ones making the money are the named and tenured professors. Everyone else gets paid below market rate. It’s the public sector.",1,1736718650.0
1hx286f,m65ty9o,lol that’s fair.,15,1736390231.0
1hx286f,m67by6v,would probably help in you getting that industry job lol,1,1736417695.0
1hx286f,m6rmssh,"I live in ATL. Got a jr data scientist position for $85k out of college. Am working on my masters and made a  switch to a startup for $110k (now $115k after one year there). I realize I’m lucky and it’s hard to get. 

But I mention to say it’s definitely possible to get 85k+ in industry for an Analyst role.",2,1736700416.0
1hx286f,m670v9i,Senior in agriculture,4,1736410475.0
1hx286f,m66wjm5,"I would say 0-1 year of corporate work experience.  A couple we get from our intern program.  The rest usually have other internships/project work.  We have, on occasion, taken one or two with absolutely no experience but blew us away during the interview process",3,1736407806.0
1hx286f,m6z4pn7,"Where are you located?  On the resume, I wouldn’t focus on the python technical skills but more on the business case for it.  Why wad Python needed?  How much time did it save? Was there any monetary benefit from it? If you can quantify the benefits, that would help.  Then during the interviews, you can detail exactly what you did and go into the nitty gritty technical details if you need to",1,1736798613.0
1hx286f,m66id5y,"I also work at a university, but within a college. What have you done when tackling classification problems with imbalance issues? 

Curious what others have done in higher ed. Also what's your math background, if you don't mind.",3,1736400118.0
1hx286f,m65yeyl,"Sounds like you have the chops to be making at least 80k. The market is tough but you have good experience and an MS. 80-100k at a big company is very reasonable.

I’m only at 2YOE so take my opinion with a grain of salt. But I have a job using similar tech (python instead of R) and started at 80k out of undergrad. The people that got hired after their MS start at 100-120k.",4,1736391838.0
1hx286f,m65ue3w,"Just so you know, that account posts nothing but comments that allow them to name drop the service they're shilling, so I would take the info they offer with a grain of salt, their posts are just disguised ads.",4,1736390387.0
1hx286f,m69fhqy,"That's true. It's fully remote and they don't care when I work as long as the work gets done - my boss is very cool. We're also ""recession proof"".",12,1736445871.0
1hx286f,m69fnby,Thanks for the encouragement! 😌🙏,1,1736445915.0
1hx286f,m6zir2r,"I’m based in Los Angeles, but my job is fully remote and the company is based in another state. That might be part of why the salary is lower, and I’m competing against people with FAANG experience.

I use Python for a lot of random tasks and projects, but honestly thinking in code helps with everything system wise in small ways, which I have a harder time adding to my resume. My managers are always super happy, but I don’t feel like I’m learning as much on the job.

I quantify the business value where I can - e.g. “x report led to $$$ contract” in rare cases, it’s usually “my code / script / automation of workflow saved my team x hours.” More like analytics engineering?

However, as a lowly humble DA I normally don’t get access to money information haha, like how much my team or company was paid or profited as a result, that would be cool to know though! My work is also just one part of a team that works with marketing and business, so I don’t know if I feel comfortable claiming my project or task led to $$$.",1,1736802714.0
1hx286f,m69gpjk,"Yeah, that is a huge problem. We generally try to control for it, but it's hard to mitigate.


I have my bachelor's in econ, came from engineering, and used to tutor in math (I love math haha, my coworkers used to call me a ""glorified mathematician"").",3,1736446223.0
1hx286f,m66cszg,Man I need to job hop too. I started after my MS at 75k and now I'm at 3 YOE,4,1736397581.0
1hx286f,m66kx8g,"It’s tough out here, 75k is still good! I got luck to get in right at the tail end of covid hiring so salaries were up.",2,1736401379.0
1hwmsd2,m675b61,"it worked with runApp() line code, problem solved",3,1736413360.0
1hwmsd2,m630fqt,I would try a symlink in the shiny app’s www directory,1,1736358719.0
1hwmsd2,m65zqy2,"I think you put the images in a www folder and reference them without the ""www/"", simply the filename.",1,1736392331.0
1hwmsd2,m67m8k5,What is shiny ui? I have never used it before. Can someone explain it to me?,1,1736423719.0
1hvzskd,m5xhrs6,"I think they are quite useful for features that have to be standardized across the org. For instance, there should be many ways to compute monthly active users. But you need consensus across the org. In such cases you would need to compute and save it in one place and let everyone use that. That being said, dumping every feature from every project results in a mess. Not unlike what you are dealing with.",61,1736281217.0
1hvzskd,m5xzl2v,[removed],32,1736286314.0
1hvzskd,m5xcl1s,"Copying and pasting a few dozen lines of SQL can eventually lead to huge problems. I would avoid this at most costs, when multiple models and teams are building in tandem. 

I generally agree with your take on too much complexity and feature stores. IMO it really only makes sense at large companies, like truly large, with a big ML presence. Eventually no one knows why something was built in some way and it was likely just because someone was paid to do *something* when there wasn’t really anything to do, so they went and built a “best practice” system where it’s not needed, write shit documentation, put it on their resume, and leave.

The real problem is always communication and orgs try to slap technology over it like it’s not actually a people problem.",48,1736279696.0
1hvzskd,m5xo39k,"My company's feature store has thousands of features. You don't simply copy and paste a few lines of SQL One simple case to demonstrate this that comes to mind is that we have had cases where there have been bugs discovered in a feature. With a feature store, you update the feature and changes get propagated automatically, models get retrained and scores rerun based on the updated features. If you have used copy/pasted code (maybe with some minor adjustments here and there because why not), this is a huge fucking ballache to deal with. And it just gets worse the more models you have. Copy/pasting SQL code is not a strategy that scales to 10-20 models and beyond. Do you know which models use the offending piece of code? Are you going to crawl through the code of all your models to figure it out?

I work in financial services and int his domain, I have always experienced feature stores as huge wins. They decrease iteration time, enforces naming standards and good documentation practice, makes the preprocessing steps far more homogeneous across data scientists, and much more. They also allow you to understand data provenance and which models are affected by which pieces of underlying data (if the original source changes or malfunctions). If you're just copy pasting SQL code, I don't see how you're going to be doing any of this and in my world that just doesn't fly. Obviously, the stakes in financial services are a lot higher than many other domains, and the regulatory environment is very different as well so that may impact my view on this.",25,1736283024.0
1hvzskd,m60thod,"My org has been using a feature store 2 years now and it's fantastic. For background, we are a global company operating in around 60 countries with billions in revenue and our models receive millions of requests every day. 

The feature store has been a huge boon and has unified the location for where models grab all their data. This means there is a single point to update if data changes (which happens somewhat regularly in my org due to the business and scale) and also we've integrated feature drift / quality checks so we get automated reports every day / slack alerts if things break (which again, happens often because there are hundreds of data sources and things break). It allows uniform documentation and feature re-use is quite high as our models operate in similar domains across the app. For example, features that we re-use quite a lot are customer-product interactions and customer-vendor interactions. We are currently working on adding in online features and integration is trivial to already existing models. 

I can appreciate that if you don't have many models it not required, but for our use case it has made our lives easier and more efficient. Just as an example, each model would be trained on a per-country basis so a single model would have 20 separate versions and the feature store tables have data for all the countries. In Q1 this year our scope has expanded to include every country we operate in which is ~60 so now we just have to update the SQL queries in a single place to have the data flow into the feature store and it will work. Due to our business, different countries have different data formats we can just update a single location instead of multiple. I think we have 15ish separate models in production across our scope (each with ~20 country-dependent versions) so monitoring all the data across these would be way too much work and not sustainable. Models are agnostic to which countries they operate in and that is specified only as a training parameter in the training DAG.",9,1736326776.0
1hvzskd,m5xklzk,"Everywhere I've ever worked, the raw data is garbage. You need some infrastructure on top of it or most of your time will be spent extracting features. And then having to discuss at great lengths why the base features you have don't add up the same way everything else does.",5,1736282036.0
1hvzskd,m60gk5f,"I feel like they're a bit superfluous if you have a good kimball-style dimensional model, as the features often end up very similar to fact tables.

And if you don't have a dimensional model, then you possibly want one for general analytics reporting.

So I think the use case for feature stores specifically is a bit narrow.

That said Databricks has some built in tools for real time inference built on the feature store, which can help with deployment.",4,1736318852.0
1hvzskd,m5xaurb,Yes… it works when their a plan in place to manage. Many times things get built because it’s easier to just do the development without considering design and implementation,2,1736279201.0
1hvzskd,m5xed8p,"it depends on how mature the model is, how good and robust the underlying data sources are, most of these times it implies a large company with very well defined process.",2,1736280215.0
1hvzskd,m5ximkc,"I agree with you on some points (too much complexity of many feature stores offered by MLOps tools).

But I disagree with you on the ‘copy and paste SQL idea’ because it leads to unnecessary duplication of work which becomes expensive if many data pipelines are doing the exact same thing. It is more efficient to run it once and use it everywhere else. 

If done right, feature stores is an important cost-saver in the ML toolkit. But as you rightly said, most options out there contain unnecessary bloat.",2,1736281464.0
1hvzskd,m5ysktq,Only time I’ve used it was one hot encoded holidays for time series related stuff,2,1736295428.0
1hvzskd,m606ki8,"Yeah it's just glorified Postgres (or Redis).

The orgs most likely to implement these are ones that don't give good eng support to their data scientists or who hire data scientists without much engineering background.

Everything becomes overengineered before it's actually proven to be a problem, and models are abstracted as at best single ephemeral docker containers and at worst strict and limited special format artifacts rather than as full fledged services.

Just treat your models like proper code, and treat the service that runs the model as its own service and not as a single entity inside a metaprogramming framework for deploying machine learning models.",2,1736313701.0
1hvzskd,m60qvv6,"DBT is not a feature store though. It's a transformation framework that solves a lot of DE issues.

But yes, I would rather just package the feature engineering code than make use of a feature store.",2,1736325087.0
1hvzskd,m73mypc,"Nah bro you haven't had enough stakeholder interaction if you're bitching about feature stores. 

The worst hell hole to live in is where you calculate a KPI one way, someone else does it another way, and then 3 other people all do it their way. 

Leadership, decision makers, everyone will keep asking why all the numbers are different, tell you to reconcile, you will reconcile between Team A and B only to next week get compared with team C and it's just a fucked up mess that goes on forever until someone gets a decision maker to weigh in on what calculation makes the most sense which means mapping all the data and having them be knolwedgeable enough to know which underlying tables are best for the specifc KPI. 

I'd much rather have someone who's job it is to define these features than waste 4 months reconciling one between all the reports in the company.",2,1736864571.0
1hvzskd,m5xd8yc,"Do you hook up your data governance tools to your modeling pipelines then? Also, how do you reconcile your features?",2,1736279887.0
1hvzskd,m5xglq2,"The cost of copying and pasting a few dozen lines of SQL may be larger than you think.

Exponentially larger if these queries are running constantly by more than one pipeline (i.e. realtime analytics)",3,1736280873.0
1hvzskd,m5ybhlw,"The amount of times i saw insane cloud infrastructure for models that could easily be trained locally on a laptop... with less than a few gigs of training data...

You will understand that this is not ""needless complexity"" but ""garbage kpi promotion complexity"" or just ""wasting time on shit wage complexity""",1,1736289883.0
1hvzskd,m5z912q,"I think feature are overly complex and often useless but they are necessary.

What you really want is a centralized store of data or a way to centralize different stores. Often the only way that gets actualized is a feature store because it is fancy enough for someone with competence to take ownership of it.

Also I disagree that copying sql over and over is simple. DRY is paramount, and if your volume is large enough, doing the same transformations for 10 different projects is unnecessary. Data storage and compute are cheap, but not that cheap.",1,1736300880.0
1hvzskd,m61d76x,"The only reason I found I needed a feature store is to avoid train-serve skew. If your data transforms run independent of the model serving code then feature stores are helpful. I've used them extensively in recommendation engines when I need to update some feature whenever a user makes a purchase, etc",1,1736338500.0
1hvzskd,m61rare,"The use of dbt/feature stores itself doesn’t seem like the problem, it might more so be how they were setup at your company.

We use dbt for everything, and the quality is very high and has been compared against raw for accuracy. The key reason for all of this is standardization across the business, not just data science. Analysts/DS/PM all had different ways of calcing and defining metrics that lead to a lot of wasted time “aligning”, now we’re always aligned and the results of analysis and DS projects are apples to apples.

If you can confirm leakage with your DE team, have them fix it. Otherwise just use it.",1,1736344450.0
1hvzskd,m65p4is,"It's essentially change controlled and trusted features for core entities in the business, and some metadata tracking for the business logic and datasets used to generate models. 

The can grow naturally as well. Start with a 1.0 of some features, and as people require/build more it can be done in the df Definition and brought to change control for future use.",1,1736388512.0
1hvzskd,m5xo21x,This post is such a great microcosm of this sub. OP doesn’t even understand the tools he’s using yet has an opinion on them in general,-1,1736283014.0
1hvzskd,m5zeqvp,"Your dozen lines of SQL are hardly traceable down the line even if you still work there, never mind if they have to find a replacement for you.",1,1736302862.0
1hvzskd,m650v58,[deleted],0,1736380266.0
1hvzskd,m5xq2eg,"You forgot the fact that these feature stores sre very useful to get a promotion, how else are people going to get to lead/principal otherwise? ",-3,1736283580.0
1hvzskd,m5y9lfh,Habibi so are neural nets for 99% of things,-1,1736289303.0
1hvzskd,m5y4jtj,"This. Calculating KPIs is hard. When budgeting, amortization, dead invoices and accruals can take years, calculating ongoing financial KPIs becomes really hard. And if you want financials to add up, or if you want any stats to be ""splittable"" by some system of features, like brands, products, or regions, it gets even harder. So basically it's a choice between complete chaos, where no two presentatons match (and sometimes no two slides within a presentation match), or you need a good, well vetoed feature store.",14,1736287767.0
1hvzskd,m5ym6f8,I feel like you and I worked at the same type of companies. A lot of the pro-feature store arguments seem to be from highly regulated industries. But I’m the chaos of tech it feels over-engineered ,3,1736293323.0
1hvzskd,m5yi7mi,">Eventually no one knows why something was built in some way and it was likely just because someone was paid to do *something* when there wasn’t really anything to do, so they went and built a “best practice” system where it’s not needed, write shit documentation, put it on their resume, and leave.

Amen brother",13,1736292018.0
1hvzskd,m5xf6dy,"My beef is that every company with more than 1k employees thinks they're a ""big company"" or going to be a ""big company.""",6,1736280452.0
1hvzskd,m632756,"OP doesn’t understand the basics of version control, observability, code lineage, development time, scaling, staging data, and a bunch of other concepts to have this opinion.

If you had even a cursory knowledge of any of this, you couldn’t possibly think maintaining models with decentralized sql queries against raw data is a good idea…

Even at a small company, this is a terrible idea. DBT costs like 100 bucks a month. Worth it alone for the change management and continuous deployments",6,1736359226.0
1hvzskd,m5xeybd,Ha. Data governance. Cute.,19,1736280386.0
1hvzskd,m5y0h3l,Why don't you provide rationale then? Your comment is pretty much just criticism without any point,5,1736286571.0
1hvzskd,m5xwa0x,Too many tools is clearly a problem of the industry ,2,1736285355.0
1hvzskd,m65a14o,Thanks Gartner,1,1736383349.0
1hvzskd,m5z6elq,The thing is that none of that means it has to be complex lol. People just go building systems that don’t need to exist,1,1736299995.0
1hvzskd,m5yc9bt,instagram had 13 employees when Facebook bought them for $1 billion.,-6,1736290119.0
1hvzskd,m5xff1s,"Well, feature stores that don’t serve any purpose do not, in fact, serve any purpose. It’s true. 

But, I would venture to guess your company doesn’t use them to their fullest.",2,1736280524.0
1hvzskd,m5y68qm,"Production data pipelines are not just “copy and pasting a bunch of SQL”. Orchestration exists for a reason - observability, materializations, cutting down development time, version control. DBT does a heck of a lot more than just “storing logic”. These layers exist for a reason. 

Writing SQL for production ML models against “raw data” in a decentralized way is such bad practice it’s hard to not just laugh",7,1736288278.0
1hvzskd,m5y2it9,"I've worked at a range of companies, starting to FAANG and mid size. The way some folks at my current midsize talk, you would think that feature stores are the only way to build data pipelines. What OP is right to point out is that the complexity particularly in maintenance and the ""bang for buck"" aspect is not considered at all when everyone just wants to build a feature store. My old unicorn startup now IPO'd company did decide to build out some datasets and task a team with maintaining them, but they were quite specific about what datasets they would bother to get such a high degree of agreement on. Maintaining those things takes a commitment of resources. My current midsize has a bunch of feature store this and feature store that, some of which aren't much used, the minute the use case stops suiting the general case (which happens often) things bifurcate and then now there's a lot more stuff to be maintained.

When I was at Facebook, most datasets were just presto tables with documentation - modelling is done by too many people to require things to be unified and consensus around the many different use cases.",5,1736287163.0
1hvzskd,m5y4y3y,Good luck,-1,1736287886.0
1hvzskd,m5zrxda,What does that have to do with with this?,12,1736307572.0
1hvzskd,m5xgxp0,"Sorry, to elaborate a bit, before I went to meetings for a living, feature stores for large financial firms were my thing. 

So, one use case is complex features, like taking input from other models, streaming services, etc. Having a handoff place between DE building the pipes and DS is useful. Governance can then audit the data as part of a normal governance pipeline without blowing up your modeling pipeline. 

Another use case is highly regulated data that needs strict controls or periodic audit with lineage. It’s a lot easier to build it separate then it is to include it in script.",3,1736280971.0
1hvzskd,m5xm0nq,"This is actually super useful to see the ""ideal"" case. Yeah we aren't doing that kind of strict governance stuff. It's just basically ""where you write SQL"" by default.",1,1736282439.0
1hvzskd,m5xmjxe,"In fairness, I force my team to use “unit tests” on SQL queries. Most new hires think I’m a psychopath, but those little tests catch more bugs in the data flows than an entire QA team.",1,1736282590.0
1hw5s76,m5yvcbt,Whatever replicates your production environment,43,1736296326.0
1hw5s76,m5ynrbr,"mamba.

Edit: More than one person asked why, its because its faster and manages the package versions better.",55,1736293842.0
1hw5s76,m5ypiot,Honest question: why? Why not just use Python + venvs?,52,1736294416.0
1hw5s76,m5yxs01,Lately I’ve been using venv instead of conda. Much easier to manage packages for specific projects.,13,1736297125.0
1hw5s76,m5ypsol,uv,18,1736294508.0
1hw5s76,m61vexz,Neither. Docker.,5,1736345965.0
1hw5s76,m5z5ty4,Miniforge is now the requirement over miniconda at my place of work (U.S. federal gov).,3,1736299802.0
1hw5s76,m5yy4eo,[7 Reasons to Switch from Conda to Pixi](https://prefix.dev/blog/pixi_a_fast_conda_alternative),7,1736297237.0
1hw5s76,m5z0py1,uv (rust based superfast),5,1736298092.0
1hw5s76,m5z8pf3,"if non python dependencies is needed then the equivalent would be pixi.

otherwise mamba",2,1736300771.0
1hw5s76,m5zr0gg,"Miniforge. Everything I need is available through the `conda-forge` channel. Mamba is now included by default as well.

However, I've been using some `uv` venvs in some projects, and pixi in others. Ultimately I think it makes sense to choose on a per-project basis which environment type(s) make sense. Both `uv` and pixi are easy to install and remove if you don't like them.",2,1736307228.0
1hw5s76,m5zs6jd,Neither. Pyenv virtual environment,5,1736307670.0
1hw5s76,m60eomh,None of the above,4,1736317814.0
1hw5s76,m60evr6,"Mamba if dealing with non-python dependencies (looking at you PyMC), or uv if I don't need to worry about that.",1,1736317921.0
1hw5s76,m60pcy3,"Neither. 

Uv",1,1736324118.0
1hw5s76,m60unaq,Jupyter + Daytona,1,1736327535.0
1hw5s76,m622msl,I bought the new Mac Mini M4 last November and all I did was installed VSCode and python + venv and I was already set to go. I always use a requirements.txt file for each project.,1,1736348430.0
1hw5s76,m628zvr,Been using docker development containers and miniconda lately. Works well,1,1736350465.0
1hw5s76,m63vwx6,[pixi.sh](https://pixi.sh/latest/) is what I use now if I need something from the conda-forge ecosystem.,1,1736367822.0
1hw5s76,m66q81g,Nix,1,1736404164.0
1hw5s76,m6776pu,"as someone building AI products, i mostly use miniforge these days. main reason is that it defaults to conda-forge channel which has better package compatibility + more up-to-date packages compared to anaconda's default channel

quick pro tip: if ur doing heavy ML/DL work, try using an AI assistant (like jenova ai or others) alongside your IDE. really speeds up debugging tensorflow/pytorch issues and helps with env setup. i personally use it daily for coding

but honestly both miniforge/miniconda work fine, the differences are pretty minimal in 2025. just avoid full anaconda install - too bloated",1,1736414604.0
1hw5s76,m69qf62,Miniconda I think,1,1736449015.0
1hw5s76,m6o5o29,Tbh it doesn't matter. I have gone my whole life not using conda at all.,1,1736644093.0
1hw5s76,m6qznsm,"For me, neither. I'd use devcontainers instead.

Conda (and its variants) had its day in the sun when you couldn't get high-performance binaries from pip. But, it has always been just flaky enough to be frustrating. When pip got binaries right, conda didn't have much left.

Devcontainers have been mature enough for a couple years to be the best option. You get a container and an OS package manager, so you can get basically whatever you want to install. The configuration lives in a repo and benefits from automation in VS Code, making it trivial for you (on a new/another computer) or a colleague to get a matching environment (including . If there's any kind of deployment, you can match up to that environment, too. All along the way, your host computer doesn't get polluted.

It's possible you have something that won't run in Docker, or a platform without GPU passthrough. Even so, there may be better workarounds than using conda.

Also, there are prebuilt devcontainers with conda, so you could have both if you want. I just much prefer pip in devcontainers, since it's already an isolated environment.",1,1736692917.0
1hw5s76,m5zdk2j,uv. rip conda. miniforge btw,0,1736302443.0
1hw5s76,m5z5tc1,There it is,6,1736299796.0
1hw5s76,m5zfhx1,Isn't libmamba the default solver for conda now? Is mamba still faster?,14,1736303128.0
1hw5s76,m5zfodn,Miniforge comes with mamba though right?,8,1736303192.0
1hw5s76,m5yrbls,"Ok, but why?",6,1736295015.0
1hw5s76,m5yorlm,This is the correct answer!,3,1736294171.0
1hw5s76,m62xg35,"yup. or uv (it’s not that big of a deal,
OP, give it a try). conda is so freaking slow now.",1,1736357853.0
1hw5s76,m5yx9eg,Why Mamba instead of Anaconda?,1,1736296955.0
1hw5s76,m5yu3ep,Conda supports non-python dependencies.,23,1736295922.0
1hw5s76,m5yzfe8,"CV2, PyTorch, niche libs dealing with Cuda stuff",6,1736297666.0
1hw5s76,m5yww4k,Handling non-Python dependencies and multiple versions of Python. And uv isn’t going to help you install libfftw3 if that’s what some package you need is expecting.,6,1736296834.0
1hw5s76,m649pid,I would if I could make PYMC work without it.,2,1736371818.0
1hw5s76,m66p1h1,Because Conda is easier so beginning data scientists or people that don’t have to deploy into production prefer to use it. Docker and/or venv are the way.,2,1736403521.0
1hw5s76,m5yy0t3,The honest reply is that I got used to them and they worked well for Data Science (for me). Just want to keep using one or the other while I learn a new way.,3,1736297205.0
1hw5s76,m5ys19l,Today I found a reason not to. Needed to run something on a GPU real quick so I copied some files to ec2. Forgot I had a .venv in there and it proceeded to copy everything up in there as well which included every binary and it was so long,3,1736295251.0
1hw5s76,m601clf,"Zero reason nowadays to use anything but \`python\`, \`pip\`, and \`venv\` (or \`virtualenv\` if you're a nushell weirdo) to manage all your venvs.

Even stuff like \`pyenv\` and \`uv\` don't make sense to me, IME people who start using stuff like that do so because they don't understand their terminal/shell enough to figure out how to order their Python version bins in their PATH variable.",-5,1736311381.0
1hw5s76,m5zhuzg,Is it just best to go vanilla python? Prod pipelines in my company are all set up that way. Might as well just bite the bullet and get used to how deployments looks like so there are no surprises. Anyway python isn’t my primary language at the moment so others may know better.,0,1736303954.0
1hw5s76,m5yx8qe,"Doesn’t handle the non-Python dependencies, which is the main reason conda exists.",10,1736296949.0
1hw5s76,m5yr49y,"Seriously. More people need to migrate to this tool, it's freaking amazing and sooooo fast.",2,1736294948.0
1hw5s76,m5ywur9,What is uv?,1,1736296821.0
1hw5s76,m5yzr0x,"Been meaning to check this out tbh, probably just on personal stuff at first or if I get a new project at work",1,1736297771.0
1hw5s76,m5za7uw,Do you have any idea of why compared to miniconda?,1,1736301285.0
1hw5s76,m60vzsu,I tried (almost) everything else. This is the only one that works consistently on my Macbook.,3,1736328418.0
1hw5s76,m5zlejm,Yeah I don't know if it's needed anymore,-1,1736305180.0
1hw5s76,m60htdm,Yes. It's what I use when creating environments,3,1736319564.0
1hw5s76,m5zfxhz,It solves packages much faster. So I am told.,2,1736303280.0
1hw5s76,m6012gt,Why would you want to manage system-wide dependencies with your Python venvs?  That sounds like a bad practice to me.,9,1736311260.0
1hw5s76,m64o0fv,I'm in bioinformatics and there are all sorts non-python tools that are hell to install (OS specific c++ complilers etc.) and conda is a dream come true for these.,2,1736376056.0
1hw5s76,m601omi,"How would Conda have helped over simply generating running the \`--dry-run\` flag with pip and generating a lock file to copy over?

(also, that's why I no longer give my Python venvs hidden file names lol.  I've done something similar by accident before)",2,1736311525.0
1hw5s76,m60grlu,"Oh look, in the time it took me to read your comment, uv already finished updating my environment!
(/s. For real: uv uses .venv, and then some goodies ontop, and the speed is just game changing)",0,1736318967.0
1hw5s76,m5zsr1e,I don’t know what’s “best”. I just adopt the simplest solution for the problem at hand and for my projects I haven’t needed anything but vanilla python and venvs,1,1736307888.0
1hw5s76,m5z47l1,"True; I've been making Docker dev containers for my environments, so I just install my non-Python dependencies in the Docker image and it's been pretty nice",9,1736299257.0
1hw5s76,m5zdf0f,Then use pixi.,1,1736302393.0
1hw5s76,m60246r,Eww.  Why would you want a tool meant for project-specific configuration to manage a system-wide dependency?  I would have a stroke if I saw someone on my team doing that.  That's like pip installing packages directly onto your system-wide Python installs.,-4,1736311710.0
1hw5s76,m5zdy2p,Some license stuff. Research by yourself but i guess companies with more than X employees shouldnt use conda without paying,7,1736302579.0
1hw5s76,m62b9qx,"Also, extremely venomous",2,1736351171.0
1hw5s76,m6051ru,"To avoid messing with your actual system version of those dependencies, to ensure that all the packages using those dependencies are using the same versions, and to have multiple versions of those dependencies installed and available for different projects.",18,1736313008.0
1hw5s76,m64o8e0,Conda envs are not just python venvs,2,1736376126.0
1hw5s76,m61hzuh,Well the environment files wouldn’t have been stored at the repo level. I’m newer to venvs since my IT department has told us we can’t use miniconda anymore. I suppose I could store all of my environment folders in a central location as opposed to in repos though,2,1736340723.0
1hw5s76,m62y8g5,"\`uv\` doesn't do anything special at all.  I never even have to think about my Python versions or which virtual environment I'm using and I don't touch \`uv\`.

A simple 3-line wrapper function on your \`cd\` command to activate a venv whenever you move into a directory, a set of default venvs in a common location (I use \`\~/.local/python-venvs\`) to use instead of system-wide installs, and another single 1-line bash function to call those venvs by name is literally all you need.  I don't even need to set up those default venvs, I have a script in my dotfiles to build them automatically for each version of Python and Pypy installed on my machine.  If I want a new system-wide or local project venv?  Easy, a single command in my terminal gives it to me.

Y'all are introducing wild external dependencies with thousands of lines of code to do the same thing that < 10 lines of bash will do lmao.  What do you do when you need debug an application on a remote server?  Do you go through and install UV?  Because all I need to do is \`scp\` a single \`.bashrc\` file and it works -- and I would be \`scp\`ing that conf file into my home directory on the server anyways.  I would literally have my venv up and activated with dependencies installed before you even have UV on the server.

I don't even need to use a command to activate the venv in my project, it just does it automatically as soon as I open the repo in my terminal.",1,1736358082.0
1hw5s76,m5zdtbt,Why?,3,1736302533.0
1hw5s76,m613sb2,"> That's like pip installing packages directly onto your system-wide Python installs.

That comparison makes no sense. Which shows that you really don't know how conda works.",5,1736333321.0
1hw5s76,m602wb4,"Do you understand the purpose of Docker? Then you understand (part of) the purpose of conda.

Edit: But to elaborate, because a lot of people really don’t understand the history of why conda exists…

You’re right, you wouldn’t want pip to install a system-wide BLAS, would you? So packages like numpy have a choice: vendor it or assume the user already has it. If you vendor it, either you force everyone to install from source, or you provide a bunch of binaries. If you assume the user has it, then it just fails with a cryptic message if they don’t.

Ideally, you could detect if the user has the system requirement installed or not, or at least tell the user they must have it installed first. But PyPI distribution packages provide no standard metadata to declare system requirements. So there’s no way for pip to know what to do anyway.

Wheels “solve” this, but everyone vendors their own binaries, for dozens of versions of Python and operating systems and architectures, which bloats all of the packages, and requires exponentially more storage space.

Conda was built before wheels “solved” this, by actually solving it. By having a way for packages to declare their system requirements, and installing them in a containerized way, but such that all other packages in the environment can share those same system requirements, to ensure compatibility.

None of the other Python package management tools do this, because they stick with PyPI, whose metadata system is fundamentally broken. And things are only starting to get better with pyproject.toml, but PEP 725 is still a long time away from being widely adopted, let alone enforced.",3,1736312052.0
1hw5s76,m606mtk,"Conda only isolates Python packages/versions, it doesn't isolate system-wide dependencies -- unless you're only referring to system-wide Python packages/versions, which is what Conda isolates.

If Conda is installing .so/.dll dependencies for you, they are definitely not isolated.",-9,1736313731.0
1hw5s76,m5zqejb,"Allows use of conda channels and capabilities, supports many languages and tools just like conda, but is much faster due to its implementation of UV and such.",2,1736306999.0
1hw5s76,m62t8ic,"Lmao ok, please explain how does that not make sense?

Installing system-wide non-Python dependencies is very much analogous to installing Python dependencies directly on your system-wide Python versions -- in fact, it's even worse, because those system-wide non-Python dependencies will impact every single non-containerized venv/Conda environment on your machine, whereas pip installs to your system-wide Python can still be isolated from your venv/Conda environments.

If Conda is installing something like \`cuda-toolkit\` to your machine, every single non-containerized environment on your machine that needs \`cuda-toolkit\` will use *that specific dependency version*.  That's significantly worse that pip installing \`pytorch\` to your system-wide Python install because the only way to isolate your version of \`cuda-toolkit\` would be to run your code in a container, but you can always use a different version of \`pytorch\` in a venv/Conda environment regardless of which version is installed directly to the system Python.",0,1736356616.0
1hw5s76,m605lzw,"Lol.

Conda venvs and Docker/podman/WASI/etc containers are completely different. Those system-wide dependencies Conda is installing are not isolated in a container -- they are being installed *system-wide* \-- but you \*can\* install those same dependencies in a container without affecting the system-wide dependencies of the machine running the container.  Only your Python dependencies are isolated by Conda.  Conda is like pip + venv + apt/pacman/brew/whatever-lite rolled into one, it is **far** from containerization.

If Conda even came close to providing the same level of isolation and reproducibility as fully-fledged containerization, it would have become something bigger than a niche tool used by Data Scientists a long time ago -- yet, it's still niche tool used largely by Data Scientists.  The fact that you seem to think they're even remotely comparable is...weird.",0,1736313260.0
1hw5s76,m6088y3,Of course it’s installing shared libraries… that’s the point! And you can have different versions of them for different projects.,11,1736314495.0
1hw5s76,m5zvh1g,"If it’s just speed, not compelling enough for me considering how mature conda is.",5,1736308953.0
1hw5s76,m607sp7,"I don’t know why you think conda installs things system-wide… they’re installed to some conda environment. The environment is the system. Yes, it’s not fully isolated like a container. But the point is you have access to different environments with different system requirements (including different versions of Python).

If I need environments with different versions of all of R and Python and some C++ libraries… conda is the easiest way to do that, because that’s the kind of thing it was built for.",5,1736314278.0
1hw5s76,m62vuna,"Conda absolutely installs system-wide dependencies for you -- in fact, that's the only extra thing Conda really does anymore.  If you're installing a library into your environment that needs something like [cuda-toolkit](https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/), that \`cuda-toolkit\` installation is *not* being isolated in that Conda environment -- it is being installed system-wide and dynamically linked within your Conda environment.  Conda only isolates Python dependencies (ie, Python libraries -- including those that use the C FFI to bind Python code to C/C++/Rust/etc code), it does not isolate the system-wide dependencies it installs.

If you need an isolated version of \`cuda-toolkit\`, you need to containerize it (which is why Conda environments are not even remotely comparable to Docker containers in functionality).  I feel like I'm going crazy in here, so many Conda stans with a fundamental misunderstanding of how Conda works shilling Conda lmao.  Wild.",1,1736357384.0
1hw5s76,m6310vy,"All of this is exactly what conda is designed to do. It sounds like you’re running into a cuda-specific issue: https://github.com/conda-forge/jaxlib-feedstock/issues/255

Edit: You are right that conda doesn’t fully isolate things, caches aggressively, and will try to use existing dependencies across environments if you already have them installed. But that isn’t the same thing as installing them system wide.",1,1736358888.0
1hvwxzv,m5xane9,"I did freelance DS quite successfully for a couple of years, and was netting about 130k EUR (full time). Was quite hard work. Some things that helped me:

- Having built up a network of contacts from my previous job
- Creating a fairly popular R package which made me quite visible and brought in work 
- Having a niche of expertise in DS
- Doing a good job for clients so they recommend to others 
- Willing to work on diverse projects and new things",43,1736279142.0
1hvwxzv,m5wymhb,"Don’t. (Speaking from the perspective of someone in the North American market… so, grain of salt)

It’s competitive and very cutthroat. Unless you’re backed by a consulting firm that can actually enforce a contract and pursue a violated one, you’re an utterly expendable and precarious resource. When you do actually land a large client, get ready for payment terms that are more punitive than unemployment. 90 days, 120 days… Can you go 4 months of working your ass off without seeing a dime? 

That’s all before we get into self-employed taxation… If you’re going to do it, get yourself an LLC.",15,1736275665.0
1hvwxzv,m5wz5iq,"It's virtually impossible, firstly small companies are out as most of them just don't have the data. The ones large enough will either have their own in-house teams or hand it off to a credible consultancy.",12,1736275817.0
1hvwxzv,m5wqexe,"Generally the freelance market is competitive as people can hire cross country with cheap price. Also, companies really wanna limit sharing data to external parties. And if DS freelancer can't control data source, it's hard to have a high quality analytics or modeling.",29,1736273300.0
1hvwxzv,m5wwlsc,Currently on Upwork rn trying to land a gig. It has never been successful for me. That may be because I’m a software developer pivoting into data analytics.,10,1736275089.0
1hvwxzv,m5xgf0t,"I think it’s a lot harder to do for Analytics than Data Science because like some have mentioned here, most small companies don’t have the data or don’t even have systems to collect data for the business. 

The medium to large companies usually have their own analytics teams and some times they may use a consultancy for projects that their own teams don’t have the bandwidth for. 

Tbh, unless a company needs an Analyst with really niche/specific expertise idk why they would pay more to a contractor versus just having their own analytics teams. 

That niche experience is probably more required/common from Data Scientist than it is from Analyst.",5,1736280819.0
1hvwxzv,m6dyxmx,"I think you should try TopTal. There’s a strong application process to get on the platform. But once you’re in, it’s a very consistent flow of offers albeit some are longer engagements than what you might be able to manage with a full time job. But you can get paid really well - several friends make >$150 per hour.",3,1736509270.0
1hvwxzv,m5y6b8c,"If you’re considering doing it alongside your main job be careful. It’s possible you may have in your contract that you may not work for anyone else, including yourself.",2,1736288299.0
1hvwxzv,m62t34e,"I work with a consulting company that brings me opportunities. They handle the contracting with client companies.

Sometimes I work solo, sometime they pair me with SWEs. I'm a domain expert in healthcare and can speak the lingo across all the subdomains and have often solved the problems that get brought to me before.

Consulting company typically aims to take 25% of the rate they negotiate",2,1736356570.0
1hvwxzv,m68h7wv,"I generated almost 2k on up work. It was difficult. The work is fine and easy. Finding work is backbreaking. I think it would've been more lucrative to work part time at Target or Panera, tbh.",2,1736435762.0
1hvwxzv,m6das6s,I think you are better off looking for a higher paying job and investing that time into personal growth.,2,1736494383.0
1hvwxzv,m5z9mwt,Data Science freelance is very difficult - most companies are very protective about their data and want to limit who has access.,1,1736301086.0
1hvwxzv,m650xef,tough,1,1736380286.0
1hvwxzv,m6gf7h3,"I consulted several years ago when I was getting bored with working at a company.

The hardest part is that it is very hard to find clients, until it isn’t and it then gets harder to deal with all of them. I would never do it again myself, but I am in a different place now. 

What you are describing is more like contracting than consulting. You might want to consider talking to places like Accenture or Robert Half or some other temp agencies. All of them suck, but they take care of more of the sucking parts of the system. A few companies back we would work with recruiters and hire people from 3-12 month contracts, I can not tell you how scummy they are, but it is a way of seeing if you like a company or not. 

This market is very competitive however.",1,1736538318.0
1hvwxzv,m6on6sm,I'm just starting to look for DS freelancing work (returning to market after 4 years of being an at-home parent)... this thread is giving me second thoughts.,1,1736650179.0
1hvwxzv,m6vuhwy,"I am looking to improve the topic modelling. Would someone be kind to suggest? 

I have tried LDA to tag news and the outcome is not ideal ie when tested with articles that are not within training set, the predicted outcome is always the same few. I have also used TF-IDF but does not seem to have noticeable improvements.",0,1736750923.0
1hvwxzv,m5ykbow,[removed],-4,1736292710.0
1hvwxzv,m5xogwi,"This!

I recommend you focus on building a personal network. Those leaders who have worked with you before and/or know you by name will be how you land a gig.",11,1736283130.0
1hvwxzv,m63e5rd,Which R package? Thank you for your answer. Greetings.,3,1736362663.0
1hvwxzv,m672cm1,"Hi. What are your thoughts on freelancing without a masters degree in Data Science? I have a degree in mechanical engineering and I want to work in data science.

I've read lots of books about data science and machine learning and did several projects using kaggle to practice and showcase my skills. After all that work and time spent I couldn't find a job in data science so I'd like to give freelancing a try.

Is there hope for finding freelance work in websites like fiverr and upwork for someone that doesn't have a masters in data science but has data science project experience? I like learning and improving myself, hence I've read lots of books. Is there hope for someone like me in freelancing?

Also, many people say that job market for data scientists isn't very good right now. How's the situation in freelancing?

Thanks.",1,1736411422.0
1hvwxzv,m5wzijc,Or they’re burned out and trigger shy because of experience with less than credible consultancy.,7,1736275920.0
1hvwxzv,m5ygsae,I’ve been trying to do analytics as a side hustle on upwork. I have 7 years of experience and never had anyone view my proposal. I refuse to pay for the boosters and what not. I don’t put a ton of effort into it but I pretty much gave up.,3,1736291557.0
1hvwxzv,m5zh3bm,"I got one gig on Upwork several years ago. But I had to work for like 1/4th of my current hourly rate. Although you can increase your rate over time, your clients can always jump ship to someone cheaper than you. So I just decided that it was not a good use of my time to try to get gigs on their platform. Funnily enough, I got a few clients asking for help on Reddit.

None of my work was for data science or analytics though. It was for Excel VBA consulting.",3,1736303683.0
1hvwxzv,m60vqp6,Been doing Upwork here and there...I've made hundreds 😂,2,1736328251.0
1hvwxzv,m6e6gc0,Their website doesn't seem to have data science... Will this be under software development?,1,1736512940.0
1hvwxzv,m62am5k,Why people downvoted you?,2,1736350969.0
1hvwxzv,m63k0u6,"Can't really say without doxxing myself. When I say ""popular"" though, I mean ""popular for people working in a certain quite narrow field of stats and data"". Not ggplot2 or anything like that.",8,1736364357.0
1hvwxzv,m68m5no,"Well if it's any consolation both my masters and PhD are in mech eng. But when I started freelance I had 10+ years of experience on top of that, and I think the experience is much more compelling than the qualifications.

I tried putting myself on upwork but never got anything from it. You'll be up against literally thousands of people. All my work came through referrals. 

You could try registering yourself on expert databases, e.g. I did that for some UN agencies etc.",1,1736437287.0
1hvwxzv,m5zcewz,I did give up as well. But here and there I go back on and try again. But you pretty up helped me to give up fully because it never actually works out fr 😂,1,1736302047.0
1hvwxzv,m6ec6zv,yep!,1,1736515331.0
1hvwxzv,m6cw6ld,I understand. Thank you for taking your time to answer. Greetings.,2,1736486587.0
1hvwxzv,m6a54cb,"You had 10+ years of experience in data science when you started? I didn't quite get it.

Also, what do you mean by expert databases?

Thanks",1,1736453282.0
1hwcayh,m60p3kn,These acronyms are so cringe in AI research.,2,1736323950.0
1hwcayh,m67cmzd,What is this TAG,1,1736418140.0
1hwcayh,m6css6y,I am a newbie I had a doubt because of your question? is datascience and ml the same?,1,1736485039.0
1hwcayh,m61fbez,I thought the same thing,1,1736339515.0
1hwcayh,m639k1e,The gag framework /s,1,1736361341.0
1hvy3ld,m5wvtak,"Memory issues perhaps? Ideally you get the entire dataset into memory to avoid disk swap. 

Also keep in mind: 99% of DS stop their training 5 seconds before it completes. Trust me bro",122,1736274861.0
1hvy3ld,m5wvpai,"700k data points and 600 features on a laptop? I don't think this is going to go anywhere anytime soon, tbh... try running a single tree just to get an idea how long that takes.",89,1736274829.0
1hvy3ld,m5wzxwp,"1. The learning rate (0.001) is too small; try values \[0.02, 0.05\]
2. if possible, use early stopping (<300).",40,1736276041.0
1hvy3ld,m5wy857,"Shrinkage here is learning rate?

0.001 is extremely low friend. Running it for 5k iterations is going to be heavy compute.

What are your laptop specs.",29,1736275552.0
1hvy3ld,m5xadtg,"You're running a hyper parameter grid of 9 options and 5-fold cv. Depending on implementation of those cv models, you could be running 9 or 45 models sequentially. Are you maxing out RAM or CPU? Run a single model first just to get an idea of runtime from that.


Since your data is sparse, you can also reduce memory and compute time by using a sparse matrix",11,1736279066.0
1hvy3ld,m5x3e4j,"As u/TSLAtotheMUn says, I try to train in five seconds. Looking at the code you've skipped entirely over your feature engineering steps, which is where I put all my effort.  

My main workflow is to loop from raw data to evaluation as many times as I can until I'm confident I've got basically everything perfect.  Each iteration I'm looking for patterns in the errors or similar and tweaking some step in the process.  Only once I feel I'm deep into diminishing returns would I add a bit of hyperparameter tuning for a few hours, expecting only a tiny incremental improvement.

What I find is that I get over 90% of the benefit from feature engineering.  The only reason I do the hyperparameter stuff at all is it doesn't take any of my time.  I can finish the model building, sleep overnight, and the next day I wake up to a slightly better version.

I have had examples where this workflow has backfired, where performance has plateaued for an hour or so before the model discovers how it can add an extra layer to get out of a tricky local minima, and suddenly we're off again.  That ... doesn't happen much and it always comes as a surprise.  Often I catch it by accident having given up and then my overnight tuning has far more impact than intended.

The other key thing I do is train (run this full codeset) on a heavily reduced dataset (say 500 rows), then on a bigger one (say 1k rows), then on a bigger one (say 2k rows) and so on, observing the changes in the final model.  What I find is that most problems asymptote very early and throwing more training data at it isn't making the slightest difference. 

Oh, lastly I like to start with what I call a strawman model.  I spend maybe five percent of the project time making the most basic crappy model you can imagine.  Then as I build better models I include the strawman in the graph - I'm trying to gauge effort vs model performance.  It's not particularly scientific but you'll be amazed how often my five minute model performs 'well enough' from a business perspective and the week I spent building something better just... doesn't generate additional revenue.",9,1736277035.0
1hvy3ld,m5x2amm,"You could start with a subset of the data, maybe 10k to 100k. See how long that takes and adjust expectations accordingly. That might also show you how good of a model you're going to end up with.",5,1736276715.0
1hvy3ld,m5xauhw,"Try with saner hyperparameters. That's way too few obs per node and too many tree. And, no, probably not a job for a laptop.",5,1736279199.0
1hvy3ld,m5xrx31,"In this field, 700k records is not large at all. However, your 600+ features are the problem, especially considering they are sparse. GBTs are non-parametric, so they will be problematic here; training them will consume too much memory as it keeps adding layers (i.e. boosting). In your case, I imagine the final number of layers it may settle at will be multiples of your feature size, probably thousands of layers, may even result in OOM error before completion. Then even if training is done, the cost of productionalizing and maintaining it may not be justified?

I suggest you consider one of the following paths instead:
* Carefully select your hyperparameters to limit how your GBTs grow, potentially sacrificing accuracy.
* Do sone preprocessing first to limit your feature size, but with 600+ features, this may not be an easy task. Consider options for generating feature embeddings maybe?
* Use something other than GBTs. Neural Networks may be better suited for your data, assuming you have taken measures against data & label imbalances.",4,1736284115.0
1hvy3ld,m5xnanc,"600+ features sounds a lot. Do you have categorical features with a lot of categories, and the number of features increased significantly after some sort of onehot encoding?

If so, then you may try another approach for categorical variables. For instance, target encoding (proportion of 1 for a given category) or count encoding.",3,1736282800.0
1hvy3ld,m5xx785,Why are you training with 600 features? Did you check for multicollinearity?,3,1736285622.0
1hvy3ld,m5ze8vr,"You need to work your way up to such an expensive job.  It's a given that once you see these results, you'll want to change something.  Your early model tunings are often discarded and iterated upon, so you'll want to start small.  Starting big will be a waste of time - trust me :)

Start with a random sample of the data (say, 10,000 rows) and a random sample of the tuning grid (even 1% of the rows often gives comparable results to the full grid of xgboost hyperparameters in my experience, given how much redundancy there is between them).

Once you get a sense of how much time it takes to run, you can get a better judge of how long a larger job will take.  It's best to have some guess for the execution time before you run it.",3,1736302685.0
1hvy3ld,m5xxj8g,"Without critiquing the approach.  I’d stop it now, and try it again with a progress bar, or more printouts to monitor progress as it’s running.",2,1736285720.0
1hvy3ld,m5y1dtb,I HIGHLY suggest using H2O instead of caret. H2O’s algorithms are fast and can be designed for speed and early stopping,2,1736286834.0
1hvy3ld,m5y3bo0,"A lot of opportunities for optimization. 

If most variables are binary / sparse, you can look for some encoder

600k samples can have lots of repeated cases that can bias your classifier, you can cluster your samples and get some information from it. Maybe (big if) 100k samples can build a decent classifier

Batch training can be more feasible than 5-fold cv",2,1736287399.0
1hvy3ld,m5ynbbo,"Downsample to 1% of observations then scale up. Also conduct some automated basic feature selection like removing near zero variance variables, linear combinations, and highly correlated variables to reduce compute time with little impact to accuracy.",2,1736293695.0
1hvy3ld,m607o8s,"You seem to be using the `gbm` package which may be quite inefficient for your data. Perhaps you could use xgboost or lightgbm with caret? 

Other speed gains could be from switching away from caret, using more efficient algorithms for hyperparameter tuning instead of grid search, etc.",2,1736314218.0
1hvy3ld,m6644sf,"I’m not sure about R, used mainly python, but if you can get a loading bar using like python’s tdqm, library, you can see how far long your data is processing. But I think it should be normal, I recently ran a backtracking feature selection program that identifies lists of features with the best f-score and it took from afternoon to the next day.",2,1736393999.0
1hvy3ld,m66bt5k,"A lot of people have mentioned your hyperparameter space, but do you really need 600 features?

I would suggest doing a more careful feature selection step. Even if they’re not correlated, some of them could be less useful for your model. Or worse, you can be feeding noise to it.

Also I noticed you didn’t mention any kind of cross validation, which I would definitely do if I had a sample of 700k datapoints.

Just be careful if this is a time series of some kind as to avoid training leakage. Especially when doing cross validation

One last tip. I would try parallelizing your training process to make it faster. GBMs are sequential by nature, but there are ways to separate the trees you’re training and doing the chunks sequentially. (At least in python, I don’t know about R)",2,1736397147.0
1hvy3ld,m5ybb21,"Think others have already said it, but the learning rate is too small, and doing this on a local PC with that many data points probably isn't the best idea.",1,1736289827.0
1hvy3ld,m5ybs01,"Run with a small subset and see how long it takes.

700K is huge even if you run it using Python Pandas/Sklearn due to inefficient memory handling. R is even worse.

Personally I would not recommend running ML models through Caret, due to additional glue code.",1,1736289972.0
1hvy3ld,m6c5ken,Is it running on one thread?,1,1736476338.0
1hvy3ld,m5wwjve,"okay so i am a newbie but can we test run such large algos on lightgm and check how they perform 

and then implement on xgboost or run them each on different machines if lightgm output is pure garbage then xgboost will only improve a slight and still be garbage

review my idea seniors",1,1736275074.0
1hvy3ld,m5wyn1c,Oh no.. did you have some form of compression before running? Minimally have a step for PCA before feeding the features into the model.,1,1736275670.0
1hvy3ld,m5wwssp,"That's a great idea - extrapolate ETA from one tree.

Yea, I'm still waiting for IT to set up my access to the company's cloud environment, hence using my laptop.",25,1736275145.0
1hvy3ld,m5y4uuq,"This is a good point. When I was a baby DS we used to refer to tasks such as this as “high scoring” the server - you were using so much memory the server crashed. 

Have you considered something like AWS? Much as I find Bezos tiresome, AWS can be useful for enormously complex tasks such as this.",10,1736287859.0
1hvy3ld,m6dry6y,Or spend some time on feature engineering,2,1736505206.0
1hvy3ld,m5x0cx4,"Good idea, thank you.",7,1736276158.0
1hvy3ld,m5x08g1,"Yes - shrinkage = learning rate. I read recommendations for going with many iterations & low learning rate to achieve better predictions.

Laptop specs: 32 GB RAM, 2.4 GHz processor.",5,1736276123.0
1hvy3ld,m5x1mcj,Yeah that’s a crazy low rate to be sure,2,1736276519.0
1hvy3ld,m5x5s9d,"Thank you, I like the incremental strawman approach. 

I did remove zero variance & perfectly correlated variables from my dataset, plus some duplicate records.

A quick principal components analysis revealed the first 3 components accounted for 55% of variation. However, as far as I know caret doesn't support selecting 2 or 3 PCs + remaining variables as model predictors.",3,1736277733.0
1hvy3ld,m5x3nhr,"I did experiment with a 50k subset, although when running I got errors or warnings due to quasi-complete separation in predictors in my CV subsets.",1,1736277110.0
1hvy3ld,m5xdgl5,"Yes, I'm going to scale back the numbervof iterations, use shrinkage = .1. Bump up minimum observations per node to 50 or 100?",1,1736279948.0
1hvy3ld,m5y0s04,"It is a lot of variables. I did calculate a Jaccard Similarity matrix, and dropped several perfectly correlated variables.",1,1736286659.0
1hvy3ld,m6a44tu,"Thank you. Yea I vastly overestimated my work laptop's capabilities. :-)

I can model the entire dataset, but am scaling back the hyperparameters to 50 iterations, 0.1 learning rate, 100 min obs per node. 

And rather than using 5 fold CV I fit one model to entire training  dataset at a time, then compare results on my test data. It's clunky but my computer can handle it.",1,1736452988.0
1hvy3ld,m5ya40l,"Thank you, I'll look into the h2o package.",1,1736289460.0
1hvy3ld,m5y9vwl,Thank you - yes I need to look into compressing the data matrix.,1,1736289392.0
1hvy3ld,m61som8,"Good suggestions - I'm taking small steps in the ML field so haven't gotten to xgboost or lightgbm yet.

There are alternatives to caret, such as the h2o and mlr3, but caret is fairly user friendly. I've read caret is no longer being developed by Max Kuhn so I ought to familiarize myself with other packages.",1,1736344968.0
1hvy3ld,m690zsy,"Not sure I can justify dropping variables to the project supervisors. They selected the variables, so presumably they're important.

Is there an accepted approach to filtering features prior to running ML models? Run a main effects logistic regression and drop variables with large p-values & negligible effect sizes?",1,1736441673.0
1hvy3ld,m63z6k8,700k rows is not huge.,2,1736368778.0
1hvy3ld,m5x5da5,"Low learning rate..is not always optimal , especially in a high dimensional space which is your use case with 500+ dimensions.

Apart from compute, there are mainly thrwe major problems

Firstly of course is the compute cost not just time... secondly,and this is slightly nuanced, unless you are sure your loss function iss a convex set, it's very likely to have multiple minima not just a single global minima which will lead to a sub optimal result if you random starting point happens to be very close to a local minima. 

Finally overfitting. Low learning rate is going to massively oberfit the data and lead to high variance.

It's just better to avoid such low learning rates. Maybe start with 0.1,0.01 and see how it's working

32GB Ram should be able to handle 700k rows and ~ 1000 columns ideally. It might take long but not 13 hours long",12,1736277610.0
1hvy3ld,m6a7hcm,"I don’t recommend this. It violates the point of a test set. Trust me, work with a smaller data set, tune the hyperparamteters the right way with CV. Hacking together your own customer workflow is almost never a good idea. ",2,1736453974.0
1hvy3ld,m5yfhyn,This might help - http://rpubs.com/DRMORRIS/874470,1,1736291141.0
1hvy3ld,m66dsi5,"Understandable, I suggested xgboost / LightGBM since you're already fitting boosted trees via gbm so why not fit the same type of models but with packages more suitable for the size of your data?

Good luck with the modelling!",2,1736398015.0
1hvy3ld,m6a47nk,"> Not sure I can justify dropping variables to the project supervisors. They selected the variables, so presumably they’re important.

You know your workplace better than I do, but I can’t see how someone would be mad to get a better model overall just because not all of the features were used

> Is there an accepted approach to filtering features prior to running ML models? Run a main effects logistic regression and drop variables with large p-values & negligible effect sizes?

What I usually do is group the features and do a qualitative analysis of what could be a source of noise. Do take into account the nature of the feature and try and think not only if it theoretically makes sense, bit how dirty the data can be.

(e.g. sometimes sensor data can sound perfect, but come with so many bad datapoints that dropping it is better than using it)

As you’re using tree based models I would then take advantage of their explainability and shuffle the groups around in different combinations to look at their feature importance/SHAP values

Try to do a little at a time and see how your score varies.

Also, try to think of how non linear correlations can affect your final model

Best of luck! Feel free to reach out if you need any help",2,1736453011.0
1huz6ax,m5p1muu,"I have nothing to contribute since I haven’t even read Attention is All You Need yet. I think your way is best; there’s so much research coming out everyday and unless it’s your day job, it makes sense to just read what’s popular.",56,1736171146.0
1huz6ax,m5pa6nm,"I just... don't.

I've not kept up to date with LLMs for about a year. Now I'm about to start a new project that uses them so I'm going to refresh and research some approaches.

The more you know, the easier it is to talk in general terms with stakeholders, understand what they need and the general way you'd approach it. Then it's easy to research specific approaches once you have a specific problem.

You don't actually need to proactively stay up to date with all the latest ML, you just need to stay practiced at quickly picking things up.",69,1736174559.0
1huz6ax,m5qtleq,"Anyone who's been in this field long enough and actually does proper modeling and value driving knows that you simply do not need to do this, lol. 

Sure, having a generic understanding of what technique/approaches are being used is helpful for discussions with leadership or team members, but unless you're actively working or preparing to work on a project that requires the use of the lastest and ""greatest"" tools/techniques, which most don't, btw, then I'd say you could spend your time being more productive in other ways.",19,1736191563.0
1huz6ax,m5pe7t9,"I don’t keep up with papers, but I look for interesting GitHub repos of applications. If I like the project then I’ll read the paper.",11,1736175979.0
1huz6ax,m5pinn5,"Personally I self host FreshRSS, link up to a variety of different blogs, websites, etc...not just ML related, but for al interests. [https://freshrss.github.io/FreshRSS/en/admins/06\_LinuxInstall.html](https://freshrss.github.io/FreshRSS/en/admins/06_LinuxInstall.html)",3,1736177437.0
1huz6ax,m64ztnx,nice,2,1736379917.0
1huz6ax,m5qr53v,I'm terrible at actually reading the papers but I try to keep up via the [arxivx RSS feed[s]](https://info.arxiv.org/help/rss.html) and listening to updates on the abstracts there daily via [CustomPod](https://custompod.io),1,1736190851.0
1huz6ax,m5r0vn6,This sounds like a solid approach. I might start doing this too!,1,1736193664.0
1huz6ax,m5s7eci,hub for RSS feeds + twitter specific profiles,1,1736206420.0
1huz6ax,m5upyzs,"I agree! Focusing on popular papers and widely adopted frameworks like transformers makes sense—there’s solid support, plenty of documentation, and proven performance. It's not worth diving into esoteric architectures without community backing. Efficiency and practicality always come first for me.",1,1736246613.0
1huz6ax,m5v81bq,I just go to the implementation. I don’t even have a degree in this stuff and hopefully I’m about to drop a pretty cool repo,1,1736255885.0
1huz6ax,m5vlk0d,PapersWithCode.com is the best site you will ever use. Papers split up by SOTA task/domain with links to GitHub code and benchmark results. The Trending feed is typically just hype GenAI stuff but still good,1,1736260950.0
1huz6ax,m61dz1e,I mean there’s no one way haha,1,1736338876.0
1huz6ax,m639dy3,"I think staying abreast is important for leadership roles - either through application of methods, recognizing when tech has caught up to yesterday's problems, or mentoring junior members.

One thing that really benefited me in grad school and continues to today - just read abstracts.  Then read intros if you have time.  Read methods for papers that are very interesting to you.  Read the whole paper if its interesting, where challenging you would result in growth, and if you have time.",1,1736361293.0
1huz6ax,m6a5g6m,I dont think it matters unless youre a research scientist,1,1736453379.0
1huz6ax,m6asvfd,i think your way is probably best,1,1736460257.0
1huz6ax,m6vgd5h,.,1,1736743721.0
1huz6ax,m5qju9t,"Im writing deep learning paper reviews (5 a week) and write technical blog on different data science related issues on my substack: [https://aiwithmike.substack.com/](https://aiwithmike.substack.com/)

  
You're invited to follow",1,1736188532.0
1huz6ax,m5tgztr,Thank you for this! This is helpful advice,1,1736221910.0
1huz6ax,m5sfv83,This. I am far more efficient in learning new modeling/feature engineering techniques whenever I have a potential project which can use them. Anything else is just a very inefficient learning at best or waste of time at worst for me.,9,1736209226.0
1huz6ax,m5stklp,"Yeah especially if you're at a big fortune 500 company where things move really slow, stakeholders aren't really keen on this new innovative techniques, and where honestly relationships trump knowing the most up to date papers. Imagine reading the first LLM paper back whenever it came out, what value can you possibly bring outside just being informed on the topic lol",6,1736213767.0
1huz6ax,m5usfnp,"Yes, unless my job is to R&D the trend and the hype, mastering classic MLs or even just linear regression can push the normal business quite far already.

Not mentioning any new technology, algo is not optimized yet and there're huge number of bugs in using them.",4,1736248127.0
1huz6ax,m62gqyn,"Yeah, as long as you got the fundamentals right.",1,1736352823.0
1huz6ax,m6q4p7q,Is there any websites where you practise? Something like leetcode?,1,1736677766.0
1huz6ax,m5tl9mc,"100%.

IMO this is true even in a slightly hyped area, but many times “truer” in a super hyped field like this. I consider constant chasing the next big architecture to be a massive anti-pattern.

There will be breakthrough ideas in ML papers, but trying to find them without building context/expertise,… and rather by trawling the ocean floor,… that won’t work for some time yet.",9,1736223592.0
1huz6ax,m5uuvhi,"simple is the best, and simple doesn't mean ineffective, while complication/complexity is more like a way to show off. Lessons some people never learn",4,1736249550.0
1huz6ax,m5pj6pk,Interesting approach. Will consider this in the future.,2,1736177607.0
1huz6ax,m5qv2v3,Would you be okay sharing which feeds you subscribed to?,1,1736191995.0
1huz6ax,m5sd54q,Are you planning to put it up on docker?,1,1736208323.0
1huz6ax,m62gknz,"Yeah, but what's yours?",1,1736352770.0
1huz6ax,m5qw5rv,i do the same. just followed :),1,1736192312.0
1huz6ax,m6q930w,"Nope, let's say I've never built a RAG app before, I'll do something like:

- Google how to use existing documents to make my LLM responses better
- Discover RAG
- Google how to implement RAG
- Discover something like LlamaIndex
- Do a LlamaIndex tutorial or use the documentation to work out how to do a basic RAG app

Then, I'll build out from there. Maybe I need to look into production level vector databases, maybe I need to do something more complex than basic RAG but I learn as I go.",1,1736680506.0
1huz6ax,m5zaut3,"Fully agree. Context and domain knowledge is what usually distinguished great Data Science projects from the failed ones. As long as you work with tabular data, Data Scientist who knows basics (like linear regression and XGBoost) reasonably well and focuses on building domain knowledge and understanding business problems is usually much more efficient then a Data Scientist who reads papers every day and keeps talking about fancy deep learning techniques.",2,1736301503.0
1huz6ax,m5x8v1j,And how'd you build that context/expertise?,1,1736278631.0
1huz6ax,m5srms7,I personally run it in am LXC container on proxmox.,1,1736213126.0
1hvfuwa,m5t0t8y,SQL.,15,1736216228.0
1hvfuwa,m5u12tj,"In python; Uv, ruff, software best practices, fastapi, pydantic, duckdb, polars, automatic testing frameworks (pytest), Github Actions (or other ci/cd). I recommend watching ArjanCodes refactor series on data science.

Outside of python running models in the cloud (Azure/AWS), Docker/Kubernetes, MLOps, Data Engineering (Spark/Delta), DevOps, GitOps.

Be a good data & software engineer and you will stand out between the data scientists.",17,1736230975.0
1hvfuwa,m5u7v2o,"I feel that model deployment, continuous training pipelines, MLOps,  Docker / Kubernetics are good skills to have for a data scientist in industry",5,1736234865.0
1hvfuwa,m5taiuq,"What is the role that you want to apply for? Look at the job requirements and decide what to learn.

I basically start learning Sagemaker 2 weeks before an interview by doing projects related to it. I got the job without spending much time on unnecessary skills.",3,1736219602.0
1hvfuwa,m5swmls,Why are you learning python if you want to go to law school?,6,1736214791.0
1hvfuwa,m5ucs7t,"I would say get comfortable with an AI first IDE like Windsurf/Cursor. Firstly, these will only get better and they are already very powerful. Secondly, they will solve your specific issue with Python - you know what to do but not the exact syntax… AI can write Python syntax for DS very well.

I recently entered the Jane Street kaggle using Windsurf to help build a solution, just to test this theory - it worked very well.

Otherwise, Julia feels like the more natural successor to R.",2,1736237933.0
1hvfuwa,m5x8mud,A cloud platform such as AWS or Azure for deploying your models,1,1736278564.0
1hvfuwa,m64zw64,sql,1,1736379941.0
1hvfuwa,m66opv4,"hey! as someone deep in the AI/tech space, i'd actually suggest learning how to effectively use AI tools for data science - it's becoming a crucial skill that many DS overlook. modern AI can help with coding, data analysis, and even visualization

specifically for DS work, you'll want to focus on:
1. prompt engineering (how to effectively ""talk"" to AI)
2. using AI for code generation/debugging
3. RAG (retrieval augmented generation) concepts
4. knowing which AI models are best for specific DS tasks

i built jenova ai specifically to help with this - it automatically routes DS/coding questions to claude 3.5 (best for coding) and data analysis to gemini 1.5 (best for analysis). you can try the free tier to get started

but yeah, if you want a traditional tech skill, spark is solid. but honestly, AI literacy might give you better ROI for job hunting rn. lots of companies are specifically looking for DS who know how to leverage AI tools effectively",1,1736403350.0
1hvfuwa,m6ps3i8,"PyTorch, Tensorflow, MongoDB, VectorDB, and Scikit",1,1736669784.0
1hvfuwa,m5tp1ow,Already got that one down. Learned on the job. Could be more proficient but I'm fluent enough to confidently put it on my resume.,2,1736225190.0
1hvfuwa,m6dycyd,I guess k8s is mostly relevant if working in an enterprise setting? Otherwise why would you have a need for it in a DS role?,2,1736508957.0
1hvfuwa,m5tr18u,Senior or Lead Data Scientist. I'd love to stay in real estate but the pickings are slim so I'm casting a wide net in terms of industry. I'm seeing a pretty broad variety of requirements when applying.,3,1736226056.0
1hvfuwa,m5tllj8,JD is job description,4,1736223729.0
1hvfuwa,m5tp2of,yup,6,1736225201.0
1hurpgg,m5qx6gi,Tired of using routine visualisation methods? Spice it up with this one simple trick.,16,1736192610.0
1hurpgg,m5q2ile,And 7th dimension as suggested by your VP of catering.,6,1736183484.0
1hurpgg,m5nocld,Noooooooo,12,1736143000.0
1hurpgg,m5nl1zr,"You forgot size of the dot as a dimension.

Shape of the dot...

So many choices besides scoville",30,1736141355.0
1hurpgg,m5txutm,"Just throw around those 2 terms, ""have you tried PCA or Dimensionality reduction""",2,1736229284.0
1hurpgg,m5whx5k,I want to be able to post as well but need 10 karma points. Can you guys help me?,2,1736270839.0
1hurpgg,m5s6iwe,scatter plots is killing me,1,1736206129.0
1hurpgg,m5svscd,lol,1,1736214506.0
1hurpgg,m5vua2p,lmaoo,1,1736263798.0
1hurpgg,m60m1wz,oh my...,1,1736322076.0
1hurpgg,m61faer,My maximum is 3x BulDak Fire Noodle,1,1736339501.0
1hurpgg,m650yom,nice,1,1736380298.0
1hurpgg,m66tg9a,it never stops 😭,1,1736405975.0
1hurpgg,m74frn7,wow!✨,1,1736873604.0
1hurpgg,m5oqkc3,Wow,0,1736166053.0
1hurpgg,m5r15t3,LOL great title,1,1736193746.0
1hurpgg,m5wf6rx,:),1,1736270040.0
1hurpgg,m5pyji1,u not a foodie?,5,1736182311.0
1hurpgg,m5nqefb,It's _supposed_ to be ridiculous.,19,1736144081.0
1hurpgg,m5nlaud,"don't forget air pressure levels, frequency and amplitude, petal shape, and resistance!",8,1736141472.0
1hurpgg,m5nl930,u forgot transparency and how to laugh 😆 its a meme not a textbook,5,1736141449.0
1hurpgg,m5p0k7f,I remember seeing a visualsation where every US County was a different face and every feature of the face meant something different. That was crazy,1,1736170526.0
1hurpgg,m5r27cf,Haha :)),1,1736194054.0
1hurpgg,m5qu9py,Digestive tract is a weenie about spice T.T,2,1736191760.0
1hurpgg,m5ockr8,"as someone who regularly tries to use shapes and size as extra dimensions (key word here is try), I'd argue that this is equally as ridiculous haha",7,1736157917.0
1hurpgg,m5nlj3e,shout out to principal component analysis and other homies,10,1736141585.0
1hurpgg,m5o8pf8,"\> mfw I use transparency for the 7th dimension

\> mfw I didn't clean the data properly and now I'm invisible",2,1736155383.0
1hurpgg,m5r6hb3,try the pain scale instead 😭😭,3,1736195291.0
1hurpgg,m5qyduw,Using size and shape is far more reasonable than using a 3D scatter plot.,1,1736192954.0
1hv3gn4,m5q1iuk,"They're called medium because they're neither rare nor well-done.

At one point (pre-2017 or so), Medium/TDS were good, but once every data science bootcamp starting having their ""students"" write a medium article, it was flooded with poorly-written garbage, often just replicating the documentation/examples from existing packages.

These days, seeing something on Medium is almost an anti-signal for quality.",148,1736183190.0
1hv3gn4,m5pzbr3,"Medium doesn’t require any sort of peer review or approval to publish. Anyone can post whatever they want whether or not it’s accurate. 

TDS should hopefully have a peer review process but I have no idea.",24,1736182543.0
1hv3gn4,m5qiiu3,A huge majority of helpful things in DS I’ve read have came from Reddit. Medium/TDS is just reformatted LinkedIn cringe,23,1736188150.0
1hv3gn4,m5qksvk,"They were great at the beginning.

They've been mostly bad the last few years.",12,1736188812.0
1hv3gn4,m5qoopi,I had a year subscription that I just cancelled due to the overflood of articles written by chatGPT,8,1736190126.0
1hv3gn4,m5qcfum,"I wish google stopped giving me Medium articles at all, since they are worst than not reading the topic at all most of the time.

The other time when their are not completely useless they are... medium quality...",5,1736186374.0
1hv3gn4,m5rh3lu,"Needle in a haystack type of a thing even for the middling articles, let alone the high-quality ones. And there seems to be correlation between article length and quality, though it's anecdotal on my part.

That said, I think it's better to go to personal blogs or substacks for (much) better quality reads. Something like Lilian Weng's blog is a good example.",6,1736198322.0
1hv3gn4,m5qcmnd,I have read some really bad articles with big flaws getting a lot of upvotes there. And of course there are some good ones. Just don't take whatever that is upvoted there as truth.,3,1736186428.0
1hv3gn4,m5qumym,"Medium isn't peer-reviewed or curated in any way. This doesn't mean it's not useful or that no one who writes on there knows what they're doing, but I wouldn't take anything on there as Gospel.",2,1736191866.0
1hv3gn4,m5sm8vw,Following-up on this question: What are your alternatives to TDS and outside of Medium?,2,1736211334.0
1hv3gn4,m5qvywi,A few years ago it was great. It seems any ape with a keyboard can write and post an article with the dream of making a passive income.,3,1736192256.0
1hv3gn4,m5qsi6r,"It's just a way of publishing text. The quality can be really good or bad. It all depends on the author. It's the same with reddit, I've seen comments and posts being upvoted that's factually wrong. At the same time, I've seen a lot of good stuff as well.",2,1736191248.0
1hv3gn4,m5rfr33,There’s a whole range to them but they’re not peer reviewed so there’s no real quality control going on there.,1,1736197938.0
1hv3gn4,m5rg1a9,"They used to be very helpful, until LLMs (e.g. chatGPT) replaced them.

I guess you could still argue that medium articles are helpful for the purpose of exposing their data to or for training LLMs (although they try to restrict it, but the data still finds its way somehow).",1,1736198018.0
1hv3gn4,m5stqen,"No. There was a time they weren’t terrible, but that time has passed.",1,1736213821.0
1hv3gn4,m5t68ns,"I find them useful for picking up the very basics of how to use certain packages or tools that have otherwise weak documentation

Other than that, most of it is meh. But there are some very useful and well written articles there",1,1736218110.0
1hv3gn4,m5taggn,It's a platform like any other. We need to do a bit research on whom to follow and once you get the right people then you should get some quality content but I personally prefer email lists from good researchers and big players in DS.,1,1736219578.0
1hv3gn4,m5u7eh4,"Some things are quite good, with code examples. Most articles are hot garbage though",1,1736234586.0
1hv3gn4,m5uecut,"I do not trust Medium articles, a lot of them are just garbage written by self proclaimed know it all experts.",1,1736238967.0
1hv3gn4,m5uefer,"Everything I've ever come across on medium looks like it was written by an AI/LLM whose only purpose was good grammar, readability, and relevance to interesting and well known topics. The thing is, just because something is highly relevant to my Google search does not at all mean it's accurate - this is the case for medium articles. (By medium I hope you're referring to the website, ""Medium""). It's as if the AI//LLM producing these articles were overtuned for falsity and volume.",1,1736239013.0
1hv3gn4,m5uihn4,"I was planning to subscribe to Medium, but then I realized I could just ask ChatGPT and get pretty solid results, so I gave up on it.",1,1736241713.0
1hv3gn4,m5ulg7s,I feel like Medium has a subset of articles that I find useful. They're mainly articles containing how-to's for a particular ML or statistical method–those that have a github repo attached to them.,1,1736243694.0
1hv3gn4,m5uwd8b,Seeing the comments here seems to indicate that it’s not the best place to read from. Any other suggestions?,1,1736250371.0
1hv3gn4,m5vn3m0,Depends on the person if you like it then good if not then it's average. You might get ideas for your projects or different things like code or analysis.,1,1736261475.0
1hv3gn4,m5wgwq0,I think some articles are good and i have been going through some.,1,1736270544.0
1hv3gn4,m5ybqfu,Useful back in like 2017-2019. Full of absolute nonsense now from every wannabe DS influencer,1,1736289959.0
1hv3gn4,m5yf38b,"The answer to this question is contingent on what someone means by the word helpful.

They are occasionally helpful to me when they introduce a model, algorithm or framework that I haven't yet experienced before or haven't touched in a while. They provide a good intro sketch enough to whet my appetite.

No one becomes an expert in their field by combing through medium articles. That's not really what they're there for",1,1736291011.0
1hv3gn4,m650zi7,yes,1,1736380306.0
1hv3gn4,m69raxg,I think it's not bad. So 💯 can't be sure,1,1736449266.0
1hv3gn4,m6q4thk,If not medium then what would be a good website to read good data science articles?,1,1736677841.0
1hv3gn4,m5q1x4u,"Some people post useful or interesting things. Some of those are put on medium or TDS.

I do not find medium to be particularly good at letting me find insightful content, and that is the \*only\* thing medium can do to be valuable. Frankly post AI boom, being on medium has seemed to be an indication that the content is bad.

If medium is effective for you to sift through and find good content, then its good. The overwhelming majority of content anywhere is horrible, no site can reasonably solve that. If its effective at letting you sift, then its good, but that's mostly personal preference.",1,1736183308.0
1hv3gn4,m5qir17,"Very,

Also a quick tip, write a blog for each and every project you do. It really helps in remembering things about a project you once did and it make project look like an end to end project.",-3,1736188216.0
1hv3gn4,m5rvoa5,"This explains why so many of the medium articles I see about explainable machine learning are just regurgitating Christoph Molnar's book chapters. I keep thinking I've found a new reference for something that didn't quite click, and then it ends up being exactly the same.",18,1736202654.0
1hv3gn4,m5t1ppw,It's just 360 blog yahoo in a new era,3,1736216540.0
1hv3gn4,m64mt75,"Anti-Signal is a word I will steal and use it from now on. Thanks kind stranger!

Anyway, I also regret that I posted on TDS back then. I really put effort into my stuff, but the garbage with no review led to no further articles... Instead I moved my stuff to YT",1,1736375681.0
1hv3gn4,m5tfd53,"I still find tons of good articles. The problem is that you need to sib to the email digest, which they cater based on not just what you click, but how far down you get in the article. If you compare my feed, which I've been careful to curate vs. that of my co worker it's night and day. Mine is quite useful and his is trash.",0,1736221303.0
1hv3gn4,m5t1fad,"TDS reviews are only at superficial levels, mainly the reviews aim to get traffic",3,1736216440.0
1hv3gn4,m5qqapx,"they have mentioned that they don't publish AI generated contents or at least this is true for TDS, nevertheless finding if an article is written with AI or assisted with GPT or AI has become very challenging.",-1,1736190604.0
1hv3gn4,m5qp6sw,You can make your Google search to exclude certain sites. I don’t remember the exact keywords but it’s not too complicated,1,1736190275.0
1hv3gn4,m5uirnd,"I feel the same, and before gpt, Google worked fine if you scrolled down a bot past all the paywalled medium posts.

For being paid, I think the quality is low. Too many badly written articles, or articles that feature incomplete information.",1,1736241900.0
1hv3gn4,m5t1lck,"well, how do they check that? GPT detector software has a lot of false positives and negatives",3,1736216498.0
1hv3gn4,m5uk46u,"I’ve been noticing that a lot of articles feel like written by AI, or at least mostly done by AI. So, why not just ask AI? I can chat with AI, and dive deep into any subtopic as I wish. And finally, let AI to summarize the entire conversation and highlight the key points.",1,1736242804.0
1huk9gq,m5lt8qe,Meetings meetings meetings meetings. And the time it takes for me to transition back to focus mode between meetings.,419,1736118932.0
1huk9gq,m5lznaz,getting access to the data,177,1736121035.0
1huk9gq,m5m76n8,Understanding and cleaning data.,83,1736123498.0
1huk9gq,m5lxstm,"Explaining to the business that it is literally impossible to build a model unless...
1. Data is in a table. 
2. The 'thing to predict' is one of the columns in the table. 
3. Each row is one instance that the 'thing to predict' would be predicted for.
4. All the other things that we know before the 'thing to predict' happens also need to be in the table.

They want me to do some transformations; I get that. Still, I cannot tell you how many times I've had a business partner come to me and say ""hey can you build me a model to predict X?"" and within a minute of me clarifying they say ""we don't even have a total for X across the entire book"". 😐",182,1736120432.0
1huk9gq,m5ma2ii,"Holy this thread is so therapeutic. I can relate to all the comments.

I also wanted to add 2 things.

1) Data understanding: You want to understand all assumptions and limitations about the data and this includes speaking to business about how the data is collected, how it's currently being used, known quality issues, etc.

2) Model risk management: I work with clients in the financial space and my god it takes months and months to ensure the model risk is properly evaluated.",60,1736124441.0
1huk9gq,m5mfbpj,"Aside from meetings with no true intention?

Data cleaning. I cycle between cleaning and analysing for hours and hours at a time. 

""This looks off, why?"" *cleans up data for aggregation and visualisation* ""Oh that's why."" *cleans up data for modelling, models* {return to first statement}",51,1736126208.0
1huk9gq,m5m8kgn,"Came here to say data prep/cleaning, but also MEETINGS. Like why can't the meetings be emails? They should be emails. Oh! You want a meeting because the email didn't make sense and yet I'm saying the exact same thing verbatim I said in the email in the meeting? Cool cool cool.",29,1736123949.0
1huk9gq,m5mgq7v,Lack of domain knowledge and any structure for all our data sources across the company kills me. I’m talking tables and columns with numbers as names and no data dictionary.,23,1736126678.0
1huk9gq,m5lzwtw,These comments are making me feel seen as a DS working with business people,33,1736121122.0
1huk9gq,m5mh35x,Reading a paper or documentation and saying “what the fuck”,14,1736126802.0
1huk9gq,m5mblvw,estimating the rational timeline and that the business team and stakeholders agree on! Honestly the business sends their data and they think everything is done!,9,1736124954.0
1huk9gq,m5mpouz,Explaining to people what the data means and then debating about why they’re confused about said data because they heard from someone else that has no clue what the hell they’re talking about.,10,1736129661.0
1huk9gq,m5mtbce,Working on someone else's poorly written/organized code feels the worst for me.,10,1736130848.0
1huk9gq,m5ncbu7,"I’m just breaking into this field and was getting incredibly frustrated by problems that I assumed were unique to my situation. While still frustrating, this is very reassuring.",7,1736137524.0
1huk9gq,m5m9mse,Annotating.,6,1736124296.0
1huk9gq,m5nuj3i,Understanding the data generating process underlying the columns and these MEETINGS,6,1736146382.0
1huk9gq,m5mi6tg,Emails and meetings. Hazard of being a director. ,6,1736127175.0
1huk9gq,m5mlfud,Data hunting and getting data ready to be processed. Especially waiting on data engineers.,5,1736128261.0
1huk9gq,m5nl6ql,"Spending too much time answered questions that don’t have significance.  
  
I like to call them rabbit holes 😂",5,1736141418.0
1huk9gq,m5odyc3,Explaining to stakeholders that data scientists aren’t magicians,5,1736158802.0
1huk9gq,m5og0nu,finding a new job :D,5,1736160113.0
1huk9gq,m5nxnni,Getting Python packages to work. Makes the language a joke but sadly it’s the most fleshed out in that field.,4,1736148261.0
1huk9gq,m5oe2p3,IT security hands down. Some weeks it takes up 30% of my time chasing or on calls to India. I don't even work in a regulated industry or deal with personal data. I'm at 3 months trying to get a azure identity created to access a storage account and azure devops artifact feed for an app.,4,1736158879.0
1huk9gq,m5p3dk2,Meetings and meetings. Data cleaning. Env setup when starting a new project (work as a consultant). I think proper modelling is probably in the low-end,4,1736171855.0
1huk9gq,m5pf389,"1. Building a solution for the wrong problem.
2. All the meetings it takes to make sure you're fixing the right problem.",4,1736176274.0
1huk9gq,m5mvxk9,"Bad projects or the ones we know can't be modelled since the driver variables responsible for the phenomenon are difficult to get. It's issues like these that waste most time because, you need to do everything knowing very well that things might not work.",3,1736131740.0
1huk9gq,m5n1qzk,"mostly meetings , requesting environment and data access. Multiple iterations of data requests etc depends on projects too.But it boils down to those things. Understanding requirements documentation is a big factor if you are working for a client.",3,1736133704.0
1huk9gq,m5nc6yw,Making sure everyone understands what im trying to do. It’s hard to get people to understand how stats translate to business outcomes.,3,1736137470.0
1huk9gq,m5npyue,"Not the biggest time sink but: getting the business side to allocate resources (read: a person from their team who can take some time from their usual work) for developing data products and for taking on the responsibility and light maintenance for the product.


By maintenance I mean relatively straightforward things like: being the point of contact for their team, keeping base data points updated and/or being the person who contacts support when problems occur down the road. 


""Business-owned"" is a double-edged sword, after all.",3,1736143852.0
1huk9gq,m5qdr84,"Everything in this thread + waiting for the client to send me the data in .csv format with proper headers 
This thread literally made my day :)",3,1736186760.0
1huk9gq,m5s91xm,Getting and cleaning the data hands down.,3,1736206967.0
1huk9gq,m5tof21,Excel,3,1736224923.0
1huk9gq,m5n5p0c,Thinking about way to quit DS and build my business. Just anyhow DS job. It’s a dead end job,5,1736135104.0
1huk9gq,m5ry1jq,"Cleaning messy data.


Specifically, the deep frustration I feel when I have to clean horrifically messy data that I have a solution for that involves data collection changes, but nobody will agree to it. 


I actually LOVE getting weirdly messy data, and then diving in to understand why it's a mess and troubleshooting and solving problems. But when my work there is ignored (usually due to an unwillingness to invest the time to allow me to build good data collection) and then I have to keep cleaning up and reconciling the same types of messes over and over again, then I feel like half of my time is just spent staring at my screen in simmering horror and frustration. ",2,1736203396.0
1huk9gq,m5vcrk8,Over engineering a general solution to importing and cleaning data for a once off problem because the next problem will need a totally different approach.,2,1736257755.0
1huk9gq,m5w7vqr,"Data access, cleaning and requirements/process engineering with colleagues….",2,1736267892.0
1huk9gq,m5x3ez1,"Trying to get the expectations from one stakeholder—somehow it always turns into several meetings, including senior management and ICs from different departments, when all I did was ask a simple question like, 'Do you want to see A or B in this data?' At this point, I just give up if it’s not a priority right now. Rinse and repeat. I haven’t written a SQL query in months—just writing docs and agendas.",2,1736277042.0
1huk9gq,m5q2leo,Meetings,1,1736183507.0
1huk9gq,m61jbgp,Meeting and cleaning data,1,1736341287.0
1huk9gq,m6510iv,meets,1,1736380315.0
1huk9gq,m6dbief,"1. Waiting for IT permissions
2. Endless meetings
3. Understanding and unpacking the business use case
4. Data clean up and analytics
5. Putting together a POC to get funding
6. Interviews for more personnel
7. Actual modeling
8. Making reports of model outputs
9. Making presentations to share with upper leadership
10. Answering questions that were already answered ages ago",1,1736494820.0
1huk9gq,m6r79xh,"If you can create a tool that gets management to respond to emails via email instead of meetings scheduled 2 weeks out, that would literally be worth several billion dollars. ",1,1736695520.0
1huk9gq,m5m9bhh,"I'm still studying, so... I don't know XD",-2,1736124194.0
1huk9gq,m5ltr34,1000%.  Most of those meetings could have been emails too.,52,1736119099.0
1huk9gq,m5m67eo,"Agreed except unlike those below, I find this isn't avoidable.  It is **the job** to be honest.  We have \~10 different stakeholders all with competing visions of what the project ought to look like.  It's your job to keep them all in line and still keep the statistics looking somewhat competent.

I find it funny people think LLMs will automate data analytics.  They don't understand that if running a Logistic Regression was the job it would have been automated in 1992.",89,1736123180.0
1huk9gq,m5lzykx,"ugh i feel that. if i have a meeting from 10-11, im not getting anything done from 11- noon bc i go to lunch.  then get back at 1ish. then try t oget in zone. uh oh, meeting at 2-3. another hour to get back in zone. next thing you know i worked about 30 minutes the whole day",62,1736121138.0
1huk9gq,m5m3v23,"Context switching. For software development many places have a culture of large time blocks for development, even entire days sometimes.",17,1736122416.0
1huk9gq,m5melwv,"My daily morning ""stand up"", which is meant to take 10min tops, usually ends up as an hour long waffle session, snatching all the wind out of my sails.",11,1736125966.0
1huk9gq,m5ltr3g,"This, always this.",7,1736119099.0
1huk9gq,m5un3yj,My old company used Snagit/Camtasia and it honestly helped so much. Now I’m at a place that is back to the endless cycle of unproductive meetings and I’ve been trying to get them to start using Snagit since we already own the software but no one does 😭,1,1736244784.0
1huk9gq,m5m40ky,The things that are considered pii these days drive me nuts. And there's never clear data governance rules for it.,38,1736122465.0
1huk9gq,m5r23jm,Just reading this made me break out into hives,4,1736194022.0
1huk9gq,m5no8gk,So do you get paid just to wait then?,3,1736142941.0
1huk9gq,m5vhn35,you ever get an excel spreadsheet consisting solely of screenshots of excel tables?,7,1736259569.0
1huk9gq,m5lys1p,"Oh... and the runner up for biggest sink...

1. Find somewhere that raw data exists that points to something they've asked to predict before.
2. Tell the business that we have the data, ask them how to build the value for the prediction unit (e.g. how to summarize time on the phone with a customer).
3. Spend more than a year repeating the question as they refuse to answer it.",42,1736120751.0
1huk9gq,m5m6h11,I have a paperclip and a piece of wire.  Please develop a money generating machine that produces $100M/year.  Go!,16,1736123268.0
1huk9gq,m5m5ibj,You're not entirely correct. You can use different paradigms such that you don't need to rely on every single variable having to exist in a row. That's exactly the problem graph databases try to solve.,25,1736122950.0
1huk9gq,m5o5hcj,"Hey, hold your horses, wizard. You are asking for way too much there, this is not a grocery store, this is a STARTUP! Here you have 75 tables, 20 links to outdated documentation pages, five days from now, and a ton of hope instead.",6,1736153269.0
1huk9gq,m5pzegr,“Can we predict x?” Is the precursor to the worst shit show of a meeting you can possible imagine,6,1736182564.0
1huk9gq,m6dh4jh,"Don't forget:  
5. The data exists in the form it will exist at the time of prediction.

6. You can do anything with the prediction",1,1736498304.0
1huk9gq,m5qcnl6,"In my case, there is no way of doing data validation. Everyone has their own concept of sales values, I kid you not, since months we've just been trying to settle on a simple sql query which gives me the freakin net sales. It's really sad.",5,1736186436.0
1huk9gq,m5n9f1v,So much data cleaning good god - why shouldn’t we have millions of tables with no shared indexes and tons of duplicated data,13,1736136431.0
1huk9gq,m5nq8p1,"> ""Oh that's why."" 


I feel seen.😁",6,1736143997.0
1huk9gq,m5mc2ot,"If one wanted to be drowning in meetings, one would be a manager.",10,1736125111.0
1huk9gq,m5uh542,"It seems some people in management devalue reading and writing skills for some reason, to the point where they can barely manage to pay attention to it. Especially if it's more than 1-2 sentences at a time.",3,1736240811.0
1huk9gq,m5mi6eh,"I mean, when we put hands on the database and try to understand things, we get to know that the real problem is many times poorly built systems.

In think that why it is important for a data scientist/analyst to be trained coming from a business background inside that company, because he knows the unwritten ins and outs, the quirks and fratures of systems.",5,1736127171.0
1huk9gq,m5mht5b,"Idunno how common this is in real life or on Kaggle, but I stopped paying attention to Kaggle after looking into a couple competitions structured like this.",3,1736127046.0
1huk9gq,m5mheyt,They send junk and expect flowers in return.,4,1736126915.0
1huk9gq,m5okdsf,Haha,1,1736162730.0
1huk9gq,m5pv08o,Building a solution for the wrong problem made me laugh and die inside hahaha.,6,1736181265.0
1huk9gq,m5qdhty,Oh god. Especially when you've spent 6 months on the solution :/,3,1736186683.0
1huk9gq,m6r6pp7,"Then when you do get the csv you find out they packed entire paragraphs (containing commas) into it and didn’t properly delimit the paragraphs…and the only person on their team who even knows what the term “file extension” means is the intern who only works on Fridays. 

This is when I just say give me the admin password. They have bigger issues than me misusing that lol ",2,1736695336.0
1huk9gq,m5qw1t1,Emails are also big time sinks!,5,1736192280.0
1huk9gq,m5wfdqg,Agree,1,1736270096.0
1huk9gq,m5mefh6,I need to print this comment and tape it to my monitor,20,1736125906.0
1huk9gq,m5ohk7a,"> It is **the job** to be honest

Correct. ""I rejected meeting with my clients as I wanna do science alone"" - a DS explained why he was fired in an interview",10,1736161070.0
1huk9gq,m61l220,"\+1000. Don't get me wrong, there are plenty of meetings that drag on, don't seem important at the time, or feel redundant, but they are absolutely crucial for intra (and inter) office communication.",1,1736342012.0
1huk9gq,m67y9pn,I'm putting this on my coffee mug.,1,1736429117.0
1huk9gq,m688opy,This is the best quote comment ever… i printed it and this is my new wallpaper,1,1736432937.0
1huk9gq,m5mgu3a,"This is terrible indeed. Up to the point where I asked for a couple no meeting days per week. 

It never gets better as well. In fact the more senior you become, the worse it becomes. 

I know of a few companies that have adopted no meeting days for engineering teams.",24,1736126715.0
1huk9gq,m5nmfaz,"Same boat for me, standing meetings everyday 9:00-9:30 then 10:00-11:00 it’s after noon before I can even really start going full bore and there’s often sporadic meetings in the afternoons as well",2,1736142026.0
1huk9gq,m5rbqbx,"Somehow any project I work in ends up having more non technical managers involved than developers, which eventually turns into micromanagement",1,1736196795.0
1huk9gq,m5nmm3j,The data privacy side of my brain likes that we take it seriously but the logical side of my brain realizes we may have gone a bit overboard,14,1736142119.0
1huk9gq,m5notfp,"What does ""pii"" stand for?


Edit: Never mind, googled it: 
""personally identifiable information"".",10,1736143242.0
1huk9gq,m5pdol5,If you just sit there and wait you're never getting access.,5,1736175795.0
1huk9gq,m5p42oz,"Yeah, it's part of the job. But there's always shit to do",3,1736172127.0
1huk9gq,m5mlivd,"Just thought of this, and graph DBs when I read ""impossible to build a model unless.. data is in a table"" (AFAIK even for relational DBs you do not necessary need to create an analytics table to predict on the connected tables)",2,1736128288.0
1huk9gq,m5nmgne,"when people say ""data clearning"", newbies imagine it is cleaning up columns, filling NAs, doing some feature transformation. Yeah those take time but can be done in a day or 2. 

The harder thing is sourcing the data and data understanding, what does this column truly mean, how was it collected, what are its limitation, what does it look like it means but doesn't, do we even have all the columns we need. And that often requires talking to multiple people from business to engineering.",27,1736142044.0
1huk9gq,m5md604,Right? Exactly. My poor manager is in even more meetings actually lol.,9,1736125479.0
1huk9gq,m5qycw5,"No manager I know wants to be a manager. They are all scientists with next to NO managerial training. Seems companies hire scientists with the expectation they do both the science and the management. Because, as we all know, science goes from point A to point B smoothly, seamlessly, and effortlessly and all we really need is someone who “knows” it to manage it.",6,1736192947.0
1huk9gq,m5refkh,"Happens way more often than you'd hope, unfortunately.",2,1736197559.0
1huk9gq,m5ohlgs,try with pprint library,3,1736161091.0
1huk9gq,m5p034g,"Honestly make your case. A lot of companies have no meeting days, or block afternoons or mornings for deep focus. It's a win win scenario, you're more productive and content, and you get more work for them.",5,1736170335.0
1huk9gq,m5wfitw,Same is happening to me as well,1,1736270137.0
1huk9gq,m5qrxiz,So that's a yes? lol,1,1736191081.0
1huk9gq,m5mp7qy,You're probably right I'm just really specialized into graph data science lol.,2,1736129505.0
1huk9gq,m5noiox,"Bonus points if the subject matter expert can explain the column to you in half an hour but they only have time for you in 1-2 weeks.


Sometimes that's just a reasonable time, and I appreciate the help but how can you even get into a work flow with a situation like that? 😁",12,1736143088.0
1hv5720,m5qhtgp,DS + SWE = ML Eng,65,1736187947.0
1hv5720,m5qd39z,"Yes, it is good. I think a lot of DS enter the workforce being weak on the coding side. Having a good grasp of how to write quality code and best practices with stuff like version control will give you a big leg up.",24,1736186564.0
1hv5720,m5qdq10,"So, logically the only way that studying both would not give you better skills if learning the other won’t give you any skill or even decrease your skills. Neither makes sense. 

So yes, learning DS and SWE is a good idea and will give you a clear edge.",10,1736186750.0
1hv5720,m5qwdm2,"Both can be super helpful. Having a solid SWE background can make you super flexible in terms of career path. Additionally, my experience being on data science teams of 1-2 people have been that it's incredible helpful to be able to flex a bit outside of a typical DS role responsibilities",6,1736192377.0
1hv5720,m5qy8tv,Yes. You will be able to build your own pipelines and own model deployment and observability. 10 times more valuable,5,1736192915.0
1hv5720,m5vkh2c,"1/2 of companies dont know the difference between DS and SWE and expect you to do both :) 

the only time you can get away with not having SWE skills if you're hat a HUGE company where roles are specialized and well defined.",2,1736260575.0
1hv5720,m61p563,I’d say it is. There are DS people who are SWE,1,1736343637.0
1hv5720,m63k9s1,Computer science would’ve taught you both.,1,1736364427.0
1hv5720,m64zywq,better,1,1736379966.0
1hv5720,m6jica6,"It is better to focus on 1 thing first then after getting a good grasp of it, you can move forward to other things.  
One good benchmark of measuring this is that you should be able to bring value using your skills.",1,1736578217.0
1hv5720,m6um4t6,…..,1,1736732492.0
1hv5720,m5qzc0p,"In my experience, real world large scale data science solution become software engineering projects.   
Plus, here is this classic blog post from Google. I believe there is a paper and a talk somewhere on YouTube if you want to learn more.  
[https://developers.google.com/machine-learning/crash-course/production-ml-systems](https://developers.google.com/machine-learning/crash-course/production-ml-systems)  
\> At the heart of a real-world machine learning production system is the ML model code, but it often represents only 5% or less of the total codebase in the system. ",1,1736193221.0
1hv5720,m5r3m8g,That’s how I did it,8,1736194461.0
1hv5720,m5r7qmy,How much SWE?,1,1736195657.0
1hv5720,m5wh84j,You can also target MLOps roles,1,1736270635.0
1hv5720,m5qdlut,Thanks brother! Honetly i love coding so i may just go into swe haha but i like ds as well,3,1736186716.0
1hv5720,m5qullg,Thanks brother:) im just anxious and always question my choices haha,1,1736191856.0
1hv5720,m6jjgyb,What do you mean by flexing,1,1736578881.0
1hv5720,m5riyst,"I'm seeing more and more that non-product DS own their entire model life, including stakeholder management and deployment . So many DS positions = DE, PM, DS (modeling) and MLE. OP, I absolutely recommend learning both. I had to pick up SWE on the fly and that's...a painful way to go about doing it. Used to be just a pure statistician - that ain't cutting it these days.",14,1736198860.0
1hv5720,m5ra78t,How would you recommend going about learning the SWE skills if you already have the DS skills?,4,1736196358.0
1hv5720,m5rb0nx,I spent the first 2 years of undergrad lazer focused one SWE and math. Worked for me. ie: knew I wanted to do ML but didn't want to distract myself with it until I had strong fundamentals.,3,1736196591.0
1hv5720,m6jjf32,I feel like my situation is manifesting like that.,1,1736578850.0
1hv5720,m6v6o4l,"I’m a hiring manager, mostly at mid-size orgs, and have interviewed and hired multiple data scientists and ML engineers. You’re spot on that people like me are screening for SWE and PM skills as much as “pure” DS skills these days. If anything I’ll de-prioritize the DS skills. It’s honestly the differentiator in hiring. To your point, statisticians alone don’t cut it anymore. 

OP learn SWE because SWE is how you move something to production, and production is what you need to do to be valuable.",1,1736739833.0
1hv5720,m5rch5x,"Study books on SWE skills. Something on writing good tests, something on modern software architecture, something on using your language of choice at an advanced level. I’d also recommend learning workflow styles like domain driven development.",11,1736197005.0
1hv5720,m5rassu,Write nontrivial apps yourself,1,1736196528.0
1hv5720,m5revzq,"Thanks for sharing, I've saved your comment and will look into each of these areas.",1,1736197690.0
1hv5720,m6q52ln,Do you think practicing leetcode questions will help?,1,1736677999.0
1hv5720,m6qgu66,"All interviews have some kind of technical assessment that you need to pass. You’ll need to pass easy leetcode or hackerrank problems at least.

If you’re aiming for elite firms, there’s a catch-22. 

Leetcode helps your career but not your actual skill as much. At the same time, the best way to build skill is through job experience at good companies. So there’s a tension there that’s hard to navigate. 

(edit: you need to know computer science and if you get that through Leetcode, then obviously it’s best to study it)

Whether or not you as an individual should invest a lot into leetcode mostly has to do with whether or not you need a new job right now. If you can afford to spend 3 months grinding leetcode, it’s likely worth it. 

At an academic conference I went to last year, a rep from Meta AI told a crowd of PhD students that even researchers need to get through their leetcode problems. So there’s really no way around it if those companies are your goal.",1,1736684979.0
1hvnkbl,m5wgnvr,"This has been demonstrated hundreds of times. The thing is, those problems are almost certainly in the training data.",9,1736270472.0
1hvnkbl,m5ve56u,"What’s the value proposition of this? I’m not gonna click on the YouTube link but I’m hoping it’s not a regurgitated medium article in there and you’re just trying to pad a portfolio because I’m not sure this adds much.

I mean, you would at least have to compare it to something but we have papers with code

And I’m not saying it’s not important because I’m trying to solve some hard problems right now, but I couldn’t pass a leet code test to save my life. I only have an associates degree. But I know I’m putting out better implementations than half the PhD’s on this sub",2,1736258274.0
1hudtrj,m5kczpc,"You **will** be rejected in many interviews. You can't avoid that, it's not in your hands.

The best preparation is practice.

I'll let you join those two bits of data into the answer you are looking for.",107,1736103628.0
1hudtrj,m5ke4go,"Interview questions have a common thread,

They want to know about you.

Your skills and how you have used those skills.

How you would fit into the company. What can you bring to the table.

Questions like this I think you should practice, You want to show/demonstrate this is who I am, this is what I have accomplished and why I am the best candidate.

If you get an interview you can you some more research on the company and thing about questions they may ask that fit their industry.",15,1736103944.0
1hudtrj,m5kow27,"I'm going to go against the grain, and disagree with the folks saying to prep AFTER you get called for an interview. Being reactive MAY work at less-competitive companies, but for more competitive places people intentionally prep waaaay before they get a chance to interview.

I know that might sound crazy/infeasible, but there's enough similarities between companies and what they ask so that it IS possible to generically prepare (which is half the point of my book [Ace the Data Science Interview](https://www.acethedatascienceinterview.com/) which covers the compiles the most frequently asked questions/topics into one place).

For example, for Product Data Science at Meta, AirBnb, Uber, etc. absolutely prepare for SQL interviews before you get that 1st round HackerRank/CodeSignal/Codility assignment. Otherwise, it's hard to ace multiple [FAANG SQL interview questions ](https://datalemur.com/questions)in a strict 45-minute window unless you've already done intentional practice over a couple of weeks. Of course, if you use SQL often on the job, then it's not so hard – but I know enough folks use pandas/R daily then get caught by surprise on the SQL screen.

Same way, practicing [Product Sense/Product Metrics questions](https://datalemur.com/blog/meta-data-scientist-interview-guide#Analytics-Reasoning-Questions) can take some time, because many people don't work on Product Analytics or do [A/B testing](https://datalemur.com/blog/ab-testing-interview-questions-and-answers) in their day to day jobs. The people who successfully get into FAANG spend quite some time reviewing books on A/B testing (like trustworthy online experimentation) and Chapter 10 of Ace DS interviews (which is on Product Analytics).

Same way, folks targeting MLE at Meta, Amazon, Google etc. totally practice Python Data Structures & Algo questions along with ML System Design (Alex Xu has a good book on this) waaay before they get a chance to interview. Folks preparing for more hardcore ML Research Scientist/Applied Scientist roles often re-read ISLR and other foundational ML texts to prep (because big-tech sometimes goes into the math/formulas behind ML tbh).",67,1736107018.0
1hudtrj,m5kbw99,"I apply for jobs first. I don't focus on interview prep until an interview has been arranged. 

You say you never feel fully prepped and you're correct, there's always more weird questions you could be asked, or they could  ask some niche you don't have any experience in. I think its best to accept that and go for the job anyway",53,1736103328.0
1hudtrj,m5kv98l,"Apply to jobs, tailor your application to the specific job description. This will help you prepare for the specific interview. After you get the interview, do a little research over the company and their mission statement that you can repeat back to them. So they feel validated about their life choices. 

 Otherwise, there are usually only so many interview questions they can ask you. Just have a few answers prepped for the following:
“Why do you want to work here”
“Why should we hire you”
“What are your strenghts”
“What are one of your weaknesses” (usually framed in a positive light, ie: sometimes I can be a little too detail oriented)
“Where do you see yourself in 5 years”

Have a few questions to ask them at the end as well, this is important. Even if it’s a question that you don’t need to ask, you want to get as much information about the job and salary ranges as you can.

 Something like: 
Can you give me a little information about what the training process is like? Is it a hands on training or is it via computer modules?”

 “If I were to be offered the position, what are some areas you think I could improve on when taking this role”

“What does a day to day look like for the position in question? Is there anything in particular that you guys need help with?”

If they give you a card or something. If it’s not automatically turned down, try and jot down their names really quick when you get a chance. 

Regardless of how the interview goes, shoot them a quick e-mail thanking them for the opportunity for a face to face interview. Use their names if you still have them, then include a note about why you think you’d be a good fit for the role. 

You’re basically apologizing for wasting both of your time, but then you’re letting them know that despite that, you still think you’d be a good fit for the position and you are interested in an opportunity to work for them. 

Also, this will give you an opportunity for some stuff to think about some techincal questions that they might have asked you during the interview about something you might not have known. 

If they reject you, they might respond and give you some infor on what you could improve on. If they don’t respond or if they say they moved forward with someone else, it is what it is. Move on. But in some instances, they’ve kinda already made up their mind, but you might give them a second chance to think about you. 

Sorry for the huge wall of text. Hope that helps. Best of luck in your job search…",6,1736108876.0
1hudtrj,m5kvzu6,"Why is it either/or? Maybe it would help you to realize that almost no employer will not consider you for a future job if you bomb an interview now. 
I think if you know what kind of role you would be looking for, doing generic interview prep while also applying would be best. Once you land an interview, you can then tailor to this company and role. 
If you are very unsure, you could try applying to a company that does not have a reputation for hardest interviews first, and treat this as a practice run. Here, it’s also really important to realize that many companies have dozens of job offers that they will send out, and you rejecting a job offer usually does not have any bearings on future job offers with them (unless it is a very small company and/or they feel like you did not behave professionally). The downside of course is that interviewing might be more difficult if it’s not a job/company you definitely want.",3,1736109091.0
1hudtrj,m5l1ek7,I have a list of the most popular questions and written out answers to all of them. I update the answers to them after each job I have had. Some updates are minor. I keep the old answers and will pick the one that's best suited for the position I am interviewing for. I started doing that after realizing I'm forgetting projects I've worked on etc. I also keep the job description saved and I update it after leaving the position. I add questions as they get asked. I interview every year to understand the market for my position and skills. Before my interview I read the file I have prepared.,3,1736110625.0
1hudtrj,m5kwev7,"In general, I'm always prepping for interviews in some way. Even though I'm not as hands on as I was in my younger years (been in field for more than 20 years), I still do a few Leetcode problems each week, go through advent of code, sometimes Kaggle, read a lot, and usually do a round of interviews about once a year to make sure I've found the best opportunities.

It seems like it's a lot - but I genuinely like solving these problems and I believe that spending a few hours a every week (not much, maybe 1-2 hours most weeks), ensures that I'm ready when the opportunity comes and don't have to go into crunch mode and my responses seem ready and natural without feeling over practiced.",2,1736109211.0
1hudtrj,m5l3145,"I apply first, I only prepare if I am contacted. Especially in our current market.",2,1736111086.0
1hudtrj,m5l9bk7,Simultaneously,2,1736112856.0
1hudtrj,m5l9kdz,You'll be effectively rejected from job you never apply for. Might as well go down swinging.,2,1736112928.0
1hudtrj,m5mapo8,"For interviews I usually study the regular interview questions in the field. Practice effective communication helps too, I learned if you sound good, you look more intelligent. It's hard for me since I'm still learning English. lmao
Please like so I can get a comment karma :P",2,1736124654.0
1hudtrj,m5l7gmx,I don’t prepare for interviews. I’m dead serious. You either know what you’re doing or not. What would you even prepare?,2,1736112322.0
1hudtrj,m5kvcrx,"I apply first. I never turn down an interview. Once I land an interview, that’s when I start to prep. 9 times outta 10, the interview won’t be for days, maybe even weeks. So you’ll have time to book appointments, prep or study. It’s better to apply. So when the interview comes, you can put your best foot forward.",1,1736108904.0
1hudtrj,m5l2olb,"I prepare for interviews first, but that's because I do it by applying for a bunch of jobs I don't want to just get practice interviews in, and then start applying for jobs I want once I start to feel comfortable.",1,1736110986.0
1hudtrj,m5lofe2,"Apply for jobs first. If you get interviews, the first round is a recruiter screen and you won’t need to prepare much, just familiarize yourself with the company and the role. Ask the recruiter what the rest of the interviews would include so you know if you need to prepare for a live coding assessment.

Also even when you feel prepared, you will still get rejected. And even if you’ve interviewed before, your first few when it’s been awhile will be rusty. 

All that is to say, don’t have high hopes for your first few interviews. They’ll be learning experiences more than anything. But the more you do, the more you’ll know how to prepare and the better you’ll get.",1,1736117401.0
1hudtrj,m5m78g6,"I recommend a mix. If you’re looking at jobs at companies that ask you to wait a year before reapplying (like many of the big tech cos so) then prep first. There will be another job you like there in 2 months time, so you don’t want to burn an opportunity and have to wait a year. Same goes for places you have an in through a connection. Get some practice (including real interviews at other companies!) before you go for these. 

If you’re generically interested in say startups, just apply. They may not hire again for a long time. And even if they do, they may not have a policy against reapplying again soon.",1,1736123514.0
1hudtrj,m5me9gk,"Apply for job and at the same time do basic preps. Yes, you cannot prepare everything within short tome but also if you don’t apply you won’t get interviews. So divide your time like that. Problem with preparing forat and applying later is you don’t know when you will get an interview. So you might forget things if you don’t get interviews in short time. If you are beginning in your job search divide by 50-50 after a few weeks months if you are still searching apply more time to the job and less on prep as by this time you would have covered a lot and would just need a few days to repeat every thing if you get an interview.",1,1736125849.0
1hudtrj,m5mpgsa,"Preparing for the interview is essential before applying for a job, as it will boost your confidence. Before attending the interview, ask current employees of the company how they prepared for their interviews to understand which areas the interviewers focus on. Additionally, explore medium blogs written by people from the company and for the roles you are applying for, as they might have shared their interview experiences.",1,1736129586.0
1hudtrj,m5o58up,"Maybe its a matter of taste and style, here is what i am doing.

I have segregated companies in two categories- 

1. Companies i care about
2. Companies i do not care about

For 1,  i make sure i apply and sit for interviews even without any preparation just to see what is asked and how ready i am.


For 2, i study as much as i can before the interview and if i feel i am yet to learn enough for the role basis job description and internet research i will not sit for them.",1,1736153112.0
1hudtrj,m5o9fde,"Here is what I have done to prepare DS interviews after college:

# Step 1: Build a Baseline Knowledge

I start by developing a foundational understanding of the key skills and concepts required for the roles I’m interested in. For example, if I’m aiming for a Data Scientist position, I refresh my knowledge of machine learning and practice Python/SQL coding using resources like LeetCode or similar platforms. This ensures that my technical skills are up to date.

# Step 2: Apply to Two Types of Positions

I categorize the positions I apply to into two groups:

1. **Positions of Interest:** These are roles at companies I genuinely want to work for.
2. **Training Positions:** These are roles at companies I’m less interested in but have a similar application and interview process as the positions of interest. I use these opportunities to gain interview experience and fine-tune my responses.

# Step 3: Prioritize Applications

I typically apply to training positions first, allowing myself to get comfortable with the interview format and expectations before moving on to the positions of interest. This staggered approach helps me improve and build confidence.

# Step 4: Research and Dive Deeper

Once I start preparing for interviews at the companies I’m genuinely interested in, I analyze the job descriptions to understand the specific technical requirements. For example:

* **Visualization Tools:** What tools are commonly mentioned (e.g., Tableau, Power BI)?
* **Programming Principles:** What coding practices or methodologies are emphasized?
* **Frameworks:** What technologies or frameworks does the company use?

# Step 5: Understand the Interviewer’s Expertise

From my perspective, one of the most crucial steps is to research the background of the interviewers, if possible. I check their expertise and areas of specialization, as it’s likely that some questions will be related to their specific field. This allows me to anticipate potential topics and tailor my preparation accordingly.

Good luck!",1,1736155856.0
1hudtrj,m5oogd7,interviewing is the best preparation for interviews,1,1736164980.0
1hudtrj,m5pptlc,"Its a mix and match and I do the below:

1. Explore the roles that I want to appear and capture the JD and key points that are required
2. Write a must have, nice to have catalog of all the skills
3. Tag the ones I know on a scale of 1-5 with 5 being the best
4. Pick the ones that are on lowest number and time box my preparation 
5. Start appearing for the roles

The success rate will be more and it worked for me whenever I picked roles bigger than my experience at that point in time!",1,1736179692.0
1hudtrj,m5r10rq,"I always apply first, that way I know what the JDs are and can practice and prepare accordingly.",1,1736193706.0
1hudtrj,m5tiljq,"Already having a DS role makes it that much easier, imo, if you're actually doing real DS work in your role. Why? Because most interviews are going to ask you questions that should mimick the work you're already doing. 

Ex. How would you build a CLTV model, given x? This one question can turn into a full 30-45 minute discussion where the interviewer can dive into deeper questions centered around outlier treatment, business justification, model selection, parameter tuning, etc. But these really shouldn't be too difficult to answer if you've been doing this sort of work in your role. 

I'd say it's always a good idea to brush up on SQL, even if you're using it often (which you should be), you may not be coding out windows functions, cte, complex joins, etc.  From scratch every day, it's best to brush up on how those work just to be safe, but everything else shouldn't be too difficult.",1,1736222528.0
1hudtrj,m5vfsac,Do both of the activity simultaneously.  There will be rejections but atleast you would get an idea what questions were asked.   Learn the concepts which you don't know.,1,1736258891.0
1hudtrj,m6aokv5,"Part of a good preparation before applying is to do a ""quick"" scan over the companies website and generally acquiring a little knowledge of who they are, what they do, and their products. You don't need to be able to discribe anything in detail but a general idea will help a lot on the second step.

The second step would be to really read the job description well. Each job description is drenched in actionable words like ""You like to -coordinate-,"" or "" -communicating- with your team is what you do""   
Mark those words and check how they apply to you and how that might fit in the job they are presenting.

Something that might also be helpful is calling the recruiter or manager. Often they have a number for questions.   
They had a issue and they want to solve that by hiring someone so you could ask questions along the lines of what they'd expect short term (couple of weeks/months) and what they hope you do by the end of the year.

If you've done those things applying is the follow-up step and honestly quite a easy one as well. You already prepared quite a bit for both this and possible interviews so most of your work is now done. You know pretty well what to expect and what will be roughly expected for you so you can use that to further prepare your interview if needed.",1,1736458980.0
1hudtrj,m5n4j5w,"But passing interviews is literally in your hands. Sure, not 100% in your hands but... it's absolutely a learnable, practicable skill. Like it's 85% in your hands. For example, it's not unreasonable to get your SQL skills to a level where you can pass 95% of SQL interviews – and that's just \~1 month of SQL practice where you do \~2-3 questions a day.

Similarly, I know tons of people who ""know"" ML – and it turns out they just blindly import random stuff from sci-kit learn, and all their projects are copied from YouTube or other people's Kaggle notebooks. It's literally in your hands to read ISLR – create flashcards – do the exercises – and get a fundamental understanding of the most important DS techniques/algorithms. Again, this might not get you a $750K ML Research Scientist role at OpenAI/DeepMind...that's not in your hands. 

But the prep I outlined should be enough ML to get a $175k ML job and standout from 90% of the bootcamp grads/new grads.

And even something more soft-skilled like behavioral interviews is absolutely workable, improvable, and fixable. I work with folks on this exact topic, and watch Data Scientists make incredible gains with just a few hours of coaching (yet people will say that behavioral interviews can't be prepared for, since it's hard to change your past work experience, character, personality in a month).",25,1736134698.0
1hudtrj,m5ljtk2,"I have your book and I love the product sense part of the book. Since I don’t have a ton of product analytics experience, I have trouble answering those questions. Your examples in the book helped a lot but I wish there were more because of my dumbass lol. 

Any resource you can suggest where I can practice more of these product sense question, bonus if they have answers attached to them just like in your book?

Edit: Sorry can I ask one more question. How worried should I be about cool down period? Do most companies have that? One of the reasons why I am afraid of applying without full prep.",11,1736116001.0
1hudtrj,m5lkdbh,"Thanks. I have been preparing for SQL rounds and behavioral but I feel like beyond that they could ask anything, so it’s better to get the interview first.",5,1736116167.0
1hudtrj,m5lkpwu,"This is great, thank you!",1,1736116274.0
1hudtrj,m5lko2v,"This is really great advice, I also realized I have forgotten about my past projects. Better to just write it down as you go.",1,1736116258.0
1hudtrj,m5nlqlv,If possible can you share that list?,1,1736141689.0
1hudtrj,m5nnwkx,"I do mostly agree with this, and also why interviews also catch false positives - I've met and worked with many - MANY - people who interviewed well but really were not competent on the job.",6,1736142772.0
1hudtrj,m5n4swl,"Great advice, I have just picked up your book today 😃 will start preparing soon!",2,1736134796.0
1hudtrj,m5su5gj,Do you have any resources to practice SQL questions?,2,1736213959.0
1hudtrj,m65hqlg,Can I ask if there are any coaches you would recommend for behavioural interviews?,2,1736385950.0
1hudtrj,m5n3rtc,"Glad you already have the book, and have found it helpful! For more practice, look into PM specific resources, like the book Cracking the PM Interview or Lewis Lin's ""[The PM Interview](https://www.lewis-lin.com/the-product-manager-interview-lewis-lin)"" book. Also, look at the book ""Lean Analytics"" since a ton of Product Sense questions are around finding good product metrics. 

Regarding cool down – it's usually 6 months. But if you super-duper fail, then maybe it's longer.",1,1736134429.0
1hudtrj,m5rocry,"Take the first, second and maybe also the third interview as practice, apply for companies that you might be interested in but they are not your dream company and practice with them. You will understand more about it and then you can prepare better for more important interviews for companies you really like",1,1736200426.0
1hudtrj,m5nsbdm,I started with free guide from ask a manager dot com. Then I bought her book. Then I added questions to the file as they came up in a real interview.,1,1736145134.0
1hudtrj,m5pbft1,Love to hear it!,2,1736175020.0
1hudtrj,m5sxtr6,Yup I run [DataLemur](https://datalemur.com/questions) – has over 100k users on the site practicing 200+ FAANG SQL questions :),2,1736215196.0
1hudtrj,m65zg3y,DM me! I’ve helped hundreds of people with both behavioral and technical!,1,1736392217.0
1huloe0,m5mc5xh,"Some companies use existing models in order to not to start from 0, usually putting in there a ""powered by"" like label in the product description. For other companies who start from 0, usually they have a brief description of its model in the technical presentation of its products.
At the code level it's really hard to start from 0, you can use tools like tensorflow in python to create some AI models.
~Please like me to get comment karma:/",14,1736125141.0
1huloe0,m5qymgu,"Do people still use tensorflow in prod for new products outside of Google/alphabet companies? 

Nobody starts by building their own library these days. It’s build on top of PyTorch, or maybe Jax depending on the segment and model.",4,1736193022.0
1hvk25m,m5ttg8u,A list ... in video form.,8,1736227159.0
1hvk25m,m5tvyik,"Best Open-Sourced LLM: DeepSeek-v3

Best Image-Video Model: Tencent’s Hunyuan-Video

Best Reasoning LLM: Gemini2 Flash Thinking Experimental

Best Image Generation Model: Flux by Black Forest Labs

Best Coding LLMs:

Gemini2 by Google

Qwen-2.5 Coder by Alibaba


Best Small-Sized LLM: Microsoft’s phi4

Best Multimodal LLM: Gemini 1.5 Pro by Google

Best Audio Cloning/TTS Models:

F5-TTS

Fish TTS


Most Popular LLM: Meta LLama 3

Best LLMs of the Year:

OpenAI GPT-4o

Anthropic Claude3.5 Sonnet",5,1736228351.0
1hvk25m,m5ttn03,Blog version : https://medium.com/data-science-in-your-pocket/the-best-llms-of-2024-0b5d930f89ff,-8,1736227247.0
1hurdd1,m5wpsek,"# Data scientist - high TC but no growth. Would you leave?

  
  
Throwaway account. I'm a data scientist at a FAANG company, where I've worked for three years in a mid-level role. My manager is supportive, and there's a high chance I'll be promoted to senior this year. Before this job, I earned an MS and PhD in CS. This is my first industry position after finishing my PhD.

Over the past year, I've barely done any in-depth coding, training models, analyzing data, or diving into stats. Most of my work these days involves using pre-built ML cloud tools and designing product architecture. It didn't used to be like this—when I started, I used to do DL, statistical analysis, and other tasks that let me use my full skill set. Even basic grunt work felt balanced out by the more challenging work I was doing. Now I feel like I'm forgetting the fundamentals, so I'm resorting to side projects and extra studying just to keep my skills sharp.

I’m surprised they still need someone with my level of education. My total compensation is high ($410k in 2024), so that’s one reason I’ve stayed. My manager wants me to succeed (and is pushing for a promotion), but I’m not growing technically. I’m wondering if this is normal. I understand that we are hired to deliver results and improve the bottom line for the company and if that involves working on ""interesting stuff"" - good, but that is not the goal.

Would you keep working a somewhat boring job while studying on the side, or look for a different role where you can do more hands-on data science?",2,1736273117.0
1hurdd1,m60jal9,"Hi Folks,

I’m currently working as a data scientist and trying to decide whether pursuing a master’s degree would be worth it for my career goals. I graduated with a math undergrad a little over three years ago and would like to stay in the data science field but specialize further in building ML models, ML Ops, and AI solutions for business cases.

In my current role, I work on building data pipelines with Python/SQL and creating dashboards with Plotly Dash. I’m starting to explore IoT data analysis and machine learning, but I feel like I lack the deep technical background needed to fully dive into these areas.

While I know I can learn on the job, I’m wondering if going back to school now for a master’s degree would better equip me for a transition into a more technical role. My ultimate goal is to become an ML Data Scientist.

From your experience in the industry, is it worth pursuing a master’s degree for this transition, or would I be better off continuing to gain experience and learning on the job?

Thanks for your insights!",2,1736320418.0
1hurdd1,m63mvw5,"Hello, I'm trying to enter data science with no job experience (only a little from an internship, but even that's not fully DS). I'm struggling with applications feeling very dispiriting and like a waste of time when it feels like you'll just get rejected or not hear back anyway. I haven't heard back from most of them (or just got a quick rejection email). To be fair I haven't applied to as many as I've seen done here (I've done about 50).

Another thing is that a lot of the positions I see on LinkedIn marked as entry-level still requires some experience, which disqualifies me. On the other hand, internships, which I feel more qualified for, often require that you still be in school, and I'm not. (For a bit of background, I graduated with a bachelors in Math about a year and a half ago. In the meantime, I've been working on upskilling my data science skills by doing online courses, reading an ML book and doing all the exercises, and doing a personal project.)

Is it still worth it to apply to positions? If not, are there better ways to get hired as a new data scientist with no experience?

If it's still worth it and necessary, what's the strat? Should I blindly mass apply, going for numbers, even though I may not be qualified? Or should I only apply to those that I feel qualified for, and tailor my application for each? Are there any companies or industries that I should target/have better chance of getting a job with no prior DS experience? What are ways to make this application process easier and faster?

TL;DR: Applications feel like a waste of time. Are they necessary to enter as data science with no experience? If so, how to make the process easier, faster, and more effective? Any companies or industries to target? If not, are there better ways to break into the field?

Thank you for any advice and insights!",2,1736365188.0
1hurdd1,m5ntsuf,"Hi community, so I have approximately 3 years of experience in market research domain where I mostly worked on report writing, market sizing and segmentation and forecasting. 

All work was mainly secondary research from web and translating all into reports manually. Also, competitive intelligence was a part of my work as in applying secondary research to annual reports and similar sources. The work was pretty much non technical and market sizing was done in basic excel sheets.

I have been learning basics of data science tools and techniques including Python, SQL and some ML algorithms as well. I dont want my market intelligence experience go completely down the drain so how possibly can I work on certain projects related to market research domain which adds an edge to my DS portfolio. Specifically, market sizing and forecasting which is only part with most logic applied. 

Summing up, I wish to transition to DS/ML domain without compromising whatever I've experienced in my non tech job. Any suggestions will be highly appreciated.",1,1736145970.0
1hurdd1,m5o7r3i,"Hello community!

I’d like to discuss a scenario that many of you might encounter when trying to break into the data science field. Unlike software engineering, where top companies often recruit directly from college, data science roles at these firms are typically reserved for experienced professionals. This raises a critical question: What’s the best path to eventually land a data scientist role at one of these top companies?

Here are two potential strategies I’m considering:

1. **Start as a Data Analyst at a Top Tech Company (e.g., FAANG)**: Accept an analyst role and work your way up by demonstrating your value, gradually taking on responsibilities like modeling and machine learning tasks.
2. **Start as a Data Scientist at a Less Prestigious Company**: Join a company where it's easier to secure a data scientist position, gain hands-on experience, and then transition to a top-tier company after 2-3 years by leveraging your knowledge and skills.

This decision is particularly relevant to me, as I’m about to finish my degree in mathematics and statistics in Europe. I’ve received offers for data analyst roles at FAANG and a leading fintech company. These positions aren’t purely business-focused; they also include tasks like modeling and ETL. On the other hand, I’ve received offers for data scientist roles at less renowned companies.

I’d love to hear your thoughts on which path might be more beneficial in the long run.",1,1736154754.0
1hurdd1,m5qo2v3,"Hello community, 

Is the Data Science market in LA or the general SoCal area heavily oversaturated or is it a lot better than San Francisco or even possibly Seattle? Is it harder to get a job or to keep a job in the area? Additionally, what cities are the best for more jobs and less saturation? Is it just smaller towns or specific cities?",1,1736189948.0
1hurdd1,m5sn857,"Laid off after maternity leave, where is my career going?

Looking for advice please. (Not a native speaker so please forgive my English.)

I was a M1 manager for 2 years managing a small DA team for a biotech company. Mainly working on analytics stuff such statistical analysis, ML model for inference, ad hoc analysis. Prior to being a manager, I was a DA for 4 years. Again, mainly data extraction + cleaning + basic analysis.

I didn’t like why I do because it was very basic and manual, and I took time to study python + data structure + ML/DL while working for about a year. I was fantasizing I could take time to do career transition.

Then, boom, I was laid off. Right after coming back from maternity leave. 

I sent out tons of resumes, asked friends for referral and even had a few interviews for DS positions. However, not sure if it was because postpartum brain frog or I was just not technical/sharp enough, I realized I could not even pass SQL question in one shot in interviews. I was so nervous about limited time, and always missed some corner cases, or sometimes just blanked out.

If I couldn’t even do SQL well, will I ever pass MLE/SDE coding round? Should I not even think about transition to MLE/SDE?

The job market was tough. I don’t want to be a DA, but I was really questioning my ability to become a MLE/SDE. Not to mention that I probably need to invest my time/energy to learn courses/boot camp if I want a transition. 

What should I do?",1,1736211659.0
1hurdd1,m5thcxt,"hi!! i got to university of waterloo in canada and im studying mathematics (stat). i really really want a data science role for my co-op (internship) in fall 2025 and i’m very interested in the field of ds/ai/ml. 

im kinda lost rn and i feel like i have the mathematical and theoretical concepts down, i just don’t know what i should spend my time learning/studying or if i should be doing projects (but like what kinds) so im employable and can ace technical interviews for f25. any guidance would be greatly appreciated!!

note: i have experience with SQL and Pandas from my last co-op but it’s rlyyyy rusty.",1,1736222049.0
1hurdd1,m5uhnii,"I just passed Meta's product data scientist 45-minute technical screen. Looking for fellow interviewees to do mock interview for product sense / ab-testing / metric questions! 

Would anyone like to help each other prep?",1,1736241150.0
1hurdd1,m5w0kdb,"Hi community!

Considering a move from Data Science to Managing Reporting and Reporting Infrastructure - advice?

I’m exploring a potential career move from a consulting data science role to managing reporting & reporting infrastructure at a MANNG company. The position involves overseeing self-service reporting products, enabling real-time insights into performance, and improving operational efficiency for a key business area including have at least one direct report. While it’s not AI-focused, it’s at least adjacent to data & AI and involves significant business impact, stakeholder interaction, and team leadership. 

Personally:

I see this role as staying firmly within the technical space of data, but shifting away from the ML/AI/Data Science focus, which is admittedly a bit unsettling. Why? The current landscape heavily values these technical skills, and I don’t want to risk a perceived hiatus—or an actual one—from AI and machine learning by stepping into a more management-focused role.

That said, this position aligns closely with my technical background, especially given its cross-functional nature and high business impact. While it’s more of a Technical Program Manager (TPM) role due to the communication and coordination requirements, it’s still deeply rooted in a critical data area. The fact that it’s at a MAANG company also makes it feel like a worthy opportunity.

For context, I’ve spent the last 10 years as a Data Scientist, working at major companies across analytics, modeling, data engineering, and more. I’ve likely held nearly every key role in the data space, including building and deploying two software applications into production.

Id be leaving a data science consultant role at a major consulting company.

Some bullet point context:

1. Current Role: Data science consultant focusing on technical and analytical projects.

2. Potential New Role: Managing reporting infrastructure—a high-visibility position driving critical business outcomes with long-term ownership over products.

3. Concerns:

Moving away from hands-on data science/AI work.

Transitioning into a management-heavy role in reporting.

Balancing career growth in leadership versus staying technical.

4. Upsides:

Significant career growth potential at a globally recognized company.

High impact, stakeholder-facing role with opportunities to transition into other areas (e.g., AI, advanced analytics) in the future as a possibility.

A chance to own and improve processes long-term, rather than short-term client-focused consulting projects.

Questions:

1. Has anyone here made a similar transition from data science to managing reporting or infrastructure? How did it impact your career?

2. How do you stay connected to your technical roots while taking on a management role?

3. Any tips for weighing the trade-offs between long-term career growth and staying technical in the short term?

Looking forward to hearing your insights and experiences!",1,1736265717.0
1hurdd1,m5wb00r,"# Advice for courses or certification apart from university

As a student pursuing a Bachelor's in Data Science, what additional certifications, or courses should I explore to enhance my career prospects and improve opportunities for getting the job? Are there specific domains or technical skills that would make me more competitive in the job market?""",1,1736268810.0
1hurdd1,m5wjfps,"**Stuck in a Non-Data Science Role After Being Hired as a Data Scientist**

  
I joined a new company a few months ago as a Data Scientist, specifically hired to work on Generative AI. Before this, I worked  in a different role at a large MNC but left that role to transition into data science. After nearly a year of job hunting, I was excited to finally start this position.

Unfortunately, things have gone downhill fast. The person who hired me resigned shortly after I joined. The company is undergoing significant cost-cutting, including reducing the data engineering team by more than 50%. The new manager has no background in data science or IT, and none of the projects are related to data science.

Instead of working on Generative AI or any data science-related tasks, I’ve been assigned to oversee the implementation of an SAP module in ECC—a module unrelated to the ones I’ve worked on in the past. To make matters worse, the manager is toxic, frequently asking irrelevant questions I can’t answer and assigning tasks completely misaligned with my role and skills.

I feel stuck and don’t know what to do. Should I leave this job and keep searching for a position that better aligns with my skills and goals? Or is there a way to make the best of this situation?

Has anyone else been in a similar position? I’d really appreciate any advice!",1,1736271282.0
1hurdd1,m5xa3kr,"**Should I Stay or Quit Before Finding a New Role?**  
  
Hi everyone, I ’m feeling stuck in my current role as a marketing data scientist and could use some advice.

A bit about me: I have a background in chemical engineering and I am doing my master’s in AI for Business and Finance. I’ve built skills in Python, SQL, AWS, S3, machine learning, and tools like Airflow and Looker, I have created and deployed ML solutions for my previous company. I accepted this role as a marketing data scientist because the company was upfront that they lacked a data culture and needed a self-starter to lead a transformation process. It seemed like an exciting challenge, but the reality has been much more frustrating.

Here’s what I’m dealing with:

* **Stakeholder resistance**: Despite their initial openness, stakeholders rarely respond to my ideas or input. Meetings with them are unproductive because they often invite 3–5 random people, making meaningful conversations impossible.
* **Database access and performance issues**: It took over a month just to get access to the company’s database. Now, pulling data is painfully slow (queries take 1–4 hours due to server performance on a replica), and DB admins frequently kill my queries without warning or explanation.
* There’s talk of granting access to a datalake (currently reserved for HubSpot use cases), but there’s no clear timeline or commitment.
* **Duplicate work and poor communication**: Teams duplicate work constantly because there’s no coordination. Stakeholders resist process changes or suggestions for improving workflows.
* **A/B testing chaos**: I’ve given up entirely because the process is such a disorganized mess.
* **Disorganized culture**: Meetings lack agendas or structure, and collaboration relies on outdated Excel files passed between people instead of cloud-based tools.

I feel like I’m making no real impact. Even small efforts like helping operational teams automatically clean their data get blocked because someone’s boss doesn’t like the changes (or my reading is that they don't want to explain the change to their boss).

For context, the company is in Eastern Europe and was recently acquired by an American equity firm, 5 months  before me joining. The C levels are all new, but senior management are people, who were from the start of the company.  My friends tell me the acquisition will bring change, but I’m struggling to stay optimistic when nothing is improving day-to-day.

I have some savings and am considering leaving before finding a new role so I can focus on uni, side projects, and building my portfolio. My questions are:

* Should I stick it out and hope the company improves, or is it better to leave now and refocus on learning?
* How do you decide whether to invest more time in a job or move on?

I’d love to hear your thoughts or experiences. Thanks in advance!",1,1736278985.0
1hurdd1,m5zj4hz,"How would you compare the datasci and software engineering job market?

How's the AI threat? How competitive is it? How about layoffs?",1,1736304390.0
1hurdd1,m5zogwo,"What kind of positions are options for someone like me who has bachelors in biotech and masters in data science looking to break through into data science roles. Seems like many companies don't offer data science as entry level role.. 

ChatGPT suggested looking at data science roles in parma industry. Any suggestion what such roles are and what's right direction ahead.",1,1736306283.0
1hurdd1,m5zq1tz,"*Offers Decision: BNY or Federal Reserve?*

I’m an upcoming grad who recently received offers for a research assistantship at one of the Fed banks and another for a data engineer analyst rotation at BNY. Both are 2-year programs geared towards developing fresh grads, with the Fed keeping some doors open for research/academia. 

At the Fed, I’d be doing research work with economists, so lots of data processing and regression analysis. At BNY, it’s pretty up in the air as it’s a custodial bank so I might end up doing lots of analyst/dashboarding work but I’ve also heard of people doing more cutting edge projects involving AI.

I’d greatly appreciate it if anyone could speak on the career outlook for either one for a career in Data Science.",1,1736306869.0
1hurdd1,m61dw96,[deleted],1,1736338839.0
1hurdd1,m626eqs,Is this a good time to switch careers to Data Science through the Masters route? There are lots of universities offering masters programs. How's the job market for data scientists in the UK for internationals?,1,1736349651.0
1hurdd1,m62xr07,"Looking for some career/Masters help.

Little bit of background, I'm a 24 year old Bio-analytical Graduate living in Ireland. I was registered to start a Bioinformatics Masters last September which fell through last minute. I ended up enrolling in a Post Graduate Diploma in Data Science with The Data Science Institute which operates through Woolf University.

I have the option to continue my studies into a full Masters but I'm unsure as I'm weary on the status of the University (Rankings, Employer recognition, Etc.). Ideally I'm looking for an online masters as I'm working from home as a caregiver for a family member during the day.

I'm considering taking my PDip. and applying for a different full masters such as the Online Msc. Statistics and Data Science from KU Leuvan. Honestly I'm abit lost at the moment as I've had alot of opportunities fall through in the last year. I suppose I'm asking 2 main questions.

**1.** Is a Data Science masters worth it? What's the Job market like, I'm open to moving anywhere in the world.

**2.** Does the University status matter, my course is accredited in Europe and all credits are ETCS, will employers be looking into that much or are they more likely to be looking at my portfolio of past projects?

Any help or thoughts at all would be much appreciated, I'm thinking over all my options and thought that it might be best to seek some advise.",1,1736357942.0
1hurdd1,m63ctpp,"Hello, I just have a quick question concerning my undergrad degree. I’m currently a sophomore studying CS entering my second semester and i’ve decided to pursue data science. I want to add a data science focused minor to my CS major, should I do statistics or business analytics? Thanks!",1,1736362280.0
1hurdd1,m63g4b1,"Hi folks, I am a Senior Talent Partner in the sports analytics space and looking to connect with Sports Data scientist in the community!",1,1736363229.0
1hurdd1,m644n6b,"Hi I am preparing for data scientist/senior role, It would be great to have a company for preparation. 
Currently working in a service based company, Targeting a good product based organisation.
If you all know of any such community, that would be helpful.

Preparation source leads are appreciated.",1,1736370348.0
1hurdd1,m64gp5s,I'm currently applying to data science and ML internships I've seen a mix of both listed as job requirements. What do you think is more useful Azure or AWS cloud certification?,1,1736373835.0
1hurdd1,m64z1om,"Anyone here transitioned to DS from product? I'm a senior level product manager considering transitioning to DS. I'm doing some Udemy courses now to understand if DS is a good fit for me. It seems on paper like it would be, but I'd love to speak with someone who has made a similar shift to get their perspective.",1,1736379654.0
1hurdd1,m6567qi,"Hi im just starting to get into data science, I have a computer science background but had a lot of statistics and mathematics as well. I need some courses and materials recommended to me from which I can start learning everything I will need to know for future. Also some starting projects would be great.",1,1736382069.0
1hurdd1,m65nvnu,"Hey all,

I am kinda considering doing my masters (current senior in CS, wanting to transfer into DS or DA). I figured with the job market out of wack, maybe furthering my education would be a good idea, but I am not 100% sure just yet. I am considering doing an online program in either business analytics or data science, and wanted to ask what you guys think are the pros/cons of each. My parents are pretty supportive so I can live with them while doing my masters. My original thoughts were to do some freelance work while I complete my masters, for extra experience/money.",1,1736388068.0
1hurdd1,m6725ex,"Freelancing without a masters in Data Science?

Hello all. I have a question about freelancing without a masters degree in Data Science.I have a degree in mechanical engineering and I want to work in data science.

I've read lots of books about data science and machine learning and did several projects using kaggle to practice and showcase my skills. After all that work and time spent I couldn't find a job in data science so I'd like to give freelancing a try. 

Is there hope for finding freelance work in websites like fiverr and upwork for someone that doesn't have a masters in data science but has data science project experience? I like learning and improving myself, hence I've read lots of books. Is there hope for someone like me in freelancing?

Also, many people say that job market for data scientists isn't very good right now. How's the situation in freelancing?

Thanks.",1,1736411293.0
1hurdd1,m67wcu8,"I’ve been comfortable in my current job for far too long now, partly because of some personal reasons and now I’m scared to even interview because I think I know nothing about DS. My current job profile would classify me more as a reporting analyst. 

Help me figure out where to even start! 
Just read someone’s post on this sub about using pixi, uv and lots of other stuff than conda. 

I recently bought a new MacBook for personal use and I know that DS is too wide, but where do I even start? Do I just use the online Jupyter to practice for interviews? 

I have a Masters in Data Science but I’ve rotted at my job and feel like I’m not up to date with the latest trends in DS. 
Just a little discipline should put me right on track, but I know I have a lot to catch up on. 

Any help/guidance  is appreciated!!",1,1736428356.0
1hurdd1,m68zexf,I've been working as a Java Software Engineer for 3.5 years and recently finished my Master's in CS with a concentration in Data Science. I want to try transitioning into something DS-related in the next 6 months to a year. My question is what should I be doing to prepare? Should I keep up self-studying my old coursework in order to prepare for a technical interview? Should I try to work on some side projects? If so any recommendations?,1,1736441219.0
1hurdd1,m69zb64,"Hi, I'm a career transition person from social sciences (masters-level stats) to data science--for the latter I completed a DS certificate course that took over 12 months and >2000 coding hours in Python and SQL. As I start my job search, I see some jobs in my area require R instead... which I have some experience in but much less than Python at this point. I wondered what your experience has been in forging a career using both--has it been difficult staying fluent in one language if you take on a job using the other? Basically, I'm trying to ascertain the risk of taking on a job using R if I want to keep fluency in Python...

Edit: to clarify, I was actually recruited for a survey data analyst job that uses R and has more analysis in the job than my previous positions. I'm hesitant because it's more of s social science job but at least it would keep me coding at least somewhat... Coding is use it or lose it",1,1736451583.0
1hurdd1,m6a0akn,"Hi. I have an associate's degree in marketing and a bachelor's degree in marketing. I am interested in pursuing a career in data science. I would like to know how can I get started, specially how to test the waters to really know if this is my field or if it's just a phase. I thought of taking some courses in coursera but I've seen that data science courses aren't that good in that platform. How can I get started? AI and data science are really interesting fields for me but they are very intimidating as I haven't studied maths other than basic statistics in the first year of my bachelor's degree.",1,1736451869.0
1hurdd1,m6aa7lp,"I graduated with my BS in Business Admin in 2020 and spent 3 years working in accounts receivable. I am now getting my MS of Analytics to help me transition into the DS field. That being said, I know only having a degree and 0 work/project experience is not super helpful. So I am wondering if there are any recruiters or professionals in here who can give me some advice on projects/other things I can do while I am in college to boost up my resume? 

(I know the biggest thing I can do is get an internship. I have been applying like crazy! I would also love some advice for trying to land an internship for while I am still in college)",1,1736454773.0
1hurdd1,m6aol1w,"I am starting a career in data science and I’m not a pro. I have used my laptop before for data processing and as my dataset was not so bog it was okay. Now I’m dealing with large data and I was trying to open it in MATLAB and it couldn’t cause it was so big. I know that most data scientists use cloud computing but for those who want to do some in their own laptop what is a good option? I am a windows user and I’m afraid if I switch to Mac, I’ll have problems. So i know Macbook pro is the best option but what are some windows options with the same quality? Price is not a problem. Thank you all.",1,1736458982.0
1hurdd1,m6i8e76,"Have a technical interview this week for my first DS job, I am a senior DA right now, although I would argue I am 25-50% DS already. I plugged the job description into AI studio live conversation version which allows me to respond into the microphone and asked it to interview me. Seems like a great use case of the tool.",1,1736559031.0
1hurdd1,m6kgshx,If someone uses orange data mining on daily basis I'd like some help with random undersampling and cross validation of an imbalanced dataset. Here is the data science stack exchange question: [https://datascience.stackexchange.com/questions/131122/how-to-properly-implement-random-undersampling-during-cross-validation-in-orange](https://datascience.stackexchange.com/questions/131122/how-to-properly-implement-random-undersampling-during-cross-validation-in-orange),1,1736599539.0
1hurdd1,m6lxrhg,"I recently completed my undergraduate degree in Computer Science with a major in AI, and I’m now exploring options for pursuing a Master’s in AI or Data Science. I’m considering four countries: the US, Canada, the UK, and Germany.

A key factor in my decision-making process is understanding how difficult or easy it is for international students to secure employment in these countries after completing their degree. I’m looking for insights from individuals who have experience researching or pursuing master’s programs in any of these countries, especially regarding post-graduation work opportunities, visa policies, and employer preferences for international graduates.",1,1736618364.0
1hurdd1,m6oys8g,"Hello, I am self teaching and completing the data science and analytics masters online at Boston university. I would like to acquire an internship somehow to further immerse myself in this field. How can I go about acquiring an internship with no certifications and a degree in progress? Would someone be willing to take me on and teach me in this field?",1,1736654580.0
1hurdd1,m6p1vlq,Any good datasets/projects for demonstrating competency in product and/or experimentation?,1,1736655878.0
1hurdd1,m6px4iy,"Hi, I am currently full time research scientist, have experience as lab tech and a bachelors in biology. I will get surgery later this year and want to transition to remote job that is related to science. Ive been interested in data science and wanted to transition to data science. Hopefully get a entry level data science job post surgery. my surgery is in august it is currently january. ive thought of datacamp, microsoft and harvard professional data science ceritificates. i know experience is more than certificate but as a complete beginner i feel i need these certificates. I have considered masters in data science but financially this would be a big risk for me especially with the coming surgery. I am lost with the order to take such courses or whether I should take all courses. im quite lost so would appreciate some advise, clarity and perspectives from all of you who have much more experience and knowledge in this field. thank you.",1,1736672973.0
1hurdd1,m6qtz77,I have a job offer for a DS position at a biotech company. I want to eventually work in tech and don't have any other relevant experience on my resume. Would it be easy to transition to tech from biotech?,1,1736690803.0
1hurdd1,m6tcb1w,How do I even start my career as a data scientist? What undergrad should i take and where?,1,1736718027.0
1hurdd1,m613huy,Can you check your DM please,1,1736333146.0
1hurdd1,m6bqqte,"Honestly the job market is so tough right now, it’s seems like you can only land an interview for a DS role if you match 100% of the qualifications or more.

What are your qualifications? I would expand your job search to other data and tech roles.",1,1736471324.0
1hurdd1,m5vfkxz,"Look for data science roles in marketing or customer/client prospecting, might fall under sales. You might find more opportunities at consultancies or agencies.",1,1736258815.0
1hurdd1,m5pnp0j,"This is a tough question. 

Right off the bat, it's always easier to move within a company. If you put in the effort and take on additional work, it will be the easiest to move up from a data analyst to a data scientist within FAANG. Reason being, you'll be able to get to know people on other teams and interview for roles open only to internal candidates.

The more nuanced answer is it depends on what type of DS work you want to do. Most DS folks at FAANG do higher-level analyst work. Only people with strong MS/PhDs are doing ML work. At smaller startups, you can get exposure to both traditional analyst work and ML/AI work.

It comes down to comp/prestige vs. passion/interest.

If I were you, I would do FAANG DA to DS and then decide if you want a broader scope of things. The FAANG network and experience on your resume helps significantly down the road.",2,1736179030.0
1hurdd1,m5rm7ny,"do FAANG DA to DS. worst case scenario, after 2 years in that role if you can’t transfer internally, you should be able to get DS interviews at non-FAANG companies like uber, doordash, lyft, etc. or other FAANG companies, and then pivot back to original one you were hired into if you’d like.",2,1736199798.0
1hurdd1,m5sqj9t,I have been searching for a junior DS role in LA for 12+ months and have little success. I am not sure if this a consequence of the Los Angeles market or the fact that it is difficult to find junior roles nation wide right now.,2,1736212761.0
1hurdd1,m5vevnr,Keep practicing SQL. It can take time to get comfortable doing those live with an audience.,1,1736258550.0
1hurdd1,m5w32ym,"Also, pay would be expected to increase 60%. Huge factor.",1,1736266473.0
1hurdd1,m5whky0,"Hi, I believe the best way to stand out is by focusing on developing personal projects. These don’t necessarily have to be complex programming projects involving advanced machine learning models. For example, you could create a blog where you explain advanced statistics or computer science concepts. There’s a saying that the best way to learn something is to explain it to your grandma. In my case, I started a blog to discuss statistical concepts and share related code, which not only helped me solidify my understanding but also gave me a platform to showcase my skills.

Additionally, getting involved in college research can significantly boost your CV. Research projects demonstrate your ability to work on structured, impactful work while collaborating with others in an academic setting.

Lastly, I recommend working on projects that help develop your soft skills. Remember, effective communication with stakeholders is crucial in any professional setting and the mayority of interviews process will asses this. For instance, I attended math conferences and participated in volunteer programs abroad, which helped me enhance both my communication and interpersonal skills.",2,1736270741.0
1hurdd1,m606cwn,I think expansion of H1Bs is a far greater threat to domestic data science/SWE folks.,2,1736313603.0
1hurdd1,m635n5b,"Pharma, Hospitals, and even Public Health organizations would love someone of your background. In addition to applying for Data Scientist positions, also apply for Data Analyst and Data Engineer roles. Also, leverage your university's career services and contact your former classmates to see if they know about any jobs you are qualified for. Get whatever relevant experience that you can. Good luck!",2,1736360226.0
1hurdd1,m6067mk,"Do you have any ambitions to ever do a PhD? Working for the Federal Reserve is one of the few occupations that academic economists are impressed by. 

My guess is that BNY would be mostly uninteresting. Not saying the Fed will be intellectually stimulating in your first two years, but it's probably a shorter path to working on some cool stuff.",1,1736313535.0
1hurdd1,m634rzn,"Hello, I'm a Quantitative Social Scientist and Statistician by education currently working in Data Science for a few years. It might be a bit of an uphill battle transitioning to Quantitative Social Science roles without a relevant degree and training, but it is doable. 

I'll answer your questions in order:

1. Yeah Python would be the right tool for your use case. Python has many libraries for sentiment analysis, text analysis, and structured survey data (although I personally would argue that R is better in terms of survey data, but that is a whole other conversation). 

2. Check out FreeCodeCamp, W3Schools, and the Summer Institute in Computational Social Science YouTube channel for free resources. Also, here is a video that you should watch:

[https://www.youtube.com/watch?v=ohleQALSrfQ](https://www.youtube.com/watch?v=ohleQALSrfQ)

If you do not mind paying, get this book: [https://www.cambridge.org/core/elements/abs/text-analysis-in-python-for-social-scientists/BFAB0A3604C7E29F6198EA2F7941DFF3](https://www.cambridge.org/core/elements/abs/text-analysis-in-python-for-social-scientists/BFAB0A3604C7E29F6198EA2F7941DFF3)

3. Since you are interested in Text/Sentiment Analysis and Survey Analysis, I think you should do two projects. The first project involves web scraping. Pick any website that you can LEGALLY web scrape and do some analysis on the data that you obtain (for example, Wikipedia). Deploy your code to an application (Streamlit is fine) and visualize your results on the app. The second project involves you finding a dataset based on any survey of interest. Maybe use this website: [https://data.census.gov/](https://data.census.gov/) Do some exploratory data analysis and build a dashboard to summarize your results. You can use Streamlit again, Gradio (if you decided to do some Machine Learning), or even Tableau Public: [https://public.tableau.com/app/discover](https://public.tableau.com/app/discover)   

Best of luck!",1,1736359977.0
1hurdd1,m64enf3,Maybe statistics and an AI/ML track if your unversity offers that BA roles are usually lower salary,1,1736373242.0
1hurdd1,m6bqvkz,Statistics,1,1736471369.0
1hurdd1,m6ggw4d,"They're kinda more equal nowadays; you can't go wrong with either. I think more organizations still use AWS. So, if you have to choose, I guess go with AWS.

Another thing you could do is to type ""AWS"" and your geographic location into Indeed. See how many results pop-up. Then do the same with Azure.

A final note: for the internship level, you don't have to go out and get the cert. It would be very impressive, but projects in which you use cloud technology suffice for most internships. Good luck getting an internship!",1,1736538811.0
1hurdd1,m6bq8yd,"Where are you located? If you’re in the US, try to get a job, any corporate or tech job, and then use tuition reimbursement to get your masters.",1,1736471158.0
1hurdd1,m6gfvwt,"It's kinda hard to freelance in the Data Science field without several years of professional work experience and a list of potential clients that you already have a relationship with.

What I would possibly do to increase your chances of getting work is to directly reach out to local organizations in your area (Small to Medium). Non-profits in particular need good Data Science work to be done. 

I personally say to skip websites and to reach out to these places. Maybe have an impressive portfolio ready to demonstrate your skillsets. Good luck!",2,1736538518.0
1hurdd1,m697y2e,"Perhaps you can look into a job position that you're interested in and look at the requirement to identify your gaps.

In addition, you may be able to leverage connection and industry knowledge to land a more technical role.",2,1736443701.0
1hurdd1,m6fxl5t,"Apply, apply, and apply. Look at job description and see where your gap is.",1,1736533212.0
1hurdd1,m6geqa1,"There are quite a number of Data Engineering and ML Platform Engineer jobs that would love an experienced Java Dev with your educational background. I would consider tailoring my resume to some of those positions and applying to them.

But like the other commenter said, ""Apply, apply, and apply.""",1,1736538177.0
1hurdd1,m6bp94g,They’re similar enough that I wouldn’t worry about it too much. Problem solving and *how* you use them is more important. If necessary you can brush up on the other.,1,1736470822.0
1hurdd1,m6bp32p,Do you have a job in marketing? Get your hands on as much data as you can and start analyzing it. I analyzed web analytics and social media data when I worked in marketing and that was how I make the pivot to a proper analytics role.,1,1736470766.0
1hurdd1,m6botyl,"As your professors if they (or any PhD candidates at your uni) have research you can help with or any projects partnering with local organizations. When I did my MSDS, they had new projects like these popping up all the time that students could do for their capstone or just for experience.",1,1736470682.0
1hurdd1,m6gdros,"How big is the data? You could try to store it in a Relational Database and then call it into MATLAB. Tools like SQLite, MySQL, and PostgreSQL may work.

Although if you want t a career in Data Science, I would do the same thing but with Python. Good luck!",2,1736537894.0
1hurdd1,m6b2cup,"You're starting a career as in you have a job doing data science right now or you're learning and building a career in data science?

For learning, you can use a portion of the data that fits into your RAM so you can focus on apply data science techniques.",1,1736463216.0
1hurdd1,m6peonz,Apply at companies that hire interns. Here is a list I compiled to get you started. https://data-storyteller.medium.com/list-of-companies-hiring-data-science-analytics-interns-and-new-grads-cb8f02a0fcff,2,1736661944.0
1hurdd1,m6uk1y0,I think you can take computer science. Some schools even offer a data science undergrad these days.,1,1736731787.0
1hurdd1,m6bxfcv,"Thank you for the response! As for qualifications I know Python, SQL (and R kinda), and ML, I graduated in Math, and I had an internship where I had to do some data cleaning, analysis, and modeling. I also had other less related experience in teaching and research.

What other data and tech roles do you suggest?",1,1736473559.0
1hurdd1,m5q390c,"Thank you for your thoughtful response!

 I’m also leaning more toward the option you recommended. Coming from a lower-ranked university, it’s currently challenging for me to secure a spot in competitive MS/PhD programs. My plan is to gain valuable experience and build credibility by working at well-known companies. After that, I aim to apply to top MS programs in Europe, which, as you mentioned, can open the door to exciting and impactful opportunities.

Thank you again for your guidance!",1,1736183700.0
1hurdd1,m60h5l9,"I enjoy research, but don’t know when I’d get tired of it, and a 6-year PhD in Econ does sound like a big commitment.",1,1736319185.0
1hurdd1,m6365f3,[deleted],1,1736360373.0
1hurdd1,m6gh2dt,Thnx!,1,1736538862.0
1hurdd1,m6k7yhb,"If only there were enough data science opportunities in the shit hole I live in. There are 1 year programs in the UK and USA as well as in few EU universities. People I've talked to said data science / machine learning job market is not very good since 2023. Do you recommend masters in data science to break into this field given the job market issue?

Thanks",1,1736594568.0
1hurdd1,m6gic0o,Thanks for the response! Definitely helpful,1,1736539230.0
1hurdd1,m6hw5jg,That would be a really great idea however I’m an online student so we don’t ever interact with the professors and live far from campus. We do have a capstone towards the end though!,1,1736554877.0
1hurdd1,m6q5iuc,Thank you! If you are who I think you are I use your site all the time.,2,1736678282.0
1hurdd1,m6zni3b,Then what?,1,1736804091.0
1hurdd1,m6c9bmn,"Analytics, Business Intelligence, Data Engineering, Data Product Management. 

What was your experience in teaching and research? That could be relevant. Lots of data vendors (dbt, Databricks, etc) have client success or training roles.",1,1736477642.0
1hurdd1,m5wdejs,"Only do a MS degree if you want to land into a specific subspecialty like Computer Vision or Robotics.

You'll be able to tackle 99% of DS roles with FAANG DA as your starting point.",2,1736269516.0
1hurdd1,m636ozy,It could. Just depends on how knowledgeable your tutor/mentor is. Try to find someone that has worked in similar roles to the jobs that you want to get hired in.,1,1736360526.0
1hurdd1,m6y02gc,"Honestly, if there are not many opportunities in your area, I would recommend moving. You could pursue an in-person's Master's degree to incentivize the move, but moving alone will greatly increase your chances.

Even if the role is remote, sometimes companies have legal requirements where they can only hire remote employees in certain areas. And many companies are incentivizing Hybrid/In-Office for a lot of these tech jobs.

Basically, you want to be in places where the job opportunities are. At least early in your Data Science career.

I also want to acknowledge that moving is a huge pain and that it is not your only option. It is just  one good option. And if you do do the Master's, make sure that it is good quality and don't spend too much money on it (look at Georgia Tech as an example). Best of luck; I know it can be rough out in this market.",1,1736786843.0
1hurdd1,m6i13ox,Ask anyway. My program was online and in-person and the online students could easily contribute to this stuff because our meetings were over zoom and all of our actual work is done online.,2,1736556555.0
1hurdd1,m6cmjy3,"I'll check those out, thanks. Is it easier to get a job in those roles?

I was a TA for math classes (linear algebra, calculus) in my college when I was studying and I did research in pure math. The internship I mentioned was also a research one dealing with transportation. What things should I search for those client success or training roles?",1,1736482464.0
1hurdd1,m6ysuzc,"I think I'll just move to another country like USA.

Also, I thought Georgia Tech's program was online only? Apparently they offer an in-person program too. In-person programs cost about the same in the USA I think as long as the program in question isn't offered by a top tier university. 

Do you have other masters programs you can recommend? I was thinking about applying to Usfca's MSDS program. While doing your masters you work 16 hours per week in a company in San Francisco. It's also a 1 year long program. Then there is also UvA's MSDS. Do you know if these programs are any good?",1,1736795181.0
1hurdd1,m6yxycz,"Off the top of my head I guess I would recommend UMich, CUNY Graduate Center, RIT, University of Arizona, and the University of Syracuse.

I literally have no clue about the Usfca's MSDS program, but a program in which you are guaranteed work experience sounds solid to me. That said, it seems kinda intense to cram all of the requirements that they do into one year (a linear algebra qualifying exam, 9 month practicum, a bootcamp, all of your coursework, and some other stuff). If you go with that program, I would be prepared to not have much of a social life for a year.

I've heard good things about the UVA program and it's generally a good university to attend. Wouldn't be a bad choice.",1,1736796660.0
1huoyaf,m5o8q8y,"Hey. Data modeling mostly ends up with people storing bunch of IDs in the metadata and then writing their own wrappers.

There is no enforcement and generally, it is difficult to version or update the models.

Most data engineering practices are not applied.

  
We worked on it by enabling:

1. Incremental loads

2. Json schema normalization

3. Pydantic models for the data transfer

4. Standard adapters for major vector and graph DBs

5. Data contracting

  
Have a look here: [https://github.com/topoteretes/cognee](https://github.com/topoteretes/cognee)",5,1736155397.0
1huoyaf,m767qzt,Tried this tool and its actually pretty good,1,1736892739.0
1huoyaf,m5oppmi,Thanks so much!,1,1736165625.0
1huoyaf,m76isw3,"Which one? cognee, the one mentioned above?",1,1736896185.0
1hu5gha,m5jb0uz,[deleted],-58,1736092402.0
1hu5gha,m5juj9g,"go to an OnlyFans subreddit and ~~post~~ *comment* some fire emojis , you'll get it 🔥🔥🔥🔥",11,1736098431.0
1hzprm8,m6rmvhi,"I remember there was a top conference paper that starts with a quote, but I forgot the title. Does anyone know what it is?",1,1736700439.0
1hzprm8,m6svfsw,Is there any paper about using asymmetric autoencoder for image upscaling? I'm just trying it out and seems to produce nice results with lpips+ and dists loss.,1,1736713112.0
1hzprm8,m6ttej4,"I try to parse msword files with from langchain\_community.document\_loaders.parsers.msword import MsWordParser. However, it parses only text ignoring tables and pictures. For pdf files I use from langchain\_community.document\_loaders.parsers import BS4HTMLParser, PDFMinerParser and they work well. I could change every word file to pdf, yet I think it will slow down the whole process. Is there any way to parse word files with tables and pictures?",1,1736723131.0
1hzprm8,m6vzurk,"I have tried LDA to tag news and the outcome is not ideal ie when tested with articles that are not within training set, the predicted outcome is always the same few. I have also used TF-IDF but does not seem to have noticeable improvements.

Any suggestions to improve the accuracy?",1,1736754142.0
1hzprm8,m71l1ry,"Need help with training a model
It's for traffic sign detection 
I created one but it is giving false positives and will not detect signs if there a distance 
So the signs have to be close to the camera",1,1736826721.0
1hzprm8,m73mx9h,I'm trying to buy a new laptop for ML work especially for computer vision. What are the things to consider? Which is important to consider in a GPU(vram vs Tensor cores)?.,1,1736864558.0
1hq5o1z,m5p5mht,"Hiring: Remote-friendly (UTC+2), Salary: up to 5K$ pm, Full Time/Contract

We're building an AI verification platform for newsrooms and need a talented and motivated Data Scientist/ML Engineer to join our team. You'll develop neural networks that help journalists verify information and track narrative spread across news sources.

Must have:

* Strong PyTorch experience
* Graph Neural Networks expertise
* Production ML system experience

Ideal:

* News media/fact-checking experience
* GDELT dataset familiarity",3,1736172721.0
1hq5o1z,m5o3van,"Any, Salary : $40000, Remote/Hybrid, Full Time, Resume: [https://drive.google.com/file/d/19z2yWD5MH1gj7yOKQSSJyxAH3d02zBs6/view?usp=sharing](https://drive.google.com/file/d/19z2yWD5MH1gj7yOKQSSJyxAH3d02zBs6/view?usp=sharing) 

  
brief - An AI and Data Science professional with expertise in machine learning, deep learning, and predictive analytics. Experienced in projects like Gesture Recognition, Client Churn Prediction, and Fraud Detection. Seeking opportunities to develop innovative ML/AI solutions with real-world impact.",2,1736152210.0
1hq5o1z,m5ogzvj,"I'll be faculty in London, UK from sept. this year. Looking for PhD student(s):

Hiring: London, UK, Salary: EPSRC salary (£21,237/y as per [this link](https://www.ukri.org/what-we-do/developing-people-and-skills/stfc/training/studentship-information-for-students/payments-to-students/), Relocation, Full Time, and Research in Causality and ML with some application (up to the student) in healthcare.",2,1736160723.0
1hq5o1z,m4nme5d,"I am a recent graduate who is looking for remote oppurtunities in the field of Data. 

Nairobi, Kenya, Salary Expectation: $40000 annually, Remote or Relocation, Full Time | Contract,\] Resume: [https://drive.google.com/file/d/1oUhu2pA25h3NFUAhvShcXXAN119fPOJ4/view?usp=sharing](https://drive.google.com/file/d/1oUhu2pA25h3NFUAhvShcXXAN119fPOJ4/view?usp=sharing) and I am a Junior in the field of Data Science with 2.5 years of experience and a recent graduate with a background in Information Science. I am an avid researcher and coder with specialisation in Data Viz, Data Modelling and Information Management.",6,1735626357.0
1hq5o1z,m6zt5c0,"Location: Nairobi, Kenya, Salary Expectation: $2500 - $4000 per month, Work Preference: Remote/open to relocation for exceptional opportunities, Employment Type: Full-time/Contract, Resume: [https://drive.google.com/file/d/1ToiIxW9EVoET-cDqhj0uacXGNpy4a9Ft/view?usp=drive\_link](https://drive.google.com/file/d/1ToiIxW9EVoET-cDqhj0uacXGNpy4a9Ft/view?usp=drive_link)Brief Overview: I am a skilled Data Analyst and Business Intelligence Specialist with over 3 years of experience. I excel in data analysis, visualization, and machine learning. I am proficient in Excel, Power BI, Python, and SQL. My expertise includes managing large datasets, creating interactive dashboards, and developing predictive models. I am looking for data science/data analyst opportunities.",1,1736805744.0
1hq5o1z,m76ltua,"Hi, as someone who hasn't really looked into a PhD before, this sort of interests me as I did a master’s in data analytics with a capstone project focused largely on causal inference, and I was particularly interested in the ML side. Are 2:1 minimums standard for applying to PhD programmes? I got a 2:2 in my 1-year M.Sc.. One of my lecturers recommended I do a PhD, so I can likely get a letter of reference from him",1,1736897190.0
1i1lg6o,m77dqyo,"If you want context for this paper, take a gander at Learning to Learn at Test Time [https://arxiv.org/abs/2407.04620](https://arxiv.org/abs/2407.04620)",7,1736906643.0
1i1lg6o,m77kth0,"The 'Titans' architecture presents a significant advancement over traditional Transformers by effectively scaling to context windows larger than 2 million tokens, which is a notable enhancement for tasks requiring extensive historical context. Its performance surpasses that of several modern linear recurrent models, indicating a shift towards architectures that integrate long-term memory more efficiently in handling complex tasks.

* [[2501.00663] Titans: Learning to Memorize at Test Time](https://arxiv.org/abs/2501.00663)
* [Titans: Learning to Memorize at Test Time](https://arxiv.org/html/2501.00663v1)
* [Titans: Learning to Memorize at Test Time : r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/comments/1i0q8nw/titans_learning_to_memorize_at_test_time/)

^(Hey there, I'm just a bot. I fact-check here and on other content platforms. If you want automatic fact-checks on all content you browse,) [^(download our extension.)](https://critiquebrowser.app)",6,1736909141.0
1i1l8d4,m777i5m,Scaling with disk rather than number of params,1,1736904484.0
1i1l8d4,m77c9x6,Neat research!,1,1736906130.0
1i1l8d4,m77wopt,I think this is the first Sakana paper I've seen that didn't list you as an author. I'm interpreting that as a sign that your lab is getting bigger. Congrats!,1,1736913573.0
1i1l8d4,m77xv50,Exciting to see!,1,1736914048.0
1i18421,m73wk5t,"There is a lot more demand for MLEs, but there is also a lot more supply. It is possible to become an MLE with a masters degree, or even as an experienced SWE moving into ML. As an RS you basically have to have a PhD.

For context there are 112k CS bachelors degrees awarded every year in the US, 51k CS masters degrees, and 2k CS PhDs.",117,1736867785.0
1i18421,m74ei7j,"PhD in ML here.

It sounds cliche, but: **Don't optimize for which there will be more demand. Optimize for the career you enjoy more and hence will thrive in more.** 

You will increase your chances of standing out if you enjoy your work.",92,1736873237.0
1i18421,m73vpa3,"A lot more demand for MLE, that is why I made the switch.",18,1736867513.0
1i18421,m73zpmb,an RS could pivot into MLE if need be but typically not the other way around.,37,1736868776.0
1i18421,m74bhtp,"It will depend on the specific role at the specific company. Where I am, the MLE title covers everything from infra (what some would consider MLOps) to applied research (research/applied scientists). My own role (MLE at a large (non-FAANG) multinational org) currently skews somewhat toward the latter, but I do some deployment stuff as well.

Generally speaking, outside of a few big companies like Google and OpenAI, ""pure"" AI/ML research isn't really a thing. If you are a researcher, then the research that you do will be restricted in scope to business needs. You might be able to come up with a novel algorithm or method, but only as applied to the company's business use case. Of course you can have great ideas outside of this scope, but you won't have the time or resources to develop them.",15,1736872347.0
1i18421,m74ik8a,"In my experience, research/PhD really doesn't mix well with career optimization. The upfront cost is high (years!), and the outcome is too unpredictable.

The students who chase it usually end up with neither money, good papers, or happiness.

If you want guaranteed big bucks, go the engineering route. If you like research, do good research and figure it out as you go.",14,1736874423.0
1i18421,m746yrr,"AI researchers: Less positions, bigger salaries
ML engineers: More positions, lower salaries",11,1736870988.0
1i18421,m73xbtt,"Research is always a risky career prospect in any industry. But a lot of people want to be working on the bleeding edge too. Money, job prospects and security will always be in engineering over research. That doesn’t mean you shouldn’t go into research, it just means that your career path is more secure.",21,1736868028.0
1i18421,m73wpm7,Sure... but there a lot more MLEs than RS as well...,8,1736867834.0
1i18421,m74hcea,Most of mainstream ML Research is scaling compute which is essentially engineering at this point. Which is also why the corporate labs have taken over.,6,1736874061.0
1i18421,m75h4u1,"Non phd researcher / engineer with 10 + years experience here at not quite fang tech co.

I would say you should absolutely stay in your phd program while also developing your eng skills. Use distirbuted / multi gpu computing, release and contribute to open source code, throw up some hobby apps/sites / startupy side projects or so summer internships.

A lot of training, scaling, serving and debuging production models starts to feel pretty researchy pretty quick. Sampeling biases, numerical stablity, subtle regularization issues, bugs in open source packages, mysterious performance degredations and a ton of staistics and data investigation all come up super regularl in industry. I've worked with a few absolutely stellar PHD engineers over the years and generally they are at an advantage vs less researchy engineer types even if they shift focus to ml infrastructure.

Also the job market is pretty tough for new grads right now from what i've heard.",6,1736884426.0
1i18421,m73vgg8,"I don't have a ton of insight of the whole industry, but at least in my org/team MLE >> RS",10,1736867435.0
1i18421,m74pbv1,"Researchers know how to write papers, engineers know how to write code. What do you want to be good at?",3,1736876397.0
1i18421,m74bnht,"[https://www.weforum.org/stories/2025/01/future-of-jobs-report-2025-jobs-of-the-future-and-the-skills-you-need-to-get-them/](https://www.weforum.org/stories/2025/01/future-of-jobs-report-2025-jobs-of-the-future-and-the-skills-you-need-to-get-them/)  
Refer to this. Might help.",3,1736872393.0
1i18421,m753ynx,"As someone who has been at a FAANG for 10+ years and acted both as a scientist and a manager hiring and leading scientists and engineers, it's always been my experience that you need fewer scientists than engineers, and a scientist who can also write some production-quality code is indeed a unicorn. I'm not convinced that the ratios will need to shift that much moving forward, at least in the business units that I'm a part of, because the scientists are constantly prototyping stuff, and then working with engineers to launch new products and features and then moving on to the next prototype. On the engineering side, you need more engineers when first launching the product, then typically fewer are needed to actively work on that product once you have worked out the operations and the engineers can be re-allocated to productionizing the next prototype.",3,1736880607.0
1i18421,m74bey4,I'm a bit pessimistic about AI research in the long run. It's mainly scaling that seem to be making a difference. It's [the bitter lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html).,5,1736872323.0
1i18421,m75ohyd,"if all you care about is market value, the only advice (facetious) is buy low sell high",2,1736886564.0
1i18421,m74xyvv,"Ai research is company dependent the field is very very diverse. However agentic flows and llms are the business in commercial settings.

There is more jobs than mle and research there is also solutions engineers, people who specialize in specific tools for example, copilot specialist for business use cases. 

What I am saying there is more jobs that mlr and mle. Additionally there is a middle ground in applied research sometimes not requiring phd.

I would say only do research if you love it my role is not researching as much anymore more so in the solutions engineering space now but I still do research cause I love it. Also my research is not the most wide applied I did do rag for the company I work for but personally I like manifold learning and gnns. 

Tldr: only go research route if you love it you can engage with research prior to a phd as well to test if you love it there is lots of reading groups and discords on various research topics.

 Mle is just a senior dev role really that can push prod really they might rewrite the code the researchers.

There is also ai product managers, product designers all roles that are needed somewhat with a ai background. Even my role although I was a researcher I am really a consultant more so that can talk about the solutions side of ai for business.",1,1736878880.0
1i18421,m76b5ap,"> For a fair comparison, let’s assume both roles are at a FAANG company.

You sound like you're reading the market in the exact same way you would've 3 years ago. Don't. You will end up in a world of pain.

One thing almost nobody has talked about: nearly every mid career professional in tech who could tried to jump on board the MLE train. There's a huge glut.",1,1736893766.0
1i18421,m77ztyx,How can a SDE become an MLE?,1,1736914869.0
1i18421,m740p6u,me too,-1,1736869085.0
1i18421,m73zr6d,"To be fair, à big chunk of those PhD graduates end up doing engineering jobs, and not publishing anything.",72,1736868790.0
1i18421,m74w5ri,"Yeah true, hiring for a sciency role is astonishingly hard because most CVs you get are more the business intelligence/data analysis type. 
Considering everyone and their dog seem to be doing ML PhDs at the moment, I rarely ever get a regular CS PhD with a couple MLy papers.

Or let's reframe this last one - I get a lot of old-school ML people. But almost nobody knowing anything about LLMs, at best that ChatGPT exists. I had Princeton and Harvard PhDs applying for an LLM/LMM/Agents role who didn't bother to even look up those terms from the job ad and didn't even try to hide they don't care about it. Pretty sure they could learn it but if they don't even bother to just read a paragraph about LLM-based agents before going into the third interview round?

Yeah I'm also not super into LLMs, I'm also coming from oldschool ML topics... but it's the name of the game at the moment so we have to know this stuff. 
I see all kinds of crazy deep interview questions posted here but I'd be happy if anyone would just know that transformers and tokenizers exist :).

Guess the US people all just try the FAANGs, idk.
All our research people including me are from Europe, Canada, Israel etc.",15,1736878360.0
1i18421,m77g1sy,"ML researchers typically have PhDs but often from a wide variety of fields, not just CS.",2,1736907448.0
1i18421,m75ufxi,"Especially because demand can disappear. Learned skills don't. 


https://kyunghyuncho.me/i-sensed-anxiety-and-frustration-at-neurips24/",9,1736888807.0
1i18421,m74zx0v,"I did that, thought programming was fun, but it's all about meetings, integration with badly documented stuff, more meetings, trying to understand half-baked stuff, etc. Almost no coding. Don't recommend",8,1736879437.0
1i18421,m746jvu,advice for making the switch?,3,1736870862.0
1i18421,m76j8dh,"Nope, SWE, MLE, etc. > money for AI research at the same level. You have to consider that it takes 5+ years to become a junior research scientist after a BSc, but usually, it never happens or you can't really find these jobs consistently. All of that is to make a comparable salary to engineers at the same level.",0,1736896327.0
1i18421,m76jpg8,"I do not think it is true, it's not what research teams write papers about. It is ML eng. There is so much work about evaluation, utilizing existing tools such as LLMs, etc.

Only a few teams actually train huge models.",1,1736896483.0
1i18421,m74chq1,"You mean demand and work, since the hiring bar for RS >>>>> MLE and I have interviewed at places like Google.",3,1736872644.0
1i18421,m76dzbz,"Indeed, making the ai researcher position more lucrative",-5,1736894639.0
1i18421,m74zemq,"By ""old school ML"" do you mean like statistical models?",3,1736879290.0
1i18421,m75ph9m,"It's really a bad time to be an unemployed data scientists like me. The jobs have seemingly fractured into ml engineering roles demanding some experience with llms Or experimentation and business type roles. 

For someone like me with broad experience with deep learning but not NLP and a good amount of experience with production systems, I'm still kind of on the outside looking in for both of these type of roles",3,1736886916.0
1i18421,m77glbi,"The same can be said about bachelors and masters degrees and MLEs though too. Whatever requirements you impose or however you slice it, the pool of talent for ML research is much smaller than the pool for ML engineering. There are many more MLE roles though, so it is a complex story.",1,1736907640.0
1i18421,m76ehr1,"y no capitalz tho


/ jokes aside, thanks for link",2,1736894800.0
1i18421,m751r5r,"Well, it sounds like you didn't do that then :D 

Your first impression was wrong, now you know you don't enjoy it. Switch jobs.",8,1736879972.0
1i18421,m74gr4i,Leverage domain knowledge.,7,1736873891.0
1i18421,m76l60f,"being an ai researcher at a top company or a well-funded startup requires hardcore academic skills, which i believe leads to better salaries. whereas the skills for a swe or a mle is learned on the job, which will lead to more people with said skills in the workforce. i too think companies need more swe or mle's, but a competition will come to such a point that juniors will comply to lower salaries. 

time will tell though, and i appreciate your perspective",1,1736896967.0
1i18421,m74eqfn,"yes, more demand for practical skills, rather than research",3,1736873303.0
1i18421,m75181k,I have seen the requirements for research scientists drop from PhD degree to MSc with demonstrated equivalent experience (e.g. first author at top conferences),1,1736879817.0
1i18421,m76p2jr,Not necessarily.,7,1736898264.0
1i18421,m76en73,"The phds doing engineering are probably doing it because they couldn’t find research jobs…

Pre ChatGPT I’d say research is more lucrative, post ChatGPT it seems like everyone is more focused on product so engineering more lucrative",1,1736894847.0
1i18421,m75cqx0,"That's a moving target ;).
But yes, partly pre-deep learning or what I also often see is ""I did some 3 layer LSTM with Tensorflow/Keras"" (probably using Python 2.7 ;)).

Which is fine for many cases in industry but we have Data Science teams for that. For the research scientist roles you can hardly avoid knowing about transformers, large multimodal models etc.
And frankly even in consulting scenarios I often see some pretrained CLIP model easily zero-shot destroy those cobbled-together networks without even having to lift a finger.

But I haven't had a single candidate who has heard about contrastive learning, for example. Recently I had one candidate who had a project using BLIP in the CV and was eager to ask about it as I haven't found the time yet to dig deeper into that.
But then it was ""downloaded from huggingface and followed the instructions"".
I had one Chinese guy who I really liked and we just chatted about his representation learning ideas. He wanted to flee the Bytedance RTO policy so everything looked great. Just to find out our recruiter does not seem to understand base comp vs total comp and so it didn't work out at all lol.

I'm definitely not a deep learning guru,.my PhD was also before it became huge and was also an applied topic and not ML theory. So I really don't expect any crazy mathy explanations from others either. Just want to see people have heard about the big things the last couple years.. know which big LLM providers exist besides ""ChatGPT"", know that there are transformers, diffusion models, perhaps contrastive learning and multimodal embedding spaces. Just anything that's somehow around the state of the art.

Last time we then actually went with a junior who built some classification on top of a vision transformer and was eager to learn more, even though we originally wanted someone a bit more senior",6,1736883152.0
1i18421,m7506ea,By old school he probably means anyone who graduated before 2012-2014,1,1736879514.0
1i18421,m77je6c,"I don't disagree with you there. My take would be that the choice between a research and engineering career should really come down to someone's interests, skills, and qualifications but not based on a perception of the long-term viability of one versus the other. a) This field is too fast moving to meaningfully forecast that right now, and b) the two careers are not interchangeable and being able to thrive in one does not mean you could in the other.",2,1736908632.0
1i18421,m74jnyq,"> Leverage domain knowledge

Unironically better career advice for most people than telling them to learn XYZ technology",14,1736874750.0
1i18421,m76mcrr,"I mean, if you have 5-4 first author papers, each in a conference at least as good as IJCAI but mostly ACL, AAAI, and likely some ICLR, NeurIPS, etc., then yes, you can be a research scientist and make more than a MLE that just finished their BSc or MSc... But don't tell me it's easier to achieve than getting to L6 in Google or so.",2,1736897366.0
1i18421,m769ptu,"That's insane to me, I work in a FAANG-esque company and everyone has a base level understanding of contrastive learning and transformers (even research engineers and MLEs). Where are you targeting recruitment?",5,1736893332.0
1i18421,m75xwk9,"Yeah I got hired into my current research scientist role as a math/CS PhD who knew a lot about autodiff and had experience with semi-neural ODEs/parameter-tuning ODEs from robotics/control. I just spent a few months reading papers before applying.

The funny thing is, I ran into several companies (mostly startups) who *said* they wanted a “research scientist” when all they really wanted was someone who pulls things off of hugging-face and follows the instructions.",2,1736889842.0
1i18421,m76gzi4,"> Last time we then actually went with a junior 

Just say you were looking for someone experienced for the price of a junior, and stop rationalizing  😂",2,1736895590.0
1i18421,m75d6xc,"Not really about the graduation date, I posted above... I myself started programming in DOS and BASIC 30 years ago . But for a researchy position just some general overview on what's going on in research right now",2,1736883284.0
1i18421,m77jqgy,"Yes, your assessment is absolutely correct in d
Deciding what to do. My first point was mostly a counterpoint to OP’s observation that available MLE roles are growing at a faster pace than ML RS roles.",1,1736908754.0
1i18421,m74tbz2,Sorry a bit dumb question. What does that exactly mean? Does it mean to use your expertise in that specific domain?,6,1736877542.0
1i18421,m76p78m,"that's sorta my point. the number ai researcher positions will get significantly lesser. ai researcher positions will only be available in top tier companies or extremely sophisticated and well-funded startups, therefore they will have a higher average salary than average mle salaries. i am talking about the average (or your favorite central moment estimator) here, not about individual positions.",1,1736898306.0
1i18421,m7630j5,"Yeah honestly that's what one got to do/is enough more often than not ;).
But I still aim that we as a team at least skim the paper and roughly understand the architecture of any model we use, try to get a paper reading group together once in a while etc.
Because that's the main differentiator from our consultants, solution architects, MLEs etc. 
Our roles are called Applied Scientists and I realize it's probably not too bad a name as a thing between RS and the other roles I mentioned.",2,1736891341.0
1i18421,m7507q8,Pretty much,2,1736879524.0
1i1hz8c,m76m3me,Use google scholar to regularly search topics you're interested in.,13,1736897281.0
1i1hz8c,m76dw1c,https://arxiv-sanity-lite.com/,8,1736894611.0
1i1hz8c,m76t6a6,Very carefully,2,1736899628.0
1i1hz8c,m77gy01,All these tools seem to be working essentially by keyword. Is there a real semantic search tool for papers?,2,1736907765.0
1i1hz8c,m770kj3,https://www.connectedpapers.com,1,1736902093.0
1i1hz8c,m76qe7y,Is it accurate? Does it always return good results?,-2,1736898700.0
1i1hz8c,m76vr1d,It does not seem very accurate,-1,1736900482.0
1i1hz8c,m76rkjp,Served me pretty well till now 🤷,2,1736899094.0
1i1hz8c,m7766zf,Google SCHOLAR is the standard way to search articles.,2,1736904031.0
1i1hz8c,m77hzyg,IC. However I am wondering if it see good enough. It seems mostly based on standard keyword search.,1,1736908140.0
1i0hfsd,m6y0q8o,"This is pretty obvious.

* Cosine Similarity is meaningful when a model has been trained using a [Cosine Embedding Loss function](https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html) (or other similar loss function that tries to move classes as far away from each other as possible in its latent space).
* However, in a network trained with CrossEntropyLoss or ContrastiveLoss, cosine similarity is not at all meaningful because that loss function does not care at all how far away vectors are -- all they care is that different classes have a minimal amount of separation from other classes - but are indifferent to how far away such classes are from each other.

For example -- consider a classifier of Dogs vs Cats.    

When you train a network with CrossEntropy Loss it's totally OK if 99.999% of the latent space is ""dogs"" with one tight cluster of ""cats"".    In that network, most dogs will be 90% apart from each other (cosine similarity of 0), and some pairs of dogs can even be 180° apart (think if the cat cluster is a spot on the equator, and dogs can be on the north and south pole).  From CrossEntropyLoss's point of view, as long as the cats form a tight cluster without dogs in them, that's a perfect training run.

Or consider training a Dog vs Cat vs Apple Vs Oranges classifier with ContrastiveLoss.   All it cares about are that classes are separate from each other.   ContrastiveLoss doesn't care the classes are in a straight line of Dog -- Apple -- Orange -- Cat,  or Apple -- Cat -- Orange -- Dog.    It just cares that they are separated by that minimal distance.

However if you trained it using a Cosine Embedding Loss Function, you will (by definition) get embeddings where cosine similarity is meaningful.",249,1736787036.0
1i0hfsd,m6xyni3,"This title and summary are sensationalist. Did anyone ever think cosine similarity was a silver bullet? Maybe they did and I have just been doing ML long enough to have the intuition to know that your similarity metric needs to be tailored to whatever your embedding space is, and if you don't know what it is you need to test different metrics to build a qualitative assessment. 

From the paper, the main point seems to be:

> Based on these insights, we caution against blindly using cosine-similarity and outline alternatives.

Which is perfectly reasonable. Not sure what game of telephone led from what the paper says to this title and summary.",195,1736786430.0
1i0hfsd,m6y7jh2,"I prefer the inverse perspective: cosine similarity is the best similarity, and the real problem is modeling approaches that don't normalize vectors.",40,1736789026.0
1i0hfsd,m6yuupb,"This has been ""discovered"" a million times, but I guess it hasn't become part of ML-lore yet.

The interesting thing is that it does work quite often, and there's a good reason why:   
If you have some function \`f(x, y) = <l(x), r(y)>\`, i.e. a dot product between some embeddings of x and y, then the cosine similarity of l(a) and l(b) is very closely related to the correlation between f(a, Y) and f(b, Y) when we let Y vary. In fact, the more well-conditioned the r(Y)-covariance matrix is, the closer cosine similarity is to that correlation.",16,1736795759.0
1i0hfsd,m6xvfqj,Link to original paper from March 2024: [https://arxiv.org/abs/2403.05440](https://arxiv.org/abs/2403.05440),31,1736785479.0
1i0hfsd,m6y3q6b,"Cosine similarity of unnormalized vectors leads to all vectors on the surface of a (hyper)cone sharing the same similarity with any vector along the cone axis.


Euclidean similarity is always about vectors on a hypersphere, sharing the same similarity with the only vector in the hypersphere centre.


Dot product similarity is probably the worse, intuition-wise. It's about all vectors on a plane orthogonal to the target vector, sharing similarity wrt this vector.


If your vectors are naturally normalized, there's a fixed, although nonlinear, relationship between Euclidean and cosine distance, so it shouldn't matter *that* much. ",28,1736787913.0
1i0hfsd,m7090uj,"""Euclidean distance: While less popular for text data due to sensitivity to vector magnitudes, it can be effective when embeddings are properly normalized.""

??

Maximization of cosine similarity is equivalent to minimizing squared euclidian distance on vector-normalized data. If you normalize your data then the use of one or the other is functionally the same... Why is this listed as a benefit? At scale the dot product of two vectors are way cheaper computationally than the L2 norm",6,1736810754.0
1i0hfsd,m6y3zq4,"havent read the paper, but is the reasoning more or less the same as euclidean distance being somewhat useless in high dimensions? eg, ratio of max diff and min diff approaches one?",2,1736787990.0
1i0hfsd,m6z39xa,"Had a whole long discussion about whether the categorical embeddings we use to control a conditional GAN could be compared using euclidean or cosine distance for some notion of similarity, considering that there is nothing particularly in the model encouraging the embedding space either way. We never really resolved it, except to say well, this is a 256 dimensional space so euclidean is probably less meaningful, but some team members remain unconvinced. I've often wondered if we should be regularizing those embeddings somehow if we want to compare them, if anyone has insights I'm all ears.",2,1736798195.0
1i0hfsd,m72nbea,"(All my experience is based on CV field, it may differ in other fields)
There is an unspoken rule, or fact as you may call it, use the model for whatever task you trained it for. If you train a metric learning model with multi similarity or proxy anchor loss and use cosine similarity as the metric to maximize for positive pairs and minimize for negative pairs, then cosine similarity will work very well. Even you use Euclidean distance in the same loss functions, then cosine similarity may not be useful again.
When you work in a few-shot learning area, the samples that you can query from are very limited, and models pretrained with any other metric than cos sim fail when used in fine-grained tasks, always. 
If you want to use cos sim for retrieval tasks, then you are either left with pair based metric learning or proxy based metric learning.
Proxy based methods are almost impossible to implement for NLP tasks in general unless the purpose is classification or categorization.
But theoretically, if you define the initial proxies in a way where they are distributed across the knowledge space is a meaningful way while there aren’t many of them, then proxy based could also work. Imagine an autoregressive model that predicts embeddings as next token and these embeddings are simply predefined proxies. There are millions of paragraphs or text with meanings. Creating proxy for each and every one of them is impossible. But with perfect distribution of limited proxies, this could be achieved. But perfectly meaningful proxies to define the structure of a knowledge space is also almost impossible :D but it feels like anything is poss in this age, so let’s see if someone will solve this problem.",2,1736847106.0
1i0hfsd,m6y7jv0,If you have been doing ML for a while you will find lots of networks that drop cosine similarity for other options. Including L2 (a simplified efficient implementation of it),3,1736789029.0
1i0hfsd,m6z6uh3,That's why you train with e.g arcface loss (or similar loss that have some contrastive meaning) when you want to use cosine similarity.,1,1736799245.0
1i0hfsd,m74u1dj,"In an image:

[https://media.licdn.com/dms/image/v2/D5612AQEVIqvzp9c2fQ/article-cover\_image-shrink\_600\_2000/article-cover\_image-shrink\_600\_2000/0/1687273797789?e=2147483647&v=beta&t=9HkPRv9U\_DnPbfx9TKB\_O2QlHCYwTHyL1QwfT9jhR44](https://media.licdn.com/dms/image/v2/D5612AQEVIqvzp9c2fQ/article-cover_image-shrink_600_2000/article-cover_image-shrink_600_2000/0/1687273797789?e=2147483647&v=beta&t=9HkPRv9U_DnPbfx9TKB_O2QlHCYwTHyL1QwfT9jhR44)",1,1736877745.0
1i0hfsd,m760dpk,Dang! How come I’m not allowed to publish papers like this!,1,1736890570.0
1i0hfsd,m6z3nld,"This paper is a few months old, but nonetheless a very helpful one, given that many more people are now using cosine similarity searches either in hobbyist or prototypes for work...

I created an AI generated summary of it here if you like (I have also created 100 or so other AI research paper summaries)

I try to publish new ones every day or so, like the rstar-math paper, the deepseek v3 technical report, meta's mender and explicit working memory papers.

I built the solution that creates them and have refined it over a number of months, so it is pretty decent now.

I make the summaries for myself, and post them on Apple Podcasts so I can listen to them while I do other stuff. 

It doesn't replace reading actual papers of course, and I link to all the papers in the shownotes.

I find they help to just get a sense of whether a new paper will be of interest. 

Anyways, for anyone it helps here are the links...

Apple Podcasts Link to episode:

[https://podcasts.apple.com/hu/podcast/new-paradigm-ai-research-summaries/id1737607215](https://podcasts.apple.com/hu/podcast/new-paradigm-ai-research-summaries/id1737607215)

Spotify:

[https://open.spotify.com/episode/1J7nn7v0QqPIehAbW2juLs](https://open.spotify.com/episode/1J7nn7v0QqPIehAbW2juLs)

YouTube:

[https://www.youtube.com/watch?v=2m\_mHwLVJQg](https://www.youtube.com/watch?v=2m_mHwLVJQg)",-5,1736798303.0
1i0hfsd,m6yhbla,"It's not just about the type of loss, but it also depends on what you are optimizing for; you can actually use cross-entropy loss with small modifications and achieve a representation where cosine similarity is applicable (and meaningful). See f.e [https://elib.dlr.de/116408/1/WACV2018.pdf](https://elib.dlr.de/116408/1/WACV2018.pdf)",52,1736791846.0
1i0hfsd,m71fh59,"IMHO your example is a bit too simplified.

A more practical situation of a problem would be: 

1. In no way we know their distances before hand, and thus using a loss function considering their distances is not possible.
1. There are countless of tokens in the problem, and it's possible that the feature space are congested enough with these tokens and similar tokens are forced to be close.
1. The embedding distances are never the ending goal and using a cosine distance is always ""good enough"".",7,1736824721.0
1i0hfsd,m72f1m0,"Its true in theory that cross entropy loss doesn’t necessary *have* to give you a good cosine embedding, but in practice lots of things affect this. Lots of classes or high L2 regularization (for example) both encourage the embedding space to make full use of its dimensions, and random initialization by itself is typically sufficient to avoid truly terrible cases.",3,1736841649.0
1i0hfsd,m77f1br,"I am doing a binary classification of signal and background events in the content of physics research. All features are float values. I applied an autoencoder but the classification result actually declined no matter how I did it. The loss function I used to train the AE is mse, and I only applied l2 normalization.   
  
Now I wonder is it possible my network subject to the rotational invariance problem discussed in the original paper [https://arxiv.org/abs/2403.05440](https://arxiv.org/abs/2403.05440) ? My understanding is that if only l2 is used, we have rotational invariance in the solution. It does not care whether the vector is still pointing the same class cluster as long as the angle between them is small. Or it does not care whether the reconstructed vector is way longer/shorter than the original one, and points at other cluster when taking length into account.

I am not trained in machine learning so some insights to me is really appreciated!",1,1736907095.0
1i0hfsd,m6yfo7o,Cosine similarity is sold as the default in any material about RAG implementations,35,1736791364.0
1i0hfsd,m70zwra,"I was definitely sold Cosine as what you should to default.

But at the same time I'm not overly surprised this is not the case and would probably have researched the right solution for any specific use case",2,1736819679.0
1i0hfsd,m6yn2av,"If the modeling approach normalized the vectors, cosine similarity equals the dot-product. If the modeling approach didn't normalize the vectors, dot-product is probably a better fit.

So dot-product is strictly superior, but you should also probably use normalization.",11,1736793497.0
1i0hfsd,m70gtyy,"More well conditioned = smaller off diagonals, or should I think of it differently than that?",2,1736813390.0
1i0hfsd,m6y6kdi,I thought cosine similarity uses normalized vectors by definition. Isn't it the dot product of two normalized vectors?,19,1736788742.0
1i0hfsd,m6ym7cd,"> Cosine similarity of unnormalized vectors leads to all vectors on the surface of a (hyper)cone sharing the same similarity with any vector along the cone axis.

If you normalize the vectors first this still holds",2,1736793248.0
1i0hfsd,m6ytp5w,"Sorry, (in your great answer) you have used too many terms for my small brain, I asked o1 to define these and now it is clearer to me what you want to say (personally I think the explanation of the **(Hyper)cone surface** and **(Hyper)sphere** are useful, the other stuff you probably know so I leave it at the bottom).

Specifically, it's interesting to consider why it is the case for a **(Hyper)cone** and a **(Hyper)sphere**

Output:

**(Hyper)cone surface**: The set of points in n-dimensional space forming a constant angle with a given axis; here, all those points yield the same cosine similarity when compared with a vector aligned to that axis.

**(Hyper)sphere**: The set of points in n-dimensional space at the same distance (the radius) from a central point; here, all those points have the same Euclidean distance to the center, hence the same Euclidean similarity with that center.

\---------------------------------

**Cosine similarity**: A measure of how close two vectors are in direction, computed as the dot product of the vectors divided by the product of their magnitudes (I add, norms).

**Unnormalized vectors**: Vectors whose magnitude has not been scaled to 1.

**Euclidean similarity**: A measure based on Euclidean distance, typically interpreted so that vectors closer in Euclidean space have higher similarity.",0,1736795426.0
1i0hfsd,m6yn80k,"That is related to or analog of cosine being zero on average, with smaller and smaller deviations.",1,1736793543.0
1i0hfsd,m6z1k7b,Normalized 2-norm is just opposite of cosine similarity (1 - cosine similarity) up to constants when the vectors are normalized. You take the max of one or the min of the other,1,1736797700.0
1i0hfsd,m6zpzh3,"One can -- but it's common to use loss functions that intentionally don't do that. 

https://medium.com/@maksym.bekuzarov/losses-explained-contrastive-loss-f8f57fe32246

> The general formula for Contrastive Loss is shown at Fig. 1.
>
> ...
>
> So we need to make sure that black dots are inside the margin m, and white dots are outside of it. And that’s exactly what the function proposed by Le Cunn does! In Fig. 6 you see, that the right part of the loss penalizes the model for dissimilar data points having the distance Dw between them < m. If Dw is ≥ m, the {m - Dw} expression is negative and the whole right part of the loss function is thus 0 due to max() operation — and the gradient is also 0, i.e. ***we don’t force the dissimilar points farther away than necessary.***

That intentional choice to ***not*** ""force the dissimilar points farther away than necessary"" is both     
(a) what makes it a good person classifier, and     
(b) what makes cosine similarity useless for that model",10,1736804819.0
1i0hfsd,m72iz8c,"Partially agreed.

Often we have reasonable approximations of relative distances -- especially when classifying nouns that are part of some ontology.

For animal or plant classification, we can see how related the species are -- with metrics like least common ancestor, or similarity of DNA. 

For faces, it's common to qualitatively say ""this person looks like that other famous person""; or more quantitatively, ""this person is a second cousin of the great aunt of that person"".",2,1736844205.0
1i0hfsd,m6ynxyp,"Yes, sold as a default because it is a reasonable default. 

But I think the notion of having a ""default"" and ability to plug in other options then signals what most developers, practitioners, and researchers already know, which this review of the paper seems to signify that they don't, which is this:

> The research highlights the need for alternatives, such as Euclidean distance, dot products, or normalization techniques, and suggests task-specific evaluations to ensure robustness.

Is there a need to highlight this then?

I much more appreciate the original paper [link](https://arxiv.org/abs/2403.05440) in that it shows the experiments and actual things that can be replicated. I think the ""sensationalist"" take is a bit of a disservice to the original paper because its authors are honestly quite humble in their conclusion.",28,1736793751.0
1i0hfsd,m71dhf8,"Because the sentence embedding models are trained with a cosine similarity loss lol. Far from blindly using cosine similarity, they're using the embeddings the way they were designed to be used",6,1736824035.0
1i0hfsd,m6z9v6z,According to the OpenAI docs about embeddings they also use cosine similarity in their code snippets. I assume that’s a good enough approach,4,1736800132.0
1i0hfsd,m6yomdw,"That's the point: IMO models that use dot product with non-normalized vectors are inferior to models that use dot product with normalized vectors, i.e. cosine similarity.",4,1736793948.0
1i0hfsd,m70xat0,"Simplifying a bit: As close as possible to a (scaled) identity matrix. So yes, small off diagonals, but also sameish values along the diagonal.

In essence, corr(f(a, Y), f(b, Y)) = cos\_sim(l(a) @ T, l(b) @ T), where T is a square root of cov(r(Y)).",3,1736818832.0
1i0hfsd,m6yaotn,For cosine similarity it doesn't matter if the vectors are normalized or not bc only the angle is relevant,14,1736789934.0
1i0hfsd,m6ylmqj,"It is. The point is, you can take 2 unnormalized vectors, take the cosine similarity by normalizing and doing dot-product, and then doing something *on the unnormalized vectors* depending on the cosine you got.


The fact that cossim(x,y) = dotprod(x/|x|,y/|y|) does not imply you're working with and passing through the network x/|x| and y/|y|",2,1736793082.0
1i0hfsd,m6ymb14,"cosine similarity is just normalized dot product between vectors, so not quite the same but yes normalization alone does not make cosine similarity better/good.",2,1736793279.0
1i0hfsd,m6ypgxc,"If you normalize first, the vectors are only on the hypersphere and its intersection with the hypercone is just a ""hypercircle"" and you don't have to mind the fact that the hypercone contains vectors of any possible magnitude, which is exactly the fact I want to highlight.


As u/bregav has commented, I tend to like the approaches where one already starts from normalized vectors, however I mostly see only tentative normalizations and the use of dot product similarity with faith in the fact that accounting for magnitude and direction with one measure is feasible and desirable, which I find debatable.",5,1736794194.0
1i0hfsd,m6zuq40,Take a look at the Circle Loss paper as well and how it is derived https://arxiv.org/pdf/2002.10857,8,1736806223.0
1i0hfsd,m6yu1x9,"Yeah that's fair. Seeing as how it's a blog of a product trying to sell LLM tooling to casuals it kind of makes sense in that context, while in a context of an experienced practitioner the title is misleading.",7,1736795528.0
1i0hfsd,m6zn91f,"Yeah, honestly it's the only measure of similarity I see used in any documentation",3,1736804019.0
1i0hfsd,m6yldyb,"If the vectors are the same length, which is the case when the vector is normalized, the cosine similarity is just the dot product.",7,1736793011.0
1i0hfsd,m6ynopl,"Right. Just to confirm my understanding, the issue is that the components in the vector may have different scales, and simply normalizing them doesn't fix this?",2,1736793677.0
1i0hfsd,m6z6oty,"But I have a feeling that the discussions about hypercones and hyperspheres just describe a simple numerical truth (unless I am missing something):

If we do not normalize the vectors the results are incomparable because the scales differ.

For example, \[99,100\] and \[2, 0\] will have a larger dot product than \[1,0\]\\cdot\[1,0\]\^t although the direction is not as similar.

Did you try saying something else I have been missing? I have a feeling I am missing something about normalizing before and after passing the vectors to the network.",1,1736799198.0
1i0hfsd,m6ym0p6,"If the vectors are the same length it is not implied that they are normalized, whatever the lengths, the cosine is exactly the dot product scaled by the product of lengths",5,1736793194.0
1i0hfsd,m6zquxr,partly. The larger dimensional you go the more spherical distance between one point and all other points becomes (which makes lots of vectors near equidistant) in both euclidean and cosine distance.,3,1736805072.0
1i0hfsd,m6zaglm,"If you refer only to the difference between cosine and dot product, yes, the description aims at visualizing (just remove the prefix hyper and imagine the objects in 3D) the consequence of the simple numerical truth.


The point is that people argue, or work like the argue, that one should account for scale similarity and thus the large dot product similarity between [99,100] and [2,0] is at worst a little price to pay to consider [99,100] and [100,99] more similar than [9.9,10] and [0.99, 1] and gain something.


Are we gaining something? Is it what we think it is?
Dot-products are all over the place in deep learning",2,1736800306.0
1i0hfsd,m6yo5pe,"You're right. ""normalized => same length"" is what I meant, but basically wrote ""same length => normalized""",4,1736793813.0
1i0hfsd,m6zii1c,"I think I understand what you are trying to say. For me, the whole ""alternatives"" discussion in the article (I did not read the paper itself) I have read just now is just a useless fluff - it depends on the data and how we interpret it.

I also agree with you that using the dot product does not make sense in 90% of the cases, intuitively cosine similarity is better to default to, and the squared Euclidean distance on normalized vectors is proportional to the cosine distance, hence this suggestion does not seem very thoughtful.

Thanks!",2,1736802641.0
1i1gr9y,m75yu6f,This is probably better for r/MLQuestions .,5,1736890113.0
1i1gr9y,m76ab6o,"AB testing? I’ve been thinking about creating an UI where you get random search results from different models in which you can’t rate and compare different models to each other and rate them to collect user input.

The most solid way would be to create a ground truth dataset, but that can be hard for embedding/search.",1,1736893513.0
1i1gr9y,m766ceq,Can you not run an AB test on the new model compared to the baseline?,1,1736892317.0
1i1gr9y,m75ypxx,"https://www.rootsignals.ai/
They have a python SDK (pip install).",0,1736890079.0
1i1gr9y,m766m6x,"Every problem domain is different. That's why there are so many benchmarks out there. Just Google ""LLM System Evaluation"" and you'll find dozens of articles on it.",0,1736892398.0
1i1aarq,m759dcq,"Finally something I know. Do you want to make a model that satisfies the standards of credit risk, or just to get the highest metric? (in credit risk, usually the metric is gini = 2\*auc - 1). These are two different tasks.",7,1736882170.0
1i1aarq,m75ds80,"I wouldn't worry too much about dimensionality. Stuff like XGBoost is really good at ignoring uninformative features. The classifiers we have in production are worse at this, lol.

GBMs are also great at dealing with imbalanced datasets, often needing no additional help.

Assuming you already did hyperparameter tuning, there's not much else you can do. Feature engineering would be the way to go if the features weren't anonymized. You can always ensemble a few different predictors, that's a pretty reliable way of increasing performance if you don't care about needing more inference compute.",4,1736883456.0
1i1aarq,m74hstb,"1000 features seems like a lot for just 100k samples - I’d remove features based on correlations between themselves or get the ones most correlated with the target metric

Also, have you tried downsampling your negative samples? Use like 5% of them

For me, what usually works: LGBM + weighting + downsampling + increased model complexity (ex: deeper trees, but be careful with overfitting)

By the way, precision, recall and f1 are dependent on the threshold. Make sure you use an optimal threshold according to your PR curve",2,1736874196.0
1i1aarq,m74l74b,"You need to do dimensionality reduction first, 1000 dimensional space is simply far too large for only 100k rows. Try deleting highly correlated columns, or PCA /UMAP/t-SNE/etc...",2,1736875195.0
1i1aarq,m762w1s,"Did you normalize/standrdize the features? Financial datasets tend to have features that have different scales, so I would fix that first.

If there are categorical features (you can infer that by looking at the unique values each feature takes), one-hot encoding them might help, too.",1,1736891304.0
1i1aarq,m75d4q4,thanks for your response. I am looking forward to currently maximizing the metric,1,1736883266.0
1i1aarq,m75egpj,"In that case I'd do lightgbm. I'd start with hyperparameters that would allow for features to get selected if they are 'informative' (so not optimizing for performance) and recursive feature elimination using SHAP values. That way you may get rid of many features that will never get split on in the trees. Then hyperparameter tuning and perhaps class weights.

However, such a model would never ever in a million years be deployed into production :-)",4,1736883656.0
1i1aarq,m75iu3x,Mind elaborating on your last point?,2,1736884917.0
1i1aarq,m7626cc,"There is a great stress on explainability and stability (in time) of the model. That is why credit risk loves logistic regression with feature binning (bucketing).

Explainability is needed for regulatory purposes, for model auditing and validation, as well as decision making if a datasource stops providing data (what do you do in a boosting model if a credit bureau is down or androind changes terms and stops providing data from your app?). If you have sudden rise in defaults, what is the reason? Is the model not performing? Some of its part? Or is it just weird economic situation or just an outlier month? If we change this part of the underwriting process, how does it influence the model or vice versa?

Stability in time means that the model performs similar month-after-month. Usually that is achieved by looking into default rates in bins of variables (for instance age is three buckets, 18-25, 25-60, 60+) and looking month after month if the ordering of default rates is the same. It does happen that something change and good bin becomes bad and vice versa. You do not want that. For that reason, things like PCA are absolutely a no go, because new features are linear combination of the original ones. And if there is a shift in one feature, that would shift the new ones. Also, one has to be very causious when 'interaction' variables are used (e.g. age X occupation). They may add performance, but they may take the power of the two features and if one changes over time, the interaction changes, and subsequently the two features are doomed.

Maybe 'never ever in a million years' was too hars of a statement, but certainly banks in Europe are (to my best knowledge) extremely conservative in the choice of models. I came to the realization that logistic regression is great when my model was supposed to score hundreds of applicants and that I really want to undestand everything that is happening in the model. I would be really scared of a boosting model. Also, boosting was not beating logistic regression by much. I guess we did not have strong interactions between the features (and it usually is the case, as I heard).",2,1736891097.0
1i13aot,m72zehi,"This doesn’t really make sense if I’m reading your intent correctly. A correlation matrix is a measure of how associated several different variables are over a set of data. Clustering would attempt to find groups of data points that share similar attributes. If you want to run a clustering algorithm, it should be run directly on your dataset with your variables as attributes. Running a clustering algorithm on a set of correlation coefficients wouldn’t give you any meaningful information. It would be helpful to step back and ask yourself what question you’re trying to answer, and then select the (single) most appropriate method to answer that question.

It’s also possible that I’m misunderstanding your intent. If so, then I’d welcome clarification!",5,1736854570.0
1i13aot,m73jxfa,"DBSCAN, OPTICS and related algorithms allow for similarity matrices as input",2,1736863470.0
1i13aot,m7486mt,Convert to dissimilarity first? Most clustering algorithms work on n\*n dissimilarity matrices.,2,1736871358.0
1i13aot,m74abf6,"If your input is similarity matrices , which are often positive semi-definite (PSD) matrices, Riemannian geometry can be a powerful tool. PSD matrices form a curved space, and the Riemannian metric respects the inherent geometry of this space, providing more meaningful measurements of distances and similarities between matrices. Geodesics (shortest paths) on the Riemannian manifold of PSD matrices take this curvature into account, resulting in more accurate interpolations and transitions between matrices. So, one can achieve a more appropriate and effective framework for tasks involving PSD matrices, such as distance measurement, clustering, classification, and interpolation. This approach respects the data's inherent structure, leading to more accurate and robust results compared to euclidean geometry.",2,1736871993.0
1i13aot,m77ww7q,"Thank you so much for the reply, honestly, When I was typing out the question, I had exactly the same question in my mind. Your answer helped me to really take a step back and realize what I wanted to do with my data. I might run the clustering algo on the data itself and see how it works out.",1,1736913655.0
1i13aot,m77x4h2,"I haven't heard about OPTICS, is it the same as the that is used in quantum computing?",1,1736913747.0
1i13aot,m77xpp1,"I did try it but the distribution is sparse with most data points acting as singleton, but that should not happen, as I am expecting lots of overlap.",1,1736913986.0
1i13aot,m77z43c,"Thank you so much, I think this might prove to be very useful, as the similarities I am using forms a high-dimensional similarity space that is often non-Euclidean. So, I am not sure if I can rely on Euclidean distance as much, Riemannian could help me capture the subtle differences in my data.",1,1736914568.0
1i194ja,m748zvl,"skeletal action recognition is a very efficient form of human action recognition (HAR). on the other hand there is HAR from video, but you need big GPUs for that. we have done both, and for video models we also did visualization of attention maps for models like Video Swin Transformers. You can perfectly see that the areas of attention are focused on objects connected to an action in some cases. We also saw that video models can easily overfit on visuals in the background. Like having a scene where people shake hands being classified as playing football because a football was present somewhere on the ground. with skeletons you can ignore such biases. 

One can model this dependence on objects implicitly with a video model. For explicit modelling I know from the top of my head that the Drive&Act dataset contains annotations for triplets of location, object and action. Maybe look for action triplets in the literature. If no human is present at all this could also be called ""event detection"" or something like that.",1,1736871602.0
1i0vrg3,m71d6vg,"You’ve got data parallelism, pipeline parallelism, and tensor parallelism. These mean models on different pods, layers on different pods, and parts of layers on different pods, respectively. Different libraries implement these techniques. They rely on networking.",3,1736823937.0
1i0vrg3,m71ccec,"For training datasets: Datatrove has a utility to implement a dataloader that works with local files or S3.


https://github.com/huggingface/datatrove/blob/main/src/datatrove/utils/dataset.py",2,1736823656.0
1i0vrg3,m71yz6c,"What are the good resources to learn how to train large models on large data, distributed training, also inferences, it would be good if someone can list some resources, tia",2,1736832602.0
1i0vrg3,m72qesi,"If you go beyond DDP, there are none imo. TorchTitan would be the closest thing",1,1736849144.0
1i1fwsg,m75qw76,what dataset did you use to select the features? just the training set or the total dataset?,10,1736887528.0
1i1fwsg,m75ram8,"As an additional step, maybe you can compare your model with other models. I always have a baseline model ( usually logistic regression), Random forest model and XGBoost model.",6,1736887701.0
1i1fwsg,m75srle,"Hmm.

I guess some potential issues might have to do with how PD is diagnosed. AFAIK it's diagnosed (and then gets the label in your dataset) based on symptoms. So there could be some kind of circular logic at play, e.g. if it's like ""people who have 7 out of these 10 symptoms are diagnosed with having PD"" and if you then just pick those 10 variables for your model.

As in, you might not be predicting the disease but just using the same diagnostic criteria that the doctors are using for the ""ground truth"".",5,1736888283.0
1i1fwsg,m76cwmc,"The biggest thing to look for is to make sure that your training and testing datasets align with what the model will be used for.

For example, your prevalence of 42% stands out to me. I think the prevalence of PD is much lower (<1% ?). This \*\*could\*\* mean that your training dataset does not reflect reality (unless maybe your model will be run on people who are already suspected of having PD). It should be fine as long as you don't have any confounding.

There's a famous (?) example of researchers falling into a similar trap \[here\](https://jamanetwork.com/journals/jamadermatology/fullarticle/2749356). The tl;dr is they sampled from a population of patients with skin cancer, but their sample didn't reflect the true population - the cases had a much higher age than the controls. As a result, their model probably just predicted patient age instead of which patients had skin cancer. It's an easy thing to miss if you aren't careful.

So I'd really think hard about if your model and data make sense given the intended use of the model.

Next steps could be:

\- check feature importance - make sure everything makes sense

\- check if you might be falling into a similar trap as the paper

\- you'll need to rerun your feature selection as you used the test set to select appropriate features. I understand that most of the features you selected with domain knowledge, but using the test set to influence your train set, even a little bit, is a cardinal sin. It would be enough to severely hurt your reputation (even if re-running only on the train set doesn't change the results, it's still a big no no).",3,1736894305.0
1i1fwsg,m76doxj,"This is actually my exact field of research. The AUC seems very high, I would be more than surprised If that is possible. Building a risk model using known risk factors yields in an AUC of not more than ~0.7. On problem in designing auch a model is that a model usually just the statistics of the confounders of sex and age as older patients and males are more likely to get diagnosed with the disease. So a meaningfull model should be created for specific age groups for females and males respectively.",3,1736894548.0
1i1fwsg,m75rsif,"The way to prove you wrong would be to collect some new patients with and without Parkinson's, collect your features, run your model, measure whether or not they actually have Parkinson's (possibly involving waiting a long time? Not sure what the diagnostic standard is here) and then observe how much worse your model does. If it does a lot worse you were disproved, if it does the same or only a little worse you were validated. 

In terms of actually getting it used, interpretability is key. Doctors and insurers will want to know why people are being diagnosed or not diagnosed. 

Are any of your features real valued or ordinal? (Ie not categorical or binary.) You could consider putting in monotonic constraints which tend to improve performance in my experience while also making the model behave in a more logical and understandable way.",1,1736887924.0
1i1fwsg,m75ssig,Better compared to what? ML metrics don't mean anything in isolation. A problem could be very hard or very easy. What do you want to be doing with your model?,1,1736888292.0
1i1fwsg,m75vpd9,You may have target leakage.,1,1736889190.0
1i1fwsg,m768oe9,"Check the calibration curves of your model, especially for medical applications, having well-calibrated prediction can be crucial for decision-making.",1,1736893019.0
1i1fwsg,m76im8y,"With the caveat that your feature selection includes data leakage, depending on the features this very high accuracy isn't necessarily a sign something is off. Alzheimer's can be classified with 90%+ accuracy from brain imaging data for example. Predicting it from genetics you can only get AUC of like 0.6. So it depends a lot on the input.",1,1736896124.0
1i1fwsg,m75ri4k,Total dataset which has 360 features,-4,1736887793.0
1i1fwsg,m75rmy5,"I have done that too, probably should have included but all reasonably similar, vary by about 1%",0,1736887855.0
1i1fwsg,m75v9o6,"great point and something I have thought about a lot, how can my model be useful if its only getting 90% correct of what doctors have diagnosed? I think my thoughts are that the assessment criteria i.e how simple it would be to answer the questions for the patient and how quickly it could be done is the use case. Whats your thoughts?",1,1736889058.0
1i1fwsg,m75w3gs,"Thanks for the feedback, yes I think one of the issues is that I would need real world aka clinical trial to test it and that may take years to get results, I am exploring interoperability and black box issues, do u have any suggestions for that?   
As for the features, yes some are real valued eg BMI and a good few are ordinal, assessing severity of something from 0-4, 0 being no pain for eg 4 being severe pain. I am not sure what monotonic constraints are do u have a link to a description on how to implement?",0,1736889306.0
1i1fwsg,m75whlf,"I guess im not sure what my end goal is , what I do know is that PD is very tricky to diagnose and often takes years before a confirmed diagnosis. Heres a good article on the problem [https://www.parkinsons.org.uk/news/poll-finds-quarter-people-parkinsons-are-wrongly-diagnosed](https://www.parkinsons.org.uk/news/poll-finds-quarter-people-parkinsons-are-wrongly-diagnosed)",1,1736889425.0
1i1fwsg,m75wzeg,"Fair point. I’ve checked for this by analysing feature importance, and none of the features stand out as significant outliers in terms of their contribution to the model’s performance.",1,1736889573.0
1i1fwsg,m75sqpq,"so thats definitely a problem

you can try to recover from it, by automating the analysis, and repeating on the training data
and taking yourself out of the selection process",12,1736888275.0
1i1fwsg,m75xqak,"Well, if the data is questionnaire data, and the diagnostic criteria are just something like ""7/10 of these symptoms"" you don't need a model, as you can just ask the questions and then get the answer (the answers *are* the answer then).

Having said that, I don't really know the diagnostic criteria for PD nor your data. But in general, the value in predicting diseases is can you predict a person getting a disease *early*? Like, if some early symptoms (I think I've heard of a decreased sense of smell in PD) can fairly well predict that the person gets other symptoms and diagnosis several years later.",3,1736889793.0
1i1fwsg,m761omi,"Here's a link to get you started. It looks like there are different algorithms to implement the monotonic constraints that you'll want to experiment with. You'll definitely benefit both in terms of performance and making sense if more pain means more likelihood of having it. BMI is tricky because both high and low BMI can be risk factors for things. You could conceivably split it into two features to enforce that really fat is always worse than fat and really skinny is always worse than skinny but that would be more complicated. 

https://www.kaggle.com/discussions/getting-started/273527",2,1736890953.0
1i1fwsg,m765sqd,"One of the tricks hidden behind ML models like this is that they're often made based on lots of tests that the patients have been through that required a doctor to prescribe them. This isn't an unbiased sample. Somebody who is misdiagosed might not even be getting these tests. You might also want to think about the quality of your labels. Are your labels just based on doctors' diagnoses? In that case, you won't be getting much more accurate.

There's an entire literature of papers that claim to diagnose better with ML than doctors, and yet that's barely something that happens due to a variety of real-world concerns that I'm not really qualified to explain. Anyways, my point is to take ""outperforming doctors"" with a grain of salt. 

ML metrics are often not sufficient to answer a question like ""is my model good?"". They're mostly for measuring whether certain models are better than others. You will need to measure your model in a clinical setting if you really want to know how well it performs.",2,1736892154.0
1i1fwsg,m764fq5,"You will need an end goal. Otherwise, you will not know where to go, which path to take, and when to stop. Even exploratory analysis benefits greatly from having some kind of goal.",1,1736891757.0
1i1fwsg,m76gxiu,"You definitely have data leakage,  you said in a reply to someone else that you used the full dataset when doing significance tests to choose variables. That can bump performance to a surprising degree.",1,1736895572.0
1i1fwsg,m75tcxa,Bc data leakage?,4,1736888468.0
1i1fwsg,m75u4bf,yup,4,1736888707.0
1i1fwsg,m75unqd,"I see your point, but I dont think the statistical analysis really had any influence on my decision making process for features it was essentially based all on my domain knowledge in a sort of trial and test style, I would only say it was to exclude those that were greater than p value 0.05 of which only 60 out of the 360 where. whats your thoughts on that",-7,1736888874.0
1i1fwsg,m763jou,"I don't feel qualified to criticise your method. But I wanted to say that in Medicine, and Biology in general, an AUC of .9 or higher should trigger alarms, especially when it is achieved early in the study. Data in those domains is usually very noisy and incomplete.",2,1736891494.0
1i1fwsg,m76i5og,Feature selection that includes the test set is one of the most common data leakage problems. You 100% cannot do this.,1,1736895972.0
1i1fwsg,m76bjxn,"you are also a model

so if eg you looked at scatterplots of the whole dataset to decide which were relevant features then this is data leakage.",1,1736893889.0
1i1fwsg,m765pxv,"I completely agree, hence I am very skeptical but I don’t know how to prove it is wrong",2,1736892131.0
1i1fwsg,m76o0xi,"I was less worried about this and more worried about doing it on the whole set. If selection happened just on training there wouldn't be overlap and leakage, correct?",1,1736897918.0
1i1fwsg,m76plwr,yea my point is doing feature selection on the whole dataset. it doesnt matter whether your feature selection is automated or by eyeballing. both are bad,1,1736898441.0
1i0g71d,m6yqvsk,"Thanks for sharing, super interesting.",3,1736794606.0
1i0g71d,m728660,"u/MagnoliaPotato, have you heard of JUDGE-BENCH? A consortium of great universities run a similar experiment and built a fairly large hallucination dataset.

https://arxiv.org/abs/2406.18403

https://github.com/dmg-illc/JUDGE-BENCH",2,1736837491.0
1i0g71d,m7327d8,My concern is that LLM-driven eval is just turtles all the way down - how do you know your validator LLM is performing correctly? Another LLM to validate the validator? And so it goes...,1,1736856043.0
1i0g71d,m6yus62,"I hope if this type of research continues and is implemented in backends, that there might be some way to turn it off-- Much of my use of LLM's is to create hallucinations, not avoid them-- Its the only way to produce novel results--",1,1736795739.0
1i0g71d,m728zrc,"u/MagnoliaPotato, I'll admit I haven't read your README.md, but I'm confused on the table you posted here. You are comparing Base models with Ragas metrics. Which metric was it used with the base settings? Perhaps adding an additional column to specify it would help.",1,1736837962.0
1i0ju9b,m72e7mg,Nice! Would be interested to see your workflow on how to create these interactive blogposts!,2,1736841136.0
1i0cd4n,m6xhfqf,"Are you planning to show results through pretraining/CPT or RAG efficacy?


And how can we control the Similarity distance threshold or number of elements to remove?


Fundamentally, it could be a very useful library, since semantic deduplication is applicable in so many situations.",2,1736781158.0
1i0cd4n,m6xgm6r,[deleted],0,1736780886.0
1i0cd4n,m6xj33k,"Good questions and thanks for the kind words! We are indeed planning to show the effect on RAG efficacy, it's one of the next items on our roadmap.  
  
You can already control the similarity using the ""threshold"" parameter (and you can also easily rethreshold using the ""rethreshold"" function, e.g. in my example you can do the following to control the similarity threshold (and number of elements to remove):

    deduplicated_test = semhash.deduplicate(records=test, threshold=0.9).deduplicated",2,1736781693.0
1i0cd4n,m6xillp,"Not that I know of; though I think the general idea is the same: create embeddings for your samples (or chunks/segments in this case), and apply the same algorithm we use in SemHash for deduplication. It's probably a bit more involved though, for example, we can show which strings matched as duplicates, but with video segments that's harder to judge. Another issue is the chunking/segmentation itself. I know there's some nice approaches for this with text, but for video/audio I'm not sure (but it's also not a domain I'm too well versed in).",1,1736781534.0
1i162tn,m73rey9,"so you generate multiple questions (queries) from the user prompt, presumably to cover all the nuances of it all, then do retrieval with all of them, sort all retrievals for each generated query based on their score, then go through each retrieval and add to their initial score 1/(rank\_in\_retrieval + 60)? 

  
and the the function you use to generate those ""relevant"" queries is: ""Generate multiple search queries related to: {original\_query}""",3,1736866114.0
1i162tn,m73ek60,"Link to Blog: [https://hub.athina.ai/blogs/how-to-implement-rag-fusion-a-step-by-step-guide/](https://hub.athina.ai/blogs/how-to-implement-rag-fusion-a-step-by-step-guide/)

Link to Notebook: [https://github.com/athina-ai/rag-cookbooks/blob/main/advanced\_rag\_techniques/fusion\_rag.ipynb](https://github.com/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/fusion_rag.ipynb)",0,1736861454.0
1i162tn,m751dn2,Spot on! 🔥,1,1736879862.0
1i162tn,m73elfl,"
I see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't 
render large Jupyter Notebooks, so just in case, here is an 
[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:

https://nbviewer.jupyter.org/url/github.com/athina-ai/rag-cookbooks/blob/main/advanced_rag_techniques/fusion_rag.ipynb

Want to run the code yourself? Here is a [binder](https://mybinder.org/) 
link to start your own Jupyter server and try it out!

https://mybinder.org/v2/gh/athina-ai/rag-cookbooks/main?filepath=advanced_rag_techniques%2Ffusion_rag.ipynb



------

^(I am a bot.) 
[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) 
[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) 
[^(Author)](https://johnpaton.net/)",1,1736861467.0
1i16ud7,m73lpgl,"I mean if it's not reliable, sounds like it's not good enough? Either way, I suggest putting it in terms of money -- perhaps how much time it saves converted to cost of labor.",26,1736864122.0
1i16ud7,m73o8d9,"By adding a disclaimer: ""Our tool can make mistakes. Check important info"". Seems to work for ChatGPT.",9,1736865018.0
1i16ud7,m73qld9,"Quantify its reliability, work with the clients to set a bar and show improvements on it to gain trust.",7,1736865836.0
1i16ud7,m73pi72,Being very reliable is a different goal from being helpful. But it still must be a conscious trade-off. If unreability prevents the tool from being helpful it needs to be redesigned at least from the UX side.,2,1736865463.0
1i16ud7,m73v1vn,"Whenever I communicate to stakeholders or non-technical people on my team, I found it to be very effective to give a little quantitative and qualitative descriptions of the model's performance.

I like to start with some big-picture quantitative stats:  What's your percent that the pipeline runs successfully.  What are your false positives? false negatives?  I wouldn't go that much deeper than this if your stakeholders are not technical.

Then, couple it with some qualitative descriptions.  I suggest, describe a specific case where it fails and show why.  

Doing both of this is a great way to effectively communicate ""good enough"" to your stakeholders.  They walk away knowing ""OK, I know it works XX% of of the time and when it doesn't work it's because it looks like one of those weird edge cases and that's good enough.""  It enables them to make the ""good enough"" conclusion instead of you telling them that the imperfect solution is good enough. 

They will never understand the ML work that you did under the hood, but they walk away feeling like they do. And that will get you buy-in.  Resistance to AI and ML models are usually rooted in distrust.  Help paint a clear and usable picture for them to demystify your work.  Sadly, you not only have to be an expert in the ML work, but you have to be an expert communicator too. 

  
Good luck!",1,1736867305.0
1i16ud7,m744h7p,Benchmarking it. Shows your model is x% realiable which (1) exceed their expectation or existing model (2) cut x amount of cost,1,1736870231.0
1i16ud7,m74d7fm,"To me this sounds like a UX problem. Sit down and observe your analysts to understand their workflow. Figure out how your non-perfect AI solution could be integrated while causing a minimal disruption and requiring the least mental effort, while still providing clear value to them. Which are their most common problems? Which ”jobs” or tasks do they perform that could be automated or performed faster? You might learn that your AI should generate 10 solutions rather than just one; alleviating the problem of occasional errors, while providing the analysts with a broader starting point for further manual work.",1,1736872856.0
1i16ud7,m73qjtt,But what happens if you provide the analyst with an insight suggesting they should fire someone?,-4,1736865822.0
1i16ud7,m73qy3g,"that is what we did, we created a benchmark using real word questions",-5,1736865956.0
1i16ud7,m73s7ub,By what metric are you making these insights lol,7,1736866380.0
1i16ud7,m74dwxv,What's the issue here?,2,1736873064.0
1i16f1c,m73kr8f,"The post highlights essential aspects of machine learning system design, particularly for interviews; however, effective interview preparation often also includes practical experience with system architecture and real-time data processing, such as using Apache Kafka for streaming and cloud services for scalability. Additionally, the emphasis on modular design is critical, as recent discussions in the field suggest that containerization and orchestration (using tools like Docker and Kubernetes) are vital for building scalable ML systems that can adapt to varying loads.

* [Top 25 Machine Learning System Design Interview ...](https://www.geeksforgeeks.org/top-25-machine-learning-system-design-interview-questions/)
* [Machine Learning System Design Interview Cheat Sheet ...](https://medium.com/analytics-vidhya/machine-learning-system-design-interview-cheat-sheet-part-1-bc3bc74eb16e)
* [Mastering Machine Learning System Design Interviews](https://medium.com/@jh.baek.sd/mastering-machine-learning-system-design-interviews-4a197e170010)

^(Hey there, I'm just a bot. I fact-check here and on other content platforms. If you want automatic fact-checks on all content you browse,) [^(download our extension.)](https://critiquebrowser.app)",-2,1736863775.0
1i16f1c,m73necv,thank you for sharing let me read on free time,-4,1736864726.0
1hzshvp,m6s5s8y,"When is the cache invalidated? When the arguments change, when the function code changes, when any dependency of the function changes?",53,1736705848.0
1hzshvp,m6s36i7,How does it differ from [joblib.Memory](https://joblib.readthedocs.io/en/latest/memory.html)?,43,1736705118.0
1hzshvp,m6s91ps,How does it differ from [https://pypi.org/project/diskcache/](https://pypi.org/project/diskcache/),19,1736706772.0
1hzshvp,m6spwgf,"It is good that you made this, but why would I use a 3rd party solution to a problem that is already solved by the Python standard library?",11,1736711572.0
1hzshvp,m6s1lxo,"Check it out: [https://github.com/shobrook/pkld](https://github.com/shobrook/pkld)

This decorator will save you from re-executing the same function calls every time you run your code. I've found this useful in basically any data analysis pipeline where function calls are usually expensive or time-consuming (e.g. generating a dataset). 

It works by serializing the output of your function using pickle and storing it on disk. And if a function gets called with the exact same arguments, it will retrieve the output from disk instead of re-executing the function.

Hopefully this helps anyone iterating on a slow ML pipeline!",12,1736704680.0
1hzshvp,m6sdzb6,[deleted],-2,1736708170.0
1hzshvp,m6ujfel,Dont we already have '@cache' doing exactly  that?,1,1736731572.0
1hzshvp,m701yea,"Might make sense for there to be a default timeout param for pickling the returned output, just in case  something very large i.e a 10gb list is returned by the func",1,1736808454.0
1hzshvp,m70eefx,"I think this is a great idea, but I read your code and want to give constructive feedback on a problem area.  
  
[https://github.com/shobrook/pkld/blob/445e6a7d9221525ad7c77f8f1c8dc52f91c639a1/pkld/utils.py#L122-L130](https://github.com/shobrook/pkld/blob/445e6a7d9221525ad7c77f8f1c8dc52f91c639a1/pkld/utils.py#L122-L130)

From my understanding, you support caching based on arbitrary objects, because you hash them using their string representation. This is rather unsafe, because the string representations of distinct objects are not guaranteed to be distinct (this is a very common situation). I appreciate that you log a warning about it, but I think (1) that could be easy for users to miss and (2) there's no clear solutions for users.

I suggest that you relax your claims (about supporting unhashable arguments) on the readme and strongly emphasize the warning there.

What you intend to do (canonical hashing of arbitrary objects in Python) is [very difficult](https://death.andgravity.com/stable-hashing).

But, instead of using `str(obj)` you may consider `dill.dumps(obj)` instead. [dill](https://github.com/uqfoundation/dill) is a Python serialization library that can support many more types than the built-in `pickle`. This should eliminate the above issue (distinct objects will serialize to distinct bytes). But, in a much smaller fraction of cases, you may have the inverse problem: equal objects (i.e. two different objects that are `==`) are not guaranteed to serialize to the same bytes. So this is not a perfect solution, but is a better one.

And you should also consider using `dill` instead of `pickle` for storing returned objects :)

Thanks for reading! Apologies for any misunderstandings on my part. Best of luck.",1,1736812571.0
1hzshvp,m6tuwql,"marimo does this, with cache invalidation based on your notebook state [https://docs.marimo.io/api/caching/?h=cache#marimo.persistent\_cache](https://docs.marimo.io/api/caching/?h=cache#marimo.persistent_cache)",0,1736723612.0
1hzshvp,m6s6hqe,"When the arguments change. You can also manually invalidate the cache by using the `disabled=True` parameter in the decorator, or by calling `.clear()` on the function itself.",17,1736706048.0
1hzshvp,m6s6742,"Also consider \`functools.lru\_cache\`.

  
[https://docs.python.org/3/library/functools.html#functools.lru\_cache](https://docs.python.org/3/library/functools.html#functools.lru_cache)",29,1736705965.0
1hzshvp,m6s6aif,"lmao

Edit: Didn’t intend to be rude, I genuinely laughed out loud when I realized this was already built. `joblib.Memory` is indeed quite similar. The only meaningful difference is `pkld` supports asynchronous functions and in-memory caching (in addition to on-disk).",42,1736705991.0
1hzshvp,m6vrr4n,How,2,1736749389.0
1hzshvp,m6ubc2w,"Hello. Pretty idiotic question but isn’t the idea behind caching results same as this ? If I have a function that runs across all the rows in a data frame, it could be repeating a lot of calculations. I usually add a dictionary that keeps track of computed results so it’s just a simple lookup later on.",2,1736728911.0
1hzshvp,m6sx4uj,What did you build pal?,0,1736713584.0
1hzshvp,m6uw8mt,"Ah, I see. This is something interesting. thanks for sharing",2,1736736018.0
1hzshvp,m6uus95,That’s an in-memory cache. It won’t persist across runs of the program.,1,1736735495.0
1hzshvp,m6s9f12,I would suggest hashing the source code of the function as well. It can be really frustrating to see that all your results are invalid because you changed some parts of the implementation and forgot to invalidate the cache manually.,77,1736706880.0
1hzshvp,m6wqzxu,"I see in the Github page that it supports unhashable arguments, but I'm curious as to how that works (short of reading the source 😅) 

If e.g. I have two steps - `get_data(start_date : str, end_date : str, seed : int) -> pd.DataFrame` and `train_model(data : pd.DataFrame, **train_kwargs) -> Model)` 

If I run `get_data` once, then `train_model` - both wrapped with `pkld`, I'd expect both to be cached. If I then change the arguments (e.g. the `seed`) for `get_data`, and run it again, I'd expect the subsequent run of `train_model` to invalidate the prior cache.

Does `pkld` do this?",1,1736770855.0
1hzshvp,m6s7hzx,"This is specifically for in-memory caching, which is useful within one run of a program, but not across runs. `pkld` supports in-memory caching too btw!",23,1736706329.0
1hzshvp,m6sbhn5,Weird response. Seems like a valid question.,20,1736707468.0
1hzshvp,m6wt9qc,"joblib.memory also uses the code of the function during hashing, so if you change the function it invalidates the cache entry.",3,1736771908.0
1hzshvp,m6vhvp1,joblib isn't a native Python library.,-1,1736744399.0
1hzshvp,m6ubks6,"What you’re describing is called memoization and yes it’s the same concept.

With pkld, you can memoize function calls across runs of a program by storing outputs on disk, or within the run of a program by storing them in memory (i.e. in a dictionary).",2,1736728987.0
1hzshvp,m6sfqn6,Oh dang that’s a cool idea. Could be accomplished using [inspect](https://docs.python.org/3/library/inspect.html) and hashing the code.,31,1736708681.0
1hzshvp,m6sfubf,But to what level. The function might call other functions/libraries that might change.,33,1736708711.0
1hzshvp,m6vbbaq,source code is not enough. what if a dependency changes that this function is calling?,2,1736741592.0
1hzshvp,m706jgz,"What happens when you make a trivial code change (with zero effects on the function output), but the cache is then invalidated? The point is to cache expensive operations, so you definitely don't want to (redundantly) recompute the function facing such changes.

You can do what [AI2 Tango](https://github.com/allenai/tango) (which is a DAG execution engine / superset of this library) does and keep a `version = ""001""` [flag](https://ai2-tango.readthedocs.io/en/latest/api/components/step.html#tango.step.Step.VERSION). It is hashed along with the arguments, so when the string changes, the previous result is effectively invalidated. A user can increment this when they make meaningful changes to the code. That's the most practical solution I have seen so far.",1,1736809936.0
1hzshvp,m707xkk,"The functionality you are looking for would be supported by a DAG execution engine.

This library would not run `train_model` again if the output of `get_data(seed=0)` is the same as `get_data(seed=1)`.",1,1736810391.0
1hzshvp,m6to898,"I prefer this approach that uses no external dependencies:

    import shelve
    import functools

    def disk_lru_cache(filename, maxsize=128):
        def decorator(func):
            @functools.lru_cache(maxsize)
            @functools.wraps(func)
            def memory_cached(*args, **kwargs):
                # In-memory caching through lru_cache
                return func(*args, **kwargs)

            @functools.wraps(func)
            def disk_cached(*args, **kwargs):
                # Disk-based caching using shelve
                with shelve.open(filename) as db:
                    key = str((func.__name__, args, frozenset(kwargs.items())))
                    if key in db:
                        return db[key]
                    result = memory_cached(*args, **kwargs)
                    db[key] = result
                    return result
            return disk_cached
        return decorator

  
Usage example

    @disk_lru_cache('disk_lru_cache.db')
    def expensive_computation(x):
        print(f""Computing {x}..."")
        return x ** 2

    result1 = expensive_computation(2)
    result2 = expensive_computation(2)
    print(result1, result2)



Advantages:

* Purely using the standard library
* Caches to both memory and disk

It feels very unnecessary to me to add an external dependency, when a small function using the standard library can do both the memory and disk caching.",18,1736721549.0
1hzshvp,m6ubqzi,Nice. It’s a pretty common sense thing to do but doesn’t occur naturally to a lot of new developers. Your basic dictionary goes such a long way in making python code faster 😊,1,1736729042.0
1hzshvp,m6t04kr,"This is where all the caching solutions hit a wall.
In Python and in most langages it's super hard to be sure different parts of the code don't interact with each other.

IMHO a ""perfect"" caching solution would have to be designed at the same time as the language itself because the two are strongly intricated.",22,1736714447.0
1hzshvp,m70xorg,"Yup, I've been looking at SnakeMake and Dagster for stuff like that - I went (very far) down the path of rolling my own but would prefer to use a third party thing that's lighter weight",2,1736818954.0
1hzshvp,m6tewdw,"I agree. For now, the programmer needs to be in charge of what gets cached and when a cache is invalidated.",6,1736718750.0
1hzshvp,m6uo62i,"it's simple enough if you're running containerized - caching lives and dies with the pod, which is always the same code",-1,1736733190.0
1hzshvp,m7190t7,I'm trying to roll my own (will maybe release in 6 months) with the goals of being extremely lightweight and Pythonic ;),1,1736822575.0
1hzshvp,m6vouht,If the code doesn't change indeed it is simple.,2,1736747816.0
1hzshvp,m6w96q9,"If you're running containerized, the caching is already done for you, at the layer-level.  If your cached computation is not its own layer, you're subject to the same challenge as described above.

I suppose a general useful solution exists when the computation is np-complete (or generally fits the pattern of hard to solve, easy to verify correctness)

That's a pretty narrow, clunky use case though",1,1736760222.0
1hzshvp,m71c21w,"Looking forward to it then! Let me know, happy to provide feedback",2,1736823564.0
1hzshvp,m71elmg,"Great, thanks!",1,1736824415.0
1hzn0gg,m6qt2gi,If you are literally *only* interested in image classification I would probably try both CNNs and vision transformers. But transformers more easily mix different modality types which is a big advantage.,175,1736690446.0
1hzn0gg,m6qvmts,"It's still worth looking at ConvNext and ConvNextv2 :

[https://arxiv.org/abs/2201.03545](https://arxiv.org/abs/2201.03545)  
[https://arxiv.org/abs/2301.00808](https://arxiv.org/abs/2301.00808)

If you are in low data regime and you cant have a robust self-supervised pretraining then cnn still beat vit. Also, vit tend to me more memory hungry.

Keep in mind a lot of hybrid architecture exist, that uses both cnn and attention, to get the best of both worlds.

Also, if you need to work with various image resolution/image size, vit is more complicated due to positional encoding things.

For segmentation a Unet is still very competitive.",64,1736691440.0
1hzn0gg,m6qvn9g,Resnets are still preferred if you don't have a large dataset. They also are necessary for low compute/memory devices.,59,1736691445.0
1hzn0gg,m6rpu0u,"Check out [“Computer vision after the victory of data”](https://www.youtube.com/live/a13aqr07tJ4?si=OdDqciK79hz_PReo) - the TL;DR is that architecture hardly matters, while your dataset matters *a lot*. Most sensible algorithms (and even some pretty dumb ones, like nearest neighbor retrieval) work pretty well if you have good data. ",21,1736701294.0
1hzn0gg,m6qy6tu,"I'm not sure if Transformers are the best networks for all the problems. In the problems of academia that analyse some astrophysical  datasets, I found that CNNs beat Transformers by a significant margin. For real world problems, vision transformers are probably beating CNNs.",9,1736692388.0
1hzn0gg,m6qsgii,"Imo yes they are very much preferred, to be more precise, self supervised ViTs like Dino with register tokens are the absolute best to grasp information from images.

Though this doesnt mean that convolutions dont work any more, just for most tasks they are less precise. For medical tasks id probably go with vits from scratch but honestly you should just run some experiments to get a grasp on what suits your case better.",40,1736690204.0
1hzn0gg,m6qzg5d,I work with small datasets and vits don't really converge ,16,1736692842.0
1hzn0gg,m6qznxh,"Not yet I think. There are still a lot of use-cases where transformers overfits and CNN or resnet in this case provide flexibility tweaking to make it work really well.

I was trying meta learning on medical images some time ago and resnet outperformed transformer in all directions. But still TF is the best invention and will continue to be for a coming times",4,1736692919.0
1hzn0gg,m6s7spn,"Battle of the Backbones did a large-scale comparison: https://arxiv.org/pdf/2310.19909

Convnext and swin transformers ended up being around equal",4,1736706413.0
1hzn0gg,m6qwy2h,"This is only tangent but I don't see why, given ViTs need to learn visual inductive biases (edge and color blob detectors, basically), there's not much movement in the direction of pretrained/predefined (Gabor, Sobel filters) convolutional kernels as linear embeddings, and transformers applied to the convolutional feature maps of e.g. ResNets.


You'd probably get smaller and more efficient ViTs at least for low data regimes.",6,1736691935.0
1hzn0gg,m6qs3j9,No,7,1736690061.0
1hzn0gg,m6r1tzi,"If you want multimodal processing, yes.",2,1736693685.0
1hzn0gg,m6runmf,"Some food for thought comes from the domain of computer chess. There, the open source distributed project of Leela Chess Zero uses a form of Transformer. There are specific constraints they are optimizing (eg, inference speed matters a lot) and it is a very specific domain, but also I feel a lot of people collaborate who are aware of the latest developments and will try many things.

Before switching to transformers they were using different ResNets and tried alll kinds of ideas with varying success. I remember SE nets working quite well, for example.

There results with transformers ended up a decent step above all their ResNet attempts in most every metric, by my understanding.

Again, keep in mind the many caveats, but I at least find it interesting.",2,1736702701.0
1hzn0gg,m6uc2qk,"Unless you have a lot of money to spend, nobody is using transformers in production for vision tasks",2,1736729144.0
1hzn0gg,m6r01x2,"Modern state of the art uses transformer backbones with CNN architectures feeding into them typically, but transformers are not only data hungry but also compute hungry. I do not recommend building your own from scratch for a personal project.",1,1736693057.0
1hzn0gg,m6r2vyq,DiT,1,1736694049.0
1hzn0gg,m6r7re7,Maybe his helps : https://lucasb.eyer.be/articles/vit_cnn_speed.html,1,1736695679.0
1hzn0gg,m6rkeim,"VAR, which predicts the next scale rather than next token as in ViT, is supposed to have better inductive bias and arguably the best vison backbone today: https://arxiv.org/abs/2404.02905",1,1736699711.0
1hzn0gg,m6rokt4,"If you’d like a more concrete example of ViT architecture and how you can fine tune it (specifically with mitochondria data), check out this video:

https://youtu.be/83tnWs_YBRQ?si=8IlGkxOY3HhsmPw_

I coincidentally ran through it last night for a use case I was toying around with and he does a great job explaining the Segment Anything model (state of the art), how it works, and how to use its. He also mentions another type of imaging that works really well.

I’d love to be challenged on this as I’m still trying to get a conceptual grasp on this, but it seems like ViT architecture triumphs over traditional CNNs because your able to get more granular with your prediction. You not only get a “does this exist”, but also a granular location via mask output as opposed to the bounding boxes provided by CNNs.",1,1736700930.0
1hzn0gg,m6rs3my,"I always thought it would be more interesting (at least for agents) to instead of dividing the image in different patches based on position, make each patch be centered in the same position but with different resolution, then make the whole thing, e.g. 8x8x3x4 a single token, and have the network output directions to where to look next together with whatever task it is trained on.

This would make it work on all kind of image resolutions and video, without lost of detail, and with a CoT like behavior.",1,1736701956.0
1hzn0gg,m6s5pf8,"They almost won, but for the best of my knowledge they need tricks as local attention to replace conv backbones to get their inductive locality bias...",1,1736705826.0
1hzn0gg,m6sbce6,"mixing convolutions with attention will get you quite far


do not be deluded into thinking it has to be one or the other.",1,1736707428.0
1hzn0gg,m6tdb1e,"Not yet, but only because we don't have the hardware to fit large enought 2d transformers in memory. In a decade: yes.",1,1736718311.0
1hzn0gg,m6un1nf,"There are also effective Vision architectures that use attention, but aren't Transformers, such as SENet or ResNest 

[https://arxiv.org/abs/1709.01507](https://arxiv.org/abs/1709.01507)

[https://arxiv.org/pdf/2004.08955](https://arxiv.org/pdf/2004.08955)

Beyond architecture, what matters is the data your model backbone was pretrained on, since you will presumably fine-tune a pretrained model rather than starting with random network weights",1,1736732803.0
1hzn0gg,m6v8932,yes,1,1736740430.0
1hzn0gg,m6ve92i,Obligatory reading on this topic: [ResNet strikes back: An improved training procedure in timm](https://arxiv.org/abs/2110.00476)(arxiv),1,1736742805.0
1hzn0gg,m6vh328,"Yes, they have.

But, have you explored the tradeoff? Amount of data needed, compute power? The ViT paper does a good job on this.",1,1736744040.0
1hzn0gg,m6x7jwz,"Here's my perspective based on my [PawMatchAI](https://huggingface.co/spaces/DawnC/PawMatchAI) project: 

I've implemented a hybrid architecture using ConvNeXtV2 as the backbone combined with MultiHead Attention layers and morphological feature integration. This combination has proven quite effective for my specific use case.

In 2025, rather than choosing between CNNs or Transformers, the trend is moving towards hybrid architectures that leverage the strengths of both approaches. CNNs excel at efficient local feature extraction, while Transformer components enhance global context understanding making them complementary rather than competing technologies.",1,1736777721.0
1hzn0gg,m6x7pzw,"fwiw transformers are technically a type of cnn

https://www.reddit.com/r/MachineLearning/s/bbXlolQQeq",1,1736777782.0
1hzn0gg,m6yo19x,"Today, I was introduced to resnets. You just have to access the model's last layer, then adjust the input/output features to meet your needs.I liked it.",1,1736793778.0
1hzn0gg,m71pab6,"I would say yes, transformers architectures are more flexible nowadays. However, it's limiting comparing transformers to CNNs bc the cool stuff is on transfer learning side. My advice is Togo to huggingface and explore new models. Over there you have code dataset, pre trained model, example for finetuning. Basically everything you need to start, with integration with colab you don'tneed a gpu either for small medium stuff. I think it never has been so easy to play with ML models.",1,1736828322.0
1hzn0gg,m6r5j0s,"Vision Transformers lol no. Visual Autoregressive Modeling (VAR) hell yes. https://arxiv.org/abs/2404.02905

I am more of a hobbyist signal processing guy, and VAR stands much closer to classical image processing algorithms. As a multiresolution algorithm it is very similar to wavelet and laplacian transforms, and it highly improves on the shared underlying model of prediction and correction. Sure I have some of my ideas on improvement, but it does not fundamentally change the concept.",-1,1736694947.0
1hzn0gg,m6rqkzm,"most likely yes, one of CNN drawbacks is the fact that everything get rescaled to 224x224
[patch n pack navit](https://arxiv.org/abs/2307.06304) alleviates that using transformer magic :)",-7,1736701509.0
1hzn0gg,m6qtwyw,"Cnns are extremely wasteful as you scale the input size - hidden activations just explode and bottleneck everything. ViT token dim is constant across layers, so this is not so much of an issue. I prefer vit’s computationally (also much faster inference typically), but it does take a lot longer to converge. I prefer a model that trains long and is fast at inference so easy choice here for a wide variety of vision taks.",-20,1736690779.0
1hzn0gg,m6r18se,"I wanna start with a simple CV problem like medical image classification (e.g. does this person have diabetic foot ulcer based on this image of their feet?).

We're talking about 1k images of high quality, labeled dataset for train/eval/test. I'm guessing my best approach would be finetuning instead of pretraining from scratch.

Would CNNs make more sense in this case?",24,1736693478.0
1hzn0gg,m6qwipo,Yeah but to be honest attention was used in compute vision for a long time already even before vision transformers became a thing,17,1736691774.0
1hzn0gg,m6rass2,"From my understanding, the reason ViTs require extreme amounts of data is because they lack the inductive bias that are embedded into the CNN concept.   
But if we have a pretrained ViT available, it should already have some good starting point and have learned the bias, so finetuning it on image data, even from a different modality (say pretrained on natural images, finetuned/trained on medical), should still be able to keep up with a CNN or even outperform?",23,1736696679.0
1hzn0gg,m6t98eu,"ViTs are also much, much slower for embedded applications. Mobilenets are still the kings for most embedded applications.",3,1736717111.0
1hzn0gg,m6rv2tb,how do ViT's and classic CNN's compare on compute vs accuracy?,1,1736702824.0
1hzn0gg,m6t5933,Any suggestion on hybrid archs?,1,1736715925.0
1hzn0gg,m6rmp39,Astrophysics is real!,11,1736700386.0
1hzn0gg,m6tbqm1,"""For real world problems""... Why? For real-world problems, people usually use CNNs as far as I know. Usually, shiny solutions work better in an academic setting.",2,1736717861.0
1hzn0gg,m6y2n5v,"I'm interested in those datasets, can you share some",1,1736787593.0
1hzn0gg,m6qzhnc,"In medical imaging (or medical data in general), a common issue when working on real-world problems is low data volume, e.g. you might only be getting data from one facility and looking at very specific conditions. It's been a while since I did medical CV research, but a lot of the time CNNs would end up doing better than the ViTs since we were usually working with small datasets. Just one potential issue in that area though, I agree ViTs are generally the better choice.",16,1736692857.0
1hzn0gg,m6r1j9i,Do you train from scratch or fine-tune an existing backbone?,8,1736693582.0
1hzn0gg,m6r1gid,I see. So looks like knowledge can be easily shared across vision problems compared to language?,1,1736693555.0
1hzn0gg,m6rxc58,"Learning a pretrained feature space is in fact already very common in CV. Consider for example stable diffusion, which leverages a pre-trained CLIP space, and then learns a VAE feature space (conditioned on the CLIP space) in which the main model finally performs its denoising.",2,1736703482.0
1hzn0gg,m6qs8sf,"Thanks for the answer.

If you were to start a new project from scratch to do image classification (medical diagnosis, etc), how would you approach it in terms of architecture and training objective?",5,1736690119.0
1hzn0gg,m6vwor1,"Any UNet-like architecture would yield solid pixel-level classification, it's just that most CNN backbones are pyramidal and feature maps have very low-res wrt the original image",1,1736752209.0
1hzn0gg,m6tklve,"Assuming you are talking about classifiers, we've known how to apply CNNs to arbitrary resolutions since at least 2013 (thanks to global average pooling): https://arxiv.org/abs/1312.4400",1,1736720450.0
1hzn0gg,m6quur3,"I couldn’t disagree more. ViT is wasteful as you scale input size, not CNNs. 
Everything following is also wrong. 
If you don’t have a dataset size that is seriously large, they either don’t even converge or overfit to the data.",29,1736691141.0
1hzn0gg,m6qx53e,"How so?  
Transformers are quadratic in context length and you have to process it all at the same time.",6,1736692008.0
1hzn0gg,m6qx4fu,"If you think you can divide an image of any size to a fixed number of otkens and not see an issue, then sure.

But in general, CNNs complexity scales as the number of pixels, while ViTs' scales as the number of pixels *squared*!",6,1736692001.0
1hzn0gg,m6r0inn,"I have rarely if ever seen anything that I found so contrary to my personal experience, but I am open to hearing why you think this. Are you talking sizes upwards of 2048x1536? 

I have *never* seen a ViT perform inference faster than a CNN, they tend to be order of magnitude of difference in speed, so I genuinely don’t know why you think this, but again, open to hearing more.",2,1736693221.0
1hzn0gg,m6rj3ww,"> ... simple CV problem like medical image classification ... does this person have diabetic foot ulcer ... 1k images ...

Uh, no.   That's not a ""simple"" ""problem"".

No matter which architecture (CNN, ViT, or almost anything else), sure, you'll eventually score OK on 1k images. 

* If the features you're looking for happen to be easily handled with a few convolutions, the CNN will train faster.
* If not (like, say, information from the top-left is relevant for something in the bottom right), a ViT should ultimately surpass the CNN's score, (unless you make some contrived CNN with really wide convolutions).

But with 1k images don't expect it to be actually useful for diagnosis.",45,1736699337.0
1hzn0gg,m6r2tij,"For what it's worth, I was in a similar position (new to medical image classification and trying to figure it out) and I just had to walk the whole path. Started with end-to-end CNNs, then pre-trained resnets, then vision transformers, and just compared them all. If you've never done any vision stuff before those will be useful steps.",30,1736694026.0
1hzn0gg,m6rcrdq,"For this particular example I’d go with CNNs. Transformers are very data hungry and can easily overfit on small datasets. You’re right, pretrained is the way to go for this one. But you should try one without pretraining just to feel the difference. Also, I might consider reducing the resolution of the images.",29,1736697333.0
1hzn0gg,m6qzd7h,Attention in so far as things like the bilateral filter or BM3D sure but content aware weighed averaging is pretty far from current day attention mechanisms. Just from a sophistication point of view. In CNNs there were plenty of papers that used a self attention mechanism before ViT but not really aware of anything pre CNNs that should really be considered attention,11,1736692813.0
1hzn0gg,m6rwi25,"If you are using medical data , for instance volumetric data (3d images) then vit is unlikely to work good i think ?",2,1736703239.0
1hzn0gg,m6uhg5w,"It’s not necessary to use a pre trained vit. From my experience, vit doesn’t need large data at not. What vits need is proper training. A small vit can beat a small cnn on small datasets. For example, vit tiny with 2m parameters can achieve 93+% on cifar 10.",2,1736730899.0
1hzn0gg,m6rey6y,"I see where you’re coming from but transformers don’t eventually “learn inductive bias”. The best way to describe it is to imagine solving a big jigsaw puzzle except you’re blindfolded. You could figure out if 2 pieces are related to one another by holding them but you can’t really say where in the picture they are. You’d need a lot of experience/tries to solve the puzzle right.

Transformers (basic ViTs or DETRs) know how any 2 pieces are related to each other and sometimes to the output but the inductive bias of knowing where they are in the big picture is something they cannot learn by going through a bunch of different puzzles. That’s the lack of inductive bias and the reason they need so much data. Even with pre training, it may not get much easier especially when you don’t have much data (which is the case with OP).",-1,1736698051.0
1hzn0gg,m6tf7ue,"There seem to be an equivalent for transformer with efficientformer (v2)  : [https://arxiv.org/abs/2212.08059](https://arxiv.org/abs/2212.08059)

However I have never used them",1,1736718843.0
1hzn0gg,m6t5tgs,"Depends on the task.

I had work on keypoint matching 2 years ago and LoFTR ( [https://zju3dv.github.io/loftr/](https://zju3dv.github.io/loftr/) ) was surprisingly good.",4,1736716092.0
1hzn0gg,m6rn5h4,My bad. It is.,3,1736700520.0
1hzn0gg,m6wwg5o,We use both. My current model has a CNN backbone followed by a transformer branch,3,1736773330.0
1hzn0gg,m6tcq5k,I'm not sure what the products like GPT or Gemini use. They do process images. I assume they're using transformers. What I've written there is the performance of CNN vs transformer in a few problems.,2,1736718150.0
1hzn0gg,m6ym2o8,These are 1d datasets. Basically some power spectra. I'll try and point you towards some of these datasets in a couple of days.,1,1736793210.0
1hzn0gg,m6tatkc,"What makes ViTs \*generally\* a better choice? There are so many cases where CNN is so lightweight and performs well. Eventually, people use simple things like YOLO...",1,1736717590.0
1hzn0gg,m6r3pzl,"Yes, it is more about the scarcity of data across various niche fields.",1,1736694340.0
1hzn0gg,m6qwcn8,"Depends what you are doing. If it’s just a pet project then try a fun architecture.

If it’s for an actual use case or product then focus on the data and make sure it’s easy to change architectures. The architecture isn’t some magical thing that’s going to make or break an application it’s the data 

Start with CNN’s you will likely get more performance benefits from better data than from the difference between VIT’s and CNN’ s. And CNNs will converge faster and infer faster",11,1736691712.0
1hzn0gg,m6rcqon,"The context length being quadratic is cope for smaller models. In larger models the mlp is more intensive. Additionally, vits don’t even typically have a long sequence length requirement to begin with",-6,1736697327.0
1hzn0gg,m6rckw9,What kind of inference are you performing? I’m working in medical imaging where I cannot even train a cnn of 17m parameters on input of 512x512x512 but fits easily on a 90m vit. 24gbs of vram in this context,0,1736697274.0
1hzn0gg,m6t7wgk,"100%, ML is as much as art as it is a science, which can throw outsiders and newcomers looking for ""the definitive solution"" to a problem. 

If you have a bunch of options before you, and you have the resources to explore all of them, there's not much reason not to try multiple options.

Even if one model massively surpasses the others, at the very least you'll have increased your own competence in the subject by going through the different options.",9,1736716710.0
1hzn0gg,m6s7002,Is there a paper that shows transformers being more data hungry? Would this still hold true for transformers with deformable attention?,4,1736706192.0
1hzn0gg,m6xhn8p,"Makes sense, whatever works works :)",1,1736781225.0
1hzn0gg,m6tlze8,"For multimodal generation models, transformers are probably used most of the time. For a simple classifier or object detection in production? I do not know, I assume CNNs.",3,1736720862.0
1hzn0gg,m6yt6i2,"You're right, ""generally"" was a poor choice of words. I just meant that, assuming you can satisfy the data volume requirements, ViTs will probably score higher than CNNs in the scenario OP was asking about. As you point out, there may be more requirements/desirables to consider than that.",2,1736795275.0
1hzn0gg,m6viwbl,"… are you applying a CNN in 3 dimensions? That would be your problem, if your sliding context window is 3 dimensional and not 2 dimensional. 

I’m not sure why that would affect your scaling worse for a transformer compared to a CNN so the only conclusion I can come to is that you’re running a 2D transformer and comparing it with a 3D CNN? I genuinely can’t think of anything else, the mathematics don’t make sense to me otherwise but I am open to being shown where I am wrong. 

YOLOv8 utilizes 26m parameters and is 14mb on RAM — I cannot imagine why, for the life of me, you need 24gbs of RAM for a model with 17m parameters; the scaling is literally orders of magnitude off, it doesn’t even pass the sniff test, so the only conclusion I can reasonably come to here is that something must be wrong with your CNN.

To answer your other question, I am currently working with both CNNs and ViT foundational models on medium resolution images with low feature dimensionality but decent resolution and multimodal feature capture.",1,1736744870.0
1hzn0gg,m6sapfo,"The (first) paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale plots accuracy with respect to dataset size and shows it starts working well at > imagenet scale data, though there were papers that tried to mitigate this. Since the model has to learn all the relationships from the data instead of having an inductive bias.",17,1736707248.0
1hzn0gg,m6wm6zv,"There is actually, convnext I think does the comparison and shows that transformers scale better, but only after you pass a certain threshold of amount of data.",1,1736768362.0
1hzn0gg,m6zj2wj,Thanks for the answer!,2,1736802807.0
1hzyjw1,m6vdg7s,Is this test time reasoning for Agentic RAG?,4,1736742462.0
1hzyjw1,m6w3vbb,"So, how this basically works, you have the RAG answearing/reasoning part sepparate and then only include the result of that in the actual process so you don't pollute the context?",4,1736756679.0
1hzyjw1,m6tkqgq,I like especially figure 2. Integrating tools and more in the reasoning is definitely something that should be done more!,3,1736720489.0
1hzyjw1,m75je2j,Why is this type of rag retrieval architecture not usually implemented in LLMs for long term memory?,1,1736885080.0
1hzychc,m6yparg,"I would interpret this intuitively as an inductive bias for solutions that are simpler.

An example for the problem of unconditional linear predictive coding (as seen in non-learned models like the FLAC lossless audio codec, et al) is [maximum entropy spectral density estimation](https://en.wikipedia.org/wiki/Maximum_entropy_spectral_estimation). The basic concept is although there are infinitely many valid spectral solutions for a time series, the best prediction tends to be blurriest spectrum that still fits the data constraints.",3,1736794145.0
1hzychc,m74nb1o,"Similar observations have been made experimentally in a more applied setting: using variational inference for classifying radio galaxies. Optimising with a looser PAC-Bayes bound which adds more variance to the evidence lower bound (ELBO) loss seems to improve the generalisation performance (as measured by test accuracy) slightly. 

See Figure 1: [https://arxiv.org/pdf/2311.08243](https://arxiv.org/pdf/2311.08243) and section 7.1 here [https://academic.oup.com/mnras/article/511/3/3722/6517465](https://academic.oup.com/mnras/article/511/3/3722/6517465) for more of the theory behind it.",2,1736875811.0
1hzychc,m74sdko,"thanks! this one should also be relevant: [https://arxiv.org/pdf/1802.04537](https://arxiv.org/pdf/1802.04537)

I was wondering whether the same principle could be applied to other areas/ class of models.",1,1736877270.0
1i0d26d,m6x91qs,"This is a fraud detection problem so I recommend fraud detection techniques. Unsupervised learning can be really powerful. 

Start with PCA and get more advanced. You might find that the clusters pretty neatly represent adults, children, and children pretenders.

Otherwise, it sounds like you are trying to do supervised learning with imbalanced classes and training data noisy enough to potentially drown out the smaller class. If you must do this, I recommend training on customers you've manually age verified. All the parameter tuning in the world won't be worth half as much as higher quality data.",4,1736778265.0
1i0d26d,m6y7jox,What's the downstream risk/cost of misclassification? Is a 10-20% error rate acceptable?,1,1736789028.0
1i0d26d,m6yb4tw,"Unsupervised is probably worth exploring but we have much better infrastructure in place and expertise for supervised, so we‘re wanting to at least try supervised first, unless it truly is a non-starter.

We only have labels for aprox 5000 customers. I suppose semi-supervised could be a good approach? Train a model with those 5000, use it to infer labels for the rest, and train a model on them all?",2,1736790063.0
1i0d26d,m6yclgz,"Honestly as long as it’s far enough above the 9% baseline to justify our time spent on the model, then it‘ll be worth it. Anything above a hit rate of 20% would be sufficient realistically",1,1736790484.0
1i0d26d,m76ukg1,"I'm not following. You have high-quality (perhaps manually verified) labels for 5000 users? If so and you trained on those, it would be a supervised model. There's a real question about whether 5,000 is enough, but it seems like you could get more. I don't understand how that is semi-supervised.

> we have much better infrastructure in place and expertise for supervised

Generally, no projects are truly ""unsupervised."" Unsupervised learning extracts features, and then you decide what to do with them in a supervised manner. Is your infrastructure very abstract, like one of the ML offerings from a big cloud provider? The idea that you don't have the infrastructure to run PCA on this dataset is odd to me. I do a lot of technical mentorship, both at work and through courses I teach, and I have joked a couple of times when people complain about the performance of unsupervised learning that if you're not good at unsupervised, you can't be very good at supervised. You might not be giving yourself enough credit.",1,1736900090.0
1i0d26d,m6yehif,"So it seems like you're aiming for a precision of 20% on the classification task of P(child account | adult account, X). Hopefully that framing helps a bit. If you can get to and measure that precision, then it sounds viable. The issue, as you described, is with actually measuring that stat. 

I'm not sure how to get the data you need, but keep in mind that a flawed model can still be useful as long as the positive predictions have sufficient lift over random guessing. I'd recommend using your model's output to **prioritize** the manual review of accounts. AUC is a helpful stat here because it can be interpreted as the likelihood a TP will have a higher P than a FP.",1,1736791023.0
1i0d26d,m72pv89,"Yeah we‘re struggling with model comparison owing to the lack of labels, because all we can compare is how well the models can detect declared status, not true status. 

We have 5000 accurate labels but that doesn’t seem like enough to draw meaningful conclusions - especially since these aren’t random, but are disproportionately customers to which a similar previous model assigned a high probability. 

Which leaves us with two flawed comparison methods",1,1736848791.0
1hzupbd,m6swhlh,"The reason is GPU parallelism on the NVIDIA cards. Do the same comparison on a mobile phone or microprocessor and watch the transformer break down into its throttled time complexity(not saying ConvNext will run perfectly without any work either).


The blog post mentions the sdpa_kernel, which maps to FlashAttention or to EfficientAttention depending on what backend you decide to use in torch.nn.attention.
Then the code goes to torch.compile -> torch.fx -> torch.inductor which sends it to Triton backend for cuda which tunes the kernels and fuses them almost perfectly as Triton was primarily built for various NVIDIA cards.


ConvNext is a bit special because it has a more complex architecture, it's not the same block stacked 50 times, you have more variation and larger 7x7 kernels which are harder to optimize as you can't break the work down to threads the same way, beyond 3x3 you almost want to put two threads on the job.


I recommend reading the FlashAttention 1 & 2 papers to really understand what kind of black magic they do to fit everything in SRAM, to recompute instead of sending things to memory, to use exponential property of logarithms to batch the softmax WITHOUT syncing in every step, only at the end. It's a work of art that really understands the hardware the compute is happening on.


If ConvNext has a single feature map larger than the SRAM, it's a round-trip to memory which means about 100x slowdown.",18,1736713403.0
1hzupbd,m6ups65,"You also have to consider the scaling of attention vs the FFN. Surprisingly, the FFN dominates until very large resolutions, where these are f16 models. From what I recall, the switchover point should be around 1024x1024, which is the edge of the plot.",5,1736733747.0
1hzupbd,m6x6mzp,"Haven't looked at the code, but if it's the facebook SAM repo, they aren't (can't) leverage SDPA because of how their relative position encoding scheme works. It also can't be converted to Flex Attention.",1,1736777384.0
1hzupbd,m6t3a84,"Thanks. I'm not overly concerned about the convnext - I'd take it with a small grain of salt without looking into it further, e.g. whether the chosen model size is a fair comparator for ViT-B16. In a comment in the code, Lucas says that he compares to that convnext because ""they chose to call it base"", so I think he might be being a bit cheeky.

I'm mainly interested in understanding the differences between the ViT with all global attention and the sam-style one with mostly local window attention. I'd have expected larger differences.

In terms of peak memory, the few global attentions in the sam-style ViT should bring it up to the vanilla ViT, but it seems a bit higher?

In terms of throughput, the sam-style ViT has a minor advantage, but I'd have expected a huge advantage, since most of the attention layers should be much less compute-intensive, especially as res increases?

Maybe the answer is ""read the FlashAttention papers"" which is fair enough, but would take me a bit and most of it might be lost on me. So I wonder if there's an answer to my questions that gives me an intuition for what is happening and why is doesn't align with what I'd expect.",2,1736715353.0
1hzupbd,m6uqb5n,"Huh, that makes sense. I never thought about it that much, but that explains why the throughput advantage of the sam-style vit is marginal at first. Thanks.",2,1736733935.0
1hzupbd,m6xf6r6,"This is a monkey patched version of the timm implementation, so that might not apply here. Interesting though",1,1736780405.0
1hzupbd,m6vv86u,"I see, I think that it's a GPU question.  
To get full understanding you need profile the local attention on the GPU. Perhaps you find that there is synchronization/local blocking dependencies required, or that its a suboptimal division. The number 14 already suggests that threadwarps/performance were not considered during the design of the architecture, you will at least have to mask out the prefetched elements since it's not 16-divisible. There is perhaps local attention window overlap(first 7 blocks used in next 7 blocks) that throttles the I/O. It can be that the local attention is calculated faster, but that the overhead of the memory I/O kills it.


I think the most intuitive understanding is that one of the operations in question has about the highest funding humanity has seen for software, and has been optimized to oblivion. If you step one step outside of the norm, add a layer or change some head dimensions without making an efficient kernel for it, you break the orchestration.",3,1736751342.0
1hzupbd,m6x72aj,"I answered in a top-level comment, but SAM isn't leveraging SDPA/FlashAttention because of the relative position bias they use. I'm using a different model that can run in the ViTDet-style hybrid windowed mode (without the relpos) and it scales much better.",1,1736777543.0
1hzy2ox,m6ud6jn,"NVIDIA makes the hardware, researchers make it slowly work. The more stable the training methods, the more noise we can introduce during the calculation. I vaguely remember the big labs nowadays using fp8 forward/backward, with fp16 accumulation. It went from fp32 (V100) to 16 (A100) to 8 (H100) to 4 (B100) with each NVIDIA generation.",8,1736729483.0
1hzy2ox,m72yxa8,"Apparently it already breaks down in softmax and in SGD, leading to poor training and lack of generalization. https://arxiv.org/abs/2501.04697",2,1736854300.0
1hzy2ox,m6uejqn,And which techniques do you use? Are there any special libraries or tuned algorithms?,1,1736729927.0
1hzy2ox,m6wfovv,What do you mean by accumulation?,1,1736764485.0
1hzy2ox,m73fmtz,Interesting paper. Thanks.,2,1736861867.0
1hzy2ox,m6wqidf,"I haven't trained a production model recently, because LLMs made my job completely different.

[Torch's autocast](https://pytorch.org/docs/stable/amp.html#torch.autocast) is great and trivial to get working. It doesn't support FP8 yet. 

For FP8 I used [NVIDIA's Transformer engine](https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/examples/fp8_primer.html) before, although that was a bit more low-level and harder to get working compared to autocast.


A great example for training stability is Layernorm before or after the residual. Another example is that over the past few months multiple people/organisations where looking at orthogonal weights/updates, and I assume some standard practice will roll out of this.",3,1736770608.0
1hzy2ox,m6wrain,"Keeping the model weights in higher precision, or (I think) the sum part of basic matmul. [NVIDIA's docs about it](https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html).",2,1736770985.0
1hz1l2j,m6lxd4i,"Link to repo: [https://github.com/juraam/snake-diffusion](https://github.com/juraam/snake-diffusion) .  I will appreciate any feedback.

I was inspired after looking at Google's Doom diffusion paper and decided to write my own implementation.",73,1736618240.0
1hz1l2j,m6m2t8s,Throw some logic on there to convert the fuzzy shapes into sharp ones and nobody would know the difference!,42,1736619934.0
1hz1l2j,m6m7nxn,"Bro that's sick a few classmates were doing a presentation of this paper and found it great they talked about lots of issues but the one that interested me was the fps of the game and how much forward you can go till it needs fixing. What about your snake game ? 

(Edit: Sentence structure)",15,1736621440.0
1hz1l2j,m6m0xaq,This is fantastic,21,1736619348.0
1hz1l2j,m6nnd0q,"So sick. But, my guy, you gotta make it work with keyboard inputs haha. Those HTML buttons are making me internally scream.

But forreal though, super cool",6,1736638059.0
1hz1l2j,m6priz3,Is this trained on actual gameplay footage?,2,1736669429.0
1hz1l2j,m6neb5r,"as a *diffusion model?* wut. okay, I kinda get passing the previous actions in as the context, but… well, I guess that probably is enough to infer which end the head is.

diffusion, though. what happens if you cut down the number of steps?

and if it does need that many steps, are higher-order schedulers like [DPM Solver](https://github.com/thu-ml/DPM-Solver-v3) effective on it? Oh, I see your EDM sampler already has some [second-order correction](https://github.com/juraam/snake-diffusion/blob/cbdae93c4bf54ec737286e81ac535b44c073fe92/src/models/gen/edm.py#L126) and you say it beats DDIM. wacky.

It'll be a bit before I get the chance to tinker with it, but it might be interesting to render \`denoised\` at each step (before it's converted to \`x\_next\`) and see how they compare.",2,1736635032.0
1hz1l2j,m6ptcwq,really cool. can you share any details on training and dataset?,1,1736670578.0
1hz1l2j,m6qhdh9,Nice! I wanted to make something like this for Tetris a while back but couldn’t get it to work. I will have a look at your repo for inspiration 😀,1,1736685264.0
1hz1l2j,m6qmsz5,"Really cool stuff – love to see this! Super interested in world models myself and applying them to gaming – pulled together a setup to run all the available diffusion games locally (if you have an NVIDIA GPU), so will add your snake game to the list when I have time over the next few days! We have parameterisation so can allow folks to increase/decrease the steps to tradeoff performance vs quality/consistency.  
  
Github here: [https://github.com/dweam-team/world-arcade](https://github.com/dweam-team/world-arcade)",1,1736687857.0
1hz1l2j,m6y6st5,"Cool stuff, I love it",1,1736788811.0
1hz1l2j,m6z9ei4,Cool,1,1736799999.0
1hz1l2j,m6mdyl3,That is SUPER cool,0,1736623393.0
1hz1l2j,m6odzhv,"cool project, always a big fan of world models! I'm definitely going to have a little tinker with this, thinking of using my smb agent to build a level 1-1 training set.

A few thoughts that popped up going over the project:

 - snake is already a pixel grid game, you could get a much more performant snake engine by training on the resolution of the logic data, then expanding it up using nearest neighbour interpolation or something to make the image size reasonably large. However i'm also wondering if this will make convergence harder, because the extra pixels also give the attention heads more to work with.

 - it could be kind of fun to train it to also try and predict next frame input as well as the next frame. Since you're building a world model anyway, and since snake is such a simple game in terms of optimal play, you can probably get a decent behavioural cloning model for free during training to boostrap an RL agent with. For snake this would mostly be a toy agent, but i'm imagining extending the idea to something like mortal kombat where having a robust RL agent would be great for modelling the opponent behaviour, and taking away the burden of predicting combat logic away from the graphical world model.",20,1736646940.0
1hz1l2j,m6m3jsu,"Haha, true. I think quality of the gif is worse than quality in the runtime, but sure it can be improved too)",18,1736620165.0
1hz1l2j,m72d0k9,"Some next gen snake game using 99% of my GPU, damn modern game optimization!",2,1736840398.0
1hz1l2j,m6m89vh,On rtx 4090 I ran with 1(maximum 2 fps) and it was okay. But I use 10 steps for inferencing edm. I think it needs more training to get the same performance with few steps(like diamond paper).,15,1736621629.0
1hz1l2j,m6m2ng1,Thanks!,5,1736619884.0
1hz1l2j,m6p7te9,"I don’t have gpu and I ran it on Runpod in Jupyter notebook. So I decided to work with widgets to run it, but of course it is a demo version to show how the model works :)",5,1736658535.0
1hz1l2j,m6puo09,"Yep, I trained an agent to play the game and recording snapshots during the training.",3,1736671411.0
1hz1l2j,m6p90dm,"I tested with a few steps and it kept good quality for small frame numbers(in my example with 10 steps it renders ok for 80-100 frames, with 5 steps it renders okay for 10-20 frames maximum). But I think it could be improved with longer training(but I haven’t check it)",1,1736659104.0
1hz1l2j,m6purzw,"Sure, I shared a dataset on hugging face. You can find an instruction how to download it in the repo",3,1736671481.0
1hz1l2j,m6qhxfh,"Thanks! After one month of failures I was thinking about dropping it, but decided to continue working",1,1736685553.0
1hz1l2j,m6qtes2,"Thanks! Cool project. do you use ready projects as diamond to include them in your repo or do you train them from scratch?
Anyway, I have lower fps than in diamond game, but I’m happy if you add my game.",1,1736690581.0
1hz1l2j,m6mf5mp,Thanks!,1,1736623767.0
1hz1l2j,m6nf7fb,I see a resize call there with Resampling.LANCZOS. Try NEAREST instead if you want a chunky pixel look while upscaling.,5,1736635322.0
1hz1l2j,m6ors1z,Make sure to turn on DLSS 3 frame generation for demanding games like Snake 😂,11,1736651860.0
1hz1l2j,m6p12ll,You probably could do a lot better if you distilled the final model to a single step inference thing.,1,1736655533.0
1hz1l2j,m6qyac8,"Yep we're taking the pre-trained models and mapping keyboard controls/creating an easy way to access them all. We've experimented training one model – Yume Nikki: [https://github.com/dweam-team/diamond-yumenikki](https://github.com/dweam-team/diamond-yumenikki) – and planning to do more but it takes time/GPUs as you might understand lol. Haven't delved into your repo yet, but any idea why fps is low relative to the other diamond models? Diamond CS:GO was 381M parameters which explains why it runs pretty slowly but the others are ok.

And that's great, thanks!",1,1736692424.0
1hz1l2j,m6pg1lm,"Yep, it needs much more training in my opinion to make the inference in one step",2,1736662677.0
1hz1l2j,m6pqe6m,"Distillation is a different process.  You’d have to train a second model specifically to the output of many steps of the first model.  You’re training your first model to only undo a single diffusion step so regardless of how long you train it you’ll never be able to run it in one shot.

So if your label for your first model is D^-1( X) your distilled one would be ((D^-1) )^50 (X) so you can then one shot it.  You can look it up, diffusion distillation.",3,1736668728.0
1hz1l2j,m6puizs,"Oh, I see, it makes sense. Thank you for the explanation!",1,1736671323.0
1hzq0ac,m6sll0d,"hi I work at Modal! I think it's going to be tough for you to find a true *serverless* H100 provider that is priced at the $2-3 mark. Altho if you do come across any we would of course like to know ;) any provider promising GPUs that can spin up/down in seconds necessarily has to have an active supply pool of GPUs with <100% utilization since it's hard to forecast demand. therefore you're going to see a price markup otherwise the unit economics don't make sense

on the bright side, H100 prices are likely going to keep going down, plus as platforms such as Modal grow their user base, demand pooling will result in better supply utilization and therefore lower markups over time",17,1736710343.0
1hzq0ac,m6sg9pw,"Perhaps you can look into [https://ori.co](https://ori.co) ... there's a Serverless Kubernetes service that allows you to scale to zero

(Disclaimer: I work for Ori)",6,1736708832.0
1hzq0ac,m6rnsr5,Paperspace maybe?,4,1736700704.0
1hzq0ac,m6rj2q8,Comment for the algo,3,1736699327.0
1hzq0ac,m6zx17e,"You should give Shadeform a try. It's a GPU marketplace built on a ton of different high quality providers like Paperspace, Lambda, Scaleway, etc.

Our current lowest priced 8xH100 instances are $15.60 ($1.95/GPU) from Hyperstack.

Everything is on-demand, so quick spin up and down, plus you can set spend or duration thresholds to auto-delete your instances.

You can configure docker images during the launch process, as well as volumes, startup scripts, etc.

Happy to answer any questions for you!",1,1736806928.0
1hzq0ac,m6v51i5,"Yeah to be clear I do not think 2x price is crazy. I do already save money by using modal, because I pay for 3x less total gpu hours.",8,1736739226.0
1hzq0ac,m6v2e21,Hey $3.80/h100/hour is pretty good!,1,1736738251.0
1hzq0ac,m71x8ia,That's the lowest price I've seen anywhere. I assume we're enjoying a VC subsidy?,2,1736831775.0
1hzq0ac,m72jw0v,"I need to run time triggered Python functions (15-20 times a day) with any cheap GPU, would your service be of any use to me?",1,1736844806.0
1hzq0ac,m722oc0,"Yeah it’s a pretty insane price point. I’d have to ask but I’d assume so.

Our next cheapest 8xH100 is $19.57/hr ($2.44/GPU) from Denvr",1,1736834461.0
1hzq0ac,m73xc0g,"Yeah definitely. In addition to our console, we have an API that mirrors its functionality. I’d suggest building around that. We have API calls to view all of the instances in the marketplace, and launch whatever you’d like.

You could technically build a function to view available instances, select the cheapest one, and deploy with a python startup script at a specific time.

Check out our [docs](https://docs.shadeform.ai/getting-started/introduction) for more info",1,1736868030.0
1hzsm1q,m6svzwx,"> I am having trouble grokking its essence

From what I can tell its relatively simple.
Instead of outright deleting weights/channels/or layers and just leaving it like that, they instead try to move important weights (of a layer they want to remove) into other (nearby) layers.

The advantage is you can identify the ""most useless"" neurons/weights and replace them with more important things from other layers.",3,1736713264.0
1hzsm1q,m6t2u0y,"to add to this, the MI metric they use is what 'indicates' which parts are informative and which are not .

also group-level in this context just means that pruning/recycling happens within close neighbour blocks. it just doesnt make sense to fuse blocks that are distant in the architecture.",3,1736715223.0
1hzsm1q,m6vj1rn,Did they fuse through some hardcore kernel implementation? Or is everything implemented in pytorch?,1,1736744939.0
1hze3vs,m6p7ylp,Project repo on GitHub: https://github.com/abhisheknair10/Llama3.cu,6,1736658604.0
1hze3vs,m6p8fik,Looks neat after a quick glance. Could learn a few things from this. What inspired you to do this?,3,1736658827.0
1hze3vs,m6t8e6u,Neat! What does inference performance look like? Curious how well it fares compared to other implementations and if the CUDA-only implementation offers a big performance benefit.,2,1736716858.0
1hze3vs,m75y1ny,Great job! What were some interesting things that you learned from this project?,1,1736889882.0
1hze3vs,m6pacmu,"Thanks!

With regard to inspiration, I mainly wanted to learn about the CUDA programming model. I had done some tinkering with getting llama.cpp and ollama working locally, and found it cool to be able to run LLMs without data-centre grade compute. I’ve found compute optimizations problems very interesting too.

I have a ML background (fine-tuning and inference), so it seemed like a pretty great project to apply my existing knowledge of ML to a compute optimization problem.",3,1736659758.0
1hze3vs,m6tdu3a,"With regard to performance, I was able to achieve ~10 tok/sec on an A10 GPU. The implementation uses CUDA cores instead of Tensor cores. I’ve heard other implementations are able to achieve north of 30-40 tok/sec by utilizing Tensor cores and KV caching (which I also don’t use).

So clearly not as performant as if I was using cuBLAS functions. Writing custom kernels that can compete with cuBLAS isn’t straightforward since Nvidia engineers have a lot more information about the hardware architecture. Additionally, I’m no expert in parallel computation.

The point of this project was to not necessarily create a commercial product that competes with llama.cpp, etc, but more of an educational/hobby project that performs, at least, reasonably well.

I’ve got another deep learning project on the way which is training and inferencing occupancy networks for 3D reconstruction. I plan on using optimized cuBLAS kernels for that, since the aim is to create a performant open source tool. I wouldn’t be able to have a holistic view of what happens in those cuBLAS kernel calls if I didn’t manually write my own kernels in Llama3.cu.",1,1736718457.0
1hz1xks,m6m3w9o,"1. You need to calculate gradients for W, but not because of the reason you state. AB do not depend on W at all and they don't need W gradients at all. You need to calculate the gradients for W because they are required for further backpropagation. 

The memory saving actually comes from not having to store optimizer states for W.

2. Yeah, after LoRa you update W by adding AB to it and the model no longer uses those matrices. This is done only once after the training is finished.",55,1736620272.0
1hz1xks,m6m72eu,"I believe the main observation comes from the fact that for any parameter matrix W, represented as
    W = W0+AB,
you never need to compute W explicitly. Any linear layer upon receiving an input x, computes:
    W x = (W0 + AB)x = W0 x + A(B x)

So your only operations are multiplying a vector by B, and then by A. You never need to form the product AB.

I don't know if that's how it is typically implemented, but it shows that the computational graph doesn't have to contain the full product AB anywhere.",10,1736621253.0
1hz1xks,m6o9f8c,">In order to compute dA and dB, don't you first need to compute dW then propagate them to dA and dB?

No, gradients are calculated analytically. In other words, you directly calculate dA from a formula.",1,1736645390.0
1hz1xks,m6q4hi7,"Just pitching a random idea, correct me if I'm wrong. In training with AdamW, the typical VRAM needed for xB param model is 6x gigabytes. In Lora's paper, they say that trainable parameter is 10000x less, but GPU usage is only 3x less. This implies that not all of the 6x gigabytes are reduced by Lora. I think it's the momentum and stuff that's been saved by Lora, not the gradient itself.",1,1736677632.0
1hz1xks,m6rrekz,"W=AB
nxn=(nxr)x(rxn)
If r<<n, you only need to store the gradient of 2rn, which is << nn",1,1736701750.0
1hz1xks,m6m4ay1,">At which point don't you need as much vram as required for computing dW?

This is true, however you don't need to store and compute dW for all the layers at the same time. The optimizer states for each layer's W can be subsequently discarded.",0,1736620398.0
1hz1xks,m6mdkti,">  The memory saving actually comes from not having to store optimizer states for W.  

Would this imply that if you're not using a complicated optimizer like Adam, but are doing Vanilla SGD then your memory gain would actually not be substantial? 

OR would it still be substantial, because while you compute dW you can discard it after computation and propagating the gradient, because you're not actually going to use them for a weight update?",8,1736623274.0
1hz1xks,m6m4x0y,"Hmmm but like the aim of A and B is to compute dW right? Where updated weight is W = W' + dW. And dW= AB. 
So to compute dA you need dL/dA = dL/dW dW/dA.

Since you have computed dL/dW, which essentially have the same parameter size as just computing the back propagation for W', I don't get how it stores less numbers than just full fine tuning.

Maybe my understanding of optimized parameter is incorrect? Is there more than a gradient information in the optimizer? Thanks",1,1736620587.0
1hz1xks,m6m58gs,What are stored in the optimizer states? You mean first and second moment vectors m and v in the Adam optimizer?,1,1736620686.0
1hz1xks,m6o9yg9,"Many say yes many say no, I don't know which is right.

But the shape of ABx is the same as Wx, so it think even if you did not compute dW directly, you would still need to effectively compute the same number of numbers",1,1736645569.0
1hz1xks,m6t8ete,"So even though people are talking about AdamW parameters, and I'm sure they can have a significant affect, maybe that's not the only efficiency gain?

As given L(h) = Wx +ABx, you don't actually need to calculate dL/dW because it's frozen and W do not depend on A or B.
So you only need to compute dL/dA and dL/dB = dL/dA dA/dB and dL/dA and dL/dB is a lot smaller than dL/dW?
So that's where the chunk of compute efficiency come from if I understand correctly?",1,1736716863.0
1hz1xks,m6m5z7w,"Hmmm... Thanks for the response
Isn't this hypothetically true for a normal fine tuning as well?

Can't you discard the weights of final layers after updating their weight and propagating their gradient?
I.e. if you had three layers, W1, W2 and W3, can't you remove dL/dW3 after computing W3 = W' + dW3 * a and dL/dW2 = dL/dW3 * dW3/dW2",1,1736620916.0
1hz1xks,m6nf7yj,"Nah. The gradients of the two Lora low rank matrices are simply much smaller than the dense weight gradient (your or statement). During back prop, you can delete all gradients of weights that are not updated, so your overall memory consumption goes down",7,1736635327.0
1hz1xks,m6ngup2,"in vanilla SGD, the optimizer is stateless and you can update the parameters pretty much in place. LoRA wouldn't help at all anymore.",-3,1736635866.0
1hz1xks,m6m7cpf,"AB is not used to compute dW in the sense you think. AB is essentially where you accumulate the change that you want to apply to W over the entire training. So you use h = WX + ABX during training and then after you finish your training you do W += AB.

As far as gradients only go, you need to calculate them for all the matrices W, A and B during backprop, so you do not get any memory savings there. But Adam also calculates two additional quantities for each parameter. Those are calculated only for A and B, as W is frozen and it does not need them. This effectively leads to 66% memory reduction, as the size of A and B is usually very small.",14,1736621342.0
1hz1xks,m6m6isz,"From the Lora Paper:

>>> Practical Benefits and Limitations. The most significant benefit comes from the reduction in
memory and storage usage. For a large Transformer trained with Adam, we reduce that VRAM
usage by up to 2/3 if r ≪ d_model as we do not need to store the optimizer states for the frozen
parameters.

Yeah I believe it’s the first and second moment vectors in Adam that don’t need to be stored for W.",3,1736621084.0
1hz1xks,m6m6e57,Yes,1,1736621044.0
1hz1xks,m6oac7u,"> I don't know which is right.

It's not a mystery. Just check out the code that implements it. PyTorch is open source.

>you would still need to effectively compute the same number of numbers

Mostly, yes. Except for a simple weight multiplication, the derivative is 1, a null operation.",1,1736645700.0
1hz1xks,m6m7tg8,"That's a good question, I believe the optimizer requires information about all the parameters because the two passes are separated into forward and then backwards. In other words, in the forward pass, gradients accumulate and in a full fine tune, each layer's dW is accumulated. There are therefore n dW gradients that are all passed to the backward pass.

Instead, under LoRA, the dW for each layer can be discarded because we save the dA and dB information instead which is much smaller. dA and dB are instead accumulated for the backwards pass.

Crucially, because the gradients for subsequent layers depend on the prior layers, there is a ""stack"" of n gradients that is unavoidable even if you could figure out how to do the backward pass simultaneously with the forward pass.

This additional information is why training in general takes more memory: if we could discard the gradients like you're thinking then it would be possible to train with marginal additional memory as well.",1,1736621487.0
1hz1xks,m6ma9g0,"Adam needs to keep weights for the momentum, which from memory is 2 params per param trained",1,1736622243.0
1hz1xks,m6rmfj1,Stored activations take up the majority of vram. Adam sgd whatever doesn’t matter they all need those.,0,1736700306.0
1hz1xks,m6m8pj3,"This is very clear to me, thank you very much.

I feel like doing h=WX+ABX is a quite a large compute overhead, more than twice as slow as just doing WX?

Is the idea the lack of need for computing optimization step with Adam for W makes up for this overhead? Is computing update step from the gradients really that computationally expensive?",4,1736621764.0
1hz1xks,m6rygcs,"You need the stored activations in LoRA too (except for rematerialisation and other tricks). So with vanilla, those activations are the only things you need. With Adam, you need 3 times that space, but you don't need 3 times the space when you LoRA under Adam.",1,1736703803.0
1hz1xks,m6masqu,"I would say it’s less than X2, as AB is a rather small matrix. Other then that, LORA is for memory reduction, not compute.",8,1736622414.0
1hz1xks,m6mb1tj,A and B are much smaller matrices than W so BX and then A(BX) are two much faster operations,4,1736622493.0
1hz1xks,m6mdojq,A and B are much smaller than W but AB is the same size as W though. This ABX is as large as WX?,1,1736623306.0
1hz1xks,m6mesno,"yes, but WX and ABX are both vectors the size of the hidden layer. AB would be large but you don't need AB",3,1736623655.0
1hz1xks,m6mhiro,"Oh so A(Bx) is much faster than (AB)x or Wx.
I didn't realise lol",4,1736624510.0
1hz1xks,m6p0819,"Yes, exactly.  This is why it matters that it's low rank: a low rank matrix is factored as a product to of two much smaller matrices.  If you multiply them out you get a whole dense matrix again, so you don't multiply them out.  Instead, you associate it the other way, applying each half in turn to the input vector. This applies to both training (backprop) and inference (forward only, so cheaper but if your model is successful, much more frequent).",2,1736655175.0
1hz1xks,m6t89y4,"So even though people are talking about AdamW parameters, and I'm sure they can have a significant affect, maybe that's not the only efficiency gain?

As given L(h) = Wx +ABx, you don't actually need to calculate dL/dW because it's frozen and W do not depend on A or B.
So you only need to compute dL/dA and dL/dB = dL/dA dA/dB and dL/dA and dL/dB is a lot smaller than dL/dW?
So that's where the chunk of compute efficiency come from if I understand correctly?",1,1736716822.0
1hz1xks,m6tki7o,"I'm honestly a lot less familiar with the implications for backprop since it's not something I regularly think about. But yes, I think that's basically right.  The derivative of A(Bx) requires computing only the derivative and values of B at x, and the derivative of A at Bx.  All of these are computationally much, much smaller than the derivative of W at x.  And since you aren't tuning W when training a LORA, its relevant partial derivatives are all zero.",2,1736720419.0
1hz4gdy,m6molds,"I probably would struggle to find the algorithm, too 😅 What you're building seems cool because it will be a long time, if ever, that LLMs with the current architecture will be able to solve it. You need a search process of some kind. ",3,1736626788.0
1hz4gdy,m6mly63,"OpenSource GitHub repo (MIT): [https://github.com/Habitante/gta-benchmark](https://github.com/Habitante/gta-benchmark)

Live Demo (Early Dev Test): [http://138.197.66.242:5000/](http://138.197.66.242:5000/)",2,1736625933.0
1hz4gdy,m6mqztu,This is pretty cool,2,1736627576.0
1hz4gdy,m6nr0y6,Cool! How do humans do on this benchmark?,2,1736639306.0
1hz4gdy,m6oistq,"Cool idea! This sounds like a harder version of ARC-AGI, not surprising models are doing poorly. You said you created several levels of difficulty and the easiest level had ^=0x55? I would dial that back a lot. How many examples does each problem have? Would be interesting to give the LLMs ability to call the function on new inputs and watch how they learn",2,1736648619.0
1hz4gdy,m6t5lrr,"We've done something similar to this at OpenAI -- it's called function deduction, see it here:

https://github.com/openai/evals/blob/main/evals/elsuite/function_deduction/README.md",2,1736716029.0
1hz4gdy,m6yznyz,"This sounds quite similar to ARC-AGI. Although, as it sounds, you'd want it to only see one example, instead of 3 (I believe) examples that the model sees now.


With natural language you lose some universality to your approach.",1,1736797155.0
1hz4gdy,m6mzr1x,"Thanks, yes, it's closer to cryptography. A search process won't take you there, computers are arlready good at searching. You need reasoning. The input data has been designed to be as helpful as possible to the model/person investigating. But, yeah, there's almost no limit to how hard a problem can get. Thats the beauty of it.",2,1736630393.0
1hz4gdy,m6q6k4q,"\[Simple concept diagram\] (https://github.com/Habitante/gta-benchmark/raw/master/docs/images/concept.png)

""Here’s your input, here’s the output, guess how we got from one to the other. Write a 5-line Python function.""",1,1736678928.0
1hz4gdy,m6pkgu0,"I could solve probably up to problems on Level 3, just from the data. But I'm not an expert cryptographer, just a cryptography aficionado. But yeah ... this idea has been designed after thinking about this problem: ¿How are we going to test models for super human intelligence, when they surpass us? This could be one of the ways.",2,1736665143.0
1hz4gdy,m6pk3a0,"Thanks. I currently have 8 levels, with 5 examples each. Levels 1 and 2 start with single byte ops (no state, no window, no dependencies on previous values). Level 8 grows to small < 10 line functions. Very hard for models, yet it would be classified as a ""dummy"" function by any encryption enthusiast.   
But it could go way harder. Do you mean like expose an API?",1,1736664929.0
1hz4gdy,m6vh5x1,"Oh great!, of course. I feel stupid now. Well, I'm available if you need more brain tissue.",1,1736744076.0
1hz4gdy,m6ncdm0,"In my head reasoning involves searching a graph of candidate functions and a heuristic to search it. Then some feedback mechanism whereby you refine your heuristic based on the results before conducting another search.

Like if you're a cryptographer your search space would include cryptographic functions and heuristic could include synthesized pattern matching that helps you recognize what functions might be good candidates.",3,1736634432.0
1hz4gdy,m6rucm8,"During eval when you allow the model to guess the hidden function you could also give it the option to gather more info by specifying new inputs, and you would feed in the corresponding outputs. That should give you some clues as to why the models are struggling, maybe you need to feed in more initial examples / problem, or there’s some domain level misunderstanding that can be addressed in your prompt",2,1736702614.0
1hz4gdy,m6pl12l,"But there's no standard cryptography function anywhere. So there's no library of cryptographic functions you can refer to. This is just random code doing random things. Levels gate the code length, number of operations, windows size, num passes through data, etc. But a nice thing is that code, while keeping complexity, could change daily. So the answers to the problems couldn't ever be learnt. You need to understand what you can do in a program, to start. And then look at the data, think, and start formulating hypothesis.",0,1736665469.0
1hz4gdy,m6rxux9,"Yeah, cool idea. I haven't automated eval yet, you have to copy-paste the prompt and then the solution. Automation presents some challenges, as they won't just work on it and give you the function. As they often struggle to see to make the right deductions, Gemini or GPT 4o will tend to give you any crap (like an unrelated function), o1 likes writting whole books, and Sonet is like ""This looks like an interesting challenge! We can work this out together. Where would you like me to start?"" ;)",1,1736703632.0
1hz541n,m6siuzd,"IMO, if you're doing research, you're better off implementing your own components.",3,1736709569.0
1hz541n,m6pycl4,"Huggingface's diffusers library for sure.  

You can start with [pretrained models](https://huggingface.co/google/ddpm-cifar10-32), then it is possible to swap out things like samplers or fine-tune on you own data.",1,1736673747.0
1hz541n,m6yo0cv,"+1 for this. Huggingface's diffusers isn't a bad place to start, especially if you're not very familiar with diffusion models, but if you're experimenting you'll want to implement your own components as you build familiarity.",1,1736793771.0
1hz2dfp,m6ms5mx,"Seems good for TPUs, the GPU branch is a few months old and maintained by NVIDIA, not much in terms of docs.",1,1736627954.0
1hz2dfp,m6zwo3z,"It's a mix of a job scheduler, launcher, hyperparameter config, and model sharding. Seems like it does too much tbh, but probably works well for Google internal workloads. 

Since PyTorch doesn't make any major assumptions, it has a cleaner separation of concerns imo.",1,1736806816.0
1hzpqgl,m6reoc2,"Your pipeline isn't utilizing the card, there's a bottleneck somewhere else. Perhaps a data loader or something.",13,1736697960.0
1hzpqgl,m6re2hm,"Perhaps you are not throwing enough load on it. Similar to gaming, some games don't stretch a GPU's capcity as much as others. 

Also, I assume with performance you mean time-to-compute?",3,1736697759.0
1hzpqgl,m6sh2ku,"> I've noticed that for all my AI experiments the fans never go above 30% and the GPU temperature is also around 50 - 55°C.

So if your GPU isn't being fully utilized, how will overclocking change anything? you can definitely get more juice from the gpu. 

You're probably not keeping the gpu ""busy"" or ""fed""

you need to be 

1. preparing data WHILE the gpu is processing a batch - dont wait for the GPU to be done, prepare more data, send data.

2. play with batch sizes

3. optimize your dataloading so it happens faster

4. send less data to the gpu - sometimes you can compress or otherwise strip down the amount of data sent per batch. 

5. train models in parallel

6. benchmark! figure out where exactly the pipeline is stalling by taking MEASUREMENTS. 

7. if you're loading image or video data off of hard drives, you might need faster / more hard storage

its difficult work but its ultimately worth it.",1,1736709055.0
1hzpqgl,m6wun5d,"No don't overclock your GPU you won't get much of a bump. Sounds like your issue is how your setting your batch parameters..  if you're not loading enough data and the card is under utilized it's probably spending time reading and writing things to memory.. the less you do of that the higher utilization your card will have... 

The arti is finding the sweet spot that doesn't go out of memory, keeps the training stable.. that is something you need to find out about through experimentation..",1,1736772534.0
1hzpqgl,m6rgfsh,This. Use nvidia-smi to monitor GPU utilisation,3,1736698533.0
1hzpqgl,m6rg11y,"Hmm. I’m mostly using existing codebase and to be specific I was fine tuning videoMAE model on UCF101 dataset. Using Vit-B model. It does occupy around 20GB VRAM. Here is the metric plot for few hours of training 
https://imgur.com/a/oqQCgIR

It’s similar over extended time too. Maybe the GPU does not have heavy load or heavy utilisation so the default settings (which I’m using) keeps fan at 30% always.",2,1736698407.0
1hzpqgl,m6rg8q4,"Could be the reason.. need to figure out how to throw more load at it so fan spins higher than 30% 🤣

Yeah by performance I was thinking about faster epoch runs, or FLOPS. Like fine tuning or training either resnet50 or ViTB to be done at faster rate.",1,1736698472.0
1hzpqgl,m6w5nml,"Also see if you can do preprocessing and augmentation on the GPU. For image processing, the Kornia library can do augmentations on the GPU. If your samples are large and you always crop a large part out during training, then it might be worth it to precompute and store the cropped data so it loads faster.

Edit: it looks like you are doing video processing. Videos are just inherently slow to load. Increasing the number of workers of the dataloader might help.",2,1736757860.0
1hzpqgl,m6rmaz5,"That says you're at like 80% utilization. You might be able to get more but you need to be comfortable tearing into the code base, which I'm guessing by your post that you're not going to do.",6,1736700268.0
1hzpqgl,m6seym7,How do you go about learning the methods to increase utilisation? Also have you got any tips for optimising code to do so?,1,1736708455.0
1hzpqgl,m6soiag,Let me know as well if you figure it out.,1,1736711170.0
1hznd9q,m6r33i1,"If you don't need a conversational component, you don't have to use an LLM. With the limited information you have given in your post, I would recommend trying out a summarization model, keyphrase extraction, and an OCR model as a pipeline for this. When using the OpenAI API keep in mind you're paying for both inference costs and IP as the models aren't open sourced. My assumption is that the local model would be the cheapest. With the local model and the cloud provider you have more versatility regarding the model choice, inference optimization, etc.",2,1736694123.0
1hznbmr,m6qyh1d,"That is not why we use RLHF (reinforcement learning from human feedback). We use it in the absence of being able to define a loss or reward function, not because the function isn't differentiable. 

Fine-tuning for tasks is different than pre-training.",23,1736692491.0
1hznbmr,m6r3rf2,"I'm not sure your question quite makes sense. 

RLHF - A framework for learning in the absence of an easily constructed reward function. You typically learn the reward function from pairs of examples and then fine tune a model to maximise the reward.

Gumbel Softmax - Is a continuous distribution which approximates samples from a categorical distribution.

One is a framework the other a distribution, we can't use one instead of the other as they're fundamentally different things.  
  
You might find this paper interesting: [https://arxiv.org/pdf/2305.18290v2](https://arxiv.org/pdf/2305.18290v2) as this avoids the RL part of RLHF and fine tunes the LLM through supervised learning instead. Do let me know if I misunderstood your question.",3,1736694354.0
1hznbmr,m6r4jy2,"For simply predicting the next token based on previous ones to model the texts from the training data, you don't need RLHF. You don't even need Gumbel softmax, you just use regular softmax to get the probabilities of each token and use gradient descent to minimize the difference between this and the 1-hot encoding of the actual token.

RLHF is for a different task, instead of trying to get the model to emulate the text patterns in the large corpus of data it was trained on, you are trying to train it to respond in a way that humans like. This doesn't depend purely on the next token, it depends on ALL the tokens that are generated (e.g. ""and yet, he was here."" should be equally valid to ""and yet, here he was."") and because you can't really have a set of hard and fast rules for what a human would prefer, you have to use reinforcement learning.",2,1736694623.0
1hznbmr,m6qxkb7,what overhead would it remove,1,1736692162.0
1hznbmr,m6qyu5r,"I like this question, though it's not actually clear to me how you'd do preference based fine tuning via Gumbel Softmax. I'll preface by saying I'm not an LLM researcher, so take this with a grain of salt. 

Most importantly, where would you get the supervision from? Once you have a target that you can optimize towards via Gumbel softmax, wouldn't you just do SFT? 
Where RLHF fits in, as I see it, is that you can use the fairly ""weak"" preference data (assigning a bit to pairs of sequences) to infer a reward model. But this reward model doesn't tell you the desired output for any arbitrary prompt, it's constructed only by binary feedback between pairs of completions from some subset of prompts. So when fine-tuning, I don't see where you'd get the signal to correct your logits directly, because you don't actually have examples of what good completions are outside your preference dataset. Instead you use RL to optimize the amount of reward accumulated.

Edit: sorry, I think I get your suggestion now. You want to use reparameterization to sample a sequence, and then directly optimize the parameters via gradient ascent on the reward function? I guess this is plausible. However if your context length is long, wouldn't you have trouble computing gradients through the autoregressive samples (ie, vanishing gradients and stuff)?",-1,1736692622.0
1hznbmr,m6tgtec,"OP is asking why we don’t replace the softmax in an LLM with a grumble softmax, use the negative reward model output as a loss, and optimize with SGD through the grumble softmax instead of using RL.

I don’t know the answer but it seems like a reasonable question to have tbh.",0,1736719308.0
1hznbmr,m6qyxhz,"Well, the reward function is a separate entity and is trained separately. We could sample tokens, give it to the reward function and the generate a reward for it . Then we would maximize the reward through gradient ascent (or descent). 

We have indeed a loss function I would say ( given the trained reward model of RLHF)",-6,1736692656.0
1hznbmr,m6r6nl4,"Yeah my question is super off haha

I wrote it in a rush.  Better phrasing would be why we need RL when we also can use SFT because of differentiable sampled tokens.

I know the DPO paper, I think it also demonstrates why RL is used: Because the sampled tokens are not differentiable traditionally (using top-k for example).

  
Gumbel softmax would allow for a differentiable sampling of tokens and we could use a separate reward model (like the ones used in RLHF based on Bradley-Terry model)  that quantifies the response of the model (sequence of sampled tokens). The reward model quantification would be a scalar that can be backpropagated and maximized.

I made it a bit clearer in that answer here:

[https://www.reddit.com/r/MachineLearning/comments/1hznbmr/comment/m6r3dub/?utm\_source=share&utm\_medium=web3x&utm\_name=web3xcss&utm\_term=1&utm\_content=share\_button](https://www.reddit.com/r/MachineLearning/comments/1hznbmr/comment/m6r3dub/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)

  
Thanks for your response :)",-2,1736695316.0
1hznbmr,m6r55hs,This makes perfect sense. Thank you! We need the RL to model it a sequential task as the model only predicts one token at a time :),3,1736694823.0
1hznbmr,m6r5s3g,"But wait, considering my response here: [https://www.reddit.com/r/MachineLearning/comments/1hznbmr/comment/m6r3dub/?utm\_source=share&utm\_medium=web3x&utm\_name=web3xcss&utm\_term=1&utm\_content=share\_button](https://www.reddit.com/r/MachineLearning/comments/1hznbmr/comment/m6r3dub/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)

We could generate tokens until an EOS token. Each generated token is one forward pass through the model and the reward is based on the generated sequence of tokens until the EOS. This should still be differentiable and we could directly optimize it",1,1736695032.0
1hznbmr,m6qxtzv,The whole RL part. Having Gumbel softmax sampling would allow for a smooth gradient flow and we could optimize the model directly to output sentences that generate  high rewards without the need for PPO,-4,1736692259.0
1hznbmr,m6r3dub,"Thanks for your reply. We could use the trained reward model (like in RLHF with a Bradley Terry model) to generate target signals from my perspective.  The reward model does output a ""preference"" value that is a real number and can be mapped back to categorical preference order through the Bradley-Terry model.  

We could use another pretrained LLM to be fine-tuned on these preference values. I mean, so far the setup would be identical to the RLHF approach. But instead of using non-differentiable sampling methods like top-k we would use the Gumbel softmax parameterization to get differentiable outputs. 

These outputs can be fed to the reward model which outputs a differentiable preference value based on the sampled tokens. This could easily be backpropagated to tune the token generation to align with preferences given by the reward model.

I am happy to be told where I am missing something :)",1,1736694223.0
1hznbmr,m6r04i9,"I don't think your response makes sense. I kind of anticipated that based on the question (misspelled title, asking why we can't just use a softmax that works with categoricals instead of a reward model for fine-tuning which is a non sequitur). It seems like reading a few Wikipedia articles or watching some YouTube videos (perhaps with an AI chat open to help) could probably do more to fill in gaps than a discussion with a disinterested party.

Put another way: as far as I can tell, you're the one that is lost, I'm not looking to be reeducated or debated when I was trying to quickly help and move on.",14,1736693082.0
1hznbmr,m6r84g7,"Good point, however, the main problem is imagine a 500 token response that you have to classify. That means your final token depends on the previous 500 tokens generated, meaning training would take 500x the time/VRAM. At that point, the usefulness of parralelizability that transformers have is moot.",0,1736695797.0
1hznbmr,m6ramfr,I have no idea why you're getting so heavily downvoted. I think you're hinting at something very interesting and I've wondered about exploring it myself.,1,1736696619.0
1hznbmr,m6r4zyp,"I wrote that in a rush :) Below is a more pronounced answer: [https://www.reddit.com/r/MachineLearning/comments/1hznbmr/comment/m6r3dub/?utm\_source=share&utm\_medium=web3x&utm\_name=web3xcss&utm\_term=1&utm\_content=share\_button](https://www.reddit.com/r/MachineLearning/comments/1hznbmr/comment/m6r3dub/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)

I did not mean to educate you :D I just reasoned why I believe that we have a loss function. If you feel attacked by that discussion I do not want to force you into something haha

I would also argue , that the non-differentiability is the main reason for the RL part (this is basically the reason why we have  DPO ). But again, no desire to educate you, just happy to have a open dicussion :)

[https://x.com/JiachenLi11/status/1821315299670684048](https://x.com/JiachenLi11/status/1821315299670684048)",-15,1736694772.0
1hznbmr,m6r96vt,"That is true. But in PPO, wouldn't we also be required to run it sequentially? I mean the parallelizability comes only in handy when we do actual language modeling (next token prediction) with teacher forcing. 

In RLHF when using PPO we generate tokens sequentially with sparse rewards and get the reward after the EOS token through our reward model.

Here is also an interesting post arguing that the important part is not the RL but the HF, i.e. the reward model.

[https://x.com/JiachenLi11/status/1821315299670684048](https://x.com/JiachenLi11/status/1821315299670684048)",1,1736696144.0
1hznbmr,m6rbih4,"Haha me neither. Probably, my initial question was phrased awkwardly.  But the main concern remains: We can generate a differentiable sequence of tokens that can be fed into a reward model quantifying the response quality and backpropagate this to maximize the reward.",2,1736696919.0
1hznbmr,m6udxq9,"No thats actually incorrect. If you look at the literature and in practice, in the traditional pipeline and in traditional RL, we don’t necessarily generate each action (in this case tokens) one at a time and assign rewards to each of them. That would induce massive computational overhead. Instead, we rollout trajectories (in this case generate the token sequence until termination) and assign the sparae reward in the terminating token. Overall, I agree that the main differentiating factor between tradition RL and RLHF is the reward model. By having a learnt scoring function with pretty noisy signals, you have a very stochastic reward that can induce training instaibility which is already a known issue in RL. But in regards to your post, I think its less about understanding RLHF vs SFT, but why RL vs Supervised Learning, which i think can be answered by looking at the task you are applying each method to.",2,1736729725.0
1hznbmr,m6rbcg2,"Hmmm, good point. I'll be honest, I am very much at the boundary of my understanding here lol, so you are probably right.",1,1736696864.0
1hznbmr,m6re990,"I haven't gone deep into this, but a few concerns exist:
- GS is a biased estimator
- Bias is likely to propagate and worsen through long sequences




That being said, I personally made some experiments using Gumbel Softmax to do fully differentiable RL on a toy problem. I think it has a lot of potential for differentiable decision making in discrete spaces.",1,1736697821.0
1hznbmr,m6rbndi,"Haha no worries, I am glad that you brought up these points. They got me into reasoning about it more deeply :)",1,1736696965.0
1hznbmr,m6rlsn7,"Yes I totally agree with that. The context of LLMs just came up to my head because we actually directly have a  softmax in the model that can easily be extended to a Gumbel softmax.

 But I asked myself this for general-purpose RL as well. What were your results and what was the problem?",1,1736700116.0
1hznbmr,m6rp650,"Going to DM, if you don't mind.",0,1736701103.0
1hzjlvy,m6q5f8t,You’re going to have to give more info; are the slice thicknesses the same or different? Are the two images registered in the same space? Presumably you want to use the segmentation mask from the T1/T2 image for segmenting the DTI?,1,1736678220.0
1hzjlvy,m6qbcny,different slice thickness & slightly differeng spatial allignment so I’ll probably have to spatially allign them,1,1736681890.0
1hzjlvy,m6qbeog,"yup! DTI has 60 slices, 1.85 slice thickness and MRI T1 has 23 slices, 3.6 slice thickness",1,1736681923.0
1hz2ct5,m6m8dny,"Particle swarm needs a lot of particles, and thus a lot of function evaluations. Your function is very costly to evaluate because it fits the LSTM. The standard approach to optimizing expensive functions is Bayesian optimization. One usual Python library for this is Optuna.",4,1736621662.0
1hz2ct5,m6msf3x,"First read up https://github.com/google-research/tuning_playbook, then do a Bayes opt on your hparams.",1,1736628040.0
1hzhrxb,m6pvu1m,"It's not clear. You want to find outliers in different mobiles based on just names?. Or given a set of mobiles, would you want to find a faulty one?",1,1736672157.0
1hzhrxb,m6q46il,I was thinking of using features like specs and price to find anomalies in the listing. For example fraud products or incorrect pricing etc. TBH the use case is difficult to figure out based on just the instruction provided.,1,1736677441.0
1hzhrxb,m6q4kzk,I see. Got it.,1,1736677693.0
1hzhrxb,m6q6m7m,"Maybe you can try the following you can use all the specs ( brand name, kind of battery they use, kind of screen each mobile uses, mfg date etc.,) and reduce the dimensionality. Use price as a separate dimension. Cluster these points to find outliers. This would be my approach.",1,1736678965.0
1hzbtak,m6t2icg,"“I don’t want the next n steps of my training data, I want the next n steps of my testing data which is unseen” doesn’t seem to make much sense. In particular, “the next n steps of the training data” sounds like these n steps are contained in the training data and we’re trying to forecast them, even though it’s useless because it’s already in the training data, there’s nothing to forecast.

What’s usually done is you train your model using the training data, then forecast using N latest observations.

Forecasting (and machine learning in general) is _all about_ predicting unseen data, so there’s no way none of the frameworks you listed supports forecasting.",1,1736715129.0
1hzbtak,m6t35h6,"I'll give you my example so u understand what I mean:
 if I give the model the battery charge going from 80 to 50, it will predict from 50 to 30. If I ask it to give me 60 to 50, it will not. It'll only give me. 50 to 30 the 30 to 10. I don't want the NEXT n from training, I want the NEXT n from inference.
Anyway the answer was called autoregression with arbitrary step forecasting, and Darts supported it with DLinear.",0,1736715315.0
1hyfaoc,m6hmemc,Don't be so hard on yourself! I think these are perfectly nice images.,51,1736551554.0
1hyfaoc,m6id5k7,Where GIGO is a goal,23,1736560652.0
1hyfaoc,m6hytyv,"i love datasets like this one, it has potential for some meaningful real world applications. Gonna see if i can get a super lightweight model working for edge devices, i like the idea of a self-sorting garbage bin",8,1736555786.0
1hyfaoc,m6hlgzi,"I like this. 

I’m browsing the images and curious about sampling bias. With a majority of the images being staged photos and a minority being the standard discarded types, might there be a higher error rate for actual refuse? As in there are pictures of moldy bread, but a few end pieces wrapped in their plastic may be more representative of bio refuse. I’ll try training with this data and comparing to my household refuse testing data.

Is that your paper comparing carbon impact of various models? Good work if so!",6,1736551239.0
1hyfaoc,m6k0r2n,This is garbage,6,1736589967.0
1hyfaoc,m6ilt32,Well done!!!! Anyone who provides data in this day and age is better than even the model providers at this point!,4,1736563717.0
1hyfaoc,m6h8q4o,amazing! 👏,3,1736547110.0
1hyfaoc,m6m36bl,"Cool!

I wonder how many municipal scale recycling centers are using something like this to auto-sort materials. ",1,1736620047.0
1hyfaoc,m6hx2kj,Thanks for the feedback!,7,1736555189.0
1hyfaoc,m6i28av,"Thanks so much! A self-sorting garbage bin is such a cool idea, and a lightweight model for edge devices sounds perfect for it. I actually created one and implemented it in an app—check it out here: [D.Waste](https://www.dwaste.live/). Let me know how it goes—I’d love to see what you create!",5,1736556938.0
1hyfaoc,m6hmzix,"There are instances of misclassified refuse, and we aim to incorporate those into our dataset. To address this, we’ve developed an app ([https://www.dwaste.live/](https://www.dwaste.live/)) where users can submit misclassified real-world images. These images are then annotated and added to our dataset to enhance accuracy. And yes, the paper compares the carbon emissions of various models.",9,1736551749.0
1hyfaoc,m6mmmy9,"I haven't come across any systems that use AI yet, but I'm currently in discussions with schools to measure their A-Waste-Less system using the Deep Waste app ([https://www.dwaste.live/](https://www.dwaste.live/)).",1,1736626156.0
1hyfaoc,m6hnmng,"Awesome, great way to close the loop on that. Impressive work, thanks for sharing!",3,1736551967.0
1hyfaoc,m6hve0c,"Fantastic!

There are also a few different datasets subs that may be interested in this as well",2,1736554621.0
1hz7n71,m6ndqr2,"I made one for SAM2, demo+link to source at [https://sam2-seven.vercel.app](https://sam2-seven.vercel.app)",1,1736634851.0
1hz7n71,m6nqchc,"Doesn’t the GitHub include code to enable it to run it in the client, in which you can customise the interaction with the model",1,1736639082.0
1hz7n71,m6nhe8f,Is it possible to remove regions?,1,1736636046.0
1hyxijp,m6l22ry,You mean the neural network incentivised to be super confident of the right option even when it shouldn't be. In other words reduce perplexity while also reducing accuracy?,7,1736608238.0
1hyxijp,m6q9xqt,This preprint might be relevant [https://arxiv.org/abs/2501.04697](https://arxiv.org/abs/2501.04697),5,1736681028.0
1hyxijp,m6pyq92,"Yes. If your softmax target is a one-hot vector, that tends to happen. I think label smoothing can help with this, and in practice it usually also increases model accuracy anyway, so I recommend to almost always use it.",3,1736673989.0
1hyxijp,m6mffgl,"Yes, but weight decay and the fact that we do early stopping in practice solve this issue.",1,1736623852.0
1hyxijp,m6ndd8g,Do look up confidence normalisation. I believe the loss is named lnc. A paper from half a dozen years prior. They do what you want.,1,1736634739.0
1hyxijp,m6oayno,The loss function is derived from rules of probability. It is not just a numerical convenience.,-1,1736645913.0
1hyxijp,m6l3pty,"Yes. And by being incentivized to be super confident, the output logit vector will tend to have something like \[50.1, -99.7, -52.6\] even for small very input vectors (just as an arbitrary example) if weight updates are unconstrained. But I do not know about reducing perplexity or accuracy. I think the premise of current benchmarks are flawed anyways.",1,1736608807.0
1hyxijp,m6rn56j,That's a really interesting analysis & pair of mitigations. Somehow none of my feeds caught it. Thanks for sharing the link!,2,1736700518.0
1hyxijp,m6qnsl3,Do you have the arxiv or the doi for the paper? I can't seem to find a specific paper related to this.,1,1736688283.0
1hyxijp,m6px73q,"I know how the loss function is derived and how logits can be turned into a cumulative distribution. But there are infinitely many ways a given domain can be turned into a CDF. So no. It is a numerical convenience. It just so happens that it works. Can you confidently say that a family of logit outputs that can differ highly in magnitude/scale correspond to good representations for a single, specific set of predictions?",1,1736673018.0
1hyxijp,m6pryn0,"Exactly

What's the problem if the weights get big? If the loss goes down, then it goes down. If the model is incentivized to do something in order to decrease loss, then why exactly isn't that thing good?",0,1736669699.0
1hyxijp,m6tx5ql,">But there are infinitely many ways a given domain can be turned into a CDF

What a strange statement. A particular problem has exactly one valid parent distribution function.

You are going about this backwards. Figure out what your problem is. Establish the loss function for that problem. Design the architecture to minimize that loss.",0,1736724343.0
1hyxijp,m6pxh15,">If the loss goes down, then it goes down. If the model is incentivized to do something in order to decrease loss, then why exactly isn't that thing good?

Because I am actually trying to get a grasp on the model's learning dynamics, and what contributes to the model effectively learning good representations, instead of blindly slapping on a loss function, treating a neural network like a black box, and get dopamine validation when I get high accuracy scores with some arbitrary benchmark.",1,1736673195.0
1hyxijp,m6x2gnr,"You are one of the types of people within the machine learning community akin to a tumor. All you do is regurgitate obvious answers anyone with a weeks worth of experience in machine learning already knows, and never stop to think ""why"" the things we currently use work and are they really optimal. I wasn't asking how to minimize a loss function for a specific problem.",0,1736775797.0
1hyxijp,m6s8rai,"Loss isn't an arbitrary benchmark. It measures the amount of information extracted from the dataset and stored in the model. In the end, it will force good representations 

Basically, if some intermediate state is necessary to achieve minimal loss, then actually getting the llm to output that intermediate state must involve the extraction of information from the data

If you increase loss, the ability of a hypothetical mechanistic interpretation tool to find information about the dataset in your model's weights will actually go down. That means no process, no matter how sophisticated, including during your end use-case, will ever be able to regain the information. This is the opposite of ""learning good representations""

If you aren't aware, information—like energy—is in some sense conserved. Decreasing loss is to learning good representations as reducing friction is to increasing energy efficiency. The causal link may not be clear, but I assure you it's helping

Okay, hopefully I've made clear why you want to decrease loss. What exactly is your problem with the pre-softmax output being large in magnitude? You say it's incentivized to give really low numbers to some tokens and really big numbers to others. I don't think I understand your point, because it's incentivized to give accurate numbers, and if a token is very unlikely then it seems good to me that the model will try to set its logit as low as possible

Of course the softmax does introduce one extra degree of freedom, so I figure either you have some subtle point about the extra degree of freedom that I'm not following, or else you're definitely mistaken",1,1736706688.0
1hyskcn,m6m4zmu,www.teamblind.com,1,1736620610.0
1hyskcn,m6k27wz,Using Gemini or gpt as an interviewer with their live mode/voice mode might provide a more realistic interview experience,-4,1736590914.0
1hypeqa,m6pcs32,"If hooking GenAI APIs up to the enterprise infrastructure is up your alley, yea there's plentiful in the large corporation currently. If you are keen to do real R&D, then there's hardly any, and the corporate culture in Aus don't exactly align to that either.",5,1736660952.0
1hypeqa,m6q5512,"I think if you're serious about doing R&D your best bet is to work at a multinational company that has Australian presence, and when you are there try to demonstrate that you are able to perform research at the appropriate level via a secondment and try to carve your own path that way. 

Its unlikely (without prior relationships) that multinational companies would support you doing research remotely. 

I have not seen any ""pure"" research roles from Australia simply because the number of Australian PhDs are relatively small + timezone challengers (Australia is like 2/3 the population of California and probably substantially less PhDs in the tech space). 

You may have more luck looking at Government roles that have a ML/Data Science focus with ties to universities if that is your preference. Otherwise I would advise that you ask your supervisor or fellow lab partners if they have appropriate connections. 

----

If your question is about general ML/Data Science roles, there should be quite a large number of such roles available",3,1736678041.0
1hypeqa,m6lynw6,+1 for this,2,1736618644.0
1hypeqa,m6y9k57,"Its picking up but get yourself ready!, [https://www.amazon.com/Breaking-into-AI-Ultimate-Interview/dp/B0DRHZ8Z93](https://www.amazon.com/Breaking-into-AI-Ultimate-Interview/dp/B0DRHZ8Z93)",0,1736789609.0
1hypeqa,m6puquu,"We're seeing a lot of companies offering data labelling, but how good they are? 
Someone on the industry of purchasing these datasets? I would love to hear how can you compare two companies?",1,1736671461.0
1hypeqa,m6sxavm,Fantastic! Thank you for that. 🙂,1,1736713631.0
1hypeqa,m6q0vo8,"Companies that specialised in providing data labelling services? Hasn't come across this in large ASX corporation afaik, I'd imagine this would be quite niche, lots of labelling can be done via foundation models (again -through API calls), and the labelling quality is fairly decent.

Unless you need a very precise labelling like image annotation for semantic segmentation etc., otherwise I doubt it is necessary.",3,1736675358.0
1i0v37l,m73txbu,Name or provide a link to that?,1,1736866938.0
1hxdk90,m69j7uy, Very interesting,1,1736446946.0
1hvjyig,m5wkfap,"I wouldn't use snowflake for queries that I needed to run in subseconds.  I've found Postgres, and other general purpose databases to be much better for this - partitions and parallelism isn't as fast as indexes if you don't need a vast amount of data to come back.

Though if your requirements are a bit more flexible, more like: 

   * 90% of all queries are complete in <= 1 second
   * 99% of all queries are complete in <= 5 seconds

And if ""realtime"" just means less than few minutes old, then, when combined with caching, it might be possible.  If this looks like it could be possible, then I'd move ahead and do more typical database & query optimizations.",1,1736271569.0
1hvjyig,m5yqgg5,"I agree. I would not use Snowflake. It's not meant for this type of database need.   
Postgres could be a good solution, Mysql too. It all depends on how many rows your tables have and what type of queries you're running. Are you ingesting a large amount of data, and do you need to perform operational analytics (real-time queries under < 1 sec)?  For that, I would suggest Singlestore.   
Each database engine excels in specific domains.",1,1736294728.0
1hvjyig,m5zy9e0,"The general solution for many of these problems is moving the work out of the query. Whether through materialization, denormalization, pre-running, etc. Window functions can be particularly problematic... and sometimes better handled in dataframe libraries: you'd be surprised to see certain queries processed faster outside the db.

But, when you find yourself writing complex multi-hundred line queries with many joins, just stop. Don't do that. Break it down.",1,1736310078.0
1hsv9pr,m5epae3,"#BigData was the buzz term ten years ago. It morphed into Data Science. You’ll do better looking for training using that term.

Data Science is in turn morphing into AI, though there is still plenty of Data Science to be done e outside of AI",3,1736022491.0
1hsv9pr,m5k2xou,"Just to be clear how much research have you done yourself? How long have you been preparing for a ""career in Big Data""? What to your current understanding would be a definition of ""Big Data"" versus ""data"" (not to be confused with Data from Star Trek)?

  
I would say one of the first areas I would recommend you spend some time researching and studying would be what is known as **E**xtract **T**ransform **L**oad or ETL for short. This is a system in which you *extract* data from a source like a database or the payload in packets of network traffic, you then *transform* the data into a nice ""structured"" format that will be useful for later search queries, and then you *load* that data into a database for those later queries.

Usually part of what makes the ""Big"" in ""Big Data"" is the volume of machines you're using in the business. The most common approach is to use **Hadoop** which provides a distributed filesystem across multiple machines. In order for Hadoop to make sense, you first need as a prerequisite to learn about **distributed systems** and the common design patterns used here.

To give you a little bit of a primer, here are some things to expect to see in distributed systems and Hadoop in particular:

1. There is usually one main NameNode at a time which acts as the ""leader"" in the distributed system. For fault tolerance (meaning the ability to withstand the application temporarily breaking and being able to quickly recover without human intervention), two more NameNodes will be used. The concept of who is the leader is maintained through continuous ping messages between each NameNode. This is typically referred to as a ""heartbeat"". If the leader goes quiet for a period of time, it will be assumed to be dead and a fallback leader is elected.

2. DataNodes access the actual data i.e. they know how to find the appropriate inodes for a file and on which machines those inodes exist. If you don't know about inodes yet, you will need a course on operating systems and will learn about it in a section on filesystems. The DataNodes are selected by the NameNode when a query is submitted to the leader NameNode.

3. JournalNodes are the actual processes that send the previously mentioned ""heartbeats"". They also ensure that the file metadata is copied between NameNodes in the event that the leader node fails.

  
Instead of Hadoop you may also come across **Kafka** which is a distributed message queue. The idea of a message queue is an intermediate machine takes on the responsibility of holding onto, delivering, and optionally verifying that the message sent gets delivered to the intended destination (i.e. a database). 

A message queue like *Kafka* is divided into two main concepts: *Producers* and *Consumers*. A third component -- The ""message broker"" -- ensures that all requests between producers and consumers is delivered or otherwise keeps track of failures. 

Message queue architectures can also provide a **Q**uality **O**f **S**ervice level or QoS for short. This means ""fire and forget the packet"", ""ensure that the packet gets delivered to at least one consumer"", or ""ensure that the packet gets delivered to one and only one consume"".

  
That's all I got for now but I hope it helps.",1,1736100870.0
1hsv9pr,m5b85cs,"Bro, we believe that you are from farming background.

There was no need to put a pic sitting in a farm, LoL.",1,1735968527.0
1houh90,m4cdfc6,I’d say spark first.  It’s common these days to read from object storage rather than hdfs and spark is more relevant than tools like hive.,4,1735473858.0
1houh90,m4ew2zi,"I'm not sure learning Hadoop is the best approach this day. It might be interesting but it's generally not used so much anymore. Depends on your industry, but I feel like unless you know you need to know Hadoop it's probably not your highest priority.",3,1735505849.0
1houh90,m4cexpp,"Would recommend Hadoop first, cuz if you learn map reduce framework than spark would be easy  ,both have a similar architecture.",2,1735474733.0
1houh90,m4ly282,You don't really need to learn hadoop anymore. Just learn Spark and whatever flavors of NoSQL are relevant to your job. If you want to get fancy you can learn Ray.,1,1735603136.0
1houh90,m4fv9xo,"What do you imagine has overtaken Hadoop versus it running in the background obfuscated from the user?

Do you imagine CephFS has adopted a large enough audience or something else?

It solves the problems of needing a filesystem in a distributed architecture so something has to replace it versus it not being used at all.",1,1735517155.0
1houh90,m4g4s8q,"When it comes to object storage, AWS S3 or equivalent.",1,1735520359.0
1hotwap,m4ii220,"Thank goodness, this sub was getting to be way too high volume. Nice to see someone taking some of the load off. 

/s",3,1735561701.0
1hkfzpa,m3fifkp,Amazing. I will give it a shot and report back,2,1734958632.0
1hkukvg,m3ha6gv,LOL,2,1734981392.0
1hkkq2k,m3g0yf8,"So one of the customers I work with that I've been working with for over a decade now also has an on-prem requirement, similar scale and setup to what you are talking about. 

Not going to lie, we've looked at alternatives through the years and haven't found much better. We've tested storing data minio and using the S3 API and tooling it was generally slower for most of our use cases we tested and we also didn't want to add yet another piece of infrastructure to maintain. Also we moved to erasure encoding by default on our production data in HDFS which actually improved performance in many cases and worst case made some things just a tiny bit slower but allowed us to reclaim 50% of our storage.


For compute we still have lots of mapreduce jobs that were written years ago running in YARN because it just works! They still meet our requirements and the dev teams know how to work with things since that's what's been there for years. We have had hive for a long time and it's still used heavily, because it just works. We've added spark scheduled via YARN for more data science/analysts type work since it's more flexible. Most of the spark stuff is done in Python.

There is some interest in looking at a few things but we haven't done it yet:
- Spark in K8s
- Trino
- Iceberg tables


For that client they've already paid the cost to learn how to use and manage that stack so although the leadership is willing to let us engineers experiment unless there is a truly compelling reason to make a change they will generally just stick with what they know. Is this the sink cost fallacy? Perhaps, but many times the added complexity isn't worth it for what usually isn't a substantial benefit.",3,1734966334.0
1hkkq2k,m5vwct7,Maybe starrocks?,1,1736264446.0
1hj6p76,m34e6n9,Will people copy and paste content from ChatGPT in 2025? Yes!,19,1734779635.0
1hj6p76,m34cr7b,"Thank you, chat gpt! Can't wait to go to india!",10,1734778716.0
1hj6p76,m34am01,"For me regarding the 7: I think nowadays with more and more self-service BI tools which do not requiring coding, you do not need to know coding that deeply",-1,1734777304.0
1hj6p76,m34ebmq,I think this is entirely wrong.  Many people are moving rapidly away from no/low code solutions and just writing python,2,1734779725.0
1hj6p76,m34ev2w,"ohh, but what about warehouse native platforms where you have automated SQL writing? Thnak you for the clarification",1,1734780073.0
1hj6p76,m34gym0,99% gimmick if you ask me.,0,1734781386.0
1hdbw7e,m1zwggi,Someone really use r?,1,1734170639.0
1hch7ch,m20hvol,The whole article reads like you got an intern to put together a bunch of platitudes to stick in a blog post for SEO. There’s zero of substance in there.  ,1,1734183481.0
1hc5gm9,m1uz2y2,"I'm here for this. Thanks!

Everything seems chill/relaxed. Got any playlists with higher energy vibes?",2,1734098886.0
1hc5gm9,m1ww2pd,"Anything for post rock? Like explosions in the sky, that type of music ?",1,1734121379.0
1hc5gm9,m1v32rg,"You're welcome

Not at the moment, sorry, apart from 2 more varied playlists with some tracks with more energetic vibes: 

Alt (alternative and underground pop, rock, electronica and jazz) > [https://open.spotify.com/playlist/2mqJyV356xjCfOUs2kPJQW?si=72ffe8374d9c4233](https://open.spotify.com/playlist/2mqJyV356xjCfOUs2kPJQW?si=72ffe8374d9c4233) 

So gooooood (multi-genre) > [https://open.spotify.com/playlist/63ItgR7hNCoXvA5x1SAhqe?si=f1ae3900736146fe](https://open.spotify.com/playlist/63ItgR7hNCoXvA5x1SAhqe?si=f1ae3900736146fe) 

H-Music",2,1734100371.0
1hc5gm9,m1w98qh,Thanks!,2,1734114077.0
1hb2w3b,m1gsdwa,This is the first time I’ve seen anyone define what a “data lakehouse “ in an understandable way.,2,1733885471.0
1hb2w3b,m1h63nc,"Thank you, I try to keep things accessible",1,1733891084.0
1ha3ecw,m162ttg,"In the early days of social, this used to be possible. There was even a company (Gnip) that provided an aggregate search api. But they eventually got bought by Twitter, shut down their other data sources, and started charging egregious amounts for the data. 

Most other social platforms either shut down these APIs, or made the terms of service so limited as to be useless (LinkedIn notably wouldn’t allow you to store the contents of the search results in your own database). 

I think BlueSky allows you to consume a “firehouse” and generate this info yourself, but I haven’t actually looked into it myself.",2,1733734526.0
1ha3ecw,m15sv9s,"Worked at FAANG. This data doesn't exist externally. SEMRush or Google Keyword Planner might have directionally close for you but not a lot of granularity. Hoping it comes one day as Top 25 search terms in Bigquery exists https://cloud.google.com/blog/products/data-analytics/top-25-google-search-terms-now-in-bigquery

If you had specific search terms you were looking for Google Trends APi could work but no volume, just index and you would have to do a lot of pulls based on the granular you want and use an anchor Search Term/Category to keep variance on the same level.",1,1733727862.0
1ha3ecw,m15u7e3,[removed],1,1733728696.0
1ha3ecw,m1lgcqz,Are you doing this via API?,1,1733954309.0
1ha3ecw,m15wlr8,Interesting... Thanks for your input. I'm shocked that Big Tech wouldn't cash in on something simple like this but I guess it gives them a competitive edge...,1,1733730247.0
1ha3ecw,m15wey1,"No, I haven't, thanks for sharing these... Do you know if there's a way to export daily searches for a certain keyword over several years from Answer the Public? Not sure if I'm missing something but the only way I could see going about it is screen scraping... & I'm still not sure if they have daily totals...",1,1733730122.0
1ha3ecw,m1s5t43,"Yeah, that's the plan right now.... Kind of meshing that with some open source datasets but I'm trying to update the data over time since it is timeseries data.",1,1734049778.0
1h94wbm,m116mi5,Anyone?,1,1733667509.0
1h5uqly,m09v4ee,Very cool!,2,1733264616.0
1hhw29e,m2u7zkp,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1734624027.0
1hhw29e,m2utac6,"I am in a role as a Research Data Specialist for a government agency. I love the work, which impacts policy and mainly revolves around a datawarehouse containing service records for housing services. I'm looking for some advice on where to look (job roles and titles, etc) for roles that fit my interests.  
  
**Thins I like about my job:**   
Diving into complex databases to become a SME.  
Writing more complex SQL Queries.  
Contributing to automating validation for data load.  
Creating/maintaining dashboards.  
Wearing many hats, jumping into to many projects, and helping link the programming and research teams together (I'm a former teacher and feel I excel at translating requirements between teams effectively).  
Basically any day where I am lost in the database writing SQL Queries, validating other's pulls, or learning about the nuances of the dataset is a great day.

**Things I don't like:**  
If I am being honest, the actual in the weeds data analysis work. I do not enjoy having to transform the data into grahs, etc. or manipulating outputs in excel.  
Excel Work in general (hate making graphs and trying to find insights in the data, but love the backend piece of ensuring the insights should BE in the dataset and that the dataset is correct and error free).  
Lack of opportunities to grow into more ETL focused role.  
No choice in vendor selection. We have what we have (govt contracts) and I most of the setuop andn maintenance of environments and workflows is done by contractors.  
Low pay (compared to tech or larger companies).

I guess I am starting to feel that my strengths are working in cross-team capacities and being a data source/database/SQL expert. I have explored some SQL DBA type classes and enjoyed them but want to be closer to the action than I think a typical DBA would be. I feel like I could explore data engineering, but would need to rework my waning non-R and non-SQL programming chops and my knowledge of vendors. Current stack is Snowflake/Informatica/Tableau/R/Office365.

Any thoughts on what type of roles to look into would be great.",2,1734631488.0
1hhw29e,m2xr0s7,"Hiiiii everyone\~ I just completed my last semester of uni and finally got my bachelors in computer science. However, I've come to realize that the software engineering career isn't really for me and I feel that Data Analytics would be a much better fit for someone like me. I understand that the tech market, data analytics included, is rather hard to break into in this current moment w/o relevant experience. I just wanted to ask if you think it would be a viable option or even possible? 

I'm not exactly in a position where I would be hurt if I don't have a job immediately as I live with my parents. I also certainly don't mind grinding on the job hunt, relocating, studying new technologies, or making a portfolio.

Maybe a couple things to note as well is that I am 23 and from the U.S. (California). I've been working a customer service job (smoothie/boba shop) the last 2 years. I do have ""some"" experience in R thanks to one of my last classes being statistics, and I feel I could pick up Python rather easily. I would still have to study things like SQL, Excel, and PowerBI or Tableau. I'm looking into certifications as well, although I'm not exactly sure if something like that would be worth it in my aspect?

Any advice would be appreciated\~

Thank you!",2,1734669065.0
1hhw29e,m3pnfe7,"I am a senior Data Analyst with a logistics firm and also a Business Analyst for another company in Nigeria as well

I also do web scrapping with python as well as Advance ML with EXPLAINABLE A.I and so forth

By the way..if anyone also need help with a side project..you can share with me 

Merry Christmas everyone from my Family to you guys",2,1735115496.0
1hhw29e,m408v8i,"Hello everyone,

I worked as a data analyst for about 6 years in different companies in Silicon Valley, 2 years after college in India and then I did a master’s degree in analytics, and then worked for 4 years before taking a break due to burnout. During that time, I started working with animals for my mental health and found a lot of love training dogs, and just decided to follow that career path for a while. After covid and a few years, I’ve worked in an animal shelter and gained supervisory experience. I’m looking to many my way back into analytics and am in need of advice about the best way to get my foot in the door again. I’m doing a Udemy course to refresh my memory and get fluent in the subject again, I was (and am working on getting) comfortable with Python, very familiar with sql, and tableau. I understand that I probably won’t be very hireable for the top companies, but I also don’t want to get stuck in bad consulting firms or sketchy companies that would put me in an even worse position than before. Any ideas on what kind of companies/verticals I can start interviewing at to get a decent starting position and build experience?",2,1735288613.0
1hhw29e,m43uqwy,what makes a good analytics project in this day and age?,2,1735340097.0
1hhw29e,m4fyvw4,"Hi all! In 2025 I want to make a career change from fashion ecommerce to the digital marketing space. I know it will be a good fit for me as I am passionate about data w/great pattern recognition. I'm considering certification or a master's degree in digital marketing and analytics. I currently hold a BA in English/Writing and a minor in media & communications. I would love to hear any advice on entering the analytics industry and space, how to be competitive, which programs are worth it and which are money grabs.",2,1735518352.0
1hhw29e,m4mizv3,How would you describe the current industry of data analytics and the future? Admittedly as a computer science student I've realized I don't truly know anything about industry trends and how to research them. I didn't fully know \*why\* software engineering had to pay well and why certain software was necessary- so some of the tech layoffs came as a shock.,1,1735610342.0
1hhw29e,m5xxob0,"Hey guys! I graduated last may with a bachelors in psychology from a decent liberal arts school and now fortunate enough to be enrolled in masters program in data analytics. I thought maybe being enrolled in this program would open some doors for me career wise, however, that does not seem to be the case as I am jobless with no internships. I just started my second semester and am desperate to find some type of entry level role that would look good on a resume for future research analyst positions. I have some class work I could throw in a portfolio that I was awarded good grades with, but in all seriousness I don't think they are anything special. Is there any type of role out there to help me pay for a little bit of grad school and add to my future credibility as an analyst? I am aware that its hard to crack into right now but any advice would be helpful. Thank you!",1,1736285760.0
1hhw29e,m60d4s5,"Hi! I am in my last year as a university student studying for a bachelor’s degree in Business Administration with a concentration in Business Analytics! In school, I learned mostly Excel and basics of Tableau and SQL! I am continuing to practice SQL, learn Python and start on a few projects through DataCamp. I only had one data analyst internship experience and planning to start product management internship soon. Any advices and suggestions for me to find a data analyst job after college graduation?",1,1736316972.0
1hhw29e,m74wvhx,"Hi! I'm a management student and I'm in the last year of my bachelors (my course lasts 3 years in Europe), starting to look into masters to apply. I'll be honest, my work experience is almost 0. I have done a ""high school internship"" in asset management which lasted 1 week and tbh I didn't like it, although I believe that not knowing finance by then didn't help. I worked 1 year on the marketing department of an NGO (thirst project) but it was mainly social media work. I have been doing sports consultancy for the past year (for a junior enterprise from my uni) which has been the closest to real experience I've had. (I gotta say, my first project was indeed very significant and I learned a lot from it, had to analyze the management model of a Portuguese soccer club and determine if they required private investment. I have had very good feedback from it!). I will be doing a summer internship this summer, that's for sure. If everything goes to plan, at Bain, BCG or McKinsey.

So far, I would say consulting, marketing, operations (supply chain included), sports management and statistics are the things that interest me the most. Finance interests me to some degree. I currently see business analytics as an amazing way to deepen my knowledge in statistics and data analysis, which is extremely useful for pretty much all the areas I mentioned above. I have studied python which also helps. Haven't studied SQL but I'd do a summer course. 

The thing is, I would like to hear from people who have done a MSc in Analytics, has it been rewarding? So far, from what you have experienced, does it translate into a crucial asset for someone doing marketing, operations or consulting? Or is it just an extra skill? How much space for innovation do analytics jobs offer? Do you think that by doing this MSc I could easily find jobs in the areas aforementioned?

Sorry if I'm overwriting, my first time writing here lol, anyways, I would be very grateful if you could help me!",1,1736878566.0
1hhw29e,m2vmcp3,"Look into data engineering and ""analytics engineering"" roles. The latter is usually in-between data analytics and data engineering in terms of technical competencies. 

Beforehand, you should pick up Python. Beyond pandas and matplotlib (i.e., the ""tidyverse"" of Python), learn these frameworks and packages:
- database drivers (e.g., the psycopg2 package for postgres) for executing pure SQL code from a Python script
- SQLAlchemy, a SQL ORM (basically, it allows you to write Python objects, then the ORM translates them into SQL code for you)
-  PySpark and pyarrow for large-scale data processing
- Airflow, depending on the company
- object-oriented programming (OOP), which I assume you do not do in R but it is paramount in Python",5,1734640820.0
1hhw29e,m30s3un,"Study SQL, Python, and a visualization tool of your choice and make a few projects using these tools, and you can use that experience in your resume and as a point of conversation in interviews. I was similar to you but I studied Computer Engineering, and this method worked for me about 3 years ago. It's a rough market out there, but since you have time on your side I would go for it. Having a strong technical background with your degree is a big advantage.",3,1734720651.0
1hhw29e,m4t55s6,"- Collect your own data, whether from an API or by web scraping. The former is easier and what I recommend. There are tons of semi-popular public/free APIs out there, like the US Census API and the Socrata API (for programmatically querying data from cities' public data portals).
- The project culminates to a tangible product, like a data warehouse or dashboard. It's not enough to have a notebook where you clean the data; do some descriptive statistics; and show a bunch of random plots. 
- (Optional) Cloud integration. Show some form of competency with the cloud (e.g., store your database on Amazon RDS). 
- Orchestration, like a bash script; makefile; or Airflow (if you're using Python). If/when someone clones your repo, in principle, can the person recreate your work with a couple keystrokes? In an interview, this is something you can talk about intelligently, ""To productionalize this project, I orchestrated it using x/y/z, I wrote a README to document my workflow, I packaged the core logics with OOP, etc. Some challenges I encountered include a/b/c.""
- In an interview, you can relay a good motivation for pursuing the project.",4,1735709024.0
1hhw29e,m4fz1k2,p.s. I already have valuable AI experience,2,1735518404.0
1hhw29e,m2vq2ik,"Appreciate a clear set of things to check out. I’ve studied OOP in college and have some (not resume worthy) projects in Python and can get that ball rolling again. 
I get the sense that role title in analytics tend to be fuzzy, but is an analytics engineer a role someone could hop into without SWE experience? It seems like data engineer jobs often point towards more dev experience.",3,1734641994.0
1hhw29e,m37mh9t,"Tysm for the reply! I'll be sure to really make sure I have these skills down then before I start applying\~ I'm kinda excited to start learning all this new stuff lol. I also wanted to ask tho, if you think something like the Google Data Analytics Certificate would be worth doing, or would my degree trump that already? I just want to make sure I use my time efficiently as I grind my way to a job.",2,1734825164.0
1hhw29e,m2wh91x,"No, analytics engineers don't need SWE experience. Check out Netflix's AE roles for reference; those are probably the most ""mature"" job description (i.e., they know what they want out of you) you will find out there for AE.

Data engineering is the same case, in thst you don't necessarilly need SWE. However, FAANG companies (i.e., those with large SWE teams) tend to have a higher bar for data engineers.",4,1734651162.0
1hhw29e,m3896la,"If the certificate already has a huge overlap with what you want to learn then sure why not, but personally I think having a strong project is more valuable. Might as well do both honestly",2,1734834537.0
1dj1a5b,l97o5qc,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1718744144.0
1dj1a5b,l97s37l,"I’d love to see more about advanced analytics and hear from the old heads. I’m 10 years in so I try to offer where I can. Analytics is such a wide open term so I see everything from basic excel to ML and statistics/epidemiology. 

But the sub feels like a job board. Lots and lots of posts looking for and asking about analytics jobs -mostly analyst positions too. The field is kinda brand new but I didn’t realize how many people flocked to it. 

I used to be the young one on this site. So I understand the skew.

I’m also subbed to r/machinelearning r/linux, r/statistics and r/mathematics because I like that they get into technicals even if I don’t understand. Analytics moving in that direction would be cool.",14,1718745466.0
1dj1a5b,l97zbvn,"Hey! I love this community for its insightful discussions and helpful advice. To improve, maybe we could have more regular AMAs with industry experts and dedicated threads for specific topics like tools, techniques, and career advice.",8,1718748052.0
1dj1a5b,l9b75bg,">50% of posts should be in the monthly career thread instead of their own posts. I don't want to discourage people from looking for career advice, but its really annowying.",5,1718806341.0
1dj1a5b,l99jeep,"Yeah, as others are saying, it’s be nice to make the his into less of a job board and more of a discussion about technique and best practices. Nothing wrong with career development talk, though. We only need to try to segregate those topics, maybe with flair and some moderated governance over properly classifying discussions. Personally I enjoy participating in both types, but it seems methods and best practice discussions are too rare, maybe not explicitly encouraged enough.",3,1718771908.0
1dj1a5b,lbs573s,"Hey Jon, I'd be open to:

1) Hosting a hackathon-like Analytics competition.

2) Setting up formal mentor / mentee system here.

3) Starting blog series talking about different roles in Analytics. I've posted in the past on this topic but this series would be more of a deep dive.

Just some idea I've had in mind for the group that I'd discuss with you eventually, that time can be now ! Thank you to this community and the mod team, I love it here and especially since many of us Analysts find ourselves on an island (on a team that does not have other Analysts) this community is so great to have.",3,1720204563.0
1dj1a5b,laes39d,"An easy win could be more expansive tagging -- maybe editable tags and user flair. I mean GA4, is a world away from Looker and Tableau, it would be nice to see what we're getting into. 

Also on aside, I'm super curious about data privacy and analytics. 

Keep up the good work with this sub, overall, I really value the discussions!",2,1719430330.0
1dj1a5b,lcu9ksd,"Hey Jon - Looks like you got some thoughtful replies here, and I sent a follow up DM. Any thoughts? Any feedback or next steps? Anything I can help with?",1,1720794657.0
1dj1a5b,l99jtk3,"I second this. I left r/datascience because there was less discussion about data science and more discussion on breaking into the field, what major to choose, college vs bootcamps, how much salary everyone is making, etc. I like it here and subs like r/statistics better because people were actually talking about analytic and statistical problems, but it’s starting to look like people are starting to come here and starting the same conversations I left the data science sub for. Ideally I wouldn’t want any career related post on here but I know that’s too extreme. I just don’t want every post to be about breaking into the field and what major to choose or how someone realized that they love analytics and deserves to be an data analysis because they managed to do a 5 months bootcamp in like 2 weeks and then throw a hissy fit when we tell them that won’t cut it, you need to go to college and take statistics.",5,1718772145.0
1dj1a5b,lcubr55,"I don't agree this sub feels like a job board.

Looking at the past 25 posts, zero are job postings. Roughly half of the posts are related to career advice of one form or another, broadly speaking (I'm having trouble with my boss - what should i do?... What degree works best for analytics? ... What does a Marketing Analyst do? ... I am a UX Designer, how can I transition to a career in Analytics?).

But what is the problem with that? What would you prefer be the focus of the sub, or would better tagging help?

Here's the detail of the past 25 posts:



Topic Summary	Job board	Career Advice

Discussion over future of web analytics	0	0

Seeking advice for hiring analysts	0	0

How can I become an analyst	0	1

Switch from program manager to Analyst	0	1

Growth modeling using Python	0	0

Venting about frustration at job	0	0.5

Is my current job a good analyst job?	0	1

Regression and prediction help	0	0

Analytics tool discussion	0	0

Changing from UX design to Analytics	0	1

How to handle IDs // anonymous IDs in dataset	0	0

Lost in career	0	1

Facebook marketing analytics help	0	0

What does a Marketing Analyst do?	0	0.5

Discussion over struggling in Analytics career	0	1

Resume help	0	1

Youtube data analytics help	0	0

Graduate degree advice for analytics	0	1

Career advice	0	1

Dealing with micromanaging boss	0	1

Resume help	0	1

AI and Analytics discussion	0	0

Georgia Tech degree program advice	0	0.5

Azure tutorial and help	0	0

Maven Analytics help	0	0",1,1720795387.0
1dj1a5b,lcu9oj8,Can you get us started with a list of topics / experts you'd like to see covered in an AMA?,2,1720794692.0
1dj1a5b,lqshg26,"I'm really late, but we'll be having an AMA with Alex the Analyst this Thursday morning on r/dataanalysiscareers !",1,1728315340.0
1dj1a5b,lbs66dl,What is the bowtied name meaning? I see it around social media but don't understand its origins,1,1720204879.0
1dj1a5b,lbs62kq,"I think a challenge here is that most of the stuff we work on will be proprietary - we can't readily share data from our company, and obfuscating it is friction.

I'd also love discussion over methods, etc. But I feel like that's kind of more for Stack Overflow, etc. as the more natural fit.",1,1720204846.0
1dj1a5b,lcu9uld,Keep going - what is your best foot forward for a comprehensive list of flairs? And any thoughts on flair management (I'm in another group with 50+ and it becomes a bit unwieldy),1,1720794749.0
1dj1a5b,ld1n771,"What in the selection bias. You show up in an analytics sub with your data being the 25 more recents posts to make a point I made a month ago?? Where the mods were actively looking for feedback back (they are mods). Imma keep real with you, chief, it don’t look too good rn.",2,1720905224.0
1dj1a5b,le1bjm4,It's a good point. If the mods have been actively removing such posts then survivorship bias is present.,1,1721448237.0
1i196lv,m744bzf,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736870188.0
1i196lv,m746rz8,I got this job because I have a masters in creative writing and can tell a story. My math skills are...fine. So yes.,145,1736870932.0
1i196lv,m74bnc0,"Yes. It's what we're being paid for.

Let's face it, it's really not that complicated to pull data and produce reports. You just need a set of instructions and that's it.

Doing actual analysis and insights from those reports, however, is the value we bring to our organizations. It's up to us to tailor a narrative to either support or dispute whatever hypotheses that our stakeholders have. I'm in a tech company so the people I work with can actually dispute what I say if my numbers are wrong, but I imagine that yes, you probably can get away with making stuff up in front of non-technical staff.

Still, it would always boil down to narrative.",35,1736872392.0
1i196lv,m7475fo,"In my experience, I’m either a story teller like you said, with basic analytics. And another role is finding ways to help other departments improve their spreadsheets for their reports. It’s always an awesome feeling when you help others’ efficiency. A lot of people waste hours on tasks that could be automated.",35,1736871045.0
1i196lv,m745t63,I’ve worked in two bigger tech companies before. It’s the same because those companies want to move and grow fast. As a result the analysis will always be done in a way to get the quickest results,17,1736870634.0
1i196lv,m747wcr,"1. Make the model anyway
2. Wrap it in a black box
3. Label it ML or AI (preferred)
4. Profit

On a serious note, is statistics just not encouraged or is it discouraged? If the former, start having conversations with your manager about it. Incorporate it into your development goals and do some basic projects in your down time that add demonstrable value. My manager does not have a DS background, and it was not in my original job description, but he never complained about paying analyst salary for DS work.",16,1736871271.0
1i196lv,m748t4u,"In my limited experience, data analysts are just there to give people data that confirms their biases and helps them get their bonuses. Data that goes against that is likely to be ignored.",23,1736871546.0
1i196lv,m747hpm,Why aren't you allowed to use any statistics? You can't even present average values?,7,1736871148.0
1i196lv,m745897,Carbon copy of yours.,7,1736870457.0
1i196lv,m74fmwd,"I have worked in an environment where Python (and any open source tools at all) were taboo and not to be used. We used Tableau Prep and local hosted SQL servers for everything, it was horrible. 

Enter Databricks - it solved all my problems by giving me access to all the open source tools I needed, wrapped up in a “compliant” software package (Azure, lol) that my company was okay with. I had to fight like hell to convince my IT apparatus that it was worth pursuing, though, as our team is probably pushing the boundaries more than any other in our company in terms of data science/engineering/analytics. If you have a cloud infrastructure at your org, see if you can’t get someone to spin you up a Databricks instance. 

That said, to answer your question, yes we are storytellers. That’s the job. What you’re describing as a problem, that the layman doesn’t understand highly technical analysis, is the crux of why this field exists. Of course the executive with an MBA doesn’t understand what Levenshtein distance is, that’s what YOU went to school for, not them. You are educated on the topic and that’s why you’re here, you get paid to make sure that the important components of that highly technical analysis make it out of the black box and into the brains of your audience in a way that doesn’t require you to explain to someone what an R Squared value is. If you want to be in the weeds talking nothing but technical jargon with fellow technical folk, you need to dive deeper down the stack.",7,1736873566.0
1i196lv,m74pvqy,"When they say ""don't use your statistical knowledge,"" what they mean is, ""math is scary, when I see math I have a panic attack, so don't talk about math."" 

Analysts do the math and present the findings in a palatable report, something that tells egotistical business heads exactly what to do so that they look good to everyone else. ""Palatable"" = appealing to monkey brain. In other words, we make logical decisions *feel* like intuitive decisions. The way we do that is through storytelling.",4,1736876558.0
1i196lv,m74cmps,"From my experience, it’s definitely dependent on the company and size of the data team. A data analyst can mean many, many things. Despite what others say, there is no unanimous consensus in academics of what a data analyst is and the ambiguity only gets more intense in the workplace since there are many systems and many different way to configure said systems…

I work for a small mental health agency, and our IT department is smaller and less developed. I am the “Data Analyst” in the IT department, but since we only have a couple hundred end users who need administrative reports, we don’t have the need for system admins and engineers who have a nuanced and deep understanding of relational databases and ETL processes. 

For dataset preparations and integrations, I do SQL and T-SQL and for pipelines we use a hybrid approach between Microsoft fabric in power bi service and a data gateway from the on prem sql server and the semantic models on power vi service. I then do the surface level reporting — both visually and tabular. Neither the data engineering aspect or BI development aspect is too complex.

At other companies, the Data systems is split into structured departments. Like the data engineers will perform data loads to a BI data model and create sql platforms for the analysts to interface with. 

In your case, you almost sound like you are in some sort of quality and compliance team without access to IT infrastructure.",3,1736872685.0
1i196lv,m74hi0x,"I‘d say as a (data/business) analyst, your main job is to be a translator between the world of data and the world of humans. Both world overlap but are not congruent with each other - after all, there’s plenty of less number-literate folks. (Which is absolutely fine to be and they surely have their strengths in other areas where you might be less strong). 
Your job as an analyst is to explain to a number-phobic person what your key data finds were. If you apply statistical methods to find your answers, go for it. However, when you explain your findings, do not expect to get very far when you use terms such as standard deviations or what your R squared value was. Use empathy and  find suitable analogies to explain your findings and their wider implications to your audience. You are not in academia anymore and a company is not a science symposium.",3,1736874108.0
1i196lv,m74t9po,"As a data analyst myself, I believe that’s the most beautiful part of data analytics",3,1736877524.0
1i196lv,m74f8lt,"Where I work you have people with big egos that don't know anything about stats or data science and are uncomfortable when you exceed the limits of their analytical knowledge. In general they don't really respect how hard it is to prove something is effective or that X caused Y, they just want numbers to tell them what they already think. It sounds good to say you're making data informed decisions but the human mind isn't really like that. Most of the time the best you can say is ""I really don't know"" which is not a good answer in the workplace, so you end up saying ""here's what I think is happening"" which means I'm dressing up my subjectivity with numbers.",2,1736873450.0
1i196lv,m74j7n7,How is Python not allowed; how does that even work? You are not allowed to process data in Python and generate vizz with other tools?,2,1736874617.0
1i196lv,m74sy5y,"The best way to have people remember and elaborate in your insights is via stories. Not numbers or graphs. 

It's just how our brains are wired.

Your job is twofold: convince people to make the right decisions, via stories, and assure that these are the right decisions by having the data that backs up your story.

This means also that your job is not to present data to people and ask them to make their own decisions.  

So yes, you should be a storyteller, but a data-driven one.",2,1736877434.0
1i196lv,m75cafk,"Yes. That’s why companies search for creative / strategists folks to fill data and analytics roles. 

The data is there to support the story you’ll tell.
Which brings us back to the topic of: you don’t have to master SQL, Python, and statistics to be a good data professional.",2,1736883018.0
1i196lv,m760m0y,"Most data analysts aren't really capable of statistical and predictive modeling, at least not without moderate supervision and/or if they don't have a quantitative degree. There's a reason why ""A/B testing"" generally falls under the responsibility of ""Data Scientists"" and ""Statisticians"" depending on your field.

I got 3 YoE and I have had to train interns and new grads on-the-job on basic statistical methodologies like power analyses (in a simulation setting) and multiple hypothesis adjustments. It's one thing to run A/B tests; the hard part is designing them properly and making sure they align with research/ hsiness objectives.",2,1736890638.0
1i196lv,m76td6g,"When playing Black Jack, the majority of people don't want to know the mathematical probability of a win with their starting cards against the dealer. They just want to know if they should Hit, Stand or Split.",2,1736899693.0
1i196lv,m7488s4,"Mine is similar, my boss came from another area of the business and doesn’t have a statistics or data background. She doesn’t know python so she doesn’t want us to use it",1,1736871376.0
1i196lv,m74998z,"Have been a ""data analyst"" in multiple companis both big and small and seems SQL + a BI tool are the main things, and some very basic stats knowledge like percentiles etc, not even hypothesis testing. And yet so many data analyst job listings demand python, DBT, advanced statistics, R etc, so I have just decided to upskill in all of these regardless of what my day job requires because the market is becoming very competitive and who knows what the minimum bar would be once AI evolves even more. I do struggle a lot with stakeholder management and haven't been able to find a proper way to learn it though and it's a key skill too.",1,1736871680.0
1i196lv,m749ef4,Sounds like the last role I was in which is a big reason I left.,1,1736871722.0
1i196lv,m74azl8,"Yep, which is why I spend more of my time working on process improvement projects or developing better practices for the ""story tellers"". I also spend a significant amount of time training the business on how proper data can make better decisions.",1,1736872193.0
1i196lv,m74cr6q,"I want to know that, Do you guys require hardware autoclicker??",1,1736872722.0
1i196lv,m74ef4f,"My insights consist of user segmentation so I can dive deeper into the data.

If you’re able to do advanced statistical stuff that people can understand and verify then sure.

Else there’s plenty of things to do",1,1736873212.0
1i196lv,m74sodo,if you can’t tell the story nothing else really matters.,1,1736877356.0
1i196lv,m74ug69,Are you working at a startup? or what kind of company?,1,1736877863.0
1i196lv,m74wvlx,"Data scientists roles will allow you to do more.  They seem to have fractured into people who do machine learning and people who do statistical analysis.

I don’t think it needs to be a tech company.  I work as a data scientist for very much not a tech company. We get interesting projects more than just data dumps.",1,1736878567.0
1i196lv,m7570sl,"Yes, a data analyst is a story teller. As far as using stats, there is a difference between saying ""the P value is >0.5"" vs, ""We can't be confident that the results are because of the test, it is possible that it's just random variance, we should run another test with these changes"".

I know people tend to think that people just want analysts to confirm their intuitions, I haven't experienced that. I have advanced in my career by giving people information counter to their intuition and translating the story the data tells into terms they can understand and helping identify a solution. No one wants to hear ""no that's wrong"", they want to hear ""That's wrong, here's why, here's what we should do to solve it""

The biggest red flag here is ""Python is not part of the toolkit"". If these means you are not allowed to use Python then that's a massive red flag. The time savings alone from automating repetitive ad hoc reports that don't justify a full dashboard alone is worth an FTE equivalent. I would be shocked if an organization had no users in the company using Python anywhere.",1,1736881482.0
1i196lv,m75dko0,"It’s actually worst. Data Analysts are story writers, they dont even tell the story. The story is told by upper management, we just code the story in.

I realized this shortly after pivoting to DA from finance, went back to finance which yeah has a lot of fiction in it as well but at least I get to sit on the big table every once in a while and actually drive some of the conversations.",1,1736883396.0
1i196lv,m75f4qg,"storytelling is the better part of it imo. the more advanced the methodology the less bankable the result. projects get method creep b/c the story isn't clear

my team is very heavy stats background with everyone except me having PhDs in quant fields. I find that I get the most done b/c I can be flexible and do a better job connecting w/ customers. it is nice however to have a team that understands when certain methods are a real value-add, although ime that is pretty rare

as for tools, a stat programming language is really useful even if you are not doing predictive modelling or ML",1,1736883850.0
1i196lv,m75xekz,You need to work where software engineering skillset intersects with analytics to escape these sorts of roles,1,1736889697.0
1i196lv,m762hv1,"It definitely depends on the position because what you are describing is more of a BI analyst. I am a data analyst of 10 years and the number of dashboards i created wouldn't pass 20. I am also clear on what i want during the interviews. I am a problem solver; i write scripts, automate existing reports, stay on the technical side. I absolutely hate visualization tools and try to stay away from those as much as possible.",1,1736891190.0
1i196lv,m762wia,Short answer use statistical tools and any software you want to find or develop the insights you need. If I buy a tv I don't need to know the background technology on how it was made,1,1736891308.0
1i196lv,m76d1xb,"Haha it sounds like Internal Audit, you can be the storyteller who says I found this which can results in x fine.

My job is to now exist before there's monitoring or to break one specific part.

We get the facts and then people argue about the story.",1,1736894350.0
1i196lv,m76x403,"Not to worry. AI is coming to the rescue and can get it done no matter what is needed. I know, not yet. But just give it the time.",1,1736900934.0
1i196lv,m774lin,"As much as many jobs are like this, these comments concern me with how much they downplay good analytics. Actually understanding how to pull numbers the RIGHT WAY. So that it's the most indicative of the hypothesis you are testing is really important. And just having writing/visual/story telling ability is half the battle. It's the part of the battle that will get you more kudos from leaders, yes unfortunately. But if you care about building a model or making decisions on a new feature/product etc. Correctly, you still need those math and analysis skills. 

If your job is only getting requests for visuals/data pulls maybe it doesn't matter much. But if you have agency in your job to decide how/what things are implemented you better have correct answers or else your ass might be on the line when results are shit/unexpected.

Or if someone is asking you to investigate the cause of a trend or to solve a business problem... being able to tell a story means nothing if you can't pick apart all the variables of the business that could be involved. Etc.",1,1736903476.0
1i196lv,m77a8rv,"Mostly the same.

I am working at a company were I just have to make a dashboard, without actually doing any analytical work.

For a budget presentation, they just read off of screenshots from the PowerBi dashboard and said ""we are up by 8%, goodnight everybody"".

I have been using this time to learn more about other systems for analytics and sharpen my skills in the background. However, when you are dealing with people who don't really know much about stats and analytics, it's mostly just re-telling them the information that they already have access to.",1,1736905428.0
1i196lv,m77pbrp,Most C suite executives are story tellers. So are you….,1,1736910762.0
1i196lv,m781dog,"Story tellers, spreadsheet Jockeys, and scapegoats. But it pays well…",1,1736915525.0
1i196lv,m76gte3,"I feel the underpinning of OP's post is around using bleeding edge ML to solve problems versus using mean/min/max with a few filters to solve problems.  In that case it depends on the questions getting asked and what, if any, actions that come from answering those questions.  


It basically breaks down into four types of questions, what happened, how did something happen, what might happen in the future, and what is the recommended action we should take. The bleeding edge stuff happens in question 4. Yes I know we have AI now, but AI for questions 1-3 is really more about replacing people. If you want to be bleeding edge (Python, R, Julia, C++, etc ..) then find a team that only answers question 4.


However, at the end of the day, it doesn't matter which one of the 4 questions you are answering, you need to be able to tell a story AND communicate your findings to your stakeholders. OK the recommended system you built says to axe product Z, why does it suggest that? You need to be able to speak to this in plain, non-technical language.",0,1736895536.0
1i196lv,m7595h1,Haha same,5,1736882107.0
1i196lv,m75aek1,On top of your masters did you take any analytics programs before applying?,5,1736882471.0
1i196lv,m74rhgf,Do you find it hard to compete in the market against more math-savvy analysts? I am a sociologist by education and am often frustrated because I feel like I'm lagging behind coworkers in math :(,4,1736877016.0
1i196lv,m750xdg,"There is a thin line between „let me help you be more efficient” and “I will automate your job away”
I think like some people justify their job by doing stupid repetitive tasks",6,1736879730.0
1i196lv,m74duyq,"That means that you're not being effective in your job. Which, as OP seems to understand, is primarily telling stories.",-5,1736873047.0
1i196lv,m7484fg,"Yes trends over time, doing some ratios... but that's all I'd say. I could do it but I don't have the support of my manager who see it as a loss of time.",4,1736871340.0
1i196lv,m777dlg,What is the next level of the stack?,1,1736904439.0
1i196lv,m76bjek,"hi, how do you train the new grads? do you have something like a list where they go through some resources? if so, could you please share it? thank you 🙏🏻",1,1736893885.0
1i196lv,m74uky4,what tool you use for segmentation?,1,1736877902.0
1i196lv,m75chpy,Well yeah. I also worked in the same industry for a decade so my domain knowledge is pretty good.,7,1736883078.0
1i196lv,m75ctm1,"Not really. Your math needs to be solid, but domain knowledge, creative solutioning, and storytelling is more important in my experience.",11,1736883175.0
1i196lv,m76c4ht,"Journalism major for me and not really. If you’re boss is very math heavy, you probably wont get on the team. If your boss is a business person (CMO,COO etc) its not bad",1,1736894065.0
1i196lv,m74fta1,"I get a good review every year and my manager and colleagues seem happy with my work. I just stopped pushing boulders uphill and stopped trying to change company culture. That never worked anyway, so why bother? Now I give people what they want. Even if I went above and beyond, what is it good for? The world is burning, my child is autistic, and I'll get replaced by AI or foreign workers soon anyway.",15,1736873618.0
1i196lv,m755ge5,"This sounds more like a leadership culture of wanting to look good in metrics, but these leaders do not understand how analysts can provide more value to the organization.",3,1736881031.0
1i196lv,m749b0j,"Then you should change team/manager. Try to end up in a setting where it is easier to succeed. It is definitely possible to do more advanced stuff, but it's all about trust and being able to show results. That gets easier if you have more domain knowledge, good stakeholders and so on. 

What industry/area at you working in?",4,1736871694.0
1i196lv,m7791pu,"If analyst sits on top, scientist would be between them and the engineer (or minimally horizontally equivalent). The scientists, or the engineers, are the ones you’d want to hang out with. That said, often times these roles are not that well defined and many of us around this subreddit likely take on the roles of all three at times.",2,1736905018.0
1i196lv,m75dfv3,Ah how would you compare using storytelling and technical communication skills vs hard analytics skills normally?,1,1736883357.0
1i196lv,m75f0px,"Exactly this. It’s one of the reasons why I value being able to engage with stakeholders very highly.

Anyone can create reports or get/clean some data but if you can’t make sense of it, tell a story and convey that to stakeholders then you’re not gonna get very far",3,1736883819.0
1i196lv,m75fd42,"As much as I agree with you, I hate that it’s true.",2,1736883917.0
1i196lv,m77uf7c,Good old capitalism at work haha,1,1736912687.0
1i196lv,m74doq0,Dirty lil secret: most business problems don't need statistical tests to understand 85% of the action needed.,19,1736872996.0
1i196lv,m74shaj,"I found the same in my career, if an org doesn't value advanced analytics, unless you are in a place of influence with a mandate to drive change and have support of the higher ups, it is better to leave. This aspect of company culture is close to impossible to be changed as an IC.",2,1736877300.0
1i196lv,m7641mt,"If you're gonna be the best, you need both. People get real fed up with analysts who can't speak in normal-people language.",3,1736891643.0
1i196lv,m772mzx,"I think you'd be surprised how many people can't properly pull data together.

Also imo the math and analytical side of data is less how to do basic pulls and calculations and more so understanding how to normalize data so that the conclusion/story is actually correct in context...

Many analysts don't know how to visualize or tell stories but there's also a ton that don't understand when to YoY, pre/post, look at things on a rate basis, look at a cohort group for control etc....

Which leads to people confidently telling stories stakeholders just take as truth when it was built on incomplete data.",2,1736902796.0
1i196lv,m74kv4k,"Not sure I would call that a secret, but you got a point, statistical tests are mainly useful when you can run randomized experiments. Depending on your stakeholders and company that may or not always be an option. But statistics is more than just statistical tests.

So to the point, if you're an analyst that wants to use statistics, then the easiest route is to find a role that allows you to do so.",3,1736875100.0
1i196lv,m74tt4u,"True, but you do need a solid understanding of variance, uncertainty and random processes, otherwise you will be caught out and over-interpret data (whether you realise that or not depends on how well you understand statistical concepts). 

Decision-makers not knowing their arse from their elbow on this sort of stuff is not an excuse for an analyst not to give a shit either.",3,1736877677.0
1i1j7vr,m76i2zl,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736895947.0
1i1j7vr,m76me19,"Well you could. Do you have experience with machine learning, stats modeling, or programming? You could probably learn some of that from a certification course, and that is the foundation of predictive analysis. 

I wouldn’t know who you should get certified through. If you want to pick up the skills, searching Coursera will probably yield some well reviewed responses. The topic is a great one to pursue.",2,1736897377.0
1i1j7vr,m76pjmg,"I’d be more impressed with a project than a paid coursera course. Meaning, if you can get away with auditing the course and saving yourself some dough, do so. Then use what you’ve learned at your current gig.",2,1736898420.0
1i1j7vr,m76mtjf,Thanks! I’ll look into Coursera,1,1736897520.0
1i1klda,m76tsk7,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736899832.0
1i1klda,m77us2g,"Wondering the same. I was trying to find more videos that took real world practical examples for data analysis. But was having a hard time finding something.

Obviously company names and some exact numbers would have to be fudged but I just want examples of real requests or business problems, how they decided on variables. How they pulled them. How they contextualize and normalize the findings. 

How did they ""story tell""? What did they present. Put in the forefront. Real world How they made visuals/dashboards.",2,1736912823.0
1i1lu49,m774il1,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736903448.0
1i1lu49,m775qw9,"that’s it boys, pack up, Joe Rogan says we’re done",67,1736903876.0
1i1lu49,m779ova,"Zuck bet big on the metaverse.

I wouldn’t really take his view on anything",29,1736905238.0
1i1lu49,m7793ua,Ohhhhh another AI post.,14,1736905038.0
1i1lu49,m775hn6,Probably wouldn’t trust joe Rogan or zuck on the topic…,26,1736903787.0
1i1lu49,m77ke04,"Maybe a lot maybe a little.  That can depend on your company as well as advances in LLMs.

The ceos want to get rid of people who write code* in every company because they are expensive.   Some companies claim they have eliminated some coders.  I think this will be harder with data than they think because most of what data people do is deal with bad data and to know where the bad data is you need experience in that particular database.

The more messy the underlying data the harder it is to replace the data person.

*code is sort of a catch all for anyone doing technical things.",5,1736908988.0
1i1lu49,m77b11e,"In a world without AGI, it's closer to copilot today, but maybe a better version of copilot. There may be some higher focus on model evaluation, or machine-learning engineering & architecture for DS.

In a world with AGI, it really doesn't matter.",2,1736905700.0
1i1lu49,m77pfrk,"Onwards and upwards. 

They’ve been saying these jobs are at risk for decades and yet, here we are

Someone, somewhere still needs to understand the unique nuance of the business and how to apply the output. 

Don’t be a code monkey.",2,1736910803.0
1i1lu49,m77dmxn,I don't know but you want to be connected to the business.   You can be the bridge to the computer.  Sort of a business analyst but for data. ,1,1736906603.0
1i1lu49,m77h1hv,This is how tech companies that have historically overpaid fix their problem.  Layoffs and then hire at a lesser salary and use AI as the scape goat.,1,1736907800.0
1i1lu49,m77qfbx,"AI will reduce the workload process for sure but will not replace human DS.

I doubt companies will be willing to share their confidential data to AI for it to process",1,1736911166.0
1i1lu49,m77tsbq,"Here’s my thought…  When you break it down our job is mostly decision support. We do analysis, provide beautiful dashboards, build great models and yet two executives looking at the same results still conclude two very different outcomes. Until executives replace themselves with AI… your data skills will always be useful. 

I’m going through a period of poor decision burnout out. I’m an associate director of BI at a Fortune 500 and have been thinking how much longer I can put up with sitting on the sidelines, thinking my next role maybe on the other side as a data consumer (Operations role, bus transformation maybe) and demonstrate how to make real data driven decisions.",1,1736912440.0
1i1lu49,m77wj71,"A CEO of a data science company once told me when ChatGPT first came out, “AI will not eliminate data scientists, but data scientists that don’t utilize AI will be eliminated.” There’s some truth to that, and I think he meant that AI as it stands now is a tool that will only make us better at what we do, but don’t fear it.",1,1736913511.0
1i1lu49,m77yiqe,"FYI COBOL was supposed to be absolute at least 2 decades ago but here we are still major Banks and Pharma use it for their mainframes.

And last place to take advice is from Jie Rogan podcast",1,1736914319.0
1i1lu49,m77d7a9,"It is a day that ends in Y, after all…",5,1736906452.0
1i1njjf,m77jiwu,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736908679.0
1i1njjf,m77p0nb,Blend at the data table level and not at the viz level.,1,1736910649.0
1i1njjf,m77slmz,Could you kindly detail a little bit better how to do this? I don’t edit looker studio reports that much so I don’t know how to do what you suggested :/,1,1736911985.0
1i18boz,m73wxfl,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736867902.0
1i18boz,m7413b6,"a job hiring an entry level person will not expect you to be producing for several months. if its a good environment w a good manager you will be ""doing projects"" that are mostly to train you on their systems and evaluate your skills to understand how you can fit into the team

no class prepares you for real data work because classes never feature access issues, database latency, large compute problems with tight deadlines, errors in data, missingness, bad spec, changing expectations etc. you can only learn that stuff by working which is ok. you are on the same page as anyone else starting a career",10,1736869205.0
1i18boz,m7450kt,"Doing some personal projects with real-world data would be a great way to bridge the gap, but as someone who made that leap within the past few years, it's not as bad as it seems. A good manager will know what they're getting hiring straight out of college and provide you with training and resources to learn what you need to know for your workflow. If you get hired it will be for your proven ""data brain"" and ability to learn, not necessarily what you already know. That said, as I mentioned, personal projects are a great way to take your prospects and knowledge to the next level (I did extensive work modeling distance running and Premier League, two interests of mine).",4,1736870392.0
1i18boz,m73yjyf,You’re a research analyst at this point. Without subject matter expertise it’ll be difficult. Especially with just a Bachelors,4,1736868415.0
1i18boz,m74630p,"The paths to a proper analytics role are … 

1. Get lucky enough to land an internship or new grad role at a company that has cohorts for those (usually big tech, consulting, some F500). These are extremely competitive and some companies hire from a small number of universities (in the US - Georgia Tech, UC Berkeley, etc). 

2. Pivot from something else. I pivoted from marketing to marketing analytics and *then* I enrolled in an MS Data Science program part-time while continuing to work. I have coworkers who pivoted from accounting, finance, business development, customer support, and software engineering. 

Most analytics/DS programs fail to mention that the majority of analytics/DS roles are not entry level. Most companies don’t view this as en entry level role and if they have an actual analytics team, it’s spread thin and they don’t have the capacity to properly train an entry level candidate. I never recommend that folks go straight from undergrad to a grad program in analytics or DS. I always recommend trying to get experience in anything first and also use tuition benefits. 

The few companies that do hire entry level roles are inundated with applications and can be extremely picky. Often they prefer to hire interns and then give return offers the following year to the strongest interns.",1,1736870718.0
1i18boz,m74la21,I was thinking the same,1,1736875219.0
1i18boz,m76ow01,"Related side topic then. I'm in a pretty similar situation as OP; my immediate supervisor isn't technically-trained. In my division, only myself and my teammate are handing data work. I would say I am ok in R and only know basic SQL (we don't use SQL) and I struggle to get my supervisor to improve my technical proficiency because they don't know it well in the first place.",1,1736898203.0
1i18boz,m73y184,"While you were studying, why didn't you go ahead of your curriculum to learn beyond what you were taught and do more research to know what to expect in the actual job market based on this niche?",-5,1736868253.0
1i18boz,m744yj0,"I agree, but there are some roles where there is only one data analyst in the team.  The op should avoid those roles because like you said a school doesn’t teach a lot of the day to day stuff.

For the OP we hired a couple people like you a couple years ago. They did dumb stuff in sql and Python.  I never looked over their visualizations but I assume they did dumb stuff there too. However that’s fine and expected.  Hell everyone does dumb stuff even after 10 years and as long as you are always trying to be better that’s fine.",8,1736870375.0
1i18boz,m748nr6,"What projects would you recommend? I see most jobs require SQL and Sheets or Excel and not many ask for Python, though I do know some decent Python. What level of complexity should the projects have?",2,1736871501.0
1i18boz,m749w47,I have a Computer Science background and worked in consulting for 2 years. Then did this MS program and did have a HR Analytics Internship and did some research while in school as well,1,1736871867.0
1i18boz,m77jyd6,What about AI tools like GPT and co pilot etc. do those help much?,1,1736908831.0
1i18boz,m73yv5a,"Yeah, OP, and you should’ve picked up neurosurgery too. Too late now, just move into your mom’s basement /s",11,1736868512.0
1i18boz,m740b13,"The assumption, and its a reasonable one, is that if you're spending 10s of thousands on an education, especially a masters degree, they will educate you on how to do the job the degree is named for.",3,1736868963.0
1i18boz,m748hrj,I did have an internship in HR analytics at a mid sized tech company and worked with complex SQL queries and made a HR dashboard with looker studio. It was hard as I was mostly on my own but I did get some experience and worked with stakeholders and used different systems. In hoping I can use this experience to get my next role,2,1736871451.0
1i18boz,m747zc5,Great advice and important point 👍,1,1736871296.0
1i18boz,m74fzld,"In reality (depends on your organization) most work can be split into the following categories: 
- building dashboards
- ad hoc analytics (business questions, this is dropping please find out why)
To get there you may take a range of approach and tools (again depends on your organization and what tech stack is available. How mature data culture is.)",3,1736873669.0
1i18boz,m74g31x,"It's all about your own interests. Excel is king and frankly a good Excel user can do just about everything an analyst will need to do (maybe throw in a data viz tool). SQL is extremely useful if it's a company that heavily uses a relational database, but Power Query can do most of the same stuff that SQL can do with a GUI instead of coding. 

As an example from my personal projects, I was interested in creating a unified track and field conversion calculator where inputting a time and distance would give you equivalent performances in standard events (and you could put in any intermediate distance, like 743m and convert it to an 800m time). I pulled data on various standard events, fit a nonlinear regression curve to it, and then used that equation to power a calculator. All of that was done in Excel.

Another example, I wanted to analyze the relationship between financial information (net spend, revenue, transfer fees, wages, etc.) and success (trophies, league position, etc.) of top 6 EPL clubs. This required pulling data on each of those variables, transforming it into tables with SQL, then visualizing each aspect in PowerBI, as well as some predictive modeling which was done with R (the visualizations were then added to PowerBI). So that used SQL, PowerBI, and R.",2,1736873697.0
1i18boz,m7573i8,In that case I would focus on people analytics roles or analytics/DS roles at consulting companies or agencies. Lean into the experience that you have. You can always get more choosy about roles later when you have more experience.,1,1736881505.0
1i18boz,m7416jl,Ouch 🤣🤣,-1,1736869232.0
1i18boz,m741pdn,"Assumptions huh? Oh well, growth is dynamic, learning is continuous. The main poster will be fine either way.",-1,1736869393.0
1i1osow,m77ujfo,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736912731.0
1i1efq3,m75dr1x,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736883447.0
1i1efq3,m75gsf7,January is a great time. Q1 in general is pretty good. Try not to limit on industry or get to specific on job titles.,10,1736884327.0
1i1efq3,m75iif2,"Hiring slows down in December but after the new year, and after budgets are approved, hiring picks up. It might still be early but I would say by the end of the month, open roles will be posted more often and recruiters will start following up for interviews.",3,1736884821.0
1i1efq3,m76oh1g,"Yea. The problem is that a lot of tech companies do their ‘bottom 10% productivity’ shaving from their staff every January. So you’re competing with people with excellent skills and more experience.

Ps. I’m employed and have been for a decade and even *I* wouldn’t ‘qualify’ for what these people are looking for: unicorns. If you’re a unicorn, yes apply.

Edit: I’m in higher ed and we are just now looking into adding another headcount. It’s surprising since a lot of departments have no idea if they’ll have continued funding due to the DC stuff. All that to say, I have no ide.",1,1736898065.0
1i1efq3,m75i00j,Is there any other job titles that I should add to my LinkedIn search? I have started to look for business analytics roles too and wondering if there’s any other areas to expand my search into,2,1736884673.0
1i1efq3,m75j7t7,That’s really reassuring! I needed to hear something positive 😃,1,1736885030.0
1i1efq3,m75k8z3,"You could try creating a couple different searches. One might just say “analyst”, or “data”, another for “analytics”, a different one for a product like tableau or sql.  Job titles are an absolute crap shoot which is why you might need to go broad. A company may have a role you’re looking for and they call it a data specialist. Also take a look at companies in your area and check out their job boards. Healthcare is always looking so you could check out some local hospital job boards.",5,1736885330.0
1i1akf5,m74g7wy,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736873736.0
1i1akf5,m755l9r,"I joined a bootcamp for the reasons you stated (structured curriculum, career coach, network), but in retrospect, I'm not sure if I would go that route again. A lot of the resources they used I could have learned for free. Even with the career coach, while they helped with building my resume and creating a job strategy, I could have gotten those resources for free through my public library (I live in the US).

I think if you have the discipline to self-study, it might be beneficial to go that route and then build project experience through volunteering opportunities where you can work with real data, freelance or develop your own side projects that you can showcase. Volunteering will also help to build your network since you'll be working with different individuals. Also, join data professional groups on LinkedIn, attend conferences, and do other activities to meet people.

Also, since you've already have experience with some DA tasks, it's worth trying to apply for jobs while you build your skill set.",1,1736881069.0
1i1akf5,m75a1l7,"I do not know what the job market is like in Europe but looking at what degrees you already have, your DA experience and actual business experience I think you could probably get a job now. Have you applied anywhere?",1,1736882367.0
1i1akf5,m75gwcr,"Thanks a lot for the answer ! Yeah i'm kinda starting to have the same feeling about bootcamps since you can learn everything yourself... 

I'm not familiar with data professional groups, what are those ?

Also do you gave websites or adive on how to find projects to volunteer for ? 

Thanks !",1,1736884358.0
1i1akf5,m75h7bh,"I still havent applied anywhere tbh, i know that i would pass the first screening but i consider i still dont have enough Python / SQL / PowerBI experience to be efficient. So i really want to be rock solid on those before even applying. 

Also have no portfolio for now",1,1736884447.0
1i1akf5,m76uiqq,"Of course! Honestly, I know I'm the type of person who needs structure and deadlines to hold me accountable, so the bootcamp was helpful in that sense. Outside of that, not too worth it. 

The data professional groups that I'm a part of on LinkedIn share different resources such as tips on how to use different analytic tools, best practices, webinars, sometimes job posts, and a chance to connect with others in the industry. There are probably different data professional groups outside of LinkedIn, which do the same. 

For volunteering, I've heard people using VolunteerMatch, Idealist,  Bluebonnet Data, and Statistics without Borders. Forage also has free ""internships"" where you can work with real data from companies with answers to the business problem being posed. You can also look to see if there are any events on meetup.com. I've seen different community groups hosting hackathons on there. I'm sure there are more opportunities available specific to your region, too. 

Although it may not necessarily be in the data analyst space, you could also use Lunchclub to network with people across different industries. 

Hope this helps!",1,1736900074.0
1i171jw,m73m8k6,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736864312.0
1i171jw,m74867c,"Learn product analytics tools and add them to your LinkedIn. Adobe Analytics, Google Analytics, Amplitude, Heap, Mixpanel, Pendo. Some of them have free product analytics courses on their website, presumably using their platform to learn.

Also make sure you are solid on experimentation specifically hypothesis testing (called A/B testing in product). Udacity has a course.",4,1736871355.0
1i171jw,m73oijs,if you looking for data analyst position you can dm me i will guide you how to crack the job interview,0,1736865117.0
1i171jw,m74brwv,"Sure, I will look into these! Thank you!",1,1736872430.0
1i171jw,m74k676,May i have some conversation regarding data analyst,1,1736874900.0
1i171jw,m74ljga,sure,1,1736875295.0
1i19sg5,m749ju1,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736871766.0
1i19sg5,m758e63,"Sounds really cool and would really love to know the factors influencing battery performance! 

* I worked at a place, where they were experimenting with Drones. Temperature was a big factor!
* How does battery degrade over time? 
* Optimal way to operate drones? \[Is that rotor speed etc\] And so on ...",1,1736881887.0
1i0l0i5,m6ymttz,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736793429.0
1i0l0i5,m6z7gsw,"I used an API to pull 15 years of play by play data for the NFL. Threw them in a local DB. Analyzed the data in Python. Built dashboards in Tableau. Used it to identify sleepers to target in my upcoming fantasy football draft. 

Got me a job as an analyst at a hotel company.",55,1736799429.0
1i0l0i5,m6yq3bv,"Did a survey of a product's community, got 2000 respondents, K-means'd them into 5 segments that I created profiles for, and also added a $ value to each",12,1736794376.0
1i0l0i5,m71flk9,"I had an interview with a consulting company that sent me a instacart dataset. I ended up not getting that job, but I put it on my resume and talking about that project got me a different job.",4,1736824764.0
1i0l0i5,m727thh,One power bi dashboard one python with sql project,1,1736837292.0
1i0l0i5,m76uehc,"How did the Google Data Analytics course go for you? I'm looking at that as well but found a free data engineering course, DE zoomcamp, that launched last week. I'm dint that now and am liking it but an still thinking about doing the GDA one next.",1,1736900034.0
1i0l0i5,m6zbmmr,"Interesting. I have hospitality already on my resume. Out of curiosity, whats the salary?",1,1736800646.0
1i0l0i5,m6zlc4e,How’d you do in the fantasy draft?,1,1736803463.0
1i0l0i5,m70385y,"hi! i wanted to start a project of what you just described, but with NBA data. is it ok if i PM you with some questions?",1,1736808858.0
1i0l0i5,m75xses,"That sounds awesome. I was thinking of doing aonwthibg aimilar for a much nerdier game - magic the gathering.

When was this if you don't mind me asking",1,1736889810.0
1i0l0i5,m771gny,Sent you a dm about this,1,1736902393.0
1i0l0i5,m73n807,Could you please elaborate on this bit ?,1,1736864663.0
1i0l0i5,m76wcz7,Google DA is really basic. Good start point for noobs but if you have a tech background you can skip/skim a lot. I passive learn the basics and actually learned how to use SQL at a very basic level.,2,1736900683.0
1i0l0i5,m6zgklq,"This happened in late 2019, so not sure how the market has adjusted to today, but I got hired at 90k and got a “raise” to 105k the next year. I used quotes around the work “raise” because it was really a counteroffer. I’ve since moved on from that company.",7,1736802081.0
1i0l0i5,m6zq8k8,Made the playoffs in 5/6 leagues. Won 4 of them.,7,1736804892.0
1i0l0i5,m70fmhm,Sure. Happy to help,1,1736812984.0
1i0l0i5,m748bwh,"Most analysts segment by discrete variables, whereas K means enables you to get a more complete picture of who's who in a community, ie kids, college students with no money but high engagement, professionals with disposable income but no time, parents with neither. And then you can basically say here's how much each of those groups accounted for your income this year and how much adding another one of those folks to your customer base would be worth to you. It's not hard to do, and the value is really apparent. Which is always a good combo in analytics.",2,1736871401.0
1i0l0i5,m6zhf20,"If I wanted to do this, how would I learn those skills?",1,1736802328.0
1i0l0i5,m71lt6s,Where did you find the dataset?,1,1736827006.0
1i0l0i5,m73geui,What types of statistics did you base your draft strategy around?,1,1736862161.0
1i0l0i5,m6zk1pr,"The question is a bit vague since you didn’t specify which skills you’re talking about, but generally speaking, I did a bootcamp that taught me the fundamentals of Python, SQL and Tableau. By fundamentals I mean data types (string v int v boolean v etc), control flow (if/else, loops, etc), data structures (lists, dictionaries, tuples, etc)

Then I just found something I was interested in and failed repeatedly until I succeeded.

PS: FWIW, the part in my original comment that got me the job was the last sentence. The tools are cool, but it’s what you do with them that matters.",9,1736803085.0
1i0l0i5,m72fm47,Sportradar API was free back then. They were just launching. Not sure where you would find something similar now. I think there are datasets on github. Or just Google for APIs,2,1736842010.0
1i0l0i5,m7553ke,"I don't remember fully since this was 5 years ago, but it was nothing advanced. I'm not good with advanced stats. Just some simple correlations of various metrics with end of year performance. For example, (making this up) the top 20% of WRs had a average depth of target higher than 12 yards and a target share above 20%. Which WRs hit those marks in the previous year but underperformed expectations. Rinse & repeat.",1,1736880930.0
1i0l0i5,m6zklc5,I know a bit of python and I know sql although I dunno tableau.,1,1736803244.0
1i0l0i5,m73pyzw,Hmm I wonder if there are any for college? I got the 1.01 in my dynasty lol,1,1736865624.0
1i0l0i5,m6zl5mw,"I edited after you commented, but doesn’t matter that you don’t know tableau. If you learned SQL and Python you can learn Tableau. 

Also, the tools themselves don’t matter as much as beginners tend to think. What matters is what you do with the information. Your problem solving skills, critical thinking, analytical reasoning, determination, etc. The best analysts i’ve met are the right mix of stubborn and lazy.",3,1736803410.0
1i0l0i5,m708265,"Currently I am doing the Google Data Analytics course (basic fundamentals, I know) and Alex the Analyst Data Analyst boot camp (free YT series), which will be followed up with the Google Advanced course and their Business Intelligence course as well. Do you have other recommendations as well?",1,1736810434.0
1i0l0i5,m70qxnd,"Im not familiar with any of these but in general, stop doing courses as soon as possible. Probably before you feel like you’re ready. Start building something as soon as possible. 

Look up the concept of Tutorial Hell",1,1736816752.0
1i15z8z,m73dnlz,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736861105.0
1i15z8z,m748hxx,StrataScratch for SQL,2,1736871453.0
1i15z8z,m73hs1f,I'd start with leetcode and hackerrank,1,1736862675.0
1i15z8z,m73e5mr,"Just be yourself

If you’re qualified for the role you won’t need to practice",-2,1736861298.0
1i15z8z,m74antt,"In addition to SQL, StrataScratch also has python, pandas, and other popular languages like pySpark and Polars. You can answer the questions in any languages so it's good if you're trying to learn a new language and only know 1 language. For example, if you only know SQL and want to learn Pandas, then you can see read the SQL code and see how it would ""convert"" to pandas.",2,1736872096.0
1i15z8z,m73ecml,Can you explain ⬆️,0,1736861373.0
1i15z8z,m73egy6,If you’re qualified for a role and the requirements then why do you need to practice?,1,1736861420.0
1i15z8z,m73fb87,To improve my skills further.,0,1736861744.0
1i15z8z,m73fldw,"Then jt is a skill issue and not an interview issue.

You should focus on:
- fundamentals
- critical thinking 
- research 

Trying to jump straight to interview prep before doing that is pretty silly and counterproductive. No offense.",-4,1736861852.0
1i19n03,m748965,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736871379.0
1i0v2kv,m7101w6,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736819726.0
1i0v2kv,m718jrj,"I’m the only one building out the entire department’s reporting needs in a Fortune 50. I’m setting up the data pipelines, making the dashboards, cleaning up the old dashboards or completely remaking them, and writing all documentation 🙃 sometimes I do wish there was someone else but I do enjoy that no one has any idea of how long anything I do takes so I can set my own pace and schedule and goals",26,1736822425.0
1i0v2kv,m712odf,My team part of large tech company and there’s 35 of us that includes analysts and data engineers.,8,1736820552.0
1i0v2kv,m716lyp,"A manager, 2 TM1 (Planning analytics dev), 1 architect/do it all (me), 1 SQL dev for ETL/ELT, and 1 Qlik Dev for reporting. We used to have some superusers in departments that would take some of the load of creating dashboards/reports but they either all left or changed roles and no longer have time for it.

I say do it all because I've done all the roles at this point and most of my experience is in SQL I've also used Qlik Sense for the last 5 years now and was solo in Qlik for 3 of the 5 years.

We support around 500 users in Qlik alone.

The team feels a bit too small at times, and we could benefit from another dev with some data engineering knowledge.",5,1736821816.0
1i0v2kv,m71elqz,"I’m at a large global company on a centralized analytics team that supports multiple functions - product, sales, supply, finance, marketing. We have about 30 analysts, data scientists, BI developers.",4,1736824416.0
1i0v2kv,m71uk8o,I am also only soul for analytics Domain so it's ok you will learn a lot,2,1736830551.0
1i0v2kv,m71vxuc,"1000+ person tech company (quite data oriented in that a big chunk of our business is data oriented but trying to become more data driven)

20-25 data analysts including managers (working similarly to analytics engineers). that doesn't include data scientists or engineers",2,1736831174.0
1i0v2kv,m74b6ju,"I work for an international retailer and my department alone has 50 data Scientist + management.

I know we have other departments, that have data analysts, data engineers, business analysts, etc.

My department is in the international HQ. Each country has their own DS team with 1-5 people, too.

We meet once per year during a conference....like 200-250 people total. I think there is nothing much bigger in terms of scale.",2,1736872252.0
1i0v2kv,m71itiu,"We have 9 people. One manager, one manager/analyst and one PM.  One of us acts in a dba type role in addition to some other work.  We are a Fortune 500 company.  There are a couple other data teams out there as the company is somewhat decentralized.",1,1736825912.0
1i0v2kv,m73a1qh,"We have a large team at my company, maybe 20~ DAs, they all work within their verticals that have specific stakeholders and their own DA managers, 5 AEs, and a bunch of DEs and DSs. I work in tech. We have a modern tech stack too. I don’t remember the last time I touched excel. I’ve worked with smaller companies where I was the only DA and then this larger company. I much prefer this larger company. I learned a lot more here.",1,1736859643.0
1i0v2kv,m73lh0b,2 person in a start up (data scientist and engineer) — employee count at this company is around 25 from which half dev,1,1736864039.0
1i0v2kv,m74ymc8,"Only data analyst in a 100+ employees company, while also having to do some database cleaning, and various scriptings for data crawling, processing.. 

Sometimes it gets tough but at least there is no inside competition",1,1736879066.0
1i0v2kv,m77ebj6,I'm the only analyst in my company at like 200mil yearly revenue. I need a raise...,1,1736906844.0
1i0v2kv,m72plcx,And how does AI fit in down the road? You’re all looking for jobs?,-1,1736848615.0
1i0v2kv,m72o045,"Haha I am in a similar situation. Nobody in my team knows what I do or how I do it and how long it takes. They just see the results. I enjoy the freedom of not working in a structured, agile team environment.",5,1736847571.0
1i0v2kv,m73zhfc,But my issue is I have no one to learn a lot from. I’ve worked a contract role where there was a more experienced analyst alongside me but they left the company after a couple of months into my tenure then I was back to being by myself. I feel like I learned a good amount from them during their little time there but I’ve never really had someone that’s more senior to work alongside who could show me a different perspective into how to do my job better.,1,1736868705.0
1i0v2kv,m732qrg,[deleted],1,1736856313.0
1i0v2kv,m749teq,i also don't have any senior i manage to learn from experience guy who has done good in data domain,1,1736871845.0
1i0v2kv,m76rdrn,And helped train the LLM models. Clever little bugger. Helps you then take your job. But it is going to be the thing if the future. We can all go to the beach and get paid while the machines do the work.,1,1736899030.0
1i0v2kv,m7351ot,I am sure. But will it replace you. Analytics seem right down its alley.,-1,1736857418.0
1i0v2kv,m73u5fu,Crazy how no one has made an AI tool that's even vaguely good at analytics then lol,6,1736867013.0
1i0v2kv,m76r1jz,Give it time. It will come I think. Probably catching bigger fish at the moment.,0,1736898917.0
1i0y95h,m71slf7,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736829690.0
1i0y95h,m71up2g,"There are three things you need to ask yourself
Do you like your current role?
Do you like research?
Is the money as good or better?",2,1736830611.0
1i0y95h,m721uom,What do you mean by how the move will be perceived?,1,1736834036.0
1i0y95h,m73lh1a,What are the actually responsibilities of the role? Some companies use “Analyst” not just for data analyst roles but basically for specialist roles. My husband is in government/politics and Political Analyst roles definitely are not the same as Data Analyst roles.,1,1736864039.0
1i0y95h,m722299,I mean in the sense that future job recruiters may think I can’t handle a pure data analyst role and changed careers because of it.,1,1736834146.0
1i0y95h,m73tfwk,"Yeah that’s kind of what I’m confused/concerned about here are the responsibilities of the role:

“- Maximize profitability for marketing opportunities while paving the way for future growth and automation 
- Ownership over Profit/Loss for pay per click (PPC) marketing campaigns
- Creation, syndication, and management of pay per click campaigns
- Management of tests and experiments
- Develop and refine processes, bidding strategies, documentation and automation 
- Competitive intelligence research
- Leverage various statistical techniques to analyze data sets to discover trends/patterns to make predictions and business strategy suggestions
- Data integrity
- Follows project management from idea to implementation“",1,1736866781.0
1i0y95h,m723e0d,"I think titles are pretty flexible so use the job title that will help you land a job, within reason.  If you’re a data analyst 1 don’t say you’re a data scientist or data engineer, but if you use sql and visualization tools that’s data analysis and no one would bat an eye if you called that roll marketing/data analyst.",3,1736834837.0
1i0y95h,m746yws,As someone who has worked in both marketing roles and marketing analytics roles - this is primarily a marketing role that has a lot of data responsibilities. This is not strictly an analytics role. You will be implementing PPC campaigns and managing projects in addition to analyzing them.,1,1736870989.0
1i1dxku,m759erm,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736882182.0
1i1dxku,m75adu2,"Sounds pretty good to me, especially considering all the posts I see on here of people trying to get into the field. Take the job and most likely you’ll have more opportunities with better pay in the future.",47,1736882465.0
1i1dxku,m75dozr,Why did you think you would be making more? Did you do research for that position in your area with your experience? I personally think it’s right where it needs to be for someone who has little experience (presumably).,17,1736883430.0
1i1dxku,m75ejjp,"$74k is fine, I started at $40k about 10 years ago.  Take advantage of the tuition reimbursement. This isn’t the only job you’ll ever have so getting some experience as soon as possible is good.",12,1736883679.0
1i1dxku,m75gsg4,"The job market sucks, honestly you’re lucky to get any offer as a new grad. Take it but don’t stop applying/interviewing. Even if you rescind, you wouldn’t be the first to do so.

Also if you’re in the US, the media salary for Data Analysts is $82k. That’s for all Data Analysts, experienced or not. Being 10% below that as a new grad is great. I’m pretty sure my company offers around $60k on the rare occasion that they hire a truly entry level candidate.",11,1736884327.0
1i1dxku,m75fyni,"I’m going to be fascinated over the next few years to see how things work out for this generation of new grads who are remote first. Like, will you be able to make the connections at work to get promoted? Will you find some way to get yourself pulled into reach projects that can help you grow? Will you be able to be successful in organizations where most knowledge is implicit? I wish you the best but I’d also encourage you to make sure your priorities are set in the way that best serves your career goals.",7,1736884091.0
1i1dxku,m75plvp,I started out at 40k as a data analyst in 2022. 74k you're doing alright.,3,1736886968.0
1i1dxku,m759y30,why do you have to move if you get to work remotely?,4,1736882338.0
1i1dxku,m75b5y8,"Depends on what your role is, industry, benefits, COL, etc. 74k is meaningless without more info.",3,1736882692.0
1i1dxku,m75m209,My first job out of undergrad paid $30k. My first proper analytics job 6 months later in 2015 paid $60k,1,1736885854.0
1i1dxku,m75mkdr,"I once moved out of state for $55k (this was eons ago) but they also offered $5k sign on bonus which was used for moving expenses. If they’re a private company, see if they’ll do a sign on instead.",1,1736886003.0
1i1dxku,m75mr80,"It's actually pretty good salary unless you are moving to an expensive state like CA or NY as examples.

You have to live in the state or area because the company has to pay taxss. In the jurisdiction you work in.  So if they don't have a branch where you currently live they need u to move to keep costs down",1,1736886059.0
1i1dxku,m75w9ii,"No, it's not, especially if it's your only job offer. Don't expect six figure starting salaries outside of big tech.",1,1736889357.0
1i1dxku,m75yvjf,"That's some next-level humble bragging here. 74k is usually only attained when you are a mid-level analyst, for a new grad it's insane. What did you have in mind, 100k? That would require being a Data Scientist or ML Engineer or something.",1,1736890124.0
1i1dxku,m75ywi9,"There are positions in my area that are less than 50k for new grad, less than 70k for senior. And that's canadian, so take about 25% off to convert to USD. 74k USD being ""too low"" for a new grad has got to be a high COL area.....or is Canada actually that far behind in real wages? We know it's behind, but people assume 10-20%. Not 60%.",1,1736890132.0
1i1dxku,m766y1g,"I was going to say ""take the job"" at first.. but I changed my mind.  

While I think the perks sound great, moving for the job if it's remote anyways sounds like a red flag to me.  Maybe it's just where they have their company registered, etc. but to me it sounds like a soft way of starting to get people to RTO.  

Also, 1/3 of your workweek is spent at your job, the other 1/3 sleeping (hopefully).  Do you want to spend the other 1/3 left and your weekends not liking where you live?  I passed up a few opportunities because they would require me to move.  Maybe that's just more important to me, but it sounds like it was important enough to you to mention it twice in your post, so I wouldn't ignore that gut feeling.",1,1736892496.0
1i1dxku,m75c117,"Why do you feel it’s too low? You said it’s quite boring. Why is it boring? 

It seems that horde trying to find reasons not to accept the job. If you feel that strongly, you may just want to reject the offer. Trust me, no one wants to be around or work with anyone with shitty energy. You’ll throw the team dynamic off. If you don’t want the job, don’t take it.",1,1736882943.0
1i1dxku,m75hz5t,"Thank you for your advice. I really appreciate it. I also think about it that way, since I don’t have a lot of options as a new grad. I think It’ll only get better from here.",4,1736884667.0
1i1dxku,m75hbck,"Thank you so much for your advice. I also think it’s really good to have experience now. I’m grateful for the offer, so I’ll just use it as a learning experience for the first couple years.",1,1736884478.0
1i1dxku,m75hmr5,Thank you for your advice. I appreciate it. I’m really grateful and lucky that I have this opportunity as a new grad. Cause I know the job market is quite bad right now. That’s what I’m doing. I’m still applying and interviewing to see if there are other opportunities for me. ,1,1736884568.0
1i1dxku,m75za97,"WFH doesn't cause someone to lose a lifetime of social skills....this reeks of ""those danged kids these days""!",3,1736890246.0
1i1dxku,m75hxbi,It is *so* much harder to get the level of visibility you need for a promotion when you are remote vs in-person. Also it’s a lot harder to get mentorship (direct or indirect via conversations and observation).,3,1736884652.0
1i1dxku,m75autl,"Chances are some states are allowed for remote work and some aren’t. Each state has different regulations, taxes, etc. I worked for a fully remote company that hired globally but not in all 50 states.

That said, if it’s remote there should at least be some options. Odd that remote would require working in a specific state, unless that’s where HQ is or something.",6,1736882601.0
1i1dxku,m75bcbr,"Labor laws are different state to state whether you are working remote or not.  If you reside in a state different than your employer, your employer may have to step through extra legal hoops for you and it doesn't sound like they're willing to do that here.",4,1736882744.0
1i1dxku,m75aq13,"I’m also questioning that. But it’s not totally remote, they said I need to be in the office 4 times a year. They said I have to be within 50 miles radius from the office. I feel like I can just fly there whenever they need me.

I have not been talking to them and sorting out this problem because I’m still applying and trying to see if I can land other offers. But I will definitely talk to them about this once it’s closer to starting date.",3,1736882563.0
1i1dxku,m75bsc7,"DA role, tuition reimbursement, 401k, 35 PTO, state: West coast but not like California or Washington cost of living, Fortune 500 company",3,1736882872.0
1i1dxku,m75n6r7,Yeah and to be clear it’s not a bite the bullet on the first job and then things will be fine. All my jobs even the ones I really liked had trade offs and suck a lot if not most of the time.,2,1736886184.0
1i1dxku,m75tw6b,"Plenty of people super commute.  I don’t think remote but based in a hub city is that unconventional…I’ve came across it at some tech companies. 

Is there an address of a family member or friend that you can use as your residence? This is technically illegal from a tax perspective, but who cares…

74k isn’t too low but always negotiate.  Ask for 15% more…say you have another offer at 90k, but you really enjoyed your internship there.  Worse case scenario they say sorry we can’t budge.  Ask for a relocation bonus. 

Regardless you can always accept and find a new job. It’s a tough market out there.",1,1736888636.0
1i1dxku,m76la0o,This honestly sounds like they're setting up for RTO down the line,1,1736897005.0
1i1dxku,m75cr4v,"35 days PTO? Holy crap, thats awesome",7,1736883154.0
1i1dxku,m75fzfi,"Your salary sounds in range for entry level. Although industry is important. Tech will pay more than healthcare/manufacturing for example. 

Are they providing any moving costs?   

Also doesn’t hurt to negotiate salary, sign on bonus, extra pto. Your entry so don’t be shocked if they tell you no.",1,1736884098.0
1i1dxku,m76o2ry,"Tbh, I’ve been interning there for 2 years and I don’t think so. 90% people work remote + hybrid. I don’t even know anyone in the company work in person 100%, at least in the IT department. Whenever I visit the office, it’s so empty. I know all the data scientists, swe, and MLE get to do remote work. But I don’t know why they told me data analysts are not eligible for remote",1,1736897934.0
1i1dxku,m75d611,But that’s also including national holidays I think. It’s still amazing regardless ,3,1736883276.0
1i1dxku,m75hii4,"I think my company starts at 33 days PTO if you’re counting vacation (15), sick (10), and holidays (8).",2,1736884534.0
1i1dxku,m75gsh7,"Thank you for answer. This is not in tech, so I get it. I did try to negotiate and they only bumped it up a little bit. They also don’t provide any moving cost either. I’m really happy and grateful to receive an offer anyways. I’m also just hoping to get paid more 😅 (typical employee mindset) but I understand since I’m a new grad. ",3,1736884328.0
1i1dxku,m75e2ar,I have unlimited PTO and 35 days is phenomenal. Way more than most people take.,3,1736883539.0
1i1dxku,m75i8s4,"Offers are great!  Keep in mind this job is a stepping stone not your final destination. Learning and career development is crucial. If you like your boss/team, the org promotes from within and is healthy then that can be worth more than finding a job that pays 90 and has none of those things.",3,1736884743.0
1i1dxku,m75m75s,"Starting to sound like you’re joining UC system. If so, yes that is a decent start. You’ll need to move around to get raises as we barely get CoL increases.",1,1736885896.0
1i0u7q9,m70saot,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736817199.0
1i0u7q9,m70tqaw,"Really entirely dependent on your audience.

Most of my work is intended to travel cross functionally.

One sentence insight. Optional one sentence observation/description of the underlying data. One sentence recommended action. One chart.

No appendix no notes no frills. “Here’s this thing. Maybe you care about why this thing. Here is the recommended path forward/decision for the problem. Here’s a chart.”",4,1736817668.0
1i0u7q9,m70vret,Who cares. Just explain it clearly and in simple terms. Stop overthinking small things,5,1736818331.0
1i0u7q9,m70yxrb,"Obviously take your time to perfect an executive presentation, but otherwise just do your best without overthinking it. People will ask questions if they don’t understand something. And over time you’ll get better at explaining complex concepts simply and anticipating what questions will be asked.",1,1736819361.0
1i0u7q9,m712t8k,"It really depends on format, audience, and what you need to convey. I strongly recommend looking out for somebody you consider good at this and asking them to critique your drafts, because there’s no one size fits all. It is the perfect job for a mentor. Seriously consider people from other expertises (like account managers or project managers).


The great news is…you are worrying about something that is (1) an extremely valuable skill to develop (anyone who says otherwise is probably terrible at it) and (2) the fact that you are worrying about it means you have recognized one of your own areas for improvement! This is tremendously valuable for your own career development. Well done!",1,1736820593.0
1i0u7q9,m71z3jz,Hmm why no appendix? Don’t you need a place for prior art? I usually gray it out but it’s possible to read.,1,1736832662.0
1i0u7q9,m71yn9l,"My boss cared. He would torture me every day for 2.5 yrs, evaluating the vast majority of my docs, messages in channels with a lot of leadership or stakeholders, and presentations. Nothing was ever optimized enough. I haven’t forgotten our punishing editing sessions. Since everyone loved his work, I thought I must do what he recommends. However, when I presented a few times without his input, everything was fine. I guess he was insane and made me neurotic in the process.",2,1736832441.0
1i0u7q9,m71zc44,Thanks!,1,1736832776.0
1i0u7q9,m71ztpu,"Because everyone already trusts that you did the work.

So unless someone asks for it, it's just bloat.",2,1736833016.0
1i0u7q9,m76lfsv,He sounds like a loser,1,1736897059.0
1i0oyno,m6zkbv1,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736803168.0
1i0oyno,m6zn7rz,"CS is a strong technical degree - though the fact you got rejected for Data Science and got offered CS really wants me to look into the curriculum. Usually CS major for Master's is far more selective and difficult than Data Science.

The field of analytics is mostly about experience in the field. So while you're in university try your best to get some form of internship experience.",17,1736804009.0
1i0oyno,m6zqbcv,"I have never heard of someone being rejected from a DS program and offered instead a CS program. Would expect the other way around. 

You can definitely go into analytics with a CS degree. Take some stats electives if you can.",12,1736804914.0
1i0oyno,m6znc7c,I think you should figure out what area you want to focus on first,6,1736804044.0
1i0oyno,m6zwcqa,I got a MSC and been in supply chain analytics for the last two years when I graduated. Its possible. Dont be like everyone else and think you need to work at a large tech company or startup.,2,1736806720.0
1i0oyno,m70czgm,"If I had a cs degree , I would consider data engineering.  Would pay more",2,1736812096.0
1i0oyno,m6zppjj,"Yea, you can. However, to advance your career in this market, you typically need some sort of background in the industry you're analyzing.",1,1736804739.0
1i0oyno,m6zyp8m,I have the same degrees but reversed (B.S. CS and MBA) and I’ve been working in analytics for 12 years.  Your only issue might be lack of exposure to statistics/predictive techniques in the CS program,1,1736807440.0
1i0oyno,m70lbqc,You can work in analytics without a degree so yes this is great. We hire for relevant skills and relevant experience rather than relevant degree.,1,1736814883.0
1i0oyno,m70y7n3,Sure just apply until you find something.,1,1736819123.0
1i0oyno,m71w89t,"You can do it with a bachelors in business without computer science.
Though, at the moment, I would advise anyone to stay away from this field.",1,1736831309.0
1i0oyno,m73jsk1,"I have a master in research and i work in analytics , id say yes, why not.

I was also scared in the beginning when i switched fields but if youre eager to learn, even in your free time, at least in the beginning, i say youll be fine. Ive noticed people really appreciate those who are enthusiats and  willing to learn anything that helps do the job",1,1736863420.0
1i0oyno,m77d5ie,"Yes, as long as you have domain knwledge you can do it without problems.",1,1736906434.0
1i0oyno,m6zwvx4,"CS seems out of alignment with your goal. If you applied to a analytics program, I could see them asking you to join the data science cohort instead based on your CS background. If you want to build models and write algorithms and leverage data matrices to solve business problems, go with DS.",1,1736806882.0
1i0oyno,m6zqxz1,May be a recent trend with all the AI hype / media coverage of job market for SWE over the past year.,3,1736805097.0
1i0oyno,m6zslvx,"Must be. This is just an anecdote, but I know of an Analytics program at an Ivy that is often talked about as a cash cow, and they don’t publish their admit rate but people at the Uni complain that it’s on the high side. I learned through a reliable connection on the admission committee that their admit rates used to be over 75%, and recently it’s fallen to under 20% with so many applicants.",3,1736805583.0
1i0oyno,m6zxcln,"To be fair, masters degrees at every university is a cash cow, especially STEM-designated programs.",4,1736807025.0
1i0jsim,m6yclaq,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736790483.0
1i0jsim,m6yfrft,"Data Science is certainly a career path, but in the real world I think you’ll find that what most companies actually need are Data Engineers. Even Data Scientist roles are starting to look more like ML Ops these days. None of the fancy models will matter if you don’t have solid infrastructure underneath and I’m telling you right now that most businesses don’t.",5,1736791391.0
1i0jsim,m6yoqa9,"If you want versatility towards business roles like PM, BA, etc. I think MIS is a good choice. If you want versatility towards technical roles like DS, DE, SWE, MLE, etc. I would recommend CS instead of DS or MIS.",4,1736793979.0
1i0jsim,m6ycwn8,"Sorry if this post isn't directly about analytics, I feel like it all falls into the same category anyways.",1,1736790573.0
1i0jsim,m6yi2qi,Tagging along to his - have you seen any Master's of Science in Business Analytics programs? I've been in between that and the MSDS. Wondering if that would also give you versatility that you're looking for!,1,1736792064.0
1i0jsim,m6zjdv8,"I have my A.S. in Computer Science and graduate soon with my B.S. in Data Science while working as a Cloud admin. From my experience, the skills I learn from DS has a huge benefit in cloud roles. Being able to clean data then have insights by using ML is amazing and companies love that. Also, if you decide to transite to more AI and ML, you’ll have the experience with that. My recommendation is to get cloud certifications as well like AWS and Azure so that jobs can come to you.",1,1736802894.0
1i0jsim,m70ailz,"MIS sound technical but aren't technical at all, I feel it was the BA/DS degrees of the early 2000s, they seem like the degree for consulting types of jobs in project management and digital transformation. One way to know if a DS degree is a money grab is if half of their courses are business with much technical and stats. A good DS degree should contain a good amount of stats courses.",1,1736811258.0
1i0jsim,m6zahng,Why do you think data engineers are needed more than data science? Isn’t the rise of AI mean more DS roles?,1,1736800314.0
1i0jsim,m73cc2b,They don't. They all run on excel. And I'm not even talking reports. I'm talking pipelines,1,1736860583.0
1i0jsim,m6zoo4c,"Hey brother, do you mind if I DM u",1,1736804432.0
1i0jsim,m72b9iz,"Not true. It’s true MIS focuses on IS as a whole, but since IT is part of IS, MIS majors do learn technical skills. After all, it’s hard to be a consultant when you don’t have any technical knowledge.

How technical it gets depends on the program. In some colleges, MIS is a business degree, but in others MIS is a STEM degree.",1,1736839317.0
1i0jsim,m6zbzi2,"Not original commenter; however, data science relies on relatively clean data for a model to hopefully work well (ie. Crude in, crude out). Many organizations imo could benefit from better data quality / availability which ideally a data engineer would assist with rather than a data scientist",3,1736800750.0
1i0jsim,m6ze8ox,Data Engineers build the reliable data model context that AI depends on to perform well. They'd also be more useful for deploying the infrastructure AI relies on. If anything I think the rise of AI means DS roles will be needed less with more use cases covered by out-of-the-box AI models and prompts.,3,1736801410.0
1i0jsim,m73e94f,Every day a Data Scientist shows up to their new job and asks where the infrastructure is.,3,1736861336.0
1i0jsim,m6zstoi,Of course!,1,1736805647.0
1i0jsim,m76kpe6,"Hey man, I also have a couple of questions, hope you don't mind if I sent you one too",1,1736896813.0
1i0mmj3,m6z0hiq,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736797392.0
1i0mmj3,m71pwam,Choose something different before it's too late to change. Over saturated now!,1,1736828562.0
1i0mmj3,m712qjw,"- Calculus and linear algebra as prereqs
- Python programming, possibly Java as well
- Problem solving, like looking up the program's admissions page by yourself so you don't look like an idiot",1,1736820570.0
1i0l1yo,m6yn6nu,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736793532.0
1i0l1yo,m77avvb,"In most cases, you’ll need a dedicated server that’s always running to refresh without interruption, unless you want to keep your machine idle.

For now, why not link your sharepoint to one drive on file explorer and just put in the path of the file as a data source?  No api needed on desktop since it’s a native connection — but for refreshing on bi service you might just need a gateway with a connection (under “manage gateways and connections” in power bi service). The gateway points to the machine and the connection stores the credentials of the service account with the sharepoint linked file explorer.  

At that point,  you’d be better off with a dedicated server, at which point you may as well do the on prem sql server and store those files as tables. 

Look up linking sharepoint to file explorer and start there. Automating a refresh from a path to a semantic model via a gateway is the final battle.

Oh and consider converting the excel file to a csv.",1,1736905651.0
1i0ku21,m6ylcxj,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736793003.0
1i0ku21,m6z2rnu,"Any course is worth learning if you’re interested in it and you want to make progress in your skills. But of course the question is exactly what is it you are interested in and how you want to develop.

But - if you mean what courses are worth it because they can get you a job, the answer is basically none of them.",6,1736798048.0
1i0ku21,m73ccyr,"Google Data Analytics Professional Certificate is a self-paced program estimated to take around 155 hours to complete, typically over six months at 10 hours per week. However, completion time varies—some finish in two months with intensive effort, while others take longer. It's flexible and designed for beginners, offering a solid foundation in data analytics skills.
To practice alongside this course, you can use platforms like StrataScratch and Kaggle for datasets and challenges and Mode Analytics for SQL tutorials.",2,1736860593.0
1i0ku21,m6zeckx,"I'm currently doing a LinkedIn Data Cleaning Challenge with Excel which is free. Awesome learning experience I tell you because my Excel abilities have been basic so far.

DataCamp is a good resource to learn be it Excel, PowerBI or Tableau or Python I think. You have tons of videos on YouTube you can follow.

One of my guides in Analytics is Alex the Analyst on YouTube. Look out for his channel.",1,1736801441.0
1i0ku21,m73fzd3,Can I learn it let's say today 5 hours a day and than 2 hour per day or they have their own schedule?,1,1736861998.0
1i0ku21,m73gtjj,">self-paced

Reading instructions might be your biggest hurdle",1,1736862314.0
1i0ku21,m73h6v0,"Unfortunately I didn't read instructions, currently I am trying to consider best options what to learn with experience from people. I flew over the text. Thanks",1,1736862454.0
1i0jxzk,m6ydwvg,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736790859.0
1i0jxzk,m74szdu,"Udemy is the best, you can have a portfolio that will help as well",1,1736877443.0
1i0059n,m6tx4t4,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736724335.0
1i0059n,m6u3o9e,Depending on where you’re based and industry you are looking at will matter a lot. I’d say on average somewhere between 60-80k with those quals.,20,1736726448.0
1i0059n,m6tyu55,I recently started an entry level data analyst position at an insurance company and my base is 82k in a HCOL. Masters and 2 previous relevant internships.,13,1736724898.0
1i0059n,m6tzv9l,We’re not very HCOL and our entry level is $65-75 + about $5k/year bonus. But we’re getting 100 resumes a week when we post a position. ,7,1736725231.0
1i0059n,m6tyht3,Market has been reset. As an AD at an analytics consulting firm - we're offering $50-55k looking for those qualifications and getting more applicants than we know what to do with.,21,1736724787.0
1i0059n,m6ty933,"I'm still a masters student, and received an offer for $100k base comp last week. 

I'd assume $70k - $100k is typical? Largely dependent on your cities cost of living.",9,1736724707.0
1i0059n,m6u1mmm,"To start a new response -  You have great qualifications, my advice would be to take anything you can get at the moment (within reason) and put in 6-12 months then start looking again. Gain some experience and sign up for as many projects you can to add 'soft skills' to your resume.  You will be in a much better position!",3,1736725794.0
1i0059n,m6v4t6q,"I hire in two areas of the country for entry level analysts and we currently hire at 55-65 LCOL, 70-80 HCOL",3,1736739138.0
1i0059n,m6v4uzj,"What country?

I’m in the US and my company has listed $60k as the minimum for Data Analyst roles so presumably that or something close to it is what they would offer a candidate right out of school.

However given how competitive the job market is honestly you’ll be lucky to get a Data Analyst role right out of school so i would accept whatever offer you can get and then start applying for your next role a year later.",3,1736739157.0
1i0059n,m6vmj6v,"I hate to say it but the question isn’t what’s a reasonable salary; but if you can get a job. While it’s gotten slightly better, it’s still a very rough IT market. Hopefully it gets better before you’re done with your last semester; but I would watch carefully what is happening with the IT job market.",2,1736746636.0
1i0059n,m6u3z7u,"Started at 73k for a consulting firm, MCOL",1,1736726547.0
1i0059n,m6uif7z,I started entry level in 2014 at $40k,1,1736731231.0
1i0059n,m6up2x3,70-85k,1,1736733504.0
1i0059n,m6v81bb,"My first analytics role was non-tech, MCOL in 2022. I was hired at $75k with a $3k signing bonus. I did my Bachelors in Business Analytics, but I was working full-time during school so no internships. I did put together a few simple portfolio projects though, which seemed to help.",1,1736740347.0
1i0059n,m6wzsuq,"I started at 67.5k with a MSDA and no internships. After a year, just fought for a 10% raise after finding out that HR caps standard performance raises at 4%.",1,1736774741.0
1i0059n,m6xu2dq,I started at 75k only intern experience,1,1736785071.0
1i0059n,m6y726r,"I started in Jun’22 at $84k plus a 10-20% bonus. Finance, MCOL, and Fortune 600 company. I had 2 prior years in credit, tangentially related to my BI Analyst position now, and finished my Analytics grad program Aug’22.

Salary history: $84k > $86.3k > $93.5k > $117.5k (upcoming in March).

Stick with it, learn the company, and make yourself valuable. Best of luck!",1,1736788886.0
1i0059n,m6z2wl4,"I’m a single data point but I’m graduating after this semester with a BS in Information Systems and Analytics. I currently work part time remotely as a business operations manager, 2 previous internships (marketing intern, and last summer as a software engineer intern). 

Accepted a job offer with the company I interned with last summer, though it’s with a different team / role. It’s a data analyst job, total comp is about 85K in a VHCOL area. Company has other good benefits such as up to 8.5% 401K match.",1,1736798088.0
1i0059n,m717vr1,"Hard to say. The software you listed is quite literally the bare minimum nowadays. Expect $50k - $100k depending on location, responsibilities, and domain (i.e., tech, finance, non-profit, etc.).",1,1736822217.0
1i0059n,m6x1ra5,$80-95K is pretty typical for a MCOL Fortune 500 company hiring “entry” level data analysts in my experience.,1,1736775523.0
1i0059n,m6tz7cm,That's way too cheap because you're a consulting firm.,15,1736725015.0
1i0059n,m6urg7p,lmao 50k,3,1736734332.0
1i0059n,m6u3nk8,"Hi, Im new here. What do you mean the market has been reset?",2,1736726442.0
1i0059n,m6tz6ya,I literally muttered “Jesus Christ” to myself,1,1736725011.0
1i0059n,m6up8k3,Prob h1b and green card  lowering salary,1,1736733558.0
1i0059n,m6xomy2,Do you mind if I ask where you searched for positions? I'm in a similar position where I'm about to graduate with a Master's but haven't had any luck.,2,1736783425.0
1i0059n,m6tzkoh,"Well we have applicants lining up from great universities with all those qualifications. That is the budget I am given from those above me...

And to set things straight, YES I absolutely think its BS. Coming from a guy who graduated in 2009 and took a starting salary of 32k.",17,1736725135.0
1i0059n,m6vutwi,For real though. Why are junior wages in consulting so shit? The pay in Big 4 here in Prague has always been known to be way below average,1,1736751113.0
1i0059n,m6u5aaa,Supply and Demand mate,0,1736726978.0
1i0059n,m6u4u6v,"There was massive hiring from 2015-2022 (with COVID amplifying it from 2019-2022) that companies were scrambling to bring in analytics folks. Even I changed jobs in 2021 and got a massive raise.

With all the macro economic stuff going on and the layoffs of the last two years every company knows they have many more qualified applicants than positions giving them leverage to low ball every job opening they have. So they want to save money and easiest way to do that is low ball the entry level folks... So they are doing it - it sucks. It's not quite the same as 2009, but has the same vibes.",10,1736726833.0
1i0059n,m6tzzhg,"Yea not a fan of it - but that's what those above me feel is market rate these days and we are getting applicants and folks accepting...

I graduated in 2009 and took a starting salary of $32k. Kinda getting the same vibes of a reset of salaries that corporate america LOVES after the hiring boom 2019-2022",2,1736725268.0
1i0059n,m6xt3o2,"Same, I’d be interested to hear more as an MS student myself",1,1736784782.0
1i0059n,m71q76l,"I applied to a hybrid role (the competition is too fierce for remote roles). 

Assuming there's a handful of qualified applicants, including you, then the game shifts from who's most qualified (everyone is) to which person would I want to spend 8 hours/day with? In those 30 min interview windows, become the person that can win the popularity contest -- that means fake it to win it all",1,1736828684.0
1i0059n,m6tzuyf,"Man...those new grads don't know their worth yet. Once they do, they will job hop most likely.",5,1736725228.0
1i0059n,m6upuht,Enjoy the endless cycle of analysts that leave every 6 months - 1 year marks.,2,1736733771.0
1i0059n,m6u01ny,"Dude

My manager at Sam’s club made more than that and he was a high school dropout (ged) with litteraly no post-secondary education",3,1736725288.0
1i0059n,m6vy8oy,"I honestly have no answer cause in my state they're paid a lot, which justifies the lack of WLB they are likely to experience at least. Destroying WLB for 50-55k? Nope no no. Here I see beginning salaries at 120-140k. Smallest range 70-95k. Average for my city is 117k.",1,1736753147.0
1i0059n,m6u746h,Consulting firms in my area wouldn't dare lol,1,1736727577.0
1i0059n,m6u65u3,[deleted],3,1736727268.0
1i0059n,m6u0g7m,"
I do not agree with it, but unfortunately they are right.",1,1736725417.0
1i0059n,m77s985,"Hey just curious did you know python, or was a SQL/Tableau/PowerBI/Excel sort of skillset enough? I’m just trying to get a sense of what’s needed to even get an interview",1,1736911853.0
1i0059n,m6u053p,I agree lol Asked for more so I wont have to onboard someone new every 9-12 months,5,1736725318.0
1i0059n,m6u0k3b,"In 2009, I had to take an unpaid internship THEN that $32k a year job. That $32k offer was from one of those big automakers..the one with the blue logo. Corporate America absolutely LOVES any excuse to knock down salaries and they got an excuse this last year.",5,1736725453.0
1i0059n,m6u74ai,"I'm in my late 30's and new to the management side of things, so the last time I saw wages get suppressed was when I was trying to break in after the 2009 recession. 

Yes, it comes in cycles for a lot of industries/fields. The biggest recommendation I could make to analytic nerds like myself is try to get into a company/industry that is a bit more recession proof than others. I worked in auto 85% of my career and somehow survived layoff after layoff. Even in record profit years, Mary Barra needs to cut costs...",6,1736727578.0
1i0059n,m6u0teq,Don’t agree either but they just want to make shareholders happy. 100 people making 50k vs 80k makes a difference on the P&L. Ya know a profit of 2B vs 1B is apparently a big deal….,2,1736725538.0
1i0059n,m6u87gq,That's a little better.,1,1736727921.0
1i0059n,m6u0rho,In 2013 I took a temp job making $13.50 an hour with an hour commute. I felt like a Saudi prince since my old job at Sam’s was paying me literal minimum wage.,1,1736725520.0
1i0059n,m6u12uo,"No, I agree, but unfortunately they are right from a business perspective.

If there is 10,000 people willing to do this job at x-price why would I pay more? Not including outsourcing, temps, h1b, automation, contractors",2,1736725625.0
1i0059n,m6u9ag2,Yea - If I had my way everyone would be making a LOT more. We're all just pawns to those above us.,1,1736728263.0
1i0059n,m6u10mb,I remember my college roommate had an offer out of college to work in accounting for the government for $42k and we all thought he was LOADED given the recession.,2,1736725606.0
1i0059n,m6u367f,All my old work buddies at General Motors are going through it...Worked at 2 of the Big 3 where shareholder optimization is literally the only goal. Work hard your entire career to get a salary you feel deserve? Congrats you are now too expensive...laid off.,2,1736726287.0
1i0059n,m6u9hzy,Exactly.,1,1736728331.0
1i0euyy,m6x7bpq,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736777638.0
1i0euyy,m6x9oxb,Understand the business requirements and goals prior to building the content. This ensures it solves an actual problem and will likely stand out more than having the prettiest viz in tableau.,5,1736778497.0
1i0euyy,m6yhzwx,"When you say content.. do you mean on social media/LinkedIn/etc.?

Or are you meaning within your organization with your business stakeholders, etc.?",2,1736792042.0
1i0euyy,m736bmc,Thank you for this! Do you any tools that we can use for building content perhaps?,1,1736858010.0
1i0euyy,m736d3w,"Social Media entirely, yes! Thank you!",1,1736858028.0
1i0euyy,m77ldb7,"Focus on creating value. There's a ton of ""fluff"" or filler content out there. If you focus on adding value with your content first, the engagement and views will come.",1,1736909339.0
1hzx2fe,m6t68pk,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736716218.0
1hzxb4s,m6t8b6w,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736716833.0
1hzxb4s,m6ts4vh,"Look at internships at Alteryx. Great intro into the data and analytics space, with a number of roles to explore from analyst to data engineering. 

They're based in Irvine also, so easy commute if you're still in the area. 

I'd prioritize getting direct experience vs a Masters. We're in an amazing period of innovation and the sooner you can gets hands on exposure, the better suited you are to capitalize in this special market.

...Datacamp is an effective resource to build your skills w widely used data tools and processes as well.

Good luck!",4,1736722749.0
1hzxb4s,m6u366r,"I am currently looking into data camp. Would you still think it's worth completing a certificate as well? I'm considering a PM certificate and a BA certificate. I've just been taking the Coursera one for BA rn but it doesn't apply the technical skills really.

Also for the games industry, I feel PM is more prevalent in games. Insight analyst positions are possible but harder to come by. Wondering which of these I should pursue first.",1,1736726287.0
1hz9kpi,m6nscba,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736639745.0
1hz9kpi,m6o5mf8,Make sure not to ask them about turn signals,48,1736644078.0
1hz9kpi,m6od0xl,"I just landed my first job out of university at a major airline company, to prep for my interview I pasted the job description into ChatGPT and had it make me some prep questions which I practiced. Could also paste your resume and have it make some answers to get an idea of how you can apply your experiences to the answer. And make sure to use the STAR method when answering situational question.

Also have some questions afterwards (I.e, what’s the day-to-day, team culture, next steps of the hiring process). 

Best of luck!",17,1736646609.0
1hz9kpi,m6nulv5,"prepare well, be on time, firm handshake, wear a dress shirt, have some questions ready at the end. You should google everything you can find about the position, the team, and your supervisor.",7,1736640490.0
1hz9kpi,m6ont6w,"Be friendly.  They don’t expect you to be an amazing analyst so don’t bs and pretend you’re better than you are.  Act interested in the company and the team.  

If you don’t know something it’s better to be honest that you don’t know and follow up with saying you would love to learn and that you’ll go read up on it after the interview.

At least this is what I would want to see from a candidate though I’m not a manager just a senior individual contributor.",5,1736650408.0
1hz9kpi,m6o3hkx,"Ask questions about the market (i.e., impact of the proliferation of Chinese EVs and how that may be impacting BMW’s business!). Know how they performed in 2024 and ask about their 2025 strategy. Reach out to people on LinkedIn who work at the company and find out a few things and bring it up during the interview. You don’t have the experience-need something to differentiate yourself. Good luck.",3,1736643351.0
1hz9kpi,m6ukvye,"Take it serious. I had an internship at a similar type of company. 1/3 of interns got return offers, I was in that group. 

Part of it was luck, part skill, mostly hustle. Take any presentations seriously. While everyone was partying the last week I made sure my presentation and work was perfect. It paid off.",2,1736732065.0
1hz9kpi,m6o6de3,"Damn nice. Good luck! I've been tryna get into analytics in the automotive world but have had no luck. 

I already am in the analytical field but in the healthcare space",1,1736644333.0
1hz9kpi,m6odwd4,"I've heard that you should treat interviews like a 3rd date and your interested. So like read up on the company and come with questions that are a little bit more in depth in your field and also with questions just about the company, culture and whatever else.  And just practice your behavioral interview type questions, STAR method is good.",1,1736646909.0
1hz9kpi,m6pd5c3,"Drive your ambition with hard and smart work, so that you can drive the brand later!! All the best",1,1736661139.0
1hz9kpi,m6q5tj5,"If you can stand up during your interview, do that. 

Get an app for notes, have it on your screen",1,1736678466.0
1hz9kpi,m6r9zgy,"I spent a few years with Daimler Mercedes benz, automotive is a very, very mature industry, and whatever findings you have are more than likely cyclical(ie already known), or as a result of regulation in that market. The systems you'll come to draw data from are very old but mature, and most manufacturers push the same system to the dealers to use. Last thing you need is to tell them to change the system because that's not gonna happen. 

Just follow what your manager tells you and see how it goes.",1,1736696407.0
1hz9kpi,m6rt17y,Don't show up in a Benz,1,1736702228.0
1hz9kpi,m6tl2sh,dont bring up oil leaks :),1,1736720593.0
1hz9kpi,m6tlrp9,"Worked for BMW (Central, Germany, Munich) as a consultant/advisor. 

AMA (as far as my NDA allows). Just shoot me a note.",1,1736720797.0
1hz9kpi,m6x8hvg,"I had an internship with them in college! I did analytics in their marketing department, not sure if that’s where you would be. Be friendly, share your thoughts as to why you’re solving the way you are- context is key. They’re looking for fit, most likely.",1,1736778064.0
1hz9kpi,m6o25r8,"If you dont drive, learn, and dont tell anyone. Had a friend in Manhattan who got to the final round of interviews with BMW NA for a high level job when she admitted she didn’t have a license. They had her escorted out.",2,1736642917.0
1hz9kpi,m6pluuv,hey can i dm you? i’m interested in working for an airline/space company,2,1736665961.0
1hz9kpi,m6pkuv1,"Hi, can I DM you?",1,1736665367.0
1hz9kpi,m6o1e53,"Thank you kind gentleman, it is online but I assume the principles are still the same. Enjoy your weekend!",1,1736642667.0
1hz9kpi,m6uvhmp,are in person interviews still a thing in tech? Every interview i’ve done was online,1,1736735748.0
1hz9kpi,m6vzyxb,We still do in-person interviews if the applicants have reasonable travel times.,1,1736754212.0
1hzb2mu,m6o5m1o,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736644074.0
1hzb2mu,m6og1e8,As a current Healthcare Analyst I can tell you a lot of positions are regarding Revenue Cycle Management. Looking into getting your CRCR would be helpful especially if you’re looking for consulting analytics. You’ll sometimes find companies though that mix with RCM analytics and population health with some kind of Tech implementation.,3,1736647650.0
1hzb2mu,m6o6ot6,Do a bit of google sleuthing about the administrative services your local hospitals and clinics have. Sometimes they’ll even publish reports and that’ll give you some insight into how they approach data.,1,1736644444.0
1hzb2mu,m76i06o,"I know I’m late to the game, but look up on your internal company registry who had the job you want and offer to buy him lunch and chat.  Find out what they do and tools they use and learn that.  Then ask their manager out for lunch and ask what you would need to do to get hired next time she has an opening.",1,1736895921.0
1hzb2mu,m6og9wq,"Awesome, I’ll see if my employer can pay for it, i would like to dabble in consulting analytics aswell. Thanks for the suggestion! Is it difficult to get the CRCR cert?",1,1736647734.0
1hzb2mu,m6oldbl,It’s through the HFMA (Healthcare Financial Management Association). I wouldn’t say it’s necessarily difficult but there is a lot of information. Basically it’s an in depth of revenue cycle certification but it’s useful if you go into consulting. It’s basically a lot of interactive tutorials  followed by like an 80 question exam.,1,1736649517.0
1hzb2mu,m6p8uvk,Does it increase your chance of getting interviews if you get that cert or you need health care analytical experience?,1,1736659030.0
1hzb2mu,m6qxj5y,"I will tell you networking has gotten me significantly farther than experience alone. Go to events, message people on LinkedIn etc. I got my CRCR while actually starting as an associate at my first consulting job. But I self taught myself SQL, Python, and Data Modeling. I also have a MS in Health Informatics that I got while working in IT for a Private Practice. It’s all about how you spin your experience. Focus on the long term goal and make steps to reach it.",1,1736692151.0
1hz53m9,m6mqsmf,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736627510.0
1hz53m9,m6mymal,Powerbi has been best in class by garter for several years now. If you want to expand skill sets do it something software agnostic like Python etc,20,1736630024.0
1hz53m9,m6mv5cu,"Power BI is I think in as high demand as ever. Feature set got good enough to compete with Tableau at a much lower price. 

If you’re not getting interviews make sure your resume speaks to the things you can do, not just the technology you used. If you’re a power bi expert, any viz tool will be an easy learn for you.",8,1736628917.0
1hz53m9,m6n37pg,When I was interviewing last year almost everyone was looking for powerbi. Those with tableau were migrating to powerbi.,7,1736631499.0
1hz53m9,m6ni8ld,"EPIC / Clarity is t-sql based and given how huge it is, you’ll be able to find a job for a long time coming.",4,1736636326.0
1hz53m9,m6omn4d,"I don’t think you should focus on learning different flavors of stuff you already know.  If a company isn’t willing to train you to learn the new flavor they probably would suck to work for.

Someone else said learn Python which I think is a good idea.  It’s better to learn something completely new than a different flavor of something you already know.",2,1736649981.0
1hz53m9,m6owfl1,"Ssrs is just called Paginated reports in Power bi.

Ssms is still in use.

Power bi is huge",2,1736653645.0
1hz53m9,m6p9u5h,"I'm honestly a big fan of power BI, it's simple and great at the time. Tableau is the most popular of course, but I think Power BI would be the 2nd best in the market",2,1736659503.0
1hz53m9,m6sue46,"Power BI is very much in demand down here. Indeed, learn Python and formalize your data modeling skills. Get comfortable with Azure SQL and Fabric, then market yourself as a Fabric-skilled Analytics Engineer. I see loads of ‘hobbyists’ out there that drag & drop PBI reports together, but there’s a lack of folks that are able to get scaled performance out of their stack without having to shell out on Premium Capacity.",2,1736712820.0
1hz53m9,m6pb028,best in class at what exactly ? i am baffled that anyone would choose to use powerbi unless they dont know how to use the many other tools out there that are superior or there is some mandate to only use pbi.,-6,1736660076.0
1hz53m9,m6n5jps,"“Best in class” is highly subjective. What i will say is that Power BI consistently wins any RFP in large part because it is significantly cheaper (on paper) to implement.

The reality though is that PBI is much less user friendly than almost all its competitors. But procurement doesn’t evaluate that when choosing software, or how productive the cie’s analysts can be when using one solution vs another.",-7,1736632233.0
1hz53m9,m6nyd4j,That's partially because tableau got really greedy with license costs.,8,1736641667.0
1hz53m9,m6qy2zh,Ew no. What one do you like?,2,1736692349.0
1hz53m9,m6n9hlq,While subjective that is not the primary determinant why it completely outperformed competitors in the magic quadrant the last several years,7,1736633486.0
1hz53m9,m6nfc88,"I have used some of those other products along with powerbi and currently use powerbi and quicksight regularly. 

None of these things are perfect and all have pros and cons. But powerbi has more advantages other than “price” depending on what you want to do",3,1736635366.0
1hz53m9,m6nv1vs,"What people don't realize is if PBI Enterprise is not set up properly, or if they are integrating with Azure and don't pay attention, their cost will be much larger than originally forecasted. Usually similar to common data engineering and analytics/DS mistakes made when transitioning from on prem to cloud.


Additionally, with Tableau there is some learning, but a lot of how-to items are transferrable skills from other tools/languages.  Then you have a whole bunch of analysts asking, ""what is DAX?"" when the company rolls out PBI as their new dashboard and reporting solution.",2,1736640633.0
1hz53m9,m6shfe2,Anyone know if this started before or after they were acquired by SFDC?,1,1736709156.0
1hz53m9,m6nxowu,"I’ve personally used pretty much all the top visualization tools out there in a professional setting. I’ve also lead many RFPs for very large orgs that wanted to update their tools.

When it comes down to it Power BI, Tableau, Google’s Looker, SAS VA, all score the same exact way on almost all the technical aspects.

The one defining factor is price. And for any company that already has Azure and extensively uses excel and Microsoft 365, PBI will be a cheaper implementation. About 30% cheaper to 50% depending on how good the procurement people are at negotiating with MS.

Now admittedly my perspective is anecdotal, but it comes from ~10 RFPs I was directly part of, and ~30 others I reviewed.

Yes from an analyst’s perspective there are slight advantages of one tool over another. From a VPs perspective it just doesn’t matter enough to justify paying a premium.",8,1736641458.0
1hz53m9,m6nz5y4,"PBI is the “middle ground”. It does everything ok, but nothing great. Quicksites is probably the worst IMO in that both the output is bad and the backend is meh. Looker has the better backend, but is limited in terms of visuals. Tableau is the best for ease of use, but the backend is cluncky and you can quickly hit performance issues with very large datasets.

The truth is though none of those are show stoppers. A good data team will work around the limitations, so the price becomes the main differentiator.",1,1736641935.0
1hz53m9,m6nybrt,"Yes, 100% agree with you here. Additionally PBI is actually more difficult to set up in a way that allows proper version control. 

But again it’s always a give and take. Tableau is way better in terms of looks, Looker is better in terms of backend, Power BI is somewhere in the middle.",1,1736641655.0
1hz53m9,m6qye7y,"Disagree entirely. Then again, I made very complex reports. I hated having to do bullshit to get conditional formatting like averahe(0) to do what powerbi can just do",1,1736692463.0
1hz53m9,m6rvxeq,"Do you disagree on version control, visual look, or backend?",1,1736703072.0
1hyhkdj,m6hhris,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736549996.0
1hyhkdj,m6hjpfq,"Internship Internship Internship

Connections Connections Connections 

U might even need a master's, but out of all the fucking interviews I had, at least 80 to 90 percent were thru my connections no joke. It took me abt 6 months or so to get an entry level job I won't lie, and that was peak shitty 2023 graduation moment, it will get better, it might not, but all I can say is that since u are a sophomore, u got 2 years, do as many internships as u can, reach out to ur professors/career center, u shouldn't stay free, trust me!

If u do want to pivot somewhere, u can, sophomore year is still okay to change ur degree, but I will say u can have hope in this path too, depends on u. 

Also, be a US citizen (if u live here), else u can 100x this difficulty no joke, because sponsorship will be tough.",53,1736550643.0
1hyhkdj,m6hkfdo,Many of the job listings I see have a minimum requirement of a degree. I definitely thing college is still very much worth it. In my opinion it has become the new high school diploma.,27,1736550887.0
1hyhkdj,m6hxag6,"Alright, first of all take every opinion with a grain of salt. I have been in tech/analytics for almost 10 years but that is only a drop in the bucket of national trends (and beyond). Here are my overall thoughts.


*Oh my goodness there are no jobs out there for CS majors*

Blatantly just not true. There are plenty of jobs out there. The problem is that every graduate with a 4.0 from a decent to higher level university can't work in big tech and make 150k or more their first year out of school. So while there are plenty of jobs, a large amount of people are competing for the most desirable ones: SWE/analytics doesn't only exist at FAANG. People are overreacting because it used to be a 6 month boot camp could land you any tech job because of demand and it just isn't that way anymore.


*Is college even worth it anymore?*

BLUF: Yes. I think so (depending on your major - anything STEM is fine). It is so rare to find a company that doesn't care about you having a degree that you really limit your options in the first few years of your career if you don't have some type of degree. I do not think an MBA is worth it unless you want to be a consulting partner. I think the connections you make in college are equally as important as the degree (both with students and faculty). Please be cautious of student loan debt - it is impossible to get rid of if you don't pay it off (even with bankruptcy most of the time). 


*Overall advice*

Soft skills are equally as important as technical ones. Most of the people I interview don't hit the bar because of a lack of soft skills, not technical ones. The expectation is you are in tech because you either have the skills or can learn them on the job, what gets you the job is being able to communicate and work through a nebulous problem.


Tldr; You're on a good path and will be fine. You might not work at apple and make 200k out the gate and that's perfectly fine. You will get a job. There are plenty out there.",22,1736555263.0
1hyhkdj,m6hp4st,Treat college like a smorgasbord. Try everything. Go nuts. It should be one of the best times of your life. Go all out. You have the rest of your life to worry about your job.,17,1736552479.0
1hyhkdj,m6hlgow,"College is definitely worth it, if you focus on growing and learning. many people just do college for grades and dont learn too much.",9,1736551236.0
1hyhkdj,m6hnfyj,"I’m gonna tell you something that is just going to be irritating, but someone needs to say it to you:

If you study something and go into a career you can barely stand, it effects *everything* in your life. If you’re at all interested in something other than data/tech, I’d find a way to keep that door open. Tech especially has annual layoffs and guess who is laid off every year? The new people. It’s hard and ruthless, unless it’s an old guard like Intel.

But yes 100% you should stay at your uni. Getting any sort of non blue collar job without one is seemingly impossible these days.",8,1736551905.0
1hyhkdj,m6hrvg6,"I got lucky. Have undergrad in Business and a grad in MDA. I was already at my company for 4 years when the hiring manager gave me a shot as a BA. Just promoted to Global Customer support manager role. Still doing alot of report internally and externally. Also, in supply chain analytics. It was worth to me for a career change at the age of 31. Couldnt do HR nomore lol",4,1736553419.0
1hyhkdj,m6hvj2r,"You’re basically halfway there.  The alternative you drop out of college and odds are nearly zero? 

Internships, networking, small projects.  The degree tells employers you can focus in on something and learn.",3,1736554668.0
1hyhkdj,m6i4nr0,For analytics? It's pretty necessary. It's hard enough to get a job with a degree and it will be so much harder without one.,4,1736557763.0
1hyhkdj,m6icne7,"Actually, data analyst are making a resurgence, but from the perspective of GenAI + Data Analytics.

I was competing for data analytics jobs when I realized that the GenAI Analytics positions are wide open. 

Can you scrape data, transform it, feed it to LLMs using different pipelines like RAG and then prompt engineer to get insights? 

Most data analysts can’t, but if you can, the market is huge right now! 

Once I realized this, I got back to back interviews within a week, then signed an offer a month later while having more offers still coming in.",6,1736560481.0
1hyhkdj,m6hyor7,"Yes, you will find getting a job is much more difficult without a degree",3,1736555737.0
1hyhkdj,m6ipugg,"If you are a data science major then just think about survivorship bias. Listening to people talk about how hard it is survivorship bias backwards. There's plenty of jobs available right now paying a ton of money in both big data and data engineering. Irrespective of all the AI hype somebody's got to keep these systems up and monitoring them and it's important work.  If you're good at what you do you'll be employed. If you want to get ahead of things start looking around it positions at companies you want to work at and the tech they're using, then get familiar with it. Databricks/spark for instance. Snowflake. If you want my honest opinion I tell you to pick one you don't have to make it your final answer but spend an hour a day each weekday playing around with it. Make some project in your head that we conceivably want to do and make it challenging so that it's not something you already know how to do. And then iterate on it start to finish and then go back and redo it learn some new functions Play with the data structures. Throw yourself a curveball and don't use the standard data sets that they give you to practice on put some stuff in there that's an anomaly because in the corporate world you'll run into that a lot. Just keep iterating and see how tight and refined and fast you can get things. It doesn't have to be big in elaborate but you'll learn more in that journey than you can imagine. And redoing the same thing three or four times you see things that you missed before.  Rinse wash and repeat. DevOps and ML ops are still really big areas too so automate the deployment afterwards 


There's a lot that's true about getting your first job but there's a lot of BS and a lot of what you hear about how hard it is is from people that are doing it wrong.  Even if you don't have much experience if you go into an interview knowing more about their pet technology then the engineers there do, even if you don't know more about everything but you actually know some aspects of it that they don't it really changes the equation. And it works absolute wonders for your self-esteem and confidence going into that interview that can't be missed.",2,1736565197.0
1hyhkdj,m6jcjea,"It's happening in every industry, the tertiary schools are pushing out students left, right, and centre.

There are only so much white-collar roles at the entry level that the business environment can take and we are starting to see it reduce even more as more companies shut down post a high spend ZIRP enviornment. That's just the market right now.

Tbh, you probs won't be one of the lucky ones to walk out of school with a job in hand for a couple of years.

You will need to snakes and ladders that shit. Look at the industries you are interested, build in the expectation that you may not get a direct ladder into the job you want and just look at jobs as stepping stones to get to where you really want to be.

That's what I did. As I always tell people generally, doing the job and succeeding is the easy part, getting the start is the hard part.",2,1736574982.0
1hyhkdj,m6r0kke,"""Is college worth it?""


The question is too simple. It depends on how much it is costing you and what you'll be bringing out of that 4 years. 


- The straight data science route isn't enough. It simply puts you in competition with a bunch of other people with the same degree.
- Yes, you need an internship and a small portfolio. But you also need some angle that differentiates you and grounds an otherwise generic data science major. For example, a minor in public health (or MPH) or finance (or MBA) or environmental science.


When I am looking at recent grads as a hiring manager, I want to see 
1) Basic skills 
2) Some differentiator, as above
3) Ability to hold a conversation FFS!!
4) Some curiosity and interest in the work


Good luck!",2,1736693239.0
1hyhkdj,m6hjtp0,I think so as long as you put in the effort to do well as well as put yourself out there. Really and I mean really try to obtain internships. They make a huge difference and it’s something I did sooner as I’m a masters student struggling to find work.,1,1736550683.0
1hyhkdj,m6hodpx,"Yes it’s worth it, most job descriptions I’ve seen require a stem degree. Plus you can even specialize if you want.",1,1736552224.0
1hyhkdj,m6hqu75,It also depends what you major in and at what school. My first boss in my first job after college told me he called me in for an interview because he knew that I graduated from a highly ranked program.,1,1736553067.0
1hyhkdj,m6hx56l,"College is absolutely still worth it. American college graduates get a huge wage premium irrespective of major

Do not go to college w a rigid expectation that you'll get a specific job after",1,1736555214.0
1hyhkdj,m6ip69a,"For analytics, I’d say almost definitely. It’s a pretty credentialed field. Even after college it’s not always easy to jump right it. Usually takes a lower tier job first and then networking in your org to get your first real shot.",1,1736564948.0
1hyhkdj,m6iv7nx,"We are currently going through one of the largest technical revolutions ever. If you look back at the history of technological revolutions, there will be fields that become obsolete and the job market will be disrupted for years or even generations.

Some envision IT staff replaced by AI with a general decline in IT fields. Some envision IT staff tending to AI agents as HR tends to human staff, bringing about a new IT renaissance. Some see a utopia and others a dystopia. There are so many viewpoints on what could happen, but nobody really knows.

What I can say is you’ll need to sharpen your ability at critical thinking in order to ride the waves of change that will be caused by GenAIs, AI agents, AI robots, and potentially AGI / ASI. The main way to do this is through education. Those without critical thinking skills will be dependent upon luck.

Will a degree guarantee a job? No, but it will give you a better chance to see potential opportunities.

The cost of a degree is the one part you can have some control over. There are many schools in the EU that offer great degree programs at a far cheaper cost than in the US.  

You will be guaranteed to change your career multiple times through your life. Make sure to follow what you love. You’ll have a far better chance to succeed in that way.

Best of luck!",1,1736567240.0
1hyhkdj,m6kv08r,"If you know you want to work in this field then it's obvious that you need atleast a bachelor's degree. 
I don't see what the problem is, the job market is rough yeah but that counts for majority of fields, if you don't have a degree you will have a lot less flexibility in what you can do and getting a job is even more difficult.",1,1736605640.0
1hyhkdj,m6lgpo6,"1000% college is still worth it. If you don't have at least a BS in Math, Statistics, CS, or something similar, you will be unlikely to get a single interview unless you have crazy good connections. Realistically, an MS for analyst jobs and PhD for DS jobs is still worth it. 

The flip side is that even with a BS/MS/PhD, you will still need some proven experience (internship or projects) and connections (internal applicant, internship, professors, etc.) in order to get even an entry-level job. But if you have those things, and you DON'T have a relevant degree, you will be far behind someone with a degree.",1,1736613053.0
1hyhkdj,m6lj834,"Is college worth it? My opinion is that it’s not at its price point. Unfortunately, we’re living in a world where we have idiots hiring, not based off of experience or knowledge, but off of whether you went to university. It’s rather illogical considering that most places don’t even care about your GPA, but only that you’ve completed your degree. Which university? Doesn’t matter UNLESS you’re going for a high level occupation that requires years of study. I’ve seen many people who are more than qualified to do a job that has been turned down because their lack of “a property/formal education”. So, is it worth it? From an economical standpoint, no. But from the court of public opinions, you cannot do without. Like everyone else here is telling you, get that stupid paper, but find connections and internships NOW! Start on projects to showcase your skills by uploading them onto sites like github, and so forth. You need to start ASAP as to get ahead of the morons in charge of hiring, and the AI bots that are sifting through resumes. Good luck.",1,1736613837.0
1hyhkdj,m6mz19l,No it is not,1,1736630159.0
1hyhkdj,m6riqyw,"In the field you chose, data science, analytics….id try to get hire but also start thinking of grad school. 

I was only taken seriously after I completed my masters.",1,1736699228.0
1hyhkdj,m6yinho,"First job is hardest - look for internships. In my experience, second job was way easier to land after the first. Once your in the door seems a bit easier",1,1736792228.0
1hyhkdj,m70uvnd,"Yes, but the community college the first few years. Then regular university (can be a less prestigious and cheaper one) to finish it out.",1,1736818044.0
1hyhkdj,m71ektd,Hello! I work as a Data Analyst. Feel free to message me. I got this job extremely easy in a flooded market. You just need to have a really well built resume.,1,1736824407.0
1hyhkdj,m6jfqs0,Data Science. That sounds like a great job for AI. I hope your degree or transferrable!,1,1736576736.0
1hyhkdj,m6hpgkm,"This will be downvoted into oblivion, but I don’t care.

Let’s not sugarcoat it: college has been turned into a glorified money grab, peddling the idea that every degree is a golden ticket to success. Here’s the truth… most of them aren’t. Degrees like Business, Marketing, Economics, Sociology, Psychology (unless you’re going all the way to become a psychologist), International Affairs, Religious Studies, Art, Theater, Journalism, Political Science, Philosophy, Anthropology, Liberal Arts, Music, Gender Studies, Communications, History, English Literature, Film Studies, Creative Writing, and Environmental Studies are, for the most part, utterly useless in the real world.

Sure, they sound interesting. They might even be fun to study. But when you graduate, congratulations… you’re just another overeducated, underemployed person trying to convince someone why your “passion for art history” is worth a paycheck. Nobody cares. Employers want skills, and most of these degrees don’t teach you any. You spent four years and tens (sometimes hundreds) of thousands of dollars learning things that can’t even be monetized. What’s your fallback plan? Starbucks? Retail?

Let’s talk about MBAs for a second. They’re sold as the “next step” for ambitious people, but here’s the dirty little secret: they’re mostly useless too. It’s been proven that MBA grads aren’t any better at managing people than someone who learned leadership on the job. Why? Because you can’t learn to lead by reading case studies and playing “what if” scenarios in a classroom. Leadership comes from doing, failing, and figuring it out in the trenches, not from sitting in a seminar analyzing a hypothetical business problem that has no bearing on reality.

Meanwhile, the trades are gasping for air. Skilled trades like electricians, plumbers, HVAC technicians, pipefitters, elevator mechanics, welders, and machinists are dying out because everyone’s been brainwashed into thinking working with your hands is beneath them. Let me break it down for you: trades keep the world running. No plumber, no water. No electrician, no power. No HVAC tech, no heat or A/C.

The irony? Most trade companies will pay for your education while you’re earning money. You won’t come out with six figures of debt… you’ll come out with six figures in your bank account. Try doing that with a Communications degree.

This country doesn’t need more unemployed liberal arts majors. It needs people who can actually fix things, build things, and keep the lights on. But instead, we’re churning out graduates who don’t know a wrench from a screwdriver, drowning in debt, and wondering why their degree didn’t come with a guaranteed job.

College isn’t for everyone, and it sure as hell isn’t the only way to succeed. But the system won’t tell you that. They’ll just keep selling overpriced, useless degrees because they make money whether you succeed or not. Meanwhile, the trades are wide open, begging for skilled workers, and offering real careers with real money. But hey, enjoy your $100,000 degree in Theater while your plumber bills you $300 an hour to fix your sink.",-1,1736552592.0
1hyhkdj,m6lem6k,"The best advice here. Took me 100 apps just to get an internship in 2020. But after that my career flew due to exp

Also yes it’s a req in analytics, because your competition will have either a Bach or mast these days",4,1736612388.0
1hyhkdj,m6htkoa,I’ve been working 10 years as a data analyst and had a recruiter say no thanks halfway a screening call because I have an associates and not a bachelors.,14,1736554001.0
1hyhkdj,m6vjj8t,This. My dad has had a few bought a of being laid off as more and more things went cloud based. He encountered several companies where not having a degree in anything bared him from consideration for the role,1,1736745172.0
1hyhkdj,m6i3ndc,Thanks for this,5,1736557418.0
1hyhkdj,m6r0yjx,Great answer here,2,1736693378.0
1hyhkdj,m6ij4tz,Thanks for this,3,1736562749.0
1hyhkdj,m6nmyn8,Do you have any tips on learning this? Currently a senior in stats with some data scraping and a lot of predictive analytics experience but am looking for whatever entry level data job I can find for the summer.,1,1736637920.0
1hyhkdj,m6lcnif,"Also, learn what works and what doesn't work depending on your use case.  A lot of experience is gained through trial and error and figuring out how to optimize systems in that situation.  Teams are always looking for someone to improve things.  For example, I am at the point where I have too many improvement projects I'd like to do and not enough time.  I wish I could hand them off, but people don't have the will, skill, or time to do them.  Budget and analytics infrastructure don't necessarily dovetail.

If I ever hear the word elegant in reference to analytics infrastructure or code, I'll know that the person is generally quite thoughtful about different methods and which method to choose over another.

&nbsp;

That said, this job market is really tough and even experienced people are not getting jobs because the supply is so high and it's hard to separate out signals from noise.  Imagine getting 500 job applications and not being able to really distinguish between people other than the company they worked at.  There's very high capability variance amongst analysts.  There are ""data engineers"" at my company who don't even really code.",1,1736611758.0
1hyhkdj,m6lg4ld,"Degrees don’t have to be transferable, for example my friend has a comparative religion degree and he works as an analyst at the CDC. It was more about the raw exp you build on your resume. The degree is just a, oh nice, you followed rules for 4 years ok you consistent.",1,1736612870.0
1hyhkdj,m6jbn8r,"I keep hearing this about the trades, but in my part of the country (Wyoming / Colorado), everybody says trades are the new master's degree. Every young person wants to be a welder and no one is pursuing a degree or a non-blue-collar job. 

I've worked in the trades and to make good money most of the time you are chasing the higher-paying jobs around the country. The ones that pay the best are normally located in the worst environmental conditions. Living in a hotel room and working ridiculous hours. 

For example, last winter apprenticing as an electrician I was working outdoors in temperatures down to negative 40 doing x6 10s and an 8 making $22 an hour before OT. The journeyman I was apprenticing under pulled in 45 to 55 an hour. You see your family maybe every few months for a long weekend. Don't forget you can get fired anytime for any made-up offense at which point you are relocating to another hotel room across the country.

If you want to stay local in the trades you're going to make far less money. Another thing is most people I know in the trades do not have health care through their employers or many other benefits. One of my roommates just had to come out of pocket 75k to pay for his wife's medical bills from a home accident. When he goes home for her surgery he doesn't get any sort of paid leave or vacation days.

Don't get me wrong there is money to be made in the trades,  but it is no bed of roses. In my opinion, the trades have some of the worst work-life balance ratios there is out side of prison.",2,1736574515.0
1hyhkdj,m6hw0c1,"I think this is an overly cynical view of things with some small grains of truth.

Some feedback if you're willing to hear it: You sound more bitter than helpful, and most people don't want to take advice from someone who seems jaded even if it's correct.

If I could offer some slightly adjacent, less aggressive thoughts:
- You don't need a degree to do well in life
- A degree can open up a lot of doors for you
- Some people prefer technical work to hands on work (and vice versa)
- Higher education institutions are always happy to take your money, as are lenders. But if you make it worthwhile, college is a fine idea.",3,1736554829.0
1hyhkdj,m6jxak4,"Economics isn't useless though, especially if it's a solidly taught program. It's usually included in STEM because of how quantitative it can be and it can open doors to many analytical roles.

The only useless Econ degrees I know of are usually from degree mills, who in general are known to have poor degrees.",1,1736587693.0
1hyhkdj,m6is4yf,"You are welcome! If it helps any, just know you can start with any job and make it in the tech space given the right career opportunities and job hops.

My first full time job was like 45k a year, my first job out of college was in accounting at 62k a year, and this year I'll clear somewhere around 500k (just under 10 years from that first 45k gig). Don't worry about the first few years. Worry about learning the right things and always trying to improve yourself and your career and you'll be fine.",3,1736566059.0
1hyhkdj,m6t172f,"Thank you! I do a lot of hiring and talking to new grads from my alma mater and it's a common trend of doom and gloom, but really really it isn't that bad out there.

If anything, some unsolicited advice would be if you are a STEM major take a public speaking class or some sort of soft-skills-enhancer just to get the reps. A lot of my interviewees have great backgrounds and are clearly smart people, but not great coworkers for one reason or another.",1,1736714751.0
1hyhkdj,m6lhqey,"Yah, probably most don't code other than spark versions and SQL. I completely agree with you on the one hand that there is market saturation if you're out there floating resumes around but at the same time there is a lot of need and a lot of b*******. I could go on for hours about the number of completely fake people that weren't even the people that interviewed are the percentages of people that were even half of what they claimed on their resume. An inside referral generally cuts through all of that crap. And people that you know online to be very knowledgeable from staff overflow or various forums or people whose git repos you've worked with etc don't go through much of that",1,1736613372.0
1hyhkdj,m6mhjdv,I do not think AI even cares. That degree and its jobs will be eaten alive by AI was my point. It was somewhat of a tongue-in-cheek reply. Maybe I should have said choose your degree wisely. But yes they have been good and followed rules. But AI does a pretty good job of following rules as well.,1,1736624515.0
1hyhkdj,m6klia5,"There is a lot to unpack here. 

I can see where you’re coming from, but your experience doesn’t paint the full picture of what working in the trades can look like. Let me break down your points and offer some perspective based on my own experience.

“Chasing higher-paying jobs around the country”

It’s true that some people in the trades chase higher-paying jobs across the country, but that’s a personal choice, not a requirement. Many tradespeople find stable, local work and still make great money. In my town, journeyman plumbers routinely earn $70k–$80k, masters make $80k-$100k per year without needing to pack up and live out of a suitcase. My brother-in-law is an electrical shop foreman who makes $80k annually working locally with no travel and great benefits. 

For those who do travel, the financial rewards can justify the inconvenience. Journeymen making $45–$55 (that’s on the low end of what I’ve seen) an hour, like the one you apprenticed under, are easily bringing in six figures with overtime. That’s a trade-off some people are willing to make, but it’s not the only way to earn good money in the trades.

“The worst environmental conditions”

Working in harsh environments is part of the deal in the trades, but it’s not just about being out in the cold or heat on a construction site. Whether you’re working outdoors on a new build or indoors dealing with service and repair, there’s always a demand. Even if new construction slows down, the service and repair side of things never stops. Pipes burst, systems fail, and people need things fixed. So yes, you might be dealing with extreme temperatures, but that’s part of the trade. It comes with the territory, and for those willing to put in the work, the rewards are there. The fact that work is so abundant means there’s a steady paycheck, whether you’re shoveling snow off a roof to get to a failed RTU … or fixing a busted pipe in someone’s kitchen.

“Living in a hotel room and working ridiculous hours”

Again, this comes down to the type of work you’re pursuing. Local trade jobs with a steady 40-45 hour workweek are widely available. My current job is a great example: I work stable hours, live at home, and have time off to spend with my family. Meanwhile, those who work overtime are often doing so because demand is high and the money is worth it. It’s not a bad thing to have the option to work extra hours if you want to pad your paycheck.

“You can get fired anytime for a made-up offense”

Let’s be real… this is true of any job, blue-collar or white-collar, in at-will employment states. The trades aren’t unique in this regard. The key is working for reputable employers. In my experience, the better companies in the trades offer job stability and invest in their employees because skilled workers are in such high demand.

“No health care or benefits”

This one’s flat-out wrong in my experience. Every company I’ve worked for in the trades has offered benefits like health insurance, 401(k) plans, and more. My current company provides:

Health insurance with a $5,000 max out-of-pocket for families.

401(k) plans and HSAs with company matching.

A pension plan where you’re fully vested after 7 years (yes, a real pension).

A mentorship program to help new hires succeed.

Paid holidays including Christmas Eve, Christmas Day, Thanksgiving and the day before, Memorial Day, Fourth of July, Labor Day, and even my birthday.

Paid sick leave—I accrue 4 hours every paycheck, and it rolls over from year to year, letting me build up a safety net for emergencies.

I get 2 weeks of paid vacation, and I acquire 2 days a year up to 5 weeks off. I also get 3 personal days and a paid day off to do community volunteering. 

I’ve worked for companies that also offer tuition reimbursement, short- and long-term disability insurance, bonuses, company vehicles and gas cards, and Employee Assistance Programs. You just need to seek out the right employers, and you’ll find the benefits can be as good as or better than what many white-collar jobs offer.

“Your roommate paid $75k out of pocket”

If someone’s paying $75k for medical bills, that’s a personal issue related to their employer or their own decisions, not the trades. Plenty of trades jobs come with solid health insurance. The key is finding the right company or union job, which is totally doable.

“Worst work-life balance”

This is subjective and largely dependent on the job you take and the choices you make. Yes, demand for skilled tradespeople is high, and that means there’s plenty of work out there. But if you prioritize work-life balance, it’s absolutely possible to find a trade job with regular hours and no travel. Sure, if you work service and repair you’re more than likely in an on call rotation. I’ve worked in roles where I’m home every evening, take weekends off, and have time to enjoy my life.

“Trades aren’t a bed of roses”

No career is. But the trades offer unique advantages: no college debt, high earning potential, job security, and a clear path for advancement. Compare that to a degree in, say, economics… where most jobs just require “a degree” and don’t care where it’s from. In trades, your skills and experience speak louder than a piece of paper, and they’re in demand everywhere. And “degree mills” give me a break… employers don’t care. 

In summary, the issues you described aren’t universal, they’re anecdotal and based on specific choices. The trades are what you make of them. They can offer excellent pay, stability, benefits, and work-life balance if you seek out the right opportunities. Sure, the work can be hard, but unlike some white-collar jobs, you’re building something tangible and valuable, and you’re well-compensated for it.",1,1736601754.0
1hyhkdj,m6hwpjm,Its chatgpt,3,1736555067.0
1hyhkdj,m6hz4wj,"College reform is long overdue. We need to stop pushing degrees in fields that won’t get you anywhere. Colleges should focus on what careers will actually be in demand in the next decade, not just pumping out graduates with useless degrees that lead to debt and dead ends. It’s time to cut the programs in sociology, political science, and other majors that don’t prepare students for real jobs.

To make this happen, we should have a strong partnership between businesses, both large and small, and the U.S. Bureau of Labor Statistics. Companies know what skills are most in demand and where the workforce gaps are. The BLS already tracks job trends and projections, and by working together, we can create a data-driven approach to align degree programs with actual job market needs.

Let’s focus on degrees that prepare students for industries with real opportunities: skilled trades, AI, STEM, healthcare (especially mental health professionals), construction management, and renewable energy (especially solar). And let’s not forget, we are in desperate need of truck drivers right now. College programs should be tailored to fill those gaps, rather than pushing students into oversaturated fields with little to no job prospects.

It’s time for colleges to adapt, work with the companies and agencies that understand the job market, and stop simply collecting tuition from students who are set up to fail. We need graduates with real skills for real jobs, not debt for degrees that lead nowhere.",3,1736555887.0
1hyhkdj,m6op4k9,"I also want to say thank you for the insight and oz of hope! I know this comment was for someone else. I'm earning my MS in an attempt to transition to analytics in my field, and all of the overwhelmingly discouraging comments haunt me at night. I will sleep better tonight.",2,1736650882.0
1hyhkdj,m6kscca,"I do want to thank you for a well thought out and well written reply. Unfortunately I do not have the time to reciprocate. I have to ask first, are you working union jobs by chance? That does make a big difference. I will agree with you on a lot of what you are saying, and it is true that my observations are anecdotal and I can only speak from my personal experiences. However a good amount of what you are saying I am not seeing. Perhaps it's a locality issue. The $45 to $55 an hour is for a 30 year journeyman building a data center for Microsoft. The reason he is sticking around for this job is because every thing else in the region is paying less. Another point about medical and 401ks or staying with a company for 7 years. I rarely see anyone stay with a company for longer then the job last. 

  
My main point of originally posting is that I keep seeing recommendations to people going for CS degrees to go work in the trades instead. I don't think most CS majors have any idea what they would be signing up for going into the trades or would be willing to do it in the first place.

  
I have to run. Once again I do want to thank you for taking the time to post a well thought out and sane response.",1,1736604594.0
1hyhkdj,m6in3nf,"Whelp... That's probably true, RIP",1,1736564182.0
1hyhkdj,m6qmkoy,"So glad to hear it!

For what it's worth, the company I work for (sorry won't give out the name, it isn't THAT big), is consistently not able to hire enough people. It is a company people want to work for, but we just cannot hire fast enough. I know plenty of other companies in the area that are the same way.

Everything outside of the Bay area bubble is pretty fine imo. This field isn't as employee sided as it was, but it's still fine.",2,1736687756.0
1hyy26u,m6l3kng,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736608759.0
1hyy26u,m6l6ska,Think you’d have to double confirm all of the IP addresses associated with the company manually if you want it to be airtight,1,1736609841.0
1hz20tc,m6m0wj6,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736619342.0
1hz20tc,m6mqi2u,Wonder what course you seling,3,1736627414.0
1hz20tc,m6ou7w4,no course,1,1736652793.0
1hy7avi,m6f1krs,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736523935.0
1hy7avi,m6f6k7h,"10-15 unless you work at a unicorn 

You can try and negotiate, but at this level it might be wise to job hop (easier said than done with the market the way it is.)",6,1736525419.0
1hy7avi,m6fhkrk,"When I’ve gone from IC to manager, my raise was 17%.",3,1736528609.0
1hy7avi,m6sl03t,"Assuming senior to lead/staff is still technically an IC track (no formal people management), I expect 15% base increase. 


If there is formal people management, I consider this a promotion to a different track altogether. I'd expect 15-20% increase in total comp in that case, but it'd depend much more on how your company sets levels and ranges for IC vs management. I say total comp here because often there are juicer management - only incentive plans that can make a mediocre increase in base acceptable if you reasonably expect to get at least 80% of the 100% target incentive. ",2,1736710176.0
1hy7avi,m6fn14f,Check out salary dot com. We don’t know your qualifications or regional salary expectations.,1,1736530185.0
1hy7avi,m6oqg06,"There isn't a hard-and-fast rule: the salary jump from IC to management, internally, can be anywhere from 10% to 40% (or more). My current job, a think thank, has a 25% bump to go from the most senior analyst role to manager. For additional context, senior analysts usually spend 2-4 years (depending on their previous experience) before getting promoted as a manager.

You should be asking your current manager(s) with whom you have a great rapport. There is bound to be someone who can give you a rough estimate of the pay band.",1,1736651367.0
1hy7avi,m6fhtry,"i think it can be smart to take a 10-15 into Lead, take that for a year, then job hop to another lead where you negotiate additional bump bc now you have proven lead experience + they need to entice you to leave your current role. ",3,1736528681.0
1hy7avi,m6f9dvw,"Lots of Lead/Staff Data Analyst positions for hire, but way less mid-level roles",2,1736526244.0
1hy7avi,m6sta1p,"Great feedback, thank you. Admittedly I’ve only been at this company for under two years so I’m still learning the intricacies of the management structure. I do not believe formal people management is involved but I don’t know for certain that’s true in my case. In either case you have made good points for me to consider regardless of how that lands. 

Appreciate it!",1,1736712506.0
1hy7avi,m6ft53b,"That’s sort of the point, I’m looking for generalities so I can form a baseline",2,1736531935.0
1hy7avi,m6f9l4e,"Oh, yeah? That makes sense.",1,1736526303.0
1hy7avi,m6fv4gg,"And I’m saying that you won’t need to. It’s free, homie. There’s also a lot more data points on it than the handful of folks that responded.

But you do you. Good luck with the pay raise!",1,1736532504.0
1hy7avi,m6ignyz,"I find it fascinating that you’d rather use Reddit data than a website that offers much more comprehensive data, considering your profession. Just saying.",0,1736561873.0
1hy7avi,m6iipwl,"In addition to. I didn’t feel it necessary to defend the post, but I’m aware of salary.com, levels.fyi, etc etc. I’m just here looking for personal anecdotes, as every bit of information is helpful to me. 

The fact that I posted this should in no way imply it’s to be my only source of information. I’m not sure why it’s being interpreted that way.",3,1736562601.0
1hy7avi,m6m5ife,"Hey, nice one guy",2,1736620772.0
1hyv7yo,m6khf93,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736599850.0
1hyv7yo,m6kneg1,"I'll say the same thing I always say when this comes up.

By the time my job is replaced by AI, so many other jobs will have been replaced that we either have universal basic income or riots in the streets. Either way, I'm putting on my comfy pajamas and having a good time.",4,1736602576.0
1hyv7yo,m6kkpz8,"Impact Analytics within Meta?

Not sure I understand your question.",1,1736601401.0
1hyv7yo,m6kmmbq,It depends if the AI can iterate quickly analyst would be able to develop solutions much faster.,1,1736602242.0
1hyv7yo,m6kmoyb,"As in how will it mpact DA, DE, and DS jobs?",-3,1736602272.0
1hyv7yo,m6kpdxo,In general or at the company that is rumored to start using AI in place of engineers?,1,1736603405.0
1hyc3oc,m6g74bv,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736535948.0
1hyc3oc,m6g9a6q,"Analytics is not generally over-saturated (genuinely good analysts are still as rare as hens’ teeth), but it probably is at the lower end, where there is a plethora of under-trained newbies wanting entry-level positions. 

Govt jobs are often pretty good to start out in - less competition due to lower pay, but they generally take the effort to train you better than some startup that has no clue.",65,1736536603.0
1hyc3oc,m6g8o37,There is no future in this field for someone that posts this same question to 5 subreddits rather than just googling it,44,1736536401.0
1hyc3oc,m6gyibh,"I would recommend picking an on-demand domain and making sure you have experience in that domain, NOT just the analytics/technical experience. E.g. Health/Healthcare analytics.",6,1736544001.0
1hyc3oc,m6gho6e,Nothing personal but I'm getting tired of seeing these same posts nearly everyday. Please use the search under Analytics.,22,1736539037.0
1hyc3oc,m6g8k72,"It's over-saturated with entry level candidates but not experienced candidates.

Basically, every job posting gets 1,000 applications from identical recent masters in business analytics grads. To a hiring manager, they all look freaking pathetic. It's all the same dumb class projects and nothing else.

Your goal, when applying to any job, should be to get your resume in the hiring managers hands. If you don't do that, you shouldn't consider it an application. If you do that, you're competing against like 10 people instead of 1,000.",25,1736536369.0
1hyc3oc,m6gm3n1,Yes.,2,1736540331.0
1hyc3oc,m6hi4ca,On research you do a lot of analyses.,2,1736550113.0
1hyc3oc,m6gczjb,I might be biased but my answer would be simulation. A good place to start is learning simulation in Python with SimPy.,2,1736537666.0
1hyc3oc,m6qfmnr,It's been said often here but the easiest way is to get a job in the industry you like then start developing technical skills on the job. It's what I did in my internship,1,1736684329.0
1hyc3oc,m6geuat,Carpentry 🪚,-1,1736538210.0
1hyc3oc,m6ggvsx,"Agreed. I'm hiring for a revenue analyst now and, no joke, 90%+ of the applications I get are from people with no experience in analytics at all, much less a specialization.",30,1736538809.0
1hyc3oc,m6glsyj,"I agree. 

There’s demand for highly skilled and experienced folks. 5+ years of experience in a specific domain, proficient on the relevant tech stack and stats methods, good business and communication skills. 

There isn’t much demand for newbies unfortunately. And most teams aren’t big enough to properly train newbies.",7,1736540243.0
1hyc3oc,m6gi7hn,What is your definition of a genuinely good analyst?,6,1736539194.0
1hyc3oc,m6jdodq,We got 200 applicants in the first 24 hours for an entry level role 😵‍💫,4,1736575591.0
1hyc3oc,m6gr9xd,Where are you looking for government jobs? I check out governmentjobs.com but rarely find anything around me.,2,1736541854.0
1hyc3oc,m6gcpfn,They kept removing my posts.,-14,1736537583.0
1hyc3oc,m6j9awx,Would you recommend doing MIT Micromasters in Supply Chain to build that domain knowledge?,0,1736573326.0
1hyc3oc,m6giq1t,"It does at least highlight the quality of analyst who wants to get into Analytics - basically someone with such little interest they can’t be bothered to search google or the sub they are posting in first. Given all data analysis is essentially research of some kind, it speaks volumes.",14,1736539343.0
1hyc3oc,m6jgtm8,">Basically, every job posting gets 1,000 applications from identical recent masters in business analytics grads. To a hiring manager, they all look freaking pathetic

Why do they look pathetic to you ?? Seriously.",6,1736577351.0
1hyc3oc,m6rh5at,How to get a resume in a hiring managers handv,1,1736698750.0
1hyc3oc,m6sftq3,"Ah, the ancient paradox: how to gain experience when gaining experience requires……experience.

Are you suggesting that they send direct messages to people on LinkedIn, for example? Or did you have something else in mind?

Does this advice apply to those 1,000 inexperienced applicants or are you mostly addressing people who already have experience?",1,1736708706.0
1hyc3oc,m6gm1ah,"Same, we’re trying to hire an experienced product/web data analyst. A very small number of applicants match the qualifications we’re looking for. Unfortunately most of them are failing the SQL screener.",19,1736540312.0
1hyc3oc,m6gn45w,"Experience in a specific domain - product, marketing, finance, supply, healthcare, etc. 

Comfortable and knowledgeable of the relevant tech stack. For example, for product analytics, that’s typically SQL and platforms like Adobe Analytics or Amplitude or something like that. 

Experienced with the relevant statistical methods - for product analytics, that’s going to be experimentation/hypothesis testing, descriptive stats, and some basic knowledge of prediction (regression and tree models). 

Good domain or business sense - can come up with the ideal success metrics and how to define them, can write proper hypothesis statements for experimentation or analysis, can take vague questions from stakeholders and turn it into a useful project with business impact, can communicate their analysis clearly and formulate useful recommendations. 

Some of these things can be taught but unfortunately a lot are learned on the job. It’s why a lot of folks working in analytics pivoted from another career.",18,1736540630.0
1hyc3oc,m6h5jrc,"Critical thinker, problem-solver, comfortable with the quantitative methods required to do good data analysis. All in someone who can talk to clients/bosses/co-workers, and who finds solving the challenge more interesting than doing fancy maths or technical solutions. That balance between quantitative and qualitative skills is a rare combo!",8,1736546121.0
1hyc3oc,m6h637t,"I’m in the UK so not relevant for most, but the civil service jobs website often has operational researcher/data-analyst/analytics jobs that would be great training. How I got my start.",5,1736546287.0
1hyc3oc,m6gudsr,Usajobs.gov is the US federal government site,2,1736542763.0
1hyc3oc,m6gjc6e,They remove them because this question is asked 15 times a day in these subreddits. Be mindful of starting a new thread before searching.,17,1736539525.0
1hyc3oc,m6nghx9,"I work for a distribution center and I have some minor experience in supply chain. I’ve thought about getting that certification. From what I’ve gathered, the certification itself isn’t going to get you much attention but it’s extremely valuable to build domain knowledge",1,1736635747.0
1hyc3oc,m6sncs5,"One time when I was applying to a job at a tech company, I searched the company on linkedin and found someone who had a similar background as me. I messaged them and asked if I could buy them coffee and do an ""Informational Interview"". Informational interview is a known institution among MBAs, and a lot of them will say yes. The guy said ""Sure"" so I had a coffee with him, talked about the job, and asked if he would email my resume to the hiring manager.",1,1736710846.0
1hyc3oc,m6smop9,"There's nothing wrong with a lack of experience: everyone starts somewhere.

What you need is to stand out despite a lack of experience. You're competing against a thousand people who all have the same certificate as you, so here's what you need:

Let's say you're applying as a pricing analyst in the sneaker industry

The relevance of your school project to your job needs to jump off the page (so choose your school project carefully) CAPSTONE PROJECT: OPTIMIZING PRICING FOR LUXURY APPAREL

There should be something in your resume that involves the industry of the job in question: I WORKED AT FOOT LOCKER

There should be something that expresses a personal relationship with the industry: I HAVE A MASSIVE SHOE COLLECTION

And then there should be something personal: In addition to shoes, I also love puzzles and coffee

This would be way more effective than 99% of the resumes you'll be competing against, because 99% of them lack personality and relevance.",1,1736710658.0
1hyc3oc,m6gyt0c,"Edit: sorry, saw your other post with the requirements

Can you share those requirements? I’m a product/web analyst with 9 yrs experience looking for a role and I find it tough to fit the experience folks are looking for AND to be up to snuff on querying w/o finding time to re-boot camp myself. I am responsible for implementation, in-platform reporting and dashboards, and some analysis that requires querying, but I also have some junior analysts on our team that I can leverage because I have bigger fish to fry. Querying is a skill that requires practice to maintain. I feel comfortable being able to get data in a normal work environment, especially with all the existing process we have, but screens take away all the resources I use to make up for the regular practice I lack. I feel like orgs need to take for granted a bit more that someone in a senior analytics role is capable of getting back up to speed on the basics they expect of junior analysts.

Not petitioning for the job, just giving my perspective.",9,1736544091.0
1hyc3oc,m6gxgxk,They do not train SQL anymore it seems.,3,1736543690.0
1hyc3oc,m6ipqq7,Can you share the JD?,1,1736565159.0
1hyc3oc,m6ho2cf,Thank you for your in-depth reply!,5,1736552114.0
1hyc3oc,m6ho09m,Thanks for the reply!,4,1736552095.0
1hyc3oc,m6ngusm,I looked into it is a pretty legit certification. I was thinking pairing that with Masters in Information Systems would make it a good candidate for supply chain analytics.,1,1736635867.0
1hyc3oc,m6sslpz,Gotcha. Ive done similar Zoom chats. Are people still meeting for coffee or in person meetings? Even if you have different backgrounds like you aren’t from the same school etc,1,1736712318.0
1hyc3oc,m6h328t,"I’m honestly not sure what our SQL assessment is like (I’ve been on this team long enough that my SQL test was via whiteboard during an in-office interview). But this role will use SQL every day, and due to our team being distributed across multiple time zones around the world, there isn’t always someone available to answer questions or review code, so we all need to be able to write accurate queries to get the necessary data. 

That being said, I’ve gone through enough live SQL interviews to know how frustrating they can be.",6,1736545366.0
1hyc3oc,m6gzj3c,I would probably fail most intermediate and up SQL screens tbh. Haven't had to write SQL since before covid.,5,1736544308.0
1hyc3oc,m6jay83,SQL is far easier and easier to remember than you give it credit for I think… unless you’re really deep into the GUIed programs world or really low tech with excel you should still be using it on the daily as an analyst in most positions(or at least Python with SQL Alchemy),1,1736574161.0
1hyc3oc,m6okf79,"Do you have any experience in supply chain, it seems like most of these analytics jobs really prioritize job experience over degrees (not to say an MS in MIS wouldn’t be valuable)",1,1736649182.0
1hyc3oc,m6stpi6,"Well, the thing is you need something that the person you're asking for an informational interview can relate to, something that helps them see themselves in you. It could be a similar background, a similar interest, but there has to be something in common that makes them relate to you and your story.",1,1736712629.0
1hyc3oc,m6jb6qv,The most frustrating ones are when the interviewer tries to make it up on the spot. And you can always tell. Some of these interviewers dont know how to interview.,3,1736574281.0
1hyc3oc,m6jb1fp,What’s your analyst specialization that you haven’t written SQL since Covid lol,3,1736574207.0
1hyc3oc,m6ovsdi,I don't have supply chain experience but I was looking to differentiate myself with other candidates. I did Chemical Engineering bachelor's degree in another life.,2,1736653401.0
1hyc3oc,m6stxvo,"I see. That makes a lot of sense! What could be examples of such things? Like I had a People Analytics Internship and I am very interested in that area so I am able to connect with people in that domain, but there are a lot of other domains too. People is very narrow.",1,1736712694.0
1hyc3oc,m6ve80j,"I'm in education policy and the data I work with is public data made available in dozens of different excel workbooks...

My pandas skills are super sharp though.",1,1736742792.0
1hy3van,m6e90df,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736514039.0
1hy3van,m6ehtsh,"I switched from a similar role to what you described into an Analytics Architect role in a marketing department at a very large company. 

Since I had some analytics experience with the tools we used internally for metrics etc, it wasn’t necessary for me to get additional certifications to qualify. I did have to learn the tool they use for implementation (Adobe Analytics) but that was fairly easy to do on the job. 

So far I’ve loved the direction I picked, my experience in managing the customer journey through acquisition to conversion and beyond has helped me a ton. It seems like a really smart next step career wise as I’m still helping to shape customer experience and drive business initiatives without having to do so much copy writing and whatnot.",5,1736517440.0
1hy3van,m6esugy,"Definitely start networking with the analytics team. Ask them what skills are the most relevant for the team so you know what to focus on. 

In the meantime, use the data you can access to start answering relevant questions for your team or the company. This is how I pivoted from marketing roles to marketing analytics.",3,1736521226.0
1hy3van,m6fichr,It never hurts to learn analytics -- definitely reach out to the team and get a sense of their stack -- SQL and python are fairly straightforward -- if you have good governance and modelling it's likely just a matter of learning Tableau or Power BI.,3,1736528834.0
1hy3van,m6eo7wa,"if you’re doing PPC, you likely already do some level of marketing analytics when it comes to optimising campaigns, KPIs/metrics, working with GA4/Tag Manager, and using Excel. if you have some dashboarding skills in Looker or something similar, even better. 

as for projects, making a new dashboard that fills a currently unmet business need would probably help with both your application and helping you figure out if you’d like the job 

the fact that you can pivot to an analytics role is a very good and rare opportunity. it’d be worth speaking to someone in the analytics team or shadowing them to see what their day to day is like and if you like it, go for it",2,1736519702.0
1hy3van,m735aq9,"Thanks, what would be best to learn first? It's a tech company with so many resources available for SQL and Python. Regarding visualization tools, I see Looker dashboards are flying around. Should I do that first or maybe focus on Tableau/Power BI",1,1736857536.0
1hy3van,m735kcz,"Thank you, this is very valuable advice. I was already doing some analytics in my current role but it would be good to see how their regular day looks.

Edit: If you can, could you explain what do you mean by this ""dashboard that fills a currently unmet business need "" Maybe an example from any industry just to have an idea in which direction I should think. Thanks",1,1736857661.0
1hxyy3j,m6d8uj0,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736493237.0
1hxyy3j,m6dala1,"Very common, especially in consultancy where you may be working on a per hour chargeout rate. 

It’s annoying, when I had to do this I usually just did it at the end of the week and guesstimated from my calendar/memory.",11,1736494268.0
1hxyy3j,m6ddm1n,"Are you doing this forever or as a temporary thing?

I have had my team do it for like 3 weeks at a time every once in a while, just to understand better where our time is being spent, but its too much extra admin to have them do it all
Day every day forecer

Usually I would use the data to make a case for an extra person, upgrading systems that are causing us problems or understanding that we are spending a lot of time on manual recurring processes to prioritize automating them, etc.",5,1736496081.0
1hxyy3j,m6ec3jq,"I’m salary and we work on a ticket system, it’s not common for me. As long as my projects get finished, no one is micromanaging me. I’m also WFH, I tend to have a lot of free time. But I my work is never an issue.",3,1736515293.0
1hxyy3j,m6eq0y3,"I work remotely and have for years and this is a requirement of my job. I use it for client billing and to help us to understand how long our client project tasks take, eg ‘can’t you just add that extra ______ while you’re working on ______?’ No Bren-duh, because that’s an entirely new dataset that will require me to work from scratch, you’re basically doubling my effort as well as your budget.

Or you could be laid off soon. Or they think you’re a complete slacker. We really cannot tell you what your boss is thinking without more context.",3,1736520311.0
1hxyy3j,m6ez11z,"I’ve had this experience in consultant time roles and it’s annoying but par the course. 

There was one role where they wanted us to track everything down to the 15 minutes… not because it was a consultancy. It was a small startup vibe org and the COO just wanted to closely monitor what everyone was doing. I didn’t last 2 months.",2,1736523161.0
1hxyy3j,m6fjoz6,"We do it down to quarter of a day before planning our sprints, at the end of the sprint we go over it and add the actual time it took.
It helps us plan our week and understand retrospectively how reality played out.
Because it has value and our team have good vibes and we are friends it’s not feeling like micro managing.",2,1736529227.0
1hxyy3j,m6ef629,"lol.

my old boss resigned because senior leadership were idiots and she was the only adult in the room.

her replacements have been trying to shuffle our team to monday.com to track our time spent generating reports/analytical products down to the minute.

one of them is trying to micro-manage her other team into compliance. our team has essentially ignored her and continued using our own kanban board and generally remained self-directed.

it works because she has no idea what we actually do or any context for the units we support. our former boss has been gone for over a year at this point. everyone in our chain-of-command above is clueless to the nuances of our work because we were plucked from an entirely different area and dropped where we are now because it made sense (to them.)

i'm salaried. if you don't trust me to do my work, then fire me and we can both hurry up and move on.

good luck maintaining our processes and products, even with our detailed SOPs.

tl;dr: yes. yes it is excessive.",3,1736516470.0
1hxyy3j,m6eq6yr,"That’s what I do! Don’t tell my boss or clients. 😉

Edit: also when I’m not guesstimating, I find I also sometimes under track. As in, I’ll charge for an hour of work when it really took 1.5 hours. It’s not that I’m trying to discount it it’s just that *when I was perfectly focused* it was an hour of that focused time. I’m pretty much screwing myself in the long run but I really don’t have the patience to track by 15min increments.

Edit2: dear lawd, typos.",3,1736520368.0
1hxyy3j,m6elfir,This seems like the way to go. I want to also track the time on how much time I spend time tracking lol,2,1736518736.0
1hxyy3j,m6efgvg,"If you guys are hiring, I'd love a referral! Looking for wfh with good wlb - i have faang experience.",0,1736516579.0
1hxyy3j,m6eqa73,"Entire team is required, so with that being said they could totally see who is slacking after a few months of data.",1,1736520397.0
1hxyy3j,m6es1g8,"It could also be used to see who needs more training. Say Employee 1 made a three slide quarterly report and it took 6 hours to make, but the new Employee 2 made it in 12 hours, you know that you need to 1) check in with Employee 2, have Employee 1 make a template for Employee 2, or have Employee 1 supervising Employee 2 next time they make a report. 

Sometimes it’s the small things that save time. If Employee 2 doesn’t know about the Align function in PPT, she’s doing all of it manually which is not only frustrating but really time intensive. Having Employee 1 walk Employee 2 through their process means the next report Employee 2 makes is closer to 10 hours, than 8 hours, etc. So it can definitely be used for training too. Don’t stress!",2,1736520971.0
1hy4jbu,m6eedls,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736516176.0
1hxktf2,m69vs6n,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736450564.0
1hxktf2,m69yurh,"Guthub - has open collections, 

Data.gov - has various types of datasets from climate to federal and local states (not every state) with accident reports, police shootings, etc.",5,1736451452.0
1hxd98p,m682plx,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736430804.0
1hxd98p,m68ajxl,"Yes it’s possible but it’s not easy. Having a CS degree is a good start though. I would make sure you know SQL and basic stats. But there aren’t lot of truly entry level roles, far less than software eng. Being a good Data Analyst requires a combination of quantitative skills (stats), technical skills (SQL, Tableau or Power BI, and sometimes Python), and business knowledge. You’re asked a lot of vague questions and often have to figure out how to answer them without a lot of handholding. Most teams aren’t setup to train absolutely newbies. This is why most companies want at least 2-3 years of experience for Data Analysts. Most of the people working in this field transitioned to it after starting their career in something else - on my team, we have people who started in marketing, business development, finance, software engineering, customer service. 

What you can do: 

- start networking. Reach out to alumni, find local industry events, join slack and discord communities. 

- do your own projects to demonstrate your competencies. 

- consider taking any corporate or tech job you can land, develop your skills in problem solving, critical thinking, communication, and start learning an industry. Network with the analytics team and apply to pivot if a role opens up.",17,1736433584.0
1hxd98p,m684wil,"It's surely possible but definitely may not be the best time to transition. 


Market is flooded with entry level talents and that's why 2-3 years exp has become the new entry level in this field.


But as I said before, it's possible you have to prepare yourself really good as once you land yourself at the door dont screw it up and mainly develop a thick skin for rejection as transition journey is gonna be long. ",9,1736431604.0
1hxd98p,m68i6nt,"I’d think about this hard before you make the jump but it’s of course possible. A CS degree is significantly more relevant than many others so that works in your favor. The reason I say to think hard about it, though, is that operationally there exists some overlap in these spaces and if you’re “not really passionate” about CS I would make absolutely sure you are about analytics because if you’re not, you won’t get anywhere. ESPECIALLY with the market as saturated as it is (you’ve seen the daily posts just like this one, I’m sure), if you are as half assed about it as you suggest you have been with your efforts in CS, it would probably be better for you to not sink the time in. 

That said, if you do find you’re passionate about it, go grab a cert that you can stack on top of that CS degree and maybe look toward a masters that’s data related down the line (I know you said not possible now, but companies often help pay for this so might be in the future), most universities have a handful of data oriented masters programs that can help you. 

Good luck!",6,1736436063.0
1hxd98p,m68mgss,"I wouldn’t bother. Maybe prep for it by taking online courses and slowly creating a portfolio, but if you’re already in a position right now I’d keep it for the next year, at least.",3,1736437380.0
1hxd98p,m683zc5,"Its possible, but the market is insane. Goodluck",4,1736431268.0
1hxd98p,m68ltxm,"You don't need to go back to school to get a BA job, with a CS degree could be considered technical enough and in most analyst job requirement will list math, stats and CS degree. That being said, you should get comfortable with SQL, excel and powerBI.

You have a a big experience gap so that might hinder your chances in the job search, DA and DS roles are the new hot topic so expect a lot of competition similar to CS roles. I think that BA roles might be at bit better because people think of it as lest technical than DA and DS roles.

To get your foot in the door look for BA types of job and you might find some gems hidden in supply chain, operations, inventory management roles because these are the traditional analyst jobs but are being overlooked for DA jobs. Basically, any jobs related to business reporting that aren’t being called DA, DS, BI. Built up experience and then network/apply to more technical jobs withing the company/industry, at the end what will matter is what you can do to do help the team/stakeholders with the analytics and reporting you are providing rather than the exact tool (tech stack).",2,1736437190.0
1hxd98p,m698om7,Most people here are from US? Job market feels way better in Scandinavia,2,1736443917.0
1hxd98p,m6cnhbh,"Yes, it’s absolutely possible. That’s exactly what I did. I graduated with a cs degree and worked as a software engineer for about 3 years. I didn’t really like it and so decided to switch to data analytics. You do need to brush up on sql, but it shouldn’t be a problem for you since you have a cs degree. Tableau, power bi, etc. you can learn on the job. Your cs degree gives you an upper hand, at least that’s how it’s been for me. Make sure you use technical lingo (appropriately of course) during the interview. Apply to less technical industries like healthcare, insurance, etc. They’ll be easier to impress. Make sure your resume highlights analytics, even though you were a qa. I would add stuff like: analyzed applications performance using sql, build a dashboard for bugs tracking, connected to client’s APIs to bring in some data associated with the application, etc. Have good examples ready for each. Stretch your experience if you must. I think you have a better chance of getting an interview/job than anyone with an online course and a portfolio. You can definitely do it.",2,1736482820.0
1hxd98p,m69z8z6,"You're behind the eight ball if your competition has domain knowledge and you don't.

I've managed to cultivate a knowledge base that would give me inroads towards education, healthcare/insurance, and housing.

Those are all things that interest me personally and aligned to my values and I've been lucky in that sense because my current and prior roles exposed me to lots of different areas, different types of data, etc.

During the interview for my current job, I demo'd a PowerBI dashboard I had created for my fantasy football league. It went over pretty well with the interview panel and it impressed because one of the interview questions asked me about my most recent analysis.

A friend had asked me which NY Jets wide receiver was most viable to start in fantasy, as they were a Jets fan and desperately wanted to play a Jets player, but still win, lol.

The answer was none of them, and then I began explaining their decreasing targets, the increased reliance on the running game by highlighting the number carries, and then I made a point about Elijah Moore, in particular, because he had been so successful towards the end of the previous year but he was generally underperforming. I highlighted his lack of targets over a couple games and how ultimately this was bad for his career as wide receivers' contracts are generally determined by their receiving statistics. I ran through this bit for the panel and added the bit about their salaries.

Reports dropped later that day about how he was trying to force his way off of the Jets and was requesting a trade.

They hired me and one of the panelists wanted my opinion on the Giants wide receivers, lol.

It also helped that the prior year I won my fantasy football league and since I assumed ownership of this particular team four years ago, we've made four playoff appearance. The team has finished 2nd, 1st, 4th and 2nd; so I got to toot my own horn a bit.

Why was computer science so tedious for you? I think you'll feel similarly about data analytics, but maybe not.",1,1736451565.0
1hxd98p,m6agpm1,Prob not worth to try. All jobs kinda suck btw just pick one that pays good and management is nice,1,1736456667.0
1hxd98p,m6cchbc,"You’d be surprised of some marketing tangent roles that require CS degree or technical background, try into looking product stuff related to marketing or other analyst roles in general",1,1736478761.0
1hxd98p,m6ccwyt,Do you like writing sql to help find and explain data for a business reason? It can actually be fun. If you like that give it a try.,1,1736478914.0
1hxd98p,m6chxb4,"Two things I dont understand:
1) Why do computer scientists want to work in data analytics?
2) Why do companies prefer computer scientists?

Data analytics is basicaly research. Mostly, the final stages of research but nevertheless, research. I would assume that data analysts would come from biology, chemistry, physics, medical, and psychology research fields. People who come from these fields are doing data analytics throughout most of their academic degrees. They are mostly doing induction. On the other hand, people who come from computer science, math, and engineering are doing hard maths throughout their degrees. They are doing deduction.",1,1736480714.0
1hxd98p,m6f01fs,"You definitely don’t need to go back to school to get a degree for a data analyst role if you already have a degree in CS. 

Do you have hobbies? Like reading books, watching films, follow football, etc? Go scrape some data from a website or two, think about some questions you want to answer with the dataset, and spin up a web app / Streamlit app that visualises that data.

If you’re working or volunteering now, look for opportunities to analyse some datasets, even if it’s in Excel/Google sheets. If you can leverage your current position, that’s your foot in the door!",1,1736523469.0
1hxd98p,m6tx5x4,"With your CS degree and QA background, you're actually well-positioned to transition into data analytics! I'd recommend starting with Python for data analysis (pandas, matplotlib) and building a simple dashboard using Preswald or Streamlit to showcase your skills - this will give you hands-on experience while building a portfolio piece that demonstrates both technical and business understanding.",1,1736724345.0
1hxd98p,m68bn72,"Not a jab, but what makes you think data is going to be any different?",0,1736433954.0
1hxd98p,m68cq3z,I mean anything is “possible” lol,0,1736434310.0
1hxd98p,m69f214,"Can you recommend best tutorial for beginners for SQl, PowerBI and maybe some business related channel ? Thank you.",1,1736445743.0
1hxd98p,m68vbjq,"I disagree with your statement that there are ""far less"" entry level data analyst roles than software engineering.",-5,1736440025.0
1hxd98p,m685ldd,"What can I do the prepare? I don't really have much I can put on a resume right now. I can put my education, and internship, and skills I have related to computer science. I can get certifications which would help, but I'm not sure what else.

For CS related jobs for example, with no experience, you can fill your resume up with side projects to show your knowledge. I'm just not sure how I would create a data analyst resume without much experience. I'm not sure how exactly I would even get started for say data analyst side projects. For CS side projects, you literally just start coding and making something that can be useful.",0,1736431852.0
1hxd98p,m6b2m2v,How can one create a portfolio? Any suggestions for projects,1,1736463298.0
1hxd98p,m69u3fa,"The tutorial should be starting projects, ramp of the complexity as you get better. Watching videos and practicing a skill in isolation won’t help you.",3,1736450075.0
1hxd98p,m6i722y,github. create a portfolio there and look at open database projects that can show your skills and add it to LinkedIn.  that's what I'm doing . I need something to back me up and to show my skills since that's basically my only experience.,1,1736558577.0
1hxd98p,m69xjzj,"Thanks, can you tell me which projects will be good for beginners?",1,1736451074.0
1hxd98p,m6a0eya,"That’s up to you man, you gotta find something that interests you and will motivate you to finish it. If you are more interested in just data analytics over data science for instance you can set up a SQL server, pull data and export it and maybe do some visualizations. Just find a way to intelligently use some common tools in conjunction.",0,1736451904.0
1hwntvr,m62gv6y,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736352858.0
1hwntvr,m62i6md,"YouTube has a variety of helpful introductory videos to APIs. One thing that wasn't explained clearly to me at first were different types of APIs. APIs can be very easy or complicated.

An API is just a connection to a data source which you can use to draw from. Simple APIs might just require a GET call with a URL. Others such as OAuth will require you to follow specific documentation to request an access token, then use that access token to access the data you need.

You can use a number of different coding languages to perform API calls. I recommend Python.",27,1736353248.0
1hwntvr,m62xw4a,The US Census has a well-documented and well-used API that you could use to pull demographic data,7,1736357984.0
1hwntvr,m63ln2o,"Basically every API has its own readme. You don't need much pre-existing knowledge about API's specifically. Just a bit about HTML requests. 

You can use Postman (free online tool) to test out any API. 

So to learn: Pick any API you want, read through documents and try to get something using postman. 

If you can get it done in Postman, it's pretty easy to translate to python or whatever you want to use.",10,1736364828.0
1hwntvr,m69t4at,"In case anyone knows and is using this successfully, I’ve been trying to build a simple application to fetch YouTube comments from the YouTube API. I have enabled this API in Gcloud but can’t seem to find the rest of the pieces of information I need to fetch comments &/+ replies. 
I’m a noob, any tips would be greatly appreciated.",3,1736449794.0
1hwntvr,m6j3pmt,"API is an extremely general term that literally just refers to how applications talk to each other. APIs allow you to use data and services from all kinds of other applications within your own. The Windows OS has a massive set of APIs whereas a microservice likely only has one or two function with a few options each.  
  
The best way to learn is to practice. If there's specific data you want for a project, search online to see if they have an API. If they do, they'll most likely have some kind of instructions on how to use it. As others have mentioned, authentication can often be tricky, but you can always ask for help on specific issues if/when you run into them.",2,1736570697.0
1hwntvr,m63m804,"Open Python editor. If you got Mac, terminal, type python3 enter. 

Code (lower case everything)- 

import requests

Headers = {something}

Response = requests.get(“url”, headers=headers)
Response.json()

———
Plug in values for the something. 


Source am data engineer, focusing on automating etl and da work.",3,1736364997.0
1hwntvr,m63130a,"What SaaS or softwares do you use? For Sprinklr, I only had to request some credentials and then followed steps in documentation to link it to PowerBI.",1,1736358905.0
1hwntvr,m64rhod,ChatGPT gets me through most API connections,1,1736377153.0
1hwntvr,m67llo2,Does anyone have any resources for R? My company predominantly uses R,1,1736423390.0
1hwntvr,m6fkyfe,This is quote a helpful thread. Glad you asked!,1,1736529591.0
1hwntvr,m6gf2ri,"Since almost all apis are different, the best method is to read the manual of the service provider. The basic idea is that you send a message and wait for a response. The structure of the message you need to send and the response you will get will vary greatly.",1,1736538280.0
1hwntvr,m637w7t,I’d just YouTube it.,1,1736360865.0
1hwntvr,m63448s,"Recently had to set up a REST API and getting through OAuth made me rethink my life choices. But then I figured it out and felt super proud!

But then the documentation said I needed to use that session to request an XCSRF token and almost cried.

I did get it going though and learned a lot along the way.",6,1736359785.0
1hwntvr,m63uyzw,I use a little python outside of mostly R. I see a lot of JSON being used when looking up anything API related,1,1736367542.0
1hwntvr,m63udhz,"I have heard of Postman, thanks for the info!",2,1736367365.0
1hwntvr,m6izssw,"I've used the YouTube Data API for a few projects in the past. It has pretty great documentation! It sounds like comment threads may be what you need. Skimming over it, it looks like you can look them up by comment ID, video ID, or channel ID depending on what you need, and you can also add search terms to filter on.

The page tokens will probably be the trickiest part to get right, or at least they were for me. Basically if there's a lot of results the API won't return them all at once. Instead, the response will include a ""next page"" token and you will need to keep repeating the request with that ""next page"" token until you get all the results.

[https://developers.google.com/youtube/v3/docs/commentThreads/list](https://developers.google.com/youtube/v3/docs/commentThreads/list)",2,1736569011.0
1hwntvr,m63uaym,Thank you this was helpful,1,1736367345.0
1hwntvr,m67t43q,I have had the best luck using DataCamp for R as well as ChatGPT. I like the R syntax and it’s easy to learn in my opinion,1,1736426995.0
1hwntvr,m63855s,"This is why I haven’t bothered learning it and tell my boss that we should look for alternatives. While mastering API would provide a lot of value, I just don’t have the time to throw my laptop off my balcony and wait for a replacement.",3,1736360936.0
1hwntvr,m646s5j,API calls frequently return tables of information. The tables are compacted and messy looking (although still readable). JSON makes it easier to retrieve only what you need and in a way that is easy to read.,1,1736370970.0
1hwntvr,m63ze8t,"It's really a convenient tool. Because every API is different, it usually takes some trial and error before you are able to get what you want. Testing it out with Postman and then when you know how to do it, just paste it to Python/R/...",2,1736368841.0
1hwntvr,m6n5tp0,Thanks a bunch. I’ll take some steps and see.,1,1736632321.0
1hwntvr,m6831dr,Are there any examples you may have? I tried Chatgpt as well but there is always server error,1,1736430925.0
1hwydwt,m64wy94,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736378948.0
1hwydwt,m6509qb,"I've never been asked for more than 3, so this is just bizarre to me.",8,1736380066.0
1hwydwt,m64xyyg,"I had to do something similar at my job, but it's a junior role and the company isn't non-profit.",6,1736379291.0
1hwydwt,m654ngw,It's been so long since anyone asked me for references that I don't even remember who's on my list.,4,1736381546.0
1hwydwt,m65oq11,"I worked at my last job for 5 years under the same manager.

I suppose I could add a skip, but asking for a manager reference from 7-10 years ago sounds like major overkill.

3 coworkers and 2 managers is more manageable, but still overkill.

A non-profit shouldn’t be so exclusive, they’re not going to pay more than private. 2 people saying you’re a good employee should be more than enough.",5,1736388369.0
1hwydwt,m66cmx9,"I work in non-profit, and this seems bizarre.  I was an internal candidate for my role, but I gave 2 or 3 names just as part of the interview process.",3,1736397507.0
1hwydwt,m655j4q,Yes. Nonprofit can be very chaotic. This is kind of a yellow flag.,2,1736381843.0
1hwydwt,m65mf5g,I’ve never been asked for more than three references. And I’ve never had an employer call more than one.,2,1736387562.0
1hwydwt,m65u67f,Never asked for a references on an app but have typically hired people who came with one from someone I knew. Source: running analytics depts for 10 years and have hired ~20 people.,2,1736390309.0
1hwydwt,m67e4gd,German here. I have never been asked for references. Nor did I ever provide some.,2,1736419081.0
1hwydwt,m698uuk,Yes that is insane. Most places don’t ask for any.,2,1736443966.0
1hwydwt,m68ohi7,"My job required 4 managers and six past colleagues. And it was a questionnaire that had to be completed or I would not be hired. I also had to get fingerprinted. Higher Ed.

Edit: oh and I wasn’t even a manager. That was just the basic employee requirement. Our senior manager candidates have to present something to the department at large too. They likely also have some sort of financial bonding, though I’ve never bothered to ask.",1,1736437990.0
1hwydwt,m6bcni1,"curiously enough, it's mostly been at non profits that I've been asked to provide extensive references.",1,1736466637.0
1hwydwt,m6exsek,"Never been asked to do more than two, and no references have ever been called",1,1736522781.0
1hwydwt,m65ht8y,Last two places didn't even bother to call my references.,4,1736385975.0
1hwydwt,m650bn0,damn 5 different references for a junior position??? What is going on fr????,8,1736380084.0
1hwydwt,m65walg,I can provide 3 references & perhaps one of them can double as a manager and a coworker but other than that I’m not sure why 5 different people,1,1736391069.0
1hwydwt,m67t1q5,Okay thank you cos I was wondering the same!,1,1736426966.0
1hwydwt,m65w0u7,Okay I see. I’ve never worked at a non profit before so that’s why I wanted to know if it’s normal,1,1736390973.0
1hwydwt,m65wuoh,Yes I’m not against references especially when there are a lot of applicants but I still think getting references from 5 different people is too much. And I was only given 24hrs to fork these references and all their information. I don’t even think federal jobs ask for this much. Plus the pay most likely still falls within what I’ve already been paid before in the private sector. Idk.,2,1736391269.0
1hwydwt,m68tqem,Wow that is nuts!,2,1736439557.0
1hwydwt,m6594jg,"They ended up being okay with 4, but it seemed like a lot to me as well.",4,1736383048.0
1hwydwt,m68p22d,"To be honest it was such a pain that I haven’t left again because I worry about asking my references for another favor like that.

I hate what recruitment has turned into.",3,1736438160.0
1hwydwt,m68tz1n,"Indeed. Luckily I like my job, but I’d be fucked if I was laid off.",1,1736439627.0
1hwydwt,m68txxi,For real!,2,1736439619.0
1hx1nqx,m65nqoj,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736388019.0
1hx1nqx,m65xha9,I can help you out but need more details about the problem statement!,1,1736391496.0
1hx1nqx,m68x00r,Could you really? Mind if I direct massage you?,2,1736440519.0
1hx1nqx,m68yrdf,Please go ahead,1,1736441030.0
1hwtr8j,m63ufar,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736367379.0
1hwtr8j,m63w3qm,"Honestly, the best career advice for noobs is to go read a newspaper article and post it here with your analysis. Mods should only allow real analytics. Not talking about analytics.

It’ll be more interesting. We learn something. And we can roast your analysis - WHICH NEEDS TO HAPPEN btw. 

We all have fun.",11,1736367877.0
1hwtr8j,m645zy1,"They jumped the shark a long time ago

These days it is mostly just influencers selling unnecessary shit to people who think it will help them get into an oversaturated profession",8,1736370742.0
1hwtr8j,m64iike,"I’m a fan of professional associations for my field as well as the Data Viz Society. I have my own workgroup at my org which is nice but I’d love something regional, but it seems to be impossible.",2,1736374376.0
1hwtr8j,m644vgo,"This is an amazing idea. If every thread asking to break in instead either presented some analysis to be critiqued, or had a specific question about some blocker it would significantly improve the quality of this sub",5,1736370416.0
1hwtr8j,m657grw,The best way to get engagement is to post something wrong.,3,1736382493.0
1hwtr8j,m63wczi,One of the best ways to learn is to get roasted :D,1,1736367955.0
1hwtr8j,m6501o4,That's unfortunately the state of society. I can understand selling things if they truly add value but some influencers especially just think anything with their name attached deserves $,2,1736379992.0
1hwtr8j,m64zje8,"I assume when you mention regional, you would want in-person events?",1,1736379821.0
1hwtr8j,m64nsbe,I can’t stand the posts that provide literally no details or any specific questions. And I kinda (really) feel like a lot of people who make such vague posts might be inherently lacking in the skills that lend themselves to being good at analytics…,5,1736375986.0
1hwtr8j,m68nic1,"I remember seeing a post once where someone said to get their homework questions answered quickly, they posted the question, logged out, logged into a second account they had, then answered it wildly incorrectly. 

It was mere minutes before people flooded to the post to correct him, lol.",1,1736437698.0
1hwtr8j,m68jrty,"Not necessarily. Maybe biannually, but I’ve been remote since 2020 so all of my networking has been online outside of in person conferences. I find I do just as well.

Edit: as more background, there is actually a regional group but getting them focused on data (which was the priority, per an early member survey) was just…ignored. It’s what led to me making the local workgroup. Sometimes ya just gotta do the damn thing yourself, ya know?",2,1736436556.0
1hwtr8j,m650kzf,"Yeah, that's a good point. Often when I'm talking to early career stage analysts it's clear that technical skills aren't the issue, it's mostly soft skills. 

I know it's said ad nauseam, hard skills get you in the door and soft skills get you paid/promoted.",3,1736380171.0
1hwtr8j,m6rdc2k,"Other subreddits where they are on a computer and then take a distant photo with a phone to ask for help on reddit, without realizing they can access Reddit on the computer their using, and take a proper screenshot and provide code/sample data to assist... Gets on my nerves so bad.  


Guess I am just too old where I know of a life where there were no smart phones so if you wanted help from a forum you posted on, you took your screenshots and shared code in the actual post.",2,1736697521.0
1hwefma,m60l2qr,"If this post doesn't follow the rules or isn't flaired correctly, [please report it to the mods](https://www.reddit.com/r/analytics/about/rules/). Have more questions? [Join our community Discord!](https://discord.gg/looking-for-marketing-discussion-811236647760298024)


*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/analytics) if you have any questions or concerns.*",1,1736321480.0
1hwefma,m632lh7,"Yea, you don't need permission to apply for an internship. Where you're at is prime internship time for a college student. Internship deadlines for F500 companies is typically Jan-Feb before the summer they start so you should get your resume ready (most colleges have career/resume services) and apply, apply, apply. 

Good internships pay enough that you'd be easily able to cover expenses so don't limit yourself geographically (in the US) unless you have other obligations.

When I was in school I had friends who would use internships as a way to scout potential cities to live in after graduation. 

Its pretty easy to write a decent resume with LLMs and even to have your LLM tweak/individualize it for each application. Set an audacious goal for total applications (like 100 by end of January and another 100 by end of February) track your application process in a spreadsheet and get after it.",9,1736359343.0
1hwefma,m63t5wz,"I got 3 DS internships when I was taking a bachelor degree in college. This is what I did: doing projects that answered questions that I was interested in. Try not to use popular Kaggle projects as your projects as that is boring and will make your portfolio the same as everyone else.

If there is no data for the questions you are interested in, scrape them. It is easy to scrape data from static website using tools like BeautifulSoup.

Last but not least, keep these projects in GitHub and have READMEs that are readable to non-technical recruiters. After having a few projects, put them together on a page. GitHub page is the most straightforward solution for this.",3,1736367014.0
1hwefma,m68t0he,Look to your schools labs for internships. It’s so much easier.,2,1736439342.0
1hwefma,m6d4u6h,"- beg any and all professors of every class you’ve taken if they would hire you as a research assistant/know anyone who is. EVERYONE needs data analysts. I got an in in the entomology department, who had been collecting data for almost 20 years but did nothing with it

- beg any and all professors to be and undergrad teaching assistant (esp any classes that needs TAs to run labs). 

- yes beg

- if you’re in the honors college, they may have funding for you to do research, possibly abroad

- apply to a Fulbright

- use handshake, apply to everything even if you hate it

- sign up for hackathons yes I mean it

- sign up for every single outreach event. Be at the job fairs, be at the guest lectures and NETWORK (INTRODUCE YOURSELF TO THE SPEAKER and thank them etc say you’re interested in the field ask for advice to get an internship)

- skip applying on LinkedIn it is nothing but bots

- BUT ALSO FILL OUT YOUR LINKEDIN and have a portfolio of any homework assignments on GitHub yes I mean it

- you can use LinkedIn to follow alumni of your program, and reach out to them and be direct about asking for mentorship

- be best friends with your guidance counselor, take every job lead they give you

Good luck!!",2,1736490986.0
1hwefma,m6269uc,Did you ask your professors?,1,1736349608.0
1hwefma,m64ieww,"Slight correction from what I saw, internships for decent F500 are at the beginning of fall semester so think Sept to Oct. Lesser known companies w/ lower pay are around the beginning ofthe year. Considering the market please start EARLY.",1,1736374346.0
1hwefma,m61hdab,"If you don't mind virtual internships, you can consider registering for **Forage internship** (theforage.com), my sister recommended them to me so I can enrol this year. I am an M.Sc. Business Analytics and Management student.",0,1736340449.0
1hwefma,m6ofvz0,How do you reach out to profs and alumni? Not quite sure how I should word it,1,1736647596.0
1hwefma,m6850lo,Appears not to be a real internship,1,1736431645.0
1hwefma,m6al6al,"I wouldn't know about what something **appears** to be, I care for what it actually is and as far as I know it is real, it's just virtual.",1,1736457979.0
1hwefma,m6avp19,"A virtual internship is a work experience program where the participant (intern) gains experience while working in a remote professional setting and is not physically present at the job location.

Forage appears to be simulations and videos that you follow along with. This is not work experience, so it isn’t really a virtual internship. If you are in an interview and you pass that off as work experience, it won’t look good.",2,1736461123.0
1hwefma,m6aymob,Doesn't make it any less real just because it's remote though.,0,1736462031.0
1hr6zga,m4vu4lb,Gonna start trying to put our Snowflake cost saving measures into play later this month. Pretty excited for that cause it’s gonna be satisfying to see the number go down and our pipelines and queries speed up. There’s a lot of low hanging fruit I get to grab all at once.,5,1735756714.0
1hr6zga,m4vtiq9,"I'm over 7 years into Data Engineering now and really wanting to pick up some side projects for money. Any useful tips on getting started? I've done cloud infra, snowflake setup/admin, terabyte scale EL to the cloud, data pipeline development and orchestration in Databricks, spark optimization on trillions of rows.

I'm not sure how to find project based consulting to leverage these skills.",3,1735756523.0
1hr6zga,m5q7bv7,"I got rejected on a basic etl assignment because i didn’t apply oop. Oop on a pd.read_csv script. This is the last time i took a home assignment, but does anybody in the industry have any idea what they are talking about or just repeating random concepts and buzzwords around?",1,1736184895.0
1hr6zga,m6hoftz,"gonna ask a random question, I figured it would be fun to build a DE pipeline focused on LinkedIn job posts. Here is my idea a user can type in a word let's say data engineer, or business intelligence analyst, any job out there really. Then the application will hit the LinkedIn api search for all the postings with that job title grab all the required and preferred qualifications and basically make a general map of what's the popular tools in the market (dbt, airflow etc.). I can also map geolocation data where jobs are hot as well. Then there can be a scrolling function where you can go through the postings one by one if you want to just see them. I'd figured I could grab the postings maybe 2 or 3 times a week. Does that sound intriguing to anyone?",1,1736552244.0
1hr6zga,m6lz2xc,"Not sure if this is the best place to seek career advice, but I would appreciate any input.

I've been in a data engineering positions for over 6 years now(mostly Python, SQL and Spark), mostly in banks. In the past few years I have a very hard time finding opportunities outside my home country. 

I'd like to receive any suggestions on any upskill programs which will make me more of a desirable candidate for international companies. I'm fine starting with basics or shifting focus. I'm not against picking up Scala or moving towards cloud solutions.",1,1736618775.0
1hr6zga,m4wihvb,"![gif](giphy|UO5elnTqo4vSg)

Might use the savings for some pizza parties",3,1735764566.0
1hr6zga,m5bamzm,I always had good luck at local meetups and interest group lightning talks. Just talking with people who are running businesses that could be made more efficient with better data - this is networking.,2,1735969695.0
1hr6zga,m6hoo66,can you give us more context on what the assignment was ? object oriented seems kind of strange to do in an etl process. But maybe there was a reason. Just hard to know without context.,1,1736552323.0
1hr6zga,m6hpwwa,"Hey, I have built lavodata.com for similar use cases. We can provide you API access to job data using either the company or other advanced filters.  Happy to answer any questions either here or DMs.",1,1736552749.0
1hr6zga,m4xx9cp,That would be a LOT of pizza,1,1735781700.0
1hr6zga,m6kfrt6,"Some csv parsing and generic data cleaning with python. Nothing obvious to apply oop and tbh i never used oop in python etl scripts.
Funnier thing is that this was for an eng manager position.",1,1736599018.0
1hr6zga,m6ickk7,"Dang man haha thanks for replying would hate to rebuild the wheel. I’ll take a look at it, would love to see what the most popular tools in the de  space would be. Free?",1,1736560454.0
1hr6zga,m6kzdx7,Yeah that seems strange. Weird,1,1736607278.0
1hr6zga,m6ict0r,"Not free unfortunately, we have a bunch of costs to do this at scale.",1,1736560534.0
1hr6zga,m6id8q1,"Haha yeah that totally makes sense haha. Dang I just checked it out, did you do this yourself and if you don’t mind what was your tech stack ?",1,1736560683.0
1hr6zga,m6imcww,"I actually wrote about how i built this here - 

https://www.reddit.com/r/dotnet/s/zy4BRJ6uNA",1,1736563914.0
1hr6zga,m6imgux,Oh thanks I’m fairly new to the community! Thanks I’ll check it out,1,1736563954.0
1h47qv8,lzwcllm,"1. Current Title - Data Engineer
2. Years of experience (YOE) - 4
3. Location - Berkshire, UK
4. Base salary & currency (dollars, euro, pesos, etc.) - £60k 
5. Bonuses/Equity (optional) - 5%
6. Industry (optional) - Finance
7. Tech stack (optional) - Snowflake , Postgres , AWS , Dagster , dbt , Docker, Python",17,1733074149.0
1h47qv8,lzx8fb5,"1. Data Quality Engineer
2. 4 YoE (2 years as an analyst, 2 as an engineer)
3. NYC - USA 
4. 145K USD
5. 7% bonus
6. Finance (Banking)
7. AWS, Databricks (PySpark and SQL), Informatica, Oracle",17,1733083811.0
1h47qv8,lzxoq66,"1. Analytics Engineer (basically solo DE on a data team)
2. 5 YOE
3. Indianapolis, IN (Hybrid)
4. $104k
5. 15% of base normally, got extra this year for being a part of an ERP transition project
6. Agriculture
7. Snowflake, DBT Cloud, Fivetran, ADF, SQL Server

First year of my career I've gotten a ""normal raise"" which was about 4%, I've gotten anywhere from 10-30% raises each year so far. I've been with the same company all five years starting as an analyst. My team is hopefully going to grow this year by a few heads and I hope to move into a management role of some sort with a higher pay band.",10,1733088845.0
1h47qv8,lzygerg,"1.	⁠Current Title - Senior Software Engineer (Team: Data Engineering)
2.	⁠Years of experience (YOE) - 5
3.	⁠Location - New York, USA (Remote)
4.	⁠Base salary & currency (dollars, euro, pesos, etc.) - 250,000 USD
5.	⁠Bonuses/Equity (optional) - 0-15% perf bonus, ~100,000 USD/yr private stock
6.	⁠Industry (optional) - Tech, Social Media
7.	⁠Tech stack (optional) - Spark+DeltaLake (Databricks), Airflow, Python, dbt, AWS, Kinesis, Elasticsearch, Dynamo",9,1733098240.0
1h47qv8,lzx2yzm,"Data Engineer

1.7 years of experience 

Düsseldorf, Germany

50K € + 7.5 % bonus, had other offer 65K€  skipped due to less technical role.

Tech stack : AWS , Databricks  + Unity Catalogue, MS SQL server, SISS",8,1733082156.0
1h47qv8,lzyilrj,"1. Current Title - Senior Data Engineer
2. Years of experience (YOE) - 7
3. Location - Columbus, OH
4. Base salary & currency (dollars, euro, pesos, etc.) - 180,000 usd
5. Bonuses/Equity (optional) - 10%
6. Industry (optional) - Healthcare
7. Tech stack (optional) - AWS, spark, Python",7,1733099009.0
1h47qv8,lzywlq2,"1. Manager, Data Analytics and Engineering.
2. 10+ DA/DE/Architect
3. Atlanta, GA
4. $150k
5. 20% of salary. 
6. Healthcare
7. AWS, Snowflake, Sigma",7,1733104006.0
1h47qv8,lzzlmxv,"1. Current title - Data Engineer 
2. Years of experience (YOE) - 4.5 (3 as an analyst, 1.5 as a data engineer)
3. Location - NYC (remote)
4. Base salary & currency - $108k
5. Bonuses/Equity - $3k at the end of the year 
6. Industry - Healthcare

7. Tech stack - Azure, Databricks",7,1733113682.0
1h47qv8,m00o5qu,"1. Data Engineer
2. 3 YOE
3. Philadelphia, PA
4. 165k USD
5. 150k RSU over 4 years
6. Tech
7. Databricks (Python/PySpark/SQL), dbt, Airflow, Terraform, AWS",4,1733136858.0
1h47qv8,m011t54,"1. Title is not data engineer, rather not say
2. 3 as cloud DE, 14 on business side (2 of those as “analytics engineer”)
3. NYC
4. 190k USD base
5. 35% of base in cash
6. Insurance",5,1733144299.0
1h47qv8,m00evkw,"1. Current Title - Data Engineer
2. Years of experience (YOE) - 3 (just under 4)
3. Location - UK (not London, not South)
4. Base salary & currency (dollars, euro, pesos, etc.) - £72k
5. Bonuses/Equity (optional) - None
6. Industry (optional) - Professional services
7. Tech stack (optional) - Python, Spark, SQL, Azure",4,1733130571.0
1h47qv8,m00jc1y,"1. Current title - Data Engineer
2. Years of experience (YOE) - \~5 years
3. Location - Croatia (working remotely)
4. Base salary & currency (dollars, euro, pesos, etc.) - 35euro/hour (around 55k euro per year), B2B contract
5. Bonuses/Equity (optional) - 0
6. Industry (optional) - PropTech
7. Tech stack (optional) - AWS, Databricks, dbt, Python, PySpark, SQL",4,1733133660.0
1h47qv8,m0icx8e,"1. Data Engineer

2. 5 YOE (2 years backend SWE, 3 years DE)

3. Remote but California, USA

4. 145k USD

5. 5% bonus

6. Finance

7. AWS, Postgres, SQL, Typescript, BigQuery, Docker. Surprisingly no Python yet as I am first DE hire for the team. Also moving off BQ so will be more RedShift soon. 

Role is fluid and at the moment more akin to a backend engineer doing some data work but will become more DE oriented as I take over data responsibilities.",3,1733386332.0
1h47qv8,m04zdvl,"1. Current title - Director
* Years of experience (YOE) - 7
* Location - ON, Canada
* Base salary & currency (dollars, euro, pesos, etc.) - 125k CAD
* Bonuses/Equity (optional) - 10%
* Industry (optional) - Telecom
* Tech stack (optional) - Snowflake, Python, Airflow, Postgres, MSSQL, PostGIS, Azure",3,1733192357.0
1h47qv8,lzzts1a,"1. Currernt title - cloud data engineer 
2. Years of experience (YOE) - 4
3. Location - full remote US
4. Base salary & currency (dollars, euro, pesos, etc.)  100,000 USD
5. Bonuses/Equity (optional)  0-5% depending on profits + 5% company stock
6. Industry (optional) - research 
7. Tech stack (optional) - depends on client needs, AWS, snowflake, python, spark, SQL, redshift",2,1733117596.0
1h47qv8,m0ir3qd,"1. Data Engineer
2. 3 YoE (3 years as an analyst)
3. Singapore
4. 65k USD
5. 0% - 5% bonus 
6. Manufacturing/retail
7. Azure, Databricks (PySpark/SQL), SQL Server/SSIS",2,1733395820.0
1h47qv8,m18c7vb,[deleted],2,1733768876.0
1h47qv8,m19jcxx,"1. Data Migration Specialist
2. 3 YOE (Same role)
3. NYC (Remote)
4. 61k USD
5. 3% (maybe lol)
6. Health
7. Excel, Python, SQL",2,1733782279.0
1h47qv8,m4bm39b,"WTH I am working in Vietnam with 2 years of expr then I got nearly 12k USD per year @@

1. Current title - Data Engineer
2. Years of experience (YOE) - 2
3. Location - HCM - Vietnam
4. Base salary & currency (dollars, euro, pesos, etc.) - 12k USD
5. Bonuses/Equity (optional) - Nope
6. Industry (optional) - Sales (outsource)
7. Tech stack (optional) - Python, SQL, Databricks, Dagster, DBT, Docker, ...",1,1735456400.0
1h47qv8,m4fkfp7," 1.Business Intelligence Developer (ETL Team)

2. 2.5

3. Midwest City 

4. 105k

5. 15k

6. Business supply

7. Informatica/SQL",1,1735513548.0
1h47qv8,m4txijs,"1. Current title: Data & Platform Expert
2. Years of experience (YOE): 4
3. Frankfurt am Main, Germany
4. 69.000 Euro
5. \-
6. Industry: FMCG
7. GCP (BigQuery, Cloud Run/Functions ), Python, Streamlit

Currently looking for ways to enhance my toolkit but honestly all the tools available seem like solutions looking for a problem to be solved. It feels like Python is so versatile that it can solve basically anything, but I am afraid that for certain tasks it may not be the right tool.",1,1735727039.0
1h47qv8,lzxougg,off topic what is like living in NYC with 150k?,5,1733088884.0
1h47qv8,lzzq8cr,"Whats your educational background? Im three years in data with a BS in Math, no callbacks yet",4,1733115824.0
1h47qv8,m4mraxc,"I am looking to enter this field. Overall, do you think California, Seattle, and NYC has people who earn higher salaries in the same field?",1,1735613290.0
1h47qv8,m01x1j3,I’d say it’s pretty low for your experience and for NY tier. 3 years as an Analyst alone should get you to 110-120k and for DE should be higher than that. Usually DE would get stock too so not sure if you have thay as well.,8,1733155975.0
1h47qv8,m1asxab,380 base and remote you are living my dream. Congrats!,2,1733798551.0
1h47qv8,lzy9evu,"I would say it’s comfortable if you can keep your housing costs relatively low, around ~2k a month. I’m able to go out with friends on the weekends, order takeout way too much, go on vacations, pay my bills, and put savings away (401K, HYSA, Brokerage, IRA) without any stress. Granted I don’t have a family, I’m sure that would make things more difficult.",11,1733095784.0
1h47qv8,lzzs28w,I got a BA in Math and took two CS classes using Python in college. Most of what I learned was through work experience or self study,8,1733116720.0
1h47qv8,m04fw3g,"Yeah I'm looking for a new job lol. Company is private so no stock.


Salary progression has been


2020 - 75k


2021 - 79k 


2022 - 87k


2023 (changed jobs) - 108k 


2024 - 108k",3,1733185321.0
1h47qv8,m1b32ej,High stress and little work life balance but ya $ is good.,2,1733802515.0
1h47qv8,m0b4bai,"We started off similarly. In 2020 I got my first fulltime DA job, started at 60k as a contractor in Feb and increased to 80k around August 2020 after getting coverted to fulltime.
Switched job to current company in Nov 2021 and salary increased to 100k, 3 years after my title is still (Lead) Data Anayst I’m now at 130k and I still think they underpay me for what I do since I mostly do engineering work now. I’m in Bay Area btw.

Looking for a new job as well to pump my pay as changing job is the fastest way to do it.",2,1733280549.0
1i17fyc,m73yqx8,"I wonder just how much will actually make it into dbt-core, although they do write (linked in post)

\> While SDF won't be included as part of the Apache 2.0 code base, *we plan to make meaningful parts of SDF’s capabilities available to all dbt users*—whether you’re using dbt Core or dbt Cloud 

It's hard not to see, especially given dbtLabs track record of server-side only features, how there will be even more of a two-tier experience and features. 

Good for dbtLabs, bad for community / open-source is my first instinct",38,1736868476.0
1i17fyc,m749x5w,What does SDF actually do?,23,1736871876.0
1i17fyc,m73wzse,They're 100% going to milk this to drive the biggest wedge they can between core and cloud,47,1736867922.0
1i17fyc,m73st18,Doesn't SQMesh use a similar tool to do this? Is it SQLglop or something? Can't look this up right now.,10,1736866573.0
1i17fyc,m746ai0,Never heard of Sdf until this. What sources am I missing,8,1736870782.0
1i17fyc,m73vw87,"This is an amazing outcome, competitively speaking, for dbt. I think sdf was a true emerging threat to their business, and now they can integrate their best ideas. I'm kind of bummed to not see sdf evolve into its final form though.",13,1736867574.0
1i17fyc,m73tysp,I have never used SDF but consolidation is rarely a good thing. However if it can reduce the dev quirks of DBT it has some promise,3,1736866951.0
1i17fyc,m767q86,Oh interesting! I hadn't heard this. I guess it makes sense.,1,1736892732.0
1i17fyc,m74abcp,"That's my fear as well. It would be awesome to get faster compilation time, true lineage, autocompletion on DBT core. I guess we will not get the lineage tool, maybe the rest...",4,1736871993.0
1i17fyc,m74yn0c,"it’s another transformation framework like sqlmesh/dbt.

it’s biggest thing is that it understands SQL natively, which unlocks so many things for metadata, the development experience, and local development. 


[checkout this podcast- it’s a good look at the problem space and what SDF was solving for](https://open.spotify.com/episode/2TtKW5dG4qyvpdufyxIzub?si=v55fR_UhSvG1eVe2uzzQbg&nd=1&utm_medium=organic&_branch_referrer=H4sIAAAAAAAAA72QTWrDMBSETyMvbSLbXQRMKQQbk26an3ZpZOvJFlEl5UlyYi969iqFXiEwi2E%2BhoGZvLdum2XOGi%2FFkjJrUyX1JXu1aHgYfGUs6ITQQgSluoCqmh4Vkr8RWkc9cPrfHsx3jMBKZzhER09%2B%2F1Xyprgus%2BVBLPd2DT3JaydJvpvLUhy683Scmw18Ag3r%2BtGPf1tMqZ4Nl2fsEfqieaSbRADzAaEyODIth%2BQHQQCi1GPXo7k5wOo9XgO81b8RisusNwEAAA%3D%3D&product=open&%24full_url=https%3A%2F%2Fopen.spotify.com%2Fepisode%2F2TtKW5dG4qyvpdufyxIzub%3Fsi%3Dv55fR_UhSvG1eVe2uzzQbg&feature=organic&_branch_match_id=1330995725090734856)",19,1736879071.0
1i17fyc,m74cyia,Curious to know too if anyone knows,5,1736872781.0
1i17fyc,m73vun4,"SQLMesh natively understands SQL using SQLGlot (other OSS by the same creators). This is what allowed them to avoid {{refs}}, get column-level lineage, and a number of other features.

I assume dbt has known about these gaps for a while and were in talks with or eyeing SDF from day one. 

The leg-up SQLMesh has (besides some of their other features) is that they had native SQL understanding day one. It will be interesting to see how dbt integrates SDF.",17,1736867561.0
1i17fyc,m76t34j,"Dbt also uses sqlglot for their lineage. Sqlglot was made by the same person who made sqlmesh btw.

My biggest thing with sqlmesh is it doesn't feel as extendable as dbt is wrt custom materializations/adapters/etc.",2,1736899598.0
1i17fyc,m74zd55,"I agree with you. It felt too that sqlmesh was coming hot n heavy for dbt but this acquisition changes that dynamic.

Many of the things that sqlmesh markets itself to fill in the big gaps of dbt are mostly gone (assuming dbt can fully integrate SDF).",5,1736879278.0
1i17fyc,m77a2ke,"It seems they have the SQLMesh innovations that was making dbt look dated, at least:

- ability to recognize reference to models without using the ref macro
- change impact analysis
- column level lineage 

So this acquisition seems to be a good way for dbt to remain in the innovation race. We'll see if they actually bring those features to dbt-core or keep it in the cloud, in the latter, SQLMesh would still remain the best FOSS solution.",5,1736905369.0
1i17fyc,m75b5wp,I love this podcast,3,1736882691.0
1i17fyc,m74p7gg,Haven’t used first hand but my understanding is that it’s a multi dialect compiler for sql. Helps detect errors in sql live. And there’s some custom data typing to prevent logic errors,4,1736876362.0
1i17fyc,m7622wj,"We just started migrating a month ago to sdf. It handles a lot of the things dbt doesn’t handle well -

Lint and error before sending to warehouse saves cost.

Local runs to avoid warehouse spend 

Multi warehouse support. 

Written in rust is faster

No need for ref or source tags",2,1736891069.0
1i17fyc,m76w2o6,"SQLMesh does support custom materializations. 

https://sqlmesh.readthedocs.io/en/stable/guides/custom_materializations.

Also there is a full fledged Python API / interface so you can do a lot with it, but it's not super well documented on how to achieve that.",2,1736900589.0
1i17fyc,m76r7kc,"Well, the million dollar question is whether DBT will make all those features available as part of DBT Core, though. SDF might give them all those capabilities but if DBT keeps them behind a paywall and SQLMesh doesn't, that'd make SQLMesh quite attractive.",1,1736898973.0
1i17fyc,m775xmn,"Nice! I see a lot more materializations now too than last I checked. I remember you saying you were working on it last year, that was a fast turnaround.

I need to reread all your documentation now lol.",2,1736903941.0
1i17fyc,m76rubo,I absolutely agree! time will tell… although we do have a track record.,1,1736899183.0
1i17fyc,m780eyw,"Is that the million dollar question, or the zero dollar question?",1,1736915115.0
1i17fyc,m77pm47,:) give it a shot!,1,1736910868.0
1i17bqf,m73t6hw,Stuff like this is not helpful to beginners. It’s just throwing a bunch of buzzwords and jargon onto a diagram. ,133,1736866694.0
1i17bqf,m73rot4,It's not even full of jargon. It's just not a good representation of how a DE would use Python. This is not useful,76,1736866204.0
1i17bqf,m74hcvz,"hey, beginners, pay no attention to this. it’s genuinely only confusing, while giving the impression of organization. 

source: 15+ years experience. i lead teams with juniors new to data engineering. i would never show this to any of them.",21,1736874065.0
1i17bqf,m73s9n0,Great diagram. I've just Paginated my Nulls behind my Output and started to CI/CD the Poetry. What next?,43,1736866396.0
1i17bqf,m740985,"Instructions unclear, I am unit testing the cloud",12,1736868948.0
1i17bqf,m751tme,Please stop with these posts,8,1736879992.0
1i17bqf,m745q47,"This was really poorly received last time.  Why upload it again?

EDIT: Oh, it's to promote a YouTube video.",11,1736870608.0
1i17bqf,m765jzn,UV > Poetry,4,1736892081.0
1i17bqf,m76o7qn,"The fact that 91 people liked the post
Edit: I've read it it's actually ok",2,1736897979.0
1i17bqf,m73vwas,I am a very visual person and like how this is laid out. Would someone be willing to recreate this with more beginner-friendly info? I am trying to plan out what skills to learn next and I am having some difficulty deciding what will be helpful and what won’t.,5,1736867575.0
1i17bqf,m761ufd,this is really fucking stupid and makes no sense whatsoever lol,2,1736890999.0
1i17bqf,m7733zl,"[roadmap.sh](https://roadmap.sh)

^ Recommended at high-level instead of this",1,1736902960.0
1i17bqf,m73u04c,"Too much. Here we see basically, general IT concepts & programming + \[Cloud\]DevOps + ML",1,1736866964.0
1i17bqf,m741atb,So you don’t need to know python syntax but you do need to know data structures and OOP. Checks out.,1,1736869269.0
1i17bqf,m76eoa1,Replace like half of this with DuckDB,1,1736894857.0
1i17bqf,m73orfl,"Intended for beginners/for quick revision. Covers all tools/techniques I used with Python as a data engineer.

Might seem a bit jargony but I’ve tried to include a mix of technology and processes.

Hope it added some value, have a great day.

If you found this helpful and want to get introduced all these topics in under 1 hour, checkout - Python for Data Engineering Crash Course (https://youtu.be/IJm--UbuSaM).",-40,1736865205.0
1i17bqf,m73tumc,"This stuff seems to go well on LinkedIn, sadly.",42,1736866913.0
1i17bqf,m76dw7i,"I’m oddly triggered by the finger pointing down. It’s like yes, we know how all media posting websites work. I automatically know you are trying to draw attention to your bullshit and I immediately don’t trust you.",6,1736894613.0
1i17bqf,m744yrx,OP is a karma bot,19,1736870377.0
1i17bqf,m76piyo,what would you recommend to an aspiring data engineer,1,1736898414.0
1i17bqf,m7421bq,Unironically what my mind thinks is going on at Faang and why I'm an imposter.,2,1736869496.0
1i17bqf,m7413vr,"Unfortunately these visuals tend to be produced by social media influencers trying to do marketing and get brownie points on LinkedIn. They always seem to be just keyword lists, etc.",8,1736869210.0
1i17bqf,m75i2ms,I also like the point of it and the lay out and I was thinking I sort of got it but then reading all the comments and have no idea why it's bad and no one is making it better... so?,1,1736884694.0
1i17bqf,m73y4yk,that video is just more convoluted visuals.,5,1736868286.0
1i17bqf,m770h68,"patience and persistence. trite as it may sound, thats the thing that works. first, learn the fundamentals of computers science, and then you just keep trying to build real things. 

python and sql, as well as bash are the sorts of things you might use on a daily basis as a developer (data-focused or otherwise), but the real skill that actually matters is learning how to keep going after you feel stuck. and that’s mostly about having some fundamentals, and the experience of having figured things out before.",3,1736902062.0
1i17bqf,m7420hn,"I’m not sure why I’m getting downvoted for my question, but I’d like to improve my understanding. How can I improve and make sure I am asking the right questions in the future?",3,1736869489.0
1i17bqf,m74n1ph,"> I’m not sure why I’m getting downvoted for my question

The main issue is that you're saying you like how this is laid out, except you want it to be more beginner friendly.  This is meant to be designed for beginners.  

Since you yourself are, by the sounds of it, a beginner, and want this but a completely different version, this is useless. There's nothing to actually like.

> How can I improve and make sure I am asking the right questions in the future?

Honestly, avoiding these kinds of infographics are a start.  95% of them are there to make you feel like you are learning.  Objectively, this graphic has loads of words on it.  Feels really good to read it, has lots of colours, it's sorted into sections etc.  As somebody who is experienced, when you look at it none of these categories make any sense.  There is no information here.  It is simply words.

Advice on how to improve as a beginner, as always, is to be hands on.  The more time you spend actually coding vs. reading about how to write code will give you the biggest jumps in improvement.",5,1736875736.0
1i17bqf,m74d8ac,"I didn't downvote you personally, I think it's a reasonable question. A question that might have done better is ""Has anyone seen a more beginner friendly version of something like this? I'm a very visual person and find diagrams like this to be helpful for mapping out what to learn.""   
  
I think part of the issue is the people who are coming in and commenting/voting are frustrated because 1) this post is a bit superficial and a bit of a mishmash of skill levels (loops are as beginner as you can possibly get and delta is more 300-400 level, just kind of a mess here) 

And 2) it feels like drive-by marketing, which people on Reddit get touchy about. Asking someone to do free labor to recreate content they don't like is probably getting you a few downvotes. But it's Reddit, some of it is Brownian motion and I try not to take it personally.

Generally, many Reddit communities require the 9:1 rules of self-promotion. 9 posts or comments that are actually engaged or interested in the community for every 1 that is self-promotional. This person appears to have created an account solely for promoting their own content, which is seen as a social faux pas here.",3,1736872863.0
1i17bqf,m74883h,lol welcome to the boat,-6,1736871370.0
1i17bqf,m76rqji,This chart was posted 5 days ago and it's generally not particularly helpful. That's my guess on why you're being shit.,2,1736899148.0
1i1j7ow,m76l8pn,Best move is to have another fact table with the new grain. Or the former one broken down to the new grain if that does not impact existing reports. This is very common as per my experience.,26,1736896992.0
1i1j7ow,m76lf4x,"You're measuring two different things, so you'd typically use two different facts. Or, you decide to change the business process to track just one grain.

It's pretty common to have an invoice table for things related to the invoice, and an invoice item table for the items on the invoice.

You'll have to decide whether your business processes would be better served by having the invoice item grain be by department (and having two rows with 5 units), having a second fact called invoice item allocation or something and using that for the breakdown, or (and I don't recommend this at all) using a ""bridge table"" to map the breakdown of the 10 in the fact to 5 and 5 on the dimension.",10,1736897053.0
1i1j7ow,m76of9e,"I gravitate towards the option to make your fact_bill table grain bill_id, Item_id, and department, and keep one table. So like in your example bill_id X and item_id Y (the laptop) would have two records, one with department as “finance” and another with department as “engineering,” each with unit_quantity as 5. When you group by bill_id and item_id you still get total sum of 10 for item Y, and yes you can count distinct to get it so the item count for that bill id is still 1 for the laptops.

If you are worried about the data storage impact of repeatable item attribute data, then you should break it out to have an item dimensional table instead of keeping those details in the fact_bills. Join by item_id to the dim_items. If you’re going down this path you might also consider a fact_bill_header table separate from fact_bill_details to also reduce repeating things about a single bill like the customer info, joining the two by bill_id.",7,1736898049.0
1i1j7ow,m76km0u,"You could add a bridge table between , that way you can filter on either or , that’s what I usually do when normalizing out lists in dimensions",4,1736896782.0
1i1j7ow,m77gto7,"Different grain, different table.",4,1736907722.0
1i1j7ow,m76q7ci,You could add a bridge table which includes the distribution of the 'laptops' across 'n' departments OR rebuild the fact table to include multiple lines for example 5 for dept 1 and 5 for dept 2.,2,1736898637.0
1i1j7ow,m77jf6i,"Why dont you add a column that works as a array, for instance in sql server you can us str_agg to concat strings, so giving that idea could like:

| departments|
 M1,M2 

So when you filter wont be difficult. 

In athena you can actually have an array so you dont need to have extra rows so you end up with a colum with the departments.",1,1736908642.0
1i1j7ow,m76m8lj,"Hello,

What do you mean its messes with the grain?

Keep in mind that the most Basic concept is to keep granularity at the lowest possible level.  you wouldn't have this kind of problem if you use a different table in which each youbl have a certain line of the invoice/order/ whatever. Besides You want to join a Dim table to a fact table, which is the purpouse of having star model. what do you expect to achieve?

This is genuine question to understand the problem, cause maybe i miss something",0,1736897327.0
1i1j7ow,m76mg2e,"Thank you! Yeah we have bills, bill_item, and cost-allocation tables. Most of the bill facts were added to bill_item so I only had to deal with the item level grain. But the need to join with the cost allocation now complicates that.",1,1736897396.0
1i1j7ow,m76qae3,"Ya that’s the way I’m leaning too. Not too worried about storage, it’s just delta tables on Databricks. Analytics is new at my company so I’m more worried about my end users needing to remember to use count distinct!",2,1736898664.0
1i1j7ow,m76wpww,">If you’re going down this path you might also consider a fact_bill_header table separate from fact_bill_details to also reduce repeating things about a single bill like the customer info, joining the two by bill_id.

This is generally an anti-pattern. 

We live in a big world and there's an edge case for all things, but I definitely wouldn't suggest this unless it's absolutely required. Kimball very specifically cautions against this trap, IIRC. Facts should always be stored at the lowest available granularity, and should join to dimensions, not to other facts on high-cardinality keys like bill_id.",1,1736900803.0
1i1j7ow,m77rjso,It’s going to a BI tool and gets filtered within that. Should’ve mentioned that in the post because this did cross my mind!,2,1736911586.0
1i1j7ow,m76nfis,"Without considering the department, there is only 1 bill item. For example, company A bought 10 laptops. However, that doesn’t mean all 10 laptops went to the same department. The budget for 5 came from engineering budget, and the budget for the remaining 5 came from finance. 

If I want to model the bill items without department, it is 1 row with the quantity 10 and unit cost. If I want to include department, i join an additional table to get department and the amount that department purchased. The 1 bill item row now turns to 2 identical rows, with the added department and department quantity different. 

Some dashboards use the bill item level. Some will use the department level. I want to make sure there aren’t any mistakes downstream",2,1736897721.0
1i1j7ow,m76p8qq,"Alright, but if you join a departament dim to that fact table, you can filter the ones that you need for a certain report. That's the whole point of making a join between fact and dimension table. 

Please keep in mind what i (and some of the people before) said. Keep your grain at the lowest possible level. If you are forced to use a table with the higher granularity,  because there is nothing else to use, then you can challenge This idea and earn some respect by pointing IT our.  This is a core concept of implementing a proper dwh.

I recommend you to have a look at the Kimball approach",0,1736898320.0
1i1j7ow,m76pyl3,"Yes I agree, but in order to get the id for the dimension, I need to essentially explode out the rows from 1 to N and the same fact table is already used for things like counts. My specific questions were about how to deal with that. If I have 2 rows in the same fact table with the same bill ID but different dim departments, if a user wants to count the number of bill IDs they have to know to count distinctly. I am searching for alternatives to this (bridge table, second fact table, modifying current behaviour to use distinct, something else)",2,1736898557.0
1i187ob,m73wwfk,Definitely not the analytics team but I admittedly didn't read everything,19,1736867894.0
1i187ob,m73ycmb,"""This made me realize that we are doing something wrong and led me to the conclusion that a transformation layer is missing from our company. To create that modeling layer, we need people who can efficiently populate the data models and also have business context. This will serve as a single source of truth plus the data models should (ideally) be easily queryable by the analysts (ideally less data scan, faster queries). But then the responsibility of data modeling will shift to the data platform and I think my company is not aligned with""

  
\- your role as a department is to facilitate efficient & better decision-making across the org. If you keep that as your true never-changing north-star goal, you will never go wrong.

Just as you have done here, you will be identifying ways you can help the org be more efficient. You are never going to have as much knowledge as the individual business that owns the source of the data. But you absolutely do own making data, its meaning, its understanding available across the gorg.",6,1736868352.0
1i187ob,m75e7fg,"Between these two choices, it's the data platform team.",4,1736883580.0
1i187ob,m76o28e,"You have a Warehouse.

You're describing Enterprise Data Models which integrate the datasets in to a new model.

Data Modelling is a specialist role. It would require Business Rules. 

A data platform team can't and shouldn't define that logical model. But they may implement it. 

I would define your role as ETL. Gathering the data. It's for others to prescribe the models.",4,1736897929.0
1i187ob,m772qen,"You need an Analytics Engineering team in between. Ideally you start a team with the most technical analyst, most business-savvy Data Platform team member, and they both learn DBT. 

If not feasible, the more technical team should own it, but set governance rules to require some ownership from the analyst team.",4,1736902829.0
1i187ob,m77lnod,"As others have said, you’re describing the functions of an Analytics Engineering team who basically own everything T in ELT. In some organizations, the AE team also owns the semantic layer and metrics, though I’ve been in orgs where the analytics team handles that. 

Generally, it’s not reasonable to expect analysts to be experts in data modeling. Writing efficient queries or adhering to coding best practices often has to be taught. 

This is not a slight to analytics teams whatsoever. They need to get a visualization in front of very prominent folks in the org and the goal is to make that work, not necessarily to make it work well or make it scalable.",2,1736909441.0
1i187ob,m74zbs2,"Ideally, both. YMMV.",3,1736879267.0
1i187ob,m73z6qm,"Thanks for replying anyway :)

I am also tilting towards that conclusion. I don't mean to demean an analyst's role, but I always wonder if they are not responsible for data modeling, what does their job entail? Are they responsible for designing the metrics and getting those metrics from the data models?",0,1736868612.0
1i187ob,m73zw8e,"\> your role as a department is to facilitate efficient & better decision-making across the org. If you keep that as your true never-changing north-star goal, you will never go wrong.

True.

\> You are never going to have as much knowledge as the individual business that owns the source of the data. But you absolutely do own making data, its meaning, its understanding available across the gorg.

Thanks, I'll remember this. How do you go about doing this (if data modeling falls under your current job description)? Say, you have multiple application teams in your company, related to different products and the stakeholders want metrics for each product? How do you begin the process? Who do you connect with to gather context? I understand this is a vague question and the answer depends on the requirements but I would love to know your thoughts.",1,1736868834.0
1i187ob,m76sg5i,Thanks for replying! Do you do data modeling at your work? How do you approach it (if you do)?,1,1736899384.0
1i187ob,m76tdln,"Thanks for replying! Data modeling seems to be a full time role, as you described. I was thinking that if the data platform team were to own it, we would definitely need to hire more people.",1,1736899696.0
1i187ob,m773izb,That makes sense. Thank you for replying :-),1,1736903105.0
1i187ob,m77n44k,"True, very well worded. Thank you for replying!",1,1736909957.0
1i187ob,m76szh9,"Thanks for replying. That’s what I was thinking too. Maybe the application team (original owners of data), the analysts (who know what metrics they need) and the data platform (maybe the ones who design the data models) should brainstorm together before a new feature is rolled out.",1,1736899564.0
1i187ob,m76j8xl,Analysts are responsible for counting and visualising the datasets they're given.,4,1736896332.0
1i187ob,m76zld9,"I assume you're an engineering team. You lay the pipes.

you don't own any data. 

the business teams and source systems own the data.

basically this isn't and shouldn't sit anywhere near engineers and programmers. 

no organisation should allow it & I suspect that's the message you have already been given.",3,1736901765.0
1i187ob,m76s7z2,Thanks!,1,1736899308.0
1i187ob,m77121u,"Got it, but do you think transformations and modeling are a part of building the pipes?",1,1736902258.0
1i1oa6j,m77q1ay,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736911024.0
1i1oa6j,m77saz8,Matillion has a free online cloud data loader i believe you can use for simple ingestion and CDC,1,1736911872.0
1i19kqh,m74az31,"I would count matching words to narrow down the possibilities.  From there, it’s going to be manual mapping.",5,1736872189.0
1i19kqh,m74pi5f,"Are you using any programming language or tools in particular?

For Python, I have used [Polars](https://github.com/pola-rs/polars/) with the [polars_ds](https://pypi.org/project/polars_ds/) plugin for [RapidFuzz](https://github.com/rapidfuzz/RapidFuzz) functionality.

It seems the description lists are comma-space separated, which you can split and ""explode"" into rows before comparing.

    import polars as pl
    import polars_ds as pds

    df = pl.DataFrame({
        'id': [17113],
        'descr': ['Chassagne-Montrachet, 1er Cru Macherelles, Jean-Marc Pillot'],
        'group': ['White Wine'],
        'department': ['France White Wine'],
        'sub_department': ['Burgundy Saint-Aubin']
    })

    df_lwin = pl.DataFrame({
        'LWIN': [1077904],
        'DISPLAY_NAME': ['Jean-Marc Pillot, Chassagne-Montrachet Premier Cru, Les Macherelles Blanc'],
        'PRODUCER_TITLE': ['NA'],
        'PRODUCER_NAME': ['Jean-Marc Pillot'],
        'WINE': ['Blanc'],
        'COUNTRY': ['France'],
        'REGION': ['Burgundy'],
        'SUB_REGION': ['Chassagne-Montrachet'],
        'SITE': ['Les Macherelles'],
        'PARCEL': ['NA'],
        'COLOUR': ['White'],
        'TYPE': ['Wine'],
        'SUB_TYPE': ['Still'],
        'DESIGNATION': ['AOP'],
        'CLASSIFICATION': ['Premier Cru']
     })
     
    (df.lazy()
       .with_columns(_key = pl.col(""descr"").str.split("", ""))
       .explode(""_key"")
       .join(
           df_lwin.lazy().with_columns(_key = pl.col(""DISPLAY_NAME"").str.split("", "")).explode(""_key""), 
           how = ""cross""
       )
       .with_columns(score = pds.str_fuzz(pl.col._key, pl.col._key_right))
       .collect()
    )

    # shape: (9, 23)
    # ┌───────┬─────────────────────────────────┬────────────┬───────────────────┬───┬─────────────┬────────────────┬─────────────────────────────────┬──────────┐
    # │ id    ┆ descr                           ┆ group      ┆ department        ┆ … ┆ DESIGNATION ┆ CLASSIFICATION ┆ _key_right                      ┆ score    │
    # │ ---   ┆ ---                             ┆ ---        ┆ ---               ┆   ┆ ---         ┆ ---            ┆ ---                             ┆ ---      │
    # │ i64   ┆ str                             ┆ str        ┆ str               ┆   ┆ str         ┆ str            ┆ str                             ┆ f64      │
    # ╞═══════╪═════════════════════════════════╪════════════╪═══════════════════╪═══╪═════════════╪════════════════╪═════════════════════════════════╪══════════╡
    # │ 17113 ┆ Chassagne-Montrachet, 1er Cru … ┆ White Wine ┆ France White Wine ┆ … ┆ AOP         ┆ Premier Cru    ┆ Jean-Marc Pillot                ┆ 0.388889 │
    # │ 17113 ┆ Chassagne-Montrachet, 1er Cru … ┆ White Wine ┆ France White Wine ┆ … ┆ AOP         ┆ Premier Cru    ┆ Chassagne-Montrachet Premier C… ┆ 0.769231 │
    # │ 17113 ┆ Chassagne-Montrachet, 1er Cru … ┆ White Wine ┆ France White Wine ┆ … ┆ AOP         ┆ Premier Cru    ┆ Les Macherelles Blanc           ┆ 0.292683 │
    # │ 17113 ┆ Chassagne-Montrachet, 1er Cru … ┆ White Wine ┆ France White Wine ┆ … ┆ AOP         ┆ Premier Cru    ┆ Jean-Marc Pillot                ┆ 0.342857 │
    # │ 17113 ┆ Chassagne-Montrachet, 1er Cru … ┆ White Wine ┆ France White Wine ┆ … ┆ AOP         ┆ Premier Cru    ┆ Chassagne-Montrachet Premier C… ┆ 0.352941 │
    # │ 17113 ┆ Chassagne-Montrachet, 1er Cru … ┆ White Wine ┆ France White Wine ┆ … ┆ AOP         ┆ Premier Cru    ┆ Les Macherelles Blanc           ┆ 0.65     │
    # │ 17113 ┆ Chassagne-Montrachet, 1er Cru … ┆ White Wine ┆ France White Wine ┆ … ┆ AOP         ┆ Premier Cru    ┆ Jean-Marc Pillot                ┆ 1.0      │
    # │ 17113 ┆ Chassagne-Montrachet, 1er Cru … ┆ White Wine ┆ France White Wine ┆ … ┆ AOP         ┆ Premier Cru    ┆ Chassagne-Montrachet Premier C… ┆ 0.375    │
    # │ 17113 ┆ Chassagne-Montrachet, 1er Cru … ┆ White Wine ┆ France White Wine ┆ … ┆ AOP         ┆ Premier Cru    ┆ Les Macherelles Blanc           ┆ 0.324324 │
    # └───────┴─────────────────────────────────┴────────────┴───────────────────┴───┴─────────────┴────────────────┴─────────────────────────────────┴──────────┘

[duckdb](https://duckdb.org/docs/api/python/overview.html) also comes with [Text similarity functions](https://duckdb.org/docs/sql/functions/char.html#text-similarity-functions) - which is another option.",6,1736876448.0
1i19kqh,m77wh8a,Create record ids on both lists - Explode the nested lists -> create generalized replacements on your list to standardize -> count key word matches for each of your entries and take the ones above that match the most as a match (first mandate certain columns (country/grape/type - whether - match) -> see what’s leftover. I think polars may be overkill here. Pandas is probably fine. You can throw it into snowflake for free on a trial account. Their sql syntax is pretty easy for pivoting. Once you have your matches you can enrich with your warehouse data.,1,1736913489.0
1i19kqh,m74cqun,What would be the most efficient way to match words across multiple fields? I have a decent list of words to exclude which should help.,1,1736872719.0
1i19kqh,m74ka1s,"I don’t think there’s an efficient way.  17,000 records isn’t much to churn through with a script.

Some synonyms will very likely help narrow them down.  (Ex. Blanc == white, rose’ == rose)  unicode mapping also might be necessary.

The work is going to be the manual matching the ones that don’t share text matching.

Watch your character set mapping in whatever database you are using.",3,1736874930.0
1i0yvo3,m71yn1v,"I’m not sure I’m fully following the flow of your story but it sounds like the client hired a DS to build the PoC and when it was robust enough pass it off to MLE/DE to productionize?

If so, yes that’s something of the pattern - (1) DS for turning the business question into value but not to scale it, then a team of MLE/DE to take what created value and do it at scale.

Whether it’s the right call or not really depends on the field, the TAM, margins, etc",41,1736832438.0
1i0yvo3,m71ynfi,So we don’t need statistics knowledge or anything to become data scientist?,17,1736832443.0
1i0yvo3,m72375b,"DS is expensive, takes long running projects (so no immediate payoff), and needs a DE to put a project in prod.
DE is also expensive but can be used in multiple ways, with immediate impact. Also most quick wins in DS and analysis can also be implemented by a DE with a DS/stats/ML background these days. IMO a specialized DS is something that you only need once your corp reaches a certain maturity (given that you have good DEs)",11,1736834736.0
1i0yvo3,m7220dn,One man data department bruh,9,1736834119.0
1i0yvo3,m71y2qg,I have seen a few which say data analyst/engineer,4,1736832171.0
1i0yvo3,m71z73s,"Yes, I have seen a few job roles asking for the other way. That is ml and data science expertise in data engineer job description",3,1736832709.0
1i0yvo3,m721j4v,"The company I work with does not have a data scientist but 2 ML engineers. To be fair, one is educated in data science and backend development and the other one is a psychologist with a data engineering background. The field is social media recommendations.

I don't really know where to draw the lines between all the data roles.",2,1736833875.0
1i0yvo3,m730rgn,I was recently hired at Uber for the exact same description. My title is DS II.,2,1736855303.0
1i0yvo3,m725i9b,"Conflating data engineering with data science has been an issue since these jobs started to be identified (I guess ~2005). I think it's because the data scientist job was highly mediatized and the data engineer job not all. I have seen multiple cases of managers hiring DS to build a data warehouse and DS thinking they were hired to do machine learning but ending up doing mostly data engineering (and resigning).  
In my experience, it's a sign of immature data management.  
ML engineering however is closer to data engineering and devops, so it makes more sense.",1,1736835985.0
1i0yvo3,m74pyss,"Vendors have moved machine learning and data science to simplified products.
Look ar snowflake cortex a data engineer can follow a script to create a chat bot and implement in a engineering methodology",1,1736876582.0
1i0yvo3,m75v0t7,I work as an MLE and I see way more data engineering positions on job boards.,1,1736888985.0
1i0yvo3,m7671rn,"I hope it’s time people realized (for the Nth time) that bad data means bad AI, ML. Garbage in, garbage out. I remember at a past company they would try all sorts of tuning, feature engineering, algorithms, etc. when the biggest improvement in our model was simply spending a week or so fixing key data cleaning issues.",1,1736892527.0
1i0yvo3,m76wl52,B,1,1736900759.0
1i0yvo3,m77tsc8,"Yeah this is how it should be. I’m a DS, and think there’s currently way too high of an expectation that DS folks will also be quality data engineers and that’s just not the case.",1,1736912440.0
1i0yvo3,m729pmv,"I am seeing that Data Engineering field is finally getting the value it was suppose to have, as compared to Data Science field. And that is a good sign becuase current market has very small pool of 'KNOWLEDGABLE' data engineers.",8,1736838387.0
1i0yvo3,m71zy9p,You do but not necessary for MLOps which is what most of these roles are for ig.,15,1736833080.0
1i0yvo3,m73ft90,"Someone from statistics here. Not really, but realistically you can get 95% of the way on most projects with a really basic understanding that most applications business come down to expected value or similarity. Basic methods with high quality data (data engineering) tend to work well.

EV = (probability of event)*(magnitude of event). Think logistic/LGBM to estimate probability of an events and working with business to estimate benefit/cost of event.

Similarity = (thing A) - (thing B), which are differences. Similarity is much more subjective. [P-values are effectively comparing similarity of distributions \(null vs. estimated\).](https://www.amstat.org/asa/files/pdfs/p-valuestatement.pdf)

Obviously there's a lot more to data science and statistics, but I've encountered so much over-engineering and/or interpretability problems I'm jaded.",6,1736861934.0
1i0yvo3,m722b32,Alwayshasbeen.gif,2,1736834271.0
1i0yvo3,m760jc7,"I huff glue on the weekends and they call me senior engineer, so I think no.",1,1736890617.0
1i0yvo3,m72g09y,"My current place seems to have a massive circle jerk over DS at the director+ levels, would be good to see this behaviour you've described come my way.",3,1736842263.0
1i0yvo3,m73xral,It’s about to get stunted by this ‘who needs a data engineer when you can have chatGPT do it!’ Phase,2,1736868166.0
1i0yvo3,m76wnvo,"But don’t they test your DS knowledge in the interview? I am actually going to apply for DS jobs soon, returning to my home country and I found that there’s not much DE jobs but lots of DS jobs. They seem to ask for tensorflow PyTorch stuffs like that. Any advice on what skills I would need to pick up for DS as a DE?",1,1736900785.0
1i0yvo3,m74ewca,"I dont think that will ever happen. I have been using chatgpt for sometime now for my development and trust me it speeds up the development by 5 times but it misses lot of test cases as its not aware of all our dataset. So chatgpt will help us in coding but testing it over our data and then understanding it is still gonna be the data engineer's job. Becuase we don't wanna expose our data to chatgpt.  
Along with that, it would be cheaper to hire data engineer to do that stuff rather than passing TB worth of our data to chatgpt to test the chatgpt code",1,1736873351.0
1i0yvo3,m74reri,"Chargpt makes you quicker so industry needs less engineers or they can use the chatgpt skills to do the data science tasks like creating chat bots

Vendors are pulling in llm into their  platforms, you will be able to replicate chatgpg inside corporate boundaries 

See snowflake, cortex, clause 3.5",2,1736876995.0
1i19t2u,m74ane1,"If you need to know it to get the task done, then yes.",21,1736872092.0
1i19t2u,m74b7ga,Depends on the org. I think all programmers should have a basic grasp on networking. In a huge org networks might be too complex for you to work with but if its a basic setup with a couple of VPCs you should be able to do work with it. ,8,1736872259.0
1i19t2u,m74ao71,Knowledge of - yes. Being able to implement - not really but then again it depends. Having a strong knowledge of networking is ideal when building your own clusters for on-prem. Cloud not so much but having a good grasp of it from an access and data security perspective definitely. You may not need to really understand the whole OSI model or things like CIDR blocks and trunking but still good to know,3,1736872099.0
1i19t2u,m74clvl,"At a small company, almost certainly. I'm a data team of one (1.5 sometimes with contract help) and manage my own AWS stack with Terraform, which requires at least some networking knowledge. I'm a DE for operational analytics and not our actual production software product.",3,1736872678.0
1i19t2u,m74d1on,"If it's a one man show I don't think u really have a choice, but then again it's a half glass empty/full kind of dilemma. You are basically doing more than what u are paid for but the learning should be immensely useful at the end of the day.",1,1736872808.0
1i19t2u,m74iyp5,"The smaller the organisation the more hats you have to wear.
I think it is worthwhile having a basic grasp of a broad spectrum of topics if only so you can get some value from error messages and exceptions that will result if it is done incorrectly.
If networking is someone elses responsibility then at least you can have a productive dialogue.
I have never been a SAN or storage administrator. Time spent with them gave me an understanding that changed my approach to DB design and implementation, and their understanding of the IO/RAM needs of a DB Server.",1,1736874543.0
1i19t2u,m74sn1q,"Security + data engineering = platform engineering. Depends on the size of your company, really big companies have dedicated resources but I know 2/3 data engineers personally who do security as well.",1,1736877346.0
1i19t2u,m75arkb,"Should it be? If you want to be relevant, otherwise no",1,1736882575.0
1i19t2u,m75dxbf,"From an org standpoint, they probably shouldn't have everyone doing their own network stuff as it increases the risk of there being security holes.  We have our own network people that own all that and work with the security team to ensure that the cloud assets are sade.  A DE should understand it for sure, but I would question whether they should be doing it.",1,1736883499.0
1i19t2u,m75lsnd,"Depends on the organisation but yes, it helps you with understanding the broader architecture. like others are saying, even if you don’t have to implement it, it’s more useful to know than not knowing it. Personally I found it interesting, though I don’t want to make a career out of it and go into security and or platform admin roles",1,1736885778.0
1i19t2u,m75uynl,"These auxillary tasks are part of a DEs job if it's a small company. So cloud sysadmin, networking, cyber security, dev ops. However, you don't have to be a specialist in it, just have a general understanding and be able to implement the basics.",1,1736888967.0
1i19t2u,m779g2t,"As a solutions architect, definitely. As a senior DE, good idea to know this well. I don't think you need to carry an advanced Cisco cert either to be effective.",1,1736905154.0
1i19t2u,m780h1q,I’m a cloud network architect and know basic SQL and can figure my way around stuff like Redis. Not a depth expert though. I know enough to do what I need. I’d say do the same with networking.,1,1736915139.0
1i19t2u,m75mg7v,"I guess at smaller companies without the staff, then we have to. And it can be fine if there's not too many resources to manage, but I may not have the knowledge to set everything up properly. My question is do we generally feel this knowledge should be expected from a data engineer.

I could google/YouTube accounting info and do my company's accounting work as well; it's just data as well. But that's always deemed a separate job.",1,1736885969.0
1i19t2u,m74bgk0,Yeah I think this is the best way to summarize. I need to be able to communicate with the team who owns and implements to resolve any issues that come up. But I don't think it's feasible to be a full time DE while owning all the cloud infrastructure and networking as well,1,1736872336.0
1i19t2u,m74fbsc,"Nice, that's a lot to manage as one but if you can pull it off that's awesome",2,1736873476.0
1i19t2u,m74dx69,"Yeah this seems to be where I usually end up, at a smaller company or small team where I need to know every piece of the puzzle. Now I'm trying to balance the workload with the learning",1,1736873066.0
1i19t2u,m75t1bx,"Try to stop thinking about your position, and think of your role as a problem solver for your company, and the task is some networking stuff. Auth layers, A records, role based access, permission boundaries policies, what have you, are all really devops and sometimes s.eng issues. That's the crossover for some data engineers. Now if you dont want to do networking, there are data Eng positions like that. But smaller companies will require some level or alot. Alot makes you more valuable *as a data engineer* for a company requiring those skills or who could benefit from them. Which is damn best most so empath goes up. But you gotta like the problems you work on man or you probably won't dig into them sufficiently to remove security gaps and the like.",3,1736888370.0
1i19t2u,m74ci4y,"Yeah. You focus on cloud - so the indepth knowledge may not be as necessary but if/when you get onto on-prem having a good grounding will be very helpful.. especially, as a DE for on-prem, if you are also responsible for server config there are a lot more options at play than cloud. Cloud has simplified a lot of stuff for you.",1,1736872647.0
1i19t2u,m74fsik,"For the most part it's ""set and forget"" so it's not so bad. I might have to touch it every few months for a fix/tweak but that's about it.",2,1736873611.0
1i1eche,m75cz3d,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736883219.0
1i1eche,m76361x,"For data science check out the following for Data Science:

1. [Onur Data Scientist](https://youtube.com/@onurdatascience?si=JX2FhU1px7ZlmM2x)

2. [Stat Quest](https://youtube.com/@statquest?si=2OgpGqU8zxI4kv8q)

There’s a 3rd one I think but it focuses a lot on learning R programming as well. If you’d like I can try to find it and link it too.

For data engineering I use mostly books like kimballs data warehouse toolkit and fundamentals of data engineering. 

If I need to know specific stuff for snowflake or databricks they have a bunch of channels on YouTube",3,1736891385.0
1i1eche,m77p6o5,You won’t get a job as a data scientist without a degree. The field is usually a masters minimum requirement nowadays. Not sure where you live but most software adjacent fields will most likely require atleast a bachelors at minimum. I would go to school and get your degree.,1,1736910710.0
1i1iogg,m76kkyb,"it was interesting, could you share the link  github, please",2,1736896772.0
1i1iogg,m76lklp,[https://github.com/Aubur9y/Job-Tracker](https://github.com/Aubur9y/Job-Tracker),3,1736897104.0
1i0v8c1,m711jhp,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736820193.0
1i0v8c1,m712k3d,I’d begin looking for a new job the day that I was told I’d be expected to come into the office full time,140,1736820517.0
1i0v8c1,m712ud8,Yes,66,1736820602.0
1i0v8c1,m71e4xv,I quit over a hybrid policy that I didn’t even follow.,55,1736824255.0
1i0v8c1,m714kqo,![gif](giphy|xT5LMHkEg6runrYJuo),48,1736821175.0
1i0v8c1,m71a08t,"Already did 3 months ago and it was moving from 3 to 4.

I prefer 2.  Ill tolerate 3.  I wont tolerate more. 

Took a 30% pay increase and way better offices and conditions while I was at it.",49,1736822893.0
1i0v8c1,m71nv5o,"Yes and I did.  Told them 2 days a week in office was my limit.  They raised it to 50 with the expec that really means 3 days a week.  I was already fed up so I just stuck to my guns and said “yeah no I said my limit was 2 days and I was serious, this is my notice“.

  
But I had the luxury of being in a good position in terms of finances and expenses and not having kids.  

But wfh raised my quality of life exponentially.  I’m not going back to the old way.  

I get plenty of hours as a freelance contractor now.  Can’t complain.",23,1736827775.0
1i0v8c1,m71bwgu,yes because my head office is in another country,12,1736823515.0
1i0v8c1,m71cv45,"I worked at a Fortune 50 company, they set a definitive date of RTO, that is two months after, I resigned and my last working day is RTO date.",10,1736823826.0
1i0v8c1,m71vmq1,"I left a job because RTO  
In my experience it is completely um-necessary for the majority of data engineering jobs",10,1736831033.0
1i0v8c1,m71f1fx,"Yep already did. I kept out as long as I could. When they gave me an RTO date, I gave my two weeks.",9,1736824565.0
1i0v8c1,m71r0uo,I turned down a meta offer for commitment from other company for 100% WFH.,10,1736829023.0
1i0v8c1,m71q9g4,"I would immediately look for a new role. I would minimally comply, and the company would see my productivity drop, because now I’m wasting a bunch of time driving around and other nonsense instead of sitting and working. 

Being fully remote, I actually work much more than I would if I went into an office, and I have the flexibility for my family life. It’s a win-win.",9,1736828709.0
1i0v8c1,m749nxv,100% but not without another job lined up,6,1736871799.0
1i0v8c1,m71f8i6,If you’re a valuable worker at the company I’d bitch about it vocally and simultaneously apply around. Don’t make it a secret that you’re unhappy with the situation,13,1736824636.0
1i0v8c1,m71fb36,Yes. Unless it was supported by a staunch fluidity in scheduling. In other words it’d have to be pretty much hybrid.,5,1736824661.0
1i0v8c1,m71t95a,HARD yes,6,1736829977.0
1i0v8c1,m722ihb,"Story of me life mate… I started with 3 work from office days, then 4, and now, the start of the new year … 5!!! 

Constantly looking for my next gig with the right fit. So I feel ya.",4,1736834378.0
1i0v8c1,m726hj1,Absolutely. There are too many other jobs out there to be required to come into office 5 days a week.,5,1736836536.0
1i0v8c1,m719109,There are still plenty of companies doing remote work.  They get it.  The RTO inspired by Musk and Trump is part of the commy agenda.  We little people must be chained to our desks while they are on the golf course sipping cocktails.,28,1736822577.0
1i0v8c1,m72j5if,I would find another job and get a raise. I'm in this field because it's fun and you can do it 100% remotely. My location is irrelevant and none of their business. I will visit the office and meet my coworkers every now and then on my own terms. There's no point in commuting hours daily just to type on a computer and attend virtual meetings and drink coffee.,4,1736844320.0
1i0v8c1,m714g08,"I'd have to because I have to drop my daughter off and pick her up after school. She can't take the bus due to the constantly varying schedules of the activities she's involved in. Considering those constraints and the commute length, I could only be at the office for 5-6 hours a day. Also my local office building is mostly home to a part of the organization I don't work for, so I'd still not be physically near my boss/team.",6,1736821130.0
1i0v8c1,m728xh6,100%,3,1736837925.0
1i0v8c1,m72h6dg,"You've got a pretty consistent line of answers, and they may all be right, but just to add some contrast...

How much have you chatted to these developers and got their take? Especially any longer-serving ones. They might also be thinking this is the final straw, or they might know the company well and genuinely believe this is a short term thing, and it's worth riding it out. It depends on the even bigger picture of how good the company is to staff who stick around and do extra. 

After doing that, have you considered discussing this (F2F!) with your line manager or even the person who called the RTO? Phrasing would be very, very important to get right (one to rehearse beforehand), but there's a chance you can have a productive conversation with constructive criticism of the company's actions, that benefits both you and the company. 

It doesn't sound like this RTO was called maliciously, the decision makers just have incomplete info. It's hard to see you're missing a certain job role if you've never had it.

You're definitely well within your moral rights to quietly move on to another job without doing any of the above. But I do think this _can_ (sometimes) be a missed opportunity. Just like personal relationships, great long-lasting professional relationships take work from both sides, and sometimes require riding out rough patches. But only you can decide if it could be one of those in the long run.",3,1736843021.0
1i0v8c1,m72lss6,"yes, because I don't feel like working in the car park of an underprovisioned office",3,1736846081.0
1i0v8c1,m72ngn1,"Have you looked for a new role? It doesn't sound like the best place to work from my viewpoint.

I'm not against full RTO if it's done well, you need to acknowledge extra costs to workers and increase comp, have core hours for people to collaborate (not ask them to be in the office 9 till 6 for 5 days a week), and mindfully change the office environment to get the benefits you were aiming for - not just assume they will happen by osmosis.",3,1736847204.0
1i0v8c1,m73d90b,"I'm old school, but still, ain't no way I'm doing 5 in the office. That's for someone else's ego or show. I work way too many extra hours, evening debugging and deployments, etc to put up with also being in the office.",3,1736860946.0
1i0v8c1,m7537ho,"I casually comply to the now 3 days RTO policy and the company doesn't seem to be tracking us. Since the door is always open, no one needs to use their card so I have no idea how they are going to enforce it. Maybe they are going to use IP.



Anyway I'm applying for a new job.",3,1736880389.0
1i0v8c1,m72h41g,"OP, chances are your leadership already was planning more RTO and using this circumstance as the excuse. If the problem is solved, the at the next leadership summit he will get kudos from peers for ""bravely"" forcing his people RTO. 

If the problem isn't solved, he will likely claim that it was because RTO didn't happen fast enough.

I have separate thoughts on which mode is truly more productive that I won't get into, but either way increasing RTO is the trend in the industry. Personally I've decided to roll with it and just assume that at my company we will eventually be in office 5 days a week. As long as there is flexibility (wfh early morning or late afternoon) I'm ok with it. Even pre pandemic I was 5 days in office, but would wfh occasionally to bang out a lot of code, or come in just for meetings.",2,1736842980.0
1i0v8c1,m72qpww,"The problem could be communication, but putting you all in the same won't solve that in and of itself. There are probably deeper problems that are more difficult to fix. Management will always go after the easy answers.",2,1736849349.0
1i0v8c1,m73cill,"I live close to work. I like the short bike ride, so I don't mind",2,1736860654.0
1i0v8c1,m73yb65,"I don’t believe RTO will fix anything at all, as the 90s teach us https://youtu.be/BTdOHBIppx8

As other people said, I’d just start looking elsewhere",2,1736868340.0
1i0v8c1,m74bjkp,without question. absolutely zero reason for me to be in office.,2,1736872361.0
1i0v8c1,m77llgo,"I started working remotely back in the early 2000s. There’s been a few periods of returning to an office, which only convinced me working remotely is far more productive and what I prefer.",2,1736909420.0
1i0v8c1,m71cpz6,"If they paid me enough to buy a new home in the new city I had to work in along with keeping my original house to rent out, I’d consider it. I love the city with the closest office but can’t afford on my salary now.",2,1736823778.0
1i0v8c1,m73971s,"I wouldn't quit over RTO no, but if I was in a job where I was working hybrid/remote and they changed the terms on me that would impose quite large transport costs and other intangibles on me so I'd be revaluing that job pretty quickly for sure if it didn't come with a pay rise that covered increased travel costs and time etc. I'm fairly chill on RTO and there's benefits to in person meetings (although approximately 0 for coding/focused thought work), but a pay cut is quite a big fuck you to deal with as an employee.",2,1736859283.0
1i0v8c1,m71lnji,"I on lyhave WFH on fridays, I don’t mind the office that much tbh since my commute is short and not stuck in traffic. I will say that it is company wide all the up to the C-Suites. I pulled the badge access swipes on all of them and they’re putting in 10-14 hour days. Directors and up at my company are required to put in 9 hour days in office 5 days a week. At least they’re suffering too? Idk I just get in early and leave early.",3,1736826947.0
1i0v8c1,m77zaor,Depends on where. More than 10 min commute - yup quitting time.,1,1736914645.0
1i0v8c1,m715iiy,"This is a good lesson to be learned: always read the offer letter cover to cover. Print out a copy and highlight all the relevant terms and conditions. 

Had you done that, you would have easily spotted the missing clauses about what you were (or were not) guaranteed around RTO.",1,1736821481.0
1i0v8c1,m740az7,"It is not about you or anyone of us. I understand what you feel, most of us went through it at one point or other in last 3 years. Its is time to jump ship, pick what suits you. 

RTO will push people out, which might be desirable for some companies.  

RTO is important for economy to run. Or govt/cities will raise taxes on something or other causing net income to drop. We cannot have the cake and eat it too. 

In most cases, No one cares about what you want and what your problems are. Organizational needs matter; after that, if they can afford, leadership will think about you. When they are in war, leaders  dont care about resources being sacrificed. They give free food and coffee to keep the morale up but sacrifice is inevitable. Unfortunately some managers do it purposefully burning resources.",1,1736868963.0
1i0v8c1,m71dxp9,"Alright, I'll play contrarian here. For me personally, I don't mind coming in to the office because I have distractions at home which makes it much more difficult for me to fully focus on work. I prefer working from home because it's still efficient, but I wouldn't consider quitting. There's pros and cons in either situation.",-1,1736824187.0
1i0v8c1,m71gslo,"lose, not loose.  Otherwise, yes, 100%.",-1,1736825183.0
1i0v8c1,m75b9ge,"I am rooting for more RTO.
Not sure why people like so much work from home.
As a TL my work is 5 time more difficult with working from home.",-1,1736882720.0
1i0v8c1,m71a714,Any piece of relevant data on this topic strongly disagrees with this group.,-9,1736822955.0
1i0v8c1,m71p93j,You are my spirit animal lol.,20,1736828309.0
1i0v8c1,m71nztb,Literally same thing.  Except It was about a year and a half ago for me.  Told them 2 days was my limit.  They kept raising it. I quit.,10,1736827824.0
1i0v8c1,m73plxj,"50 days a week in the office is way too much, I'd quit too!",6,1736865498.0
1i0v8c1,m71f6vs,"Here I was going you complain about a 1,197 mile commute…",8,1736824620.0
1i0v8c1,m75253c,Poetic,1,1736880084.0
1i0v8c1,m75qkk1,This is how we make a difference for the future,0,1736887383.0
1i0v8c1,m71f7cl,I fear you’re right. Musk’s fight against WFH won’t stop at the federal workforce.,8,1736824625.0
1i0v8c1,m71tl4q,Commy agenda.. that's a joke right?,7,1736830123.0
1i0v8c1,m71ey2w,I don’t see any value in this. There’s never going to be a written guarantee. Company can always fuck you,8,1736824533.0
1i0v8c1,m71p6qm,"Sure that is totally your right.  I know a few people who are that way and I respect it.  You just have to realize you’re probably an outlier in this industry.  And that a lot of people don’t have issues with distractions at home.  They have issues with distractions, and bullshit, in the office.  Not to mention the expense of driving. Not just gas but time. It’s a huge quality of life decrease and a huge pay cut, effectively, for a lot of us    

I never had any problems with the folks on my old team who preferred to come in for whatever reason.  More power to you.  But a couple of them were determined to piss in the rest of our lemonade by making comments against wfh just because they didn’t like it or were major extroverts or were bored and that pissed me off a bit.    


One guy was always kissing the CFOs ass saying things like “I’ve seen wfh ruin company culture it’s really not good you got to have that face to face contact” and the entire rest of the team, tech folks, just gave the dude death eyes lol.  But that guy was a ladder climber, extreme extrovert adhd kind of dude.  Nice guy we are actually still sort of friends.  But still.  Jackass too sometimes.",3,1736828283.0
1i0v8c1,m71ouwr,"lol what is this comment?

""Data says you're wrong""... presents no data",10,1736828159.0
1i0v8c1,m71o6gc,"Fuck around, find out…

We only get one vote.  I choose to exercise my vote.  So I vote ‘leave’ when Im no longer satisfied with conditions.",11,1736827895.0
1i0v8c1,m71v5kv,"Given the state of civic education in the US, it probably isn't.",12,1736830818.0
1i0v8c1,m72pupd,Commy = anything unamerican = anything I don't like =...profit?,2,1736848781.0
1i0v8c1,m72q4eh,"My contract states 100% remote, no specific location required, occasional travel at the expense of the company. RTO would mean a new contract. I'm a contractor though",1,1736848957.0
1i0v8c1,m74h7ua,You don’t see any value in reading your offer letter? wtf kind of response is that?? Lmao,1,1736874025.0
1i1141c,m72gn2s,"I think databricks offers some spark training and spark specific certs, but there’s ton of stuff online for free. That said, pyspark supports both python and sql. Depends on what you need to do. If you have pure sql analyst, picking up spark to write custom scripts and programs then it will take some time. If you want to use pyspark sql to write sql like queries while leveraging the spark engine in the background then it’s less challenging but still need to understand spark fundamentals and how spark works under the hood.",13,1736842669.0
1i1141c,m7403ea,"Wow.

So many things going on here.

There are two ressource that helped me understand where Batch processing is today :  
\-  Advanced Database course from Andy Pavlo on Youtube.  
\- The chapter in DDAI about Batch processing also. It talks mostly about MapReduce but it's very important to understand where distributed batch processing comes from (procedural map-reduce) to understand where it is now (declarative API to a distributed query planner and optimizer).

I can't talk about Snowflake, but this is what I understood of pySpark vs Python vectorized computing libraries that might be good to internalize :

Spark :  
\- Swap mecanism to allow paging on disk for datasets bigger than RAM  
\- Multi-threaded and SIMD compatible  
\- Distributed (multi-machine) out of the box. The same code can be run a single machine or a cluster. It's a full-on distributed compute orchestrator, with retrys etc.

Polars :  
\- Swap mecanism to allow paging on disk for datasets bigger than RAM  
\- Multi-threaded and SIMD compatible  
\- No distributed compute orchestrator included (you'd need to package it as K8s jobs...)

Pandas :  
\- OOMs when manipulating a datasets bigger than memory  
\- SIngle-threaded but SIMD compatible  
\- No distributed compute orchestrator included (you'd need to package it as Dask or K8s jobs...)

DuckDB :  
\- Swap mecanism to allow paging on disk for datasets bigger than RAM  
\- Multi-threaded and SIMD compatible  
\- No distributed compute orchestrator included (you'd need to package it as K8s jobs...)

What you can see from this is that Spark kinda makes sense if you are planning to handle big datasets that don't fit on a single machine. Otherwise it'll be more complicated to set-up and slower than the Python libraries.",5,1736868897.0
1i1141c,m72he4a,"Thank you. Yes seems getting lost as there are lot of trainings and docs out there. So was thinking , if can get some guidance on specific certifications or udemy course which should be attempted to have a clear path for this transition without getting diverted into lot of stuff rather sticking to the important ones. As i got to know the pyspark is used in the building new data pipeline for data ingestion/curation from kafka to the target database like snowflake/data bricks etc.",0,1736843159.0
1i1141c,m74ov39,\+1 for the Advanced Databases course by Andy Pavlo from CMU. This has been a gem in helping me understand how modern query engines work. And the fact that its freely available on youtube... couldnt ask for more.,1,1736876262.0
1i1141c,m72iit8,I started from the OReilly book the definitive guide to spark.. I personally struggle to follow videos etc maybe someone else in the comments can help more,1,1736843907.0
1i1141c,m73k2y3,Snowflake can consume directly from Kafka using snowpipe streaming. It’s super efficient (see cheap) st loading data to snowflake fdn or iceberg tables.,1,1736863527.0
1i1fo6n,m75urii,"You will need SOME catalog for sure (HMS or something) regardless of it you are using Hive, Iceberg, or Delta Lake table formats. More info at [https://trino.io/docs/current/object-storage/metastores.html](https://trino.io/docs/current/object-storage/metastores.html) and it basically says you need a Thrift HMS or AWS Glue for the metastore -- unless you are using the Iceberg connector which then has several other options as called out at https://trino.io/docs/current/object-storage/metastores.html#iceberg-specific-metastores. Obviously, Starburst Enterprise (disclaimer; DevRel at starburst.io here) has much more assistance in this space than base OSS Trino, but you can get there. 

If the heart of your question is about validating your ADLS data lake can be the home for your tables, I'd CONSIDER just using the free options of hosted SaaS Trino instance called Starburst Galaxy, [https://www.starburst.io/starburst-galaxy/](https://www.starburst.io/starburst-galaxy/), and creating a connector that points to your ADLS config. Galaxy already has it's own metastore that you can use, plus you can create Hive, Iceberg, and/or Delta Lake table formats in the same config.

Sorry I don't have all the answers to your questions, but wanted to share what I did have available.",3,1736888906.0
1i1i8b7,m76chll,"You might struggle to get a DE role without any kind of related work experience, even if you get certs. I believe many go into Data Analytics first then transition to DE.

That said, a free DE bootcamp started yesterday that I’ve done previously. I did it a few years back and found it very good for getting hands on with building pipelines:
https://www.youtube.com/live/X8cEEwi8DTM?feature=shared",2,1736894178.0
1i1i8b7,m76lljo,"This. I usually expect prior experience in an adjacent field before pivoting to DE. Sometimes that’s analytics, software dev or more operational/support (with data focus).",1,1736897113.0
1i1i453,m76a07x,Congrats!,1,1736893420.0
1i1i453,m76gpso,Where did you do your practice questions?,1,1736895503.0
1i1i453,m76l29w,"I did them from ITExams, certlibrary and examtopics",1,1736896933.0
1i1hygv,m76h6fb,"Hi, u/AdventurousMatch6600 . I am an engineer at Airbyte and I help support PyAirbyte. We're always welcoming feedback. Admittedly, the PyAirbyte docs are hosted on GitHub pages now and perhaps aren't as discoverable as we'd like. The best way to see the docs is to use the ""API Reference"" link on [docs.airbyte.com/pyairbyte](http://docs.airbyte.com/pyairbyte) or else bookmark directly: [https://airbytehq.github.io/PyAirbyte/airbyte.html](https://airbytehq.github.io/PyAirbyte/airbyte.html)

We also have a slack channel for PyAirbyte, which you can use for feedback and questions. We know from Slack comments and from testimonials that many users do leverage PyAirbyte for daily syncs, AI-related applications, and data engineering workloads. Let us know if we can help!

Thanks,

AJ",5,1736895651.0
1i1hygv,m76mdpp,"My work blocks slack but I will try requeting access.  My biggest issue was with finding how to setup the configs for pyAirbyte, however i found a reference in the API docs to the 'print\_config\_spec' function.  I'm using that to setup my configs now and will message back with how it goes.",2,1736897374.0
1i1hygv,m776mgf,"Yeah, the configuration of connectors is a rough edge we're aware of... In the future, we're looking at Pydantic models for those configs, which would give autocomplete and IDE support during connector setup. 


I can share a couple other points which might be helpful: 
1. If you just run ""check()"" on a connector with invalid/incomplete config, the error message is supposed to (as much as possible) point you in the right direction. If you are stuck, you may have good luck just sending a blank config and then reading the error message for any clues to resolve - iterating from there. 
2. Many of our sources have a ""Reference"" section at the bottom of their docs page, including a reference of input configs expected. The url to the connector's docs page should be included in the error messaging noted above.
3. You've already discovered `print_config_spec()` which is the most reliable programmatic way to get the expected config inputs for a source or destination. (Although the json schema format is admittedly not super intuitive or readable.)


Because you don't have Slack access, another option is to create an issue or discussion in the PyAirbyte repo. Return time on GitHub is not as good as slack (and holidays made this temporarily worse) but it's another good way to reach out if you need help. 


Hope this helps! ",2,1736904179.0
1i0uaou,m70t1rm,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736817443.0
1i0uaou,m70wkcq,Just take the offer. There is nothing to lose.,129,1736818594.0
1i0uaou,m71qkf1,"There’s a bootcamp when you join Meta - the good news is basically all the technical problems are solved as an IC4 and you just need to write SQL and work with product people. Culture depends on team but believe that most people want to succeed and just communicate with them honestly (about work and deadlines).

I don’t think layoffs at Meta are likely at the moment  and any “eagerness” is just a function of you being a competent candidate and them needing to hire. You’re overthinking it - it just saves everyone time. Think about if you had to spend 3 months interviewing without an offer on the table!Take the money.",26,1736828834.0
1i0uaou,m711uas,"Layoffs are a normal part of the industry and ""fit"" is a constant struggle for DE roles due to the vast nature of the field. Don't let one unpleasant experience rattle your confidence or change your career trajectory. 

If you take the Meta offer the worst case scenario is that you get pipped but you will have Meta on your CV, get to keep the sign on and get a severance. 

The question about relocating is a bigger issue IMO. Any of those locations will put you in a tech hub so it will be easier to find another role if Meta doesn't work out or if you want to move on. Living in a HCOL city just for work can be either a miserable experience or the greatest decision you ever made.

Edit- Meta has just announced more aggressive layoffs starting in February and that may be why the recruiter seems  eager to get you on board. 

There is one more thing about working in big tech that a few other posters mentioned- it can get extremely toxic. Similar to yourself, you are going to be working with very ambitious, very talented people and unfortunately some of your coworkers may look at you as an obstacle to their success, especially with layoffs looming. Your manager may have favorites that they are trying to keep around and purposely put you in uncomfortable situations or assign you undesirable projects. Your time at the office may be similar to an episode of Game of Thrones. 

I am only mentioning this because if you decide to join Meta, your biggest challenge may not be the work. Apologies if this adds to your anxiety but I think it's important to explore a scenario where you need to have an early exit.

[Here](https://www.reddit.com/r/cscareerquestions/s/6RUoGN2Jvh) is a thread from r/cscareerquestions about the news.",31,1736820291.0
1i0uaou,m7101fq,So the last two to three months data engineers have been in high demand. I don’t claim to understand why but I’ve had at least two recruiters reach out to me a day since November.  In my seven years in the data field I have never seen a higher demand. ,16,1736819722.0
1i0uaou,m72d25t,"I worked at Meta for a long time, but I’m retired now. It was by far my favorite job I ever had. They won’t hold your hand to train you, but they do understand that people need time to ramp up and they’ll point you at sources you can go to to teach yourself how to do what you need.

I was always a little frustrated that they weren’t doing things like pair programming and stuff like that in order to train people up faster, but it really is every man for himself there. Folks will help you to a degree, but they need to get back to their own stuff. I think one of the company mantras is to never ask the same question twice so be sure to keep good notes for when you forget stuff.

So be confident in yourself and your ability to learn and go there with the expectation That you’ll be able to take care of yourself and learn what you need.",8,1736840426.0
1i0uaou,m722qeg,Didn't you grind leetcode and passed countless rounds to get this offer? That's not something anyone has the skills and/or motivation to do.,7,1736834492.0
1i0uaou,m71dzt9,"Take the offer. They saw your potential and want you. Trust that.

Make sure to do research about the culture/health of the team you’ll be joining and the company as a whole. One bad experience shouldn’t define your entire career.

Also not a lot of places are hiring these days so this could be an opportunity to get a foot in the door and prove your worth. What’s the monetary offer look like? Can you negotiate now as compared to when you last spoke to them?",8,1736824207.0
1i0uaou,m722m88,"Don't let a failure at a startup define you. It is likely the startup needed something very specific and they just don't have the means to keep people around who weren't meeting those needs.

Meta is the exact opposite. You will not feel incompetent there. Worst case, you land on a team that is ""hard"" to work for, as in 50h weeks. But as others have said, the technical problems are all figured out. You'll walk away with less learning than a startup, but a massive green check mark on your resume.",3,1736834431.0
1i0uaou,m71kyja,"It sounds like you were fired, not laid off. That is a distinction, but something not worth beating yourself up over. As others have said, DE is a big field and it's on the startup for a) not providing you the resources you needed and b) not being able to figure this out during the interview process. If you want to make it sound nicer (and you should!) just say you were let go. It happens to the best of us.  

Why is Facebook hiring so aggressively? A few reasons, from what I can tell: 1) they're seeing lots of attrition due to RTO, Zuck's comments, and them doing lack-of-virtue signaling shit like taking tampons out of men's rooms and stuff. They're pissing off a lot of people who otherwise weren't bothered by Meta's other very severe issues (like assisting the Rohingya genocide and doing nothing about it, Cambridge Analytica, etc.). 2) They're pivoting yet again. Facebook is mostly dying/dead as a platform, the Metaverse is a long play that isn't paying off yet (and it still remains to be seen if it will), and they're jumping into gen AI which they're seeing more immediate success with (and doing a pretty decent job at, all things considered). 3) Despite the health of their big platforms, they have tons of data that's still growing at a big clip, and the gen AI pivot requires a lot of it. 

All of this leads to needing more DEs. 

As for whether you should take the job? It's up to you - do you have significant enough moral differences with Meta to ignore it? Do you have the resources to allow you to? Note that none of these questions are about your skills: bigger companies are generally better about filtering out false positives (not so much at false negatives), and they have far, far more resources to assist you with upskilling - it's why I typically recommend early career devs to start at a bigger company.  

But the only important advice here: never doubt if you're good enough or can get good enough. All of this shit is learnable, and it's made easier if you enjoy it. Ain't nothing to it but to do it, and learning new skills will serve you well. Never be afraid of making a big jump.",6,1736826688.0
1i0uaou,m735dk3,"IC4 DE at meta will be similar to a very specialized analytics engineer role at a startup, still very fulfilling and very good for your CV. Just don’t go in expecting it to be super technical and “true DE work” as you say, if that to you means anything other than creating and maintaining ETL pipelines and creating dashboards",3,1736857572.0
1i0uaou,m7121ly,"Living the dream

Seize the opportunity",2,1736820357.0
1i0uaou,m71fvkz,"Seize the opportunity or just let me know how you got it, so i can take that opportunity",2,1736824862.0
1i0uaou,m738rmw,"Imposter syndrome is normal in this industry. If they gave you an offer, it means you are already good enough. Think about it like this 1.) imposters don’t get imposter syndrome and 2.) the worst case scenario is that you collect a really good salary for a little bit and have Meta on your resume",1,1736859101.0
1i0uaou,m73jm9j,"If you were laid off from some startup because of your technical skills I can't imagine the requirements will be less at Meta. 

Saying that I would still go for it if you're doing okay financially.",1,1736863355.0
1i0uaou,m73o4vd,"I got nailed with the ""fit"" thing and laid off in October. After doing the job for nearly three years, I was no longer a good ""fit"" for the team... OK?

""Fit"" can mean anything. Your boss doesn't like you. You work slightly differently than other people, so it rubs people wrong. You made a faux pas that stuck with someone. Your boss has expectations for you to do something that doesn't at all align with your skill/will matrix. The team skill needs have changed (ie the team now needs higher level or even lower skilled people than previous). Salary budgets have changed. Anything",1,1736864984.0
1i0uaou,m73slbi,"No one is forcing you to take a job and stay there. Just as you got fired from the startup for ""fit"", you can fire Meta if they don't meet your fit.

Take the Meta offer closest to the location of your next desirable job. That way, you can network with the companies that you do want to join.",1,1736866503.0
1i0uaou,m73t373,"I currently work at Meta as a DE, joined as IC4 3 years ago and got a promotion to IC5 in the first 6 months. Feel free to DM me and I can share some perspective on what you might expect joining.",1,1736866664.0
1i0uaou,m76w2u1,Shit if you don't take the offer give it to me 😂,1,1736900590.0
1i0uaou,m771x6y,Take the offer. You’ll learn what you need and meta is much more supportive than a startup would be. Most des are just doing a lot of sql and dashboards. You’ll do just fine,1,1736902549.0
1i0uaou,m73n7wj,"From the post, it sounds like OP has to move to one of the three locations. So they could move, and Meta finds out a few weeks later that he's not good enough, and he's fired *again*",6,1736864662.0
1i0uaou,m72f0et,My proposal would be a lot of people have a lot of AI projects and they've started to realise how fucked those projects are without good systems for data. My employer was basically trying to limp along into a load of different AI projects with an Indian DBA team trying to test everything manually and just kept stepping on rakes before putting some significant money into several good data engineers with good software skills. ,6,1736841628.0
1i0uaou,m71sk8r,"I’m freelance and have steady work with a consulting firm as one of my main things and yeah, we have landed like 6 projects since early December.  Nobody ever messages me on LinkedIn though.  Maybe it’s how I have it set up though.  I don’t mess with linkedin a lot.  Has always seemed a waste of time. Only recruiters I’ve heard from are offering truly terrible work.",2,1736829676.0
1i0uaou,m725gnx,"Weird, I had crazy amounts of messages during covid, literally multiples a day at times, and haven't seen any at all in months. Maybe it's my middle manager title despite being more a tech lead. ",1,1736835960.0
1i0uaou,m73ecyl,Annual budgets,1,1736861377.0
1i0uaou,m73h0fd,Thanks for the anecdote. This explains why we've had such a turd of a time hiring a new data engineer in the last quarter. I assumed the job market was still shit for all engineers but maybe all the AI companies are finally realizing governance and curation are critical to success.,1,1736862386.0
1i0uaou,m71v24c,"Would you mind if I reach out to get some feedback on my resume? I’m also a data engineer with a couple of years of experience looking to move into a more technical role, but can’t seem to get any call backs to my applications.",-1,1736830776.0
1i0uaou,m76wbyv,Great response!,1,1736900674.0
1i0uaou,m73qewe,Hey I would be interested in doing freelance work do you mind if I get in touch with you via private message?,1,1736865775.0
1i0uaou,m74fs21,Not at all.  One thing I can say is I found work through local networking mostly.  Not linkedin or other advertising.  I just went to local data clubs and also leveraged the network I built up over 18 years working tech-adjacent or in an actual tech role.  Luckily that snowballed and now I've got more work than I want tbh.,1,1736873608.0
1i0uaou,m75q9h6,"Nice, and how much can you charge as experienced date engineering ? Is more with it than working in a big tech?",1,1736887248.0
1i0uaou,m760fds,"$100 to $150, I don't try to charge super high rates b/c I'm just a dude, and if they wanted to pay $225/hr they'd hire a proper DE firm.

Yes, there's more than big tech.  Small and medium size companies have plenty of needs.  That's the sweet spot IMO.",1,1736890584.0
1i15aov,m738agr,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736858894.0
1i15aov,m74gza8,I believe you are right. It isn't about the dot notation it is about the fact that you have an ARRAY(ROW()) in there and Trino is wanting each column to be a simple datatype or a ROW datatype (which itself would allow the dot notation).,1,1736873956.0
1i15aov,m76olnr,Do you think there is a way around this? or am I limited to unnesting arrays in separate CTEs and the language just doesn't have any native way of handling such scenarios elegantly?,1,1736898107.0
1i1cbwp,m74xu0m,It's bad everywhere. Find a niche that you're interested in and go after that. Be that DE or something else.,16,1736878842.0
1i1cbwp,m754rqp,"Poor & I don't think it will ever be a massive growth area.

Most data engineering jobs advertised aren't really DE jobs.

Most are actually looking for BA's with coding skills.....",15,1736880837.0
1i1cbwp,m77ktl8,"Little difficult for below 2 yrs but vacancies are there .It's good for people with 3-10 YOE,it has improved from the last 4-6 months and hopefully continues to get better in the next 5-7 months . Pls don't listen to people badmouthing DE , it's a good career and will definitely grow as well. Just continue doing the hardwork",2,1736909142.0
1i1cbwp,m74z5r6,"1-2 years , very bad. 10+ yoe , fine I guess",4,1736879219.0
1i1cbwp,m74ytlz,I guess a better question would be how is data engineering market compared to everything else,0,1736879123.0
1i1cbwp,m760frg,I heard so many people talking about is growing because companies need a lot more data engineers than data scientists,1,1736890587.0
1i1cbwp,m75ef7r,what about for 5+?,1,1736883644.0
1i1cbwp,m7506x5,On par,6,1736879518.0
1i1cbwp,m76cf6l,"They will. But not at scale. 

Gathering & warehousing datasets is not labour intensive and is easily automated already. 

AI is already having impacts and a killer ETL AI agent is just around the corner. 

A more general career in automation is probably a better route than pigeon holes like data engineering",1,1736894157.0
1i1cbwp,m75ewy0,"Eh we aren’t hiring them. Companies want seniors, that can hit the ground running.",2,1736883788.0
1i1cbwp,m7642rh,"It’s ok, but not great. I’m 5YOE and got a job few months ago. Pay is lower and more competitive. I was in final rounds against 7-10+ YOE for <130k salary.",1,1736891652.0
1i1cbwp,m76oj0l,"Thats an interesting point. When looking at job titles, just for CV purposes, would you prefer a different title to the ""data engineer""?",1,1736898083.0
1i1cbwp,m77q6ni,"People with 5+ YOE should be operating at a senior data engineer level and be able to hit the ground running IMO, but sure.",1,1736911079.0
1i1cbwp,m770dhr,"companies are rebranding groups as data engineering teams. 

I've seen a company call anyone who knows SQL a data engineer 

In the market, it's just a loose term for a database developer",1,1736902027.0
1i1bb5k,m74otjz,"What?

Many tech startup exit plan are to be acquired, only select few can become a large player.",2,1736876250.0
1i1bb5k,m74o1sp,"sorry i've not seen these companies before. they seem like they are all sorts of ""connectors"" products where you port data from one source to warehouse/destination.",1,1736876026.0
1i1bb5k,m74rau9,Agreed! But of the lot only Fivetran has been making 3-digit million dollar figures and rest of the guys are left sulking. Wondering what Fivetran did differently what most of them are not able to do!,2,1736876964.0
1i1bb5k,m74odhw,"Yes , low/no code ELT/ETL products",1,1736876122.0
1i1bb5k,m74tv5f,"They know to whom they should sell their service and manage their accounts. What they are selling has pretty high margin. 

They cost averages like $500 per month per million rows, and here i am writing codes to ingest billion of rows per month and still slaving away to corporate.",2,1736877694.0
1i1bb5k,m74pt07,"ah i see.. personal thought is this space is quite saturated (there's so many connector companies nowaday) + super expensive + hard to do security. 

the real value add (or work i see) is when i can integrate data together say taking customer data from subscription management platform to customer service platform.. these connector product only do it half way.. like it's still so much work to actually put the ""copied"" data to use.",1,1736876536.0
1i1bb5k,m7558qs,SDF is a code-based transformation framework not a low code ETL product,1,1736880971.0
1i1bb5k,m74uck9,Yeah they probably have a better sales team than engineering i guess! Does HVR sells more or the Fivetran platform?,1,1736877834.0
1i1bb5k,m74r3kv,"Trying to understand your challenges here

\- What you are wanting them to do is move data which is transactional data in nature(lifecycle is not complete, as in not historical) and move to another system?  
\- My assumption is the applications would already be doing this as the requirement would be to do it near-real time without any failures, is that correct?",1,1736876906.0
1i1bb5k,m75642n,Yup! Similar to DBT. What are your thoughts on the fragmented and saturated data tools market?,1,1736881218.0
1i1b60g,m74qqma,Are you a team member or the team leader?,1,1736876803.0
1i1b60g,m74sdi3,Is your team in another country in itself?,1,1736877270.0
1i1b60g,m753639,I am a team member,1,1736880378.0
1i1b60g,m753jzw,Yes most of them. Few are in same country but in another city. I can get relocated but it is costly for me to do so.,1,1736880489.0
1i19lz5,m74fxlp,"Have you checked this?


https://cloud.google.com/storage-transfer/docs/create-transfers/agentless/s3",1,1736873653.0
1i19lz5,m74ofmr,I would use the minio client: https://medium.com/google-cloud/using-google-cloud-storage-with-minio-object-storage-c994fe4aab6b,1,1736876139.0
1i19lz5,m74kht1,No I have not seen this. Thanks for thr suggestion. So basically write a python code. Have you worked with this and how does it work with high volume of data?,1,1736874992.0
1i19lz5,m74nrhm,"Sorry, I'm on mobile and searched this in a rush. I wanted to share something different. Hope it's the correct one this time :)


https://cloud.google.com/storage-transfer/docs/overview


It's a paid service, no code is needed, you configure everything from the UI. 



If the data is organized properly in s3, with time based prefixes or partitions, this can also copy your data on a schedule


Edit: *your data",1,1736875944.0
1i19lz5,m74o6wl,Thanks! Can this work both ways? I need to copy to s3. Also Google cloud services are kind of out of the picture given that we are not owners of them and thr other prolly would not want to incur costs but still want to Know the options,1,1736876068.0
1i19emm,m7468x4,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736870768.0
1i19emm,m748b69,"Other than the technical flow diagrams, what you are describing are activities normally attributed to the Data Steward. Data Stewards are almost never on the technical side of the house, but rather the business. Your challenge is going to be finding someone on that side of the house to take it over. Good luck with that. You will need it.",3,1736871396.0
1i19emm,m76h9e7,Thanks i guess yeah i will need a lot of luck xD,1,1736895678.0
1i0hj62,m6xx0sz,I am disappointed to see that the question is not about writing a database engine from scratch.,192,1736785949.0
1i0hj62,m6y2ajs,"Step 1: Why?

What's the primary purpose, reporting, analytics, customer outreach? 

Step 2: Hire someone who knows how to do this, like an actual data warehouse/database architect. 

I mean you could just stand up a MySQL, PostgreS, MS SQL, or even Access DB and shove stuff in; but what you are hoping to get out of it and how, that's the rub? Then you gotta automate as much as possible.",19,1736787492.0
1i0hj62,m6xxxz0,"What's your budget? Hardware? Data volume? Access? Do you have a support team? Number of employees at company that need access to the data and their Technical Experience?  
  
In my opinion, there is no such thing as automated data cleaning, and by that I mean upon first ingestion there will be some development. once that's done you can save the code right? and run it as an automated job upon upload. 

2 and 3 depend on how they need to be accessed and used, as cost is involved. take for example iceberg storage (super cheap, but the data isn't accessed regularly). No code, in a lot of cases, means increased cost/overhead. 

Sounds like to me you need to put together a couple ideas, then show leadership their advantages/disadvantages before pulling the trigger on anything. If you don't you'll set yourself up to fail when management complains that a one person shop (I'm assuming) didn't build them an Enterprise Data Management System that didn't include the kitchen sink.",11,1736786224.0
1i0hj62,m6ya9k7,">> * 1. How do I clean such a data?

What you are describing is the tough discipline of data engineering called master data management, MDM.
There exists several solutions to help you, and often they are not cheap.

I have heard about people coding their own solutions and trying to catch everything in scripts. I haven't heard about it being done successfully when home made.

I don't want to sound condescending, but it sounds like you are out in deeper water.

There is no 1 way to do this, but often times it requires an agreed upon process that involves different parts of the business who owns the data, to choose what is the right value, and then IT to implement it through whatever MDM solution is chosen, that handle all your sources.

The main competition to a MDM system, is to hire some students, to fix every entry manually.
Some calculations only the business can make, about what makes the most sense.

If you have large enoug volumes of data that makes this hard, I would consider getting consultants in, to either plan and do a test run, or just completely hand over the entire MDM project to them, and you maintain it. 

And speaking of; maintainment. Unless you can get power over the input, MDM is a something that constantly needs to be maintained and is not a onetime thing, you set and forget.",7,1736789811.0
1i0hj62,m6xup7v,RemindMe! 3 days,7,1736785260.0
1i0hj62,m6xwlzi,"You need to learn basic DB design methods and how to do stagings areas.

Get your company to hire a data engineer, either full time or contract. If you can do remote over VPN, you open up a very talented pool from other countries that have a low hourly rate, compared to USA/Canada. Just my opinion, help below.

Help if you want to try yourself:

Quick overview, you dedicate staging tables per source, then after ingesting from source (like excel file) you run a stored proc that does a 2nd level staging to make the data uniform, before ingesting a 3rd time into a ""raw"" layer that has proper Primary Keys computed from valid Business Data columns that are ""cleaned up"".

I usually use reference tables per source, to align with the proper PK value the company wants.

So in a reference table called reference.Companies you have multiple records for each different source / spelling like ""ABC Inc"" & ""A.B.C Inc"" that both rows are assigned the same PK value.

So when going from first staging (1-1 match with source file) to 2nd staging, the 2nd staging table uses a stored proc to do lookups and fix all the PKs.

Then the import into the ""raw"" layer from each source file only what is required for each file & PK.

This way you can have 50 excel files from various departments with company information, and you combine them all into a common raw table(s) (you might have child records per company, like company reps, company notes - that go into a detail table, not into more columns).",25,1736785825.0
1i0hj62,m6xwgu7,"For point 1 You can make an approximate cleaning, or include cleaning, *abc* then (normalized name).",4,1736785783.0
1i0hj62,m70jpf5,"Bro. This is not a technical challenge anymore, more like operational. You need a whole new position (Data Engineer) to solve this, not just a ""database"". Either you become one or a dedicated person has to be hired. 

With that kind of messy data source, you need to communicate clearly with everyone about ""PRIORITIES"". Make a list of tables, that need to be created, ranking them by the stakeholders' needs. Then work backwards priorities which data source needed to be cleaned/transformed first.

YOU WILL NOT DO DATA SCIENCE soon. If you grind hard and everyone in the company is willing to help, maybe you will get back to data science after 1 year.

For the tech, just choose any low-code tool on the market, and save the cleaned data in PostgreSQL. Don't be over engineered when you are under engineered.",3,1736814344.0
1i0hj62,m6y7t7g,Sounds like you need to define a single source of the truth as step 1.,2,1736789104.0
1i0hj62,m6ymuzp,[https://airbyte.com/connectors](https://airbyte.com/connectors),2,1736793439.0
1i0hj62,m6yzmcf,"1. Cleaning data is actually the most difficult bit of Data Engineering because what counts as ""clean"" data is not some objective, general thing that you can just outsource to a library: it's a specific function of what the data is being used for. For example, if you're search logs, then any data you can `grep` through, i.e. any data at all, is ""clean"", whereas if you're trying to calculate monthly spending by users across specific categories, you'll basically need a full relational database schema. For your company name mapping case, there are a bunch of options. One would be to manually assemble a mapping table of all of the versions of the name you've found; another would be to use regular expressions; another would be to use machine learning (which could actually be a good fit in this case). None of these will be perfect, best test a few our for your use case.
2. PostgreSQL, unless you have a specific reason to use something else. If the data's in Excel now, you'll have more than enough space in PostgreSQL.
3. No. See Point 2.",2,1736797141.0
1i0hj62,m6xv8me,[deleted],1,1736785420.0
1i0hj62,m6xxoaj,"hey, for cleaning those company names, Phlorin could help automate data fetching and integration from different sources. it makes working with Google Sheets way easier, especially for unstructured data like yours. for storage, it can also help you set up a more organized pipeline instead of relying on Google Drive.",1,1736786144.0
1i0hj62,m6y9jb0,RemindMe! 3 days,1,1736789602.0
1i0hj62,m6yckv5,Saved for future ref.,1,1736790479.0
1i0hj62,m6yfyae,"You need to hire a team of data engineers and likely someone with data architecting experience. There are also companies you can consult with to provide this skillset if it's something that you won't continue to need in the future.

I doubt you have the experience to be able to sell this to management, but if you did this is how you get a major promotion.",1,1736791447.0
1i0hj62,m6yghie,"Best option here is to do a schemaless structure leveraging something like S3, partitioning, python, pyspark. Your looking to normalize the data with an ETL approach.",1,1736791604.0
1i0hj62,m6ygqqf,"I’d look at airbyte (open source but also has a decent GUI)

As far as company mapping, you’re looking at a master data management issue. I’d read up on that. There’s vendor solutions but they cost money. There’s data providers that can help as well. 

If your budget is $100 a month, and it’s just you. I’d level set that this is a several month long project and that initial expectations of data quality should be average at best.

I’ve done this a few times with similar budget and team size. My fastest deployment was 2 years to a point where everything was as good as the business wanted.",1,1736791677.0
1i0hj62,m6yhebj,"The answer to all of this is “it depends…” followed by a lot more questions.  

For question 3., if your Management wants to maintain the data as Excel or CSV in Google Drive, what is your argument for doing something different? What is the benefit of a structured database? Now consider the cost of implementing it and maintaining it, both in terms of money and your time. Realistically, will the benefit outweigh the cost?

The Pros of the Excel/GDrive option is that it is relatively simple and anyone with Excel experience could probably make use of the data. This is also a Con, since it is easier for a user to do something to mess it up. That said, it is a perfectly viable solution for many use cases. Don’t be tempted by something flashy and complicated if it really isn’t necessary.",1,1736791867.0
1i0hj62,m6yl87k,"You need to ask more questions before you start thinking about a solution. 

Business case, budget, resources, security, etc etc. 

Important things to know is how is the data coming to you. Are those inputs (excel, csv etc) from a transactional source system or are they manually curated files. (Will the columns change frequently? … they likely will if manually curated, which makes the job a lot harder. )",1,1736792965.0
1i0hj62,m6zb2vu,RemindMe! 3 days,1,1736800486.0
1i0hj62,m6zvuqt,It would have been the ultimate flex.. 😄,1,1736806567.0
1i0hj62,m707fwp,How much data do you have? How many files? How many rows? How many clients do you have? Do you want to keep the data unstructured? My first instinct is to build a quick MongoDB database since it sounds like your data is very unstructured. I would store the different names as aliases and refer back to the unique id for that specific business.,1,1736810229.0
1i0hj62,m71dmrk,"First step is to learn more about databases and then figure out how your requirements fit in. Nothing you’ve told us says much about how this database will be used, what the shape of the data is etc. Redshift and snowflake are expensive big boy analytics databases.",1,1736824085.0
1i0hj62,m72e477,if Data now exists in Excel or in csv  there is no need for red shift or snowflake. Just use postgresql or mysql as a db and call it a day.,1,1736841077.0
1i0hj62,m73wgka,"I get a sense you are missing some experience in programming, etl and infrastructure.  So I'd start simple and then make it more complex on iteration.

1. pick a simple project and talk to management until you understand the requirements and all data sources.  Start some documentation on it.
2. Get all the raw data sources and store them centrally somewhere.  You want to have good security systems in place for this like firewalls and logins blocking easy access.  So ask IT or if you are IT maybe consider blob storage.
3. Find software that can regularly schedule getting raw files and putting them into your storage system.
4. Write or find software that takes a dataset from central storage (google drive is an option, not my first choice, but you can get it to work), processes it and stores it somewhere probably the same storage system for later use.  Separate processed data from the raw data.  Good example of software is a python script or maybe an ETL tool like SSIS.
5. At this point, you should have some cleaned data sets.  Write another script/program/use software that fetches the cleaned datasets and creates a final end product you can use for downstream data consumption.  So maybe it's an excel file, a website that reads a file and creates a visualization or maybe it's an import to a database that data analysts can query.
6. Update the scheduling to include raw data import, processing and final product creation.  Then actually schedule it.   Add logging, email etc so that you can be notified if it breaks down.  Test that downstream products are there every day etc.

Then add any extra system related stuff as needed.  Do you have a website to support? Maybe add a SQL database.  Is the data quiet large and you can't easily process it.  Maybe apply some kind of data processing framework etc.  Do you support mostly finance?  Then maybe you can get away with just excel exports.  Try to start small and get some quick wins.  Probably the best way to get head count or budget.  At least get management's support.

Try to network in IT and data engineering department to get some mentorship.  Be vocal about your needs as well.  Management can expect you to wear many hats, but if you never wore those hats they can't expect you to be quick about it or not make mistakes.",1,1736867753.0
1i0hj62,m75j18p,Hi i liked the problem statement. I am currently working on building an open source solution to your problem to reduce the dependency on commercial cloud data warehouses to reduce operational complexity + expenses. The project is in very initial stages and i would be happy to have your opinions to shape our roadmap. This is open for anyone whoever wants to be a part of it. Send me a DM and i ll share more details and and probably also get your feedback.,1,1736884976.0
1i0hj62,m6yiwah,"100 different format?

You will need a team to accomplish this task.

I advise you to learn ETLs.  You can choose your tech stack according to your expertise and current organization infrastructure, Azure, AWS, Snowflake, Google Big Query, etc.

You can start with an introductory course in Udemy or YouTube about ETLs / data pipeline",0,1736792298.0
1i0hj62,m6ynn01,"You can DM if your company is looking to hire a Data Engineer for lower rates to help you, I dont live in the US :)",0,1736793663.0
1i0hj62,m6yru0k,"In case anyone is interested.  Here is the beginning of that journey.

https://www.youtube.com/watch?v=otE2WvX3XdQ&list=PLSE8ODhjZXjYDBpQnSymaectKjxCy6BYq",21,1736794880.0
1i0hj62,m6zef1w,Same lol,5,1736801461.0
1i0hj62,m71pdd0,"lol I know I was like “damn, why tho?”",1,1736828355.0
1i0hj62,m6xxd03,"Pls elaborate! How do u think database engine will help here, willing to learn",-11,1736786050.0
1i0hj62,m6y1tcr,"Willing to spend a few hundred dollars a month.
Its a one man army for now. Only I need access to the data, to retrieve and provide said data to Marketing/production team.",4,1736787352.0
1i0hj62,m6xuweg,"I will be messaging you in 3 days on [**2025-01-16 16:21:00 UTC**](http://www.wolframalpha.com/input/?i=2025-01-16%2016:21:00%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1i0hj62/database_from_scratch/m6xup7v/?context=3)

[**2 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1i0hj62%2Fdatabase_from_scratch%2Fm6xup7v%2F%5D%0A%0ARemindMe%21%202025-01-16%2016%3A21%3A00%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201i0hj62)

*****

|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|
|-|-|-|-|",1,1736785319.0
1i0hj62,m6xxd62,"There are commercial tools available in the DQ space (data quality) where you build dictionaries and the tools dumps ""valid"" data into your staging database.

It could be a big time saver, see this link for some: [https://www.softwarereviews.com/categories/data-quality](https://www.softwarereviews.com/categories/data-quality)

Whatever you do, please don't use INT AutoIncrement(1,1) for your PKs, GUIDs are a much better choice, or my favorite, Hashing with MD5().

Guids will always be unique and are quick to generate, and become surrogate keys, much like hashing.

With hashing, you can always calculate the resulting hash value from the business data anytime, in any language, in any SQL variant, Oracle / MySQL / MSSQL / Postgres.

Also with hashing you can calculate data changes by hashing the entire row of data, so with a HashKey and a HashRow, know if any new data or if it can be ignored because you already have it in the RAW.",8,1736786051.0
1i0hj62,m6yavhm,"This is pretty much what I do, but let me ask you a question about your staging tables though.  I'm using SQL Server, so I will have a LAND database where I import each exact external file.  Then I will load that into another database where the table structure has all the right data types.   Similar to stage 2 in the example above. Then I'll run some stored procedures like you are saying to update things.  In SQL Server I can easily write a stored procedure to load data from the LAND database to the STAGE database then to a final database.  

I have been thinking about trying Postgres, but I understand it's more difficult to do cross database procedures and queries.  Do most people just use Python for ETL in Postgres in order to move stuff from a land or stage database to something for reporting?  I assume they do that instead of trying to keep the land/stage/reporting in a single database.",1,1736789987.0
1i0hj62,m6ydi0a,"> If you can do remote over VPN, you open up a very talented pool from other countries that have a low hourly rate, compared to USA/Canada.

At cost of open sourcing your companies internal data. System design around incentives predicts eventually this will be a security nightmare. Maybe not this job. Or the next. But eventually organized bad actors discover that can subsidize the labor to strip mine the data.",1,1736790742.0
1i0hj62,m6xx66z,"And what if we missed a particular variation to write a company name, wont the system take it as another entry?",0,1736785993.0
1i0hj62,m6xvmg0,"Quite certain that is not at all what OP means, but the issues in the following sentence, i.e. the inconsistent naming of companies that OP is looking a solution for.",1,1736785533.0
1i0hj62,m6xy482,"He was joking.  Your original title slightly hinted towards building a data engine from scratch.  
You do ***not*** need to learn how to build your own engine. :-)",45,1736786274.0
1i0hj62,m6xyhsb,"It wont, it will delay the process by several years",14,1736786385.0
1i0hj62,m6xy6rt,"No, I’m sure they were joking. Definitely do not create your own database engine from scratch. Utilize existing dbs to serve your needs.",2,1736786295.0
1i0hj62,m6xz60u,"As others said it was joke. I misinterpreted your title, because I am interested in that sort of thing.
Don't build the engine yourself though :) Unless you are interested in that sort of thing, but it won't solve your current problem.",2,1736786581.0
1i0hj62,m6y9byq,"You're severely limited on what you can provide then. Make sure to keep upper management's expectations in check. 

Major cloud providers have tools (wizzards, if you will) out there that let you click though a questionnaire to forecast cost, look into that for starters, then agree on a POC/demo to show managment. 

It's wild (to me) that you've been tasked with this as just one person, on such a small budget no less...

Again, sounds like you need to regroup with management and set some serious expectations, because it sounds like a great opportunity to learn, but be realistic, and don't get take advantage of. Your company is asking you, the Data Scientist, to also be an entire Data Engineering department.",9,1736789543.0
1i0hj62,m6ybquh,"> Hashing with MD5()

You should not use an MD5 for your PK. Don't get me wrong, I use it to compare deltas between stage and target, for incremental/temporal loads; but there is a risk of collision when you use it as a PK. 

*The probability of accidental hash collisions for MD5 is approximately 1.47×10−29, but with today’s computing power, generating collisions can be done within seconds. The first known MD5 collision was demonstrated in 2004, and since then, the ease of creating collisions has significantly decreased. By 2006, a collision could be found within a minute on a single notebook computer.*

Works great for comparing 2 binary strings quickly though.

edit: 
>please don't use INT AutoIncrement(1,1) for your PKs

YOU ARE NOT MY SUPERVISOR. guilty as chards. It's fine for small refs. I should go fix that one thing though...",8,1736790240.0
1i0hj62,m6yt8mo,Maybe I am missing something obvious here but why shouldnt we use autoincremented integers as PK?,3,1736795292.0
1i0hj62,m6xz4b6,"It would be flagged as a reject or not processed, and you get a business analyst to upkeep the dictionaries every day.

The first staging table does an outer join to the reference (dictionary) table, and rows not ingested can be found with the PK reference being null, you can output this.

Can be a near full-time job in a large company with many departments.",3,1736786567.0
1i0hj62,m6y0s0b,"So, there can be some logic thrown at normalizing company names.  
1) Remove punctuation.   ""A.B.C. Inc."" -> ""ABC Inc""  
2) Unify case.   ""ABC Inc"" -> ""abc inc""  
3) Unify the designators/suffix.  ""abc inc"" -> ""abc inc"",  ""abc incorporated"" -> ""abc inc""  
and build out these kinds of actions to get a unique naming structure.

There are global and national companies so you'll need to figure out if you care about that.  If not, make them unique within the state they reside.  ""abc inc"" in Texas can be a different company from ""abc inc"" in Delaware.  You'll cover a lot with just this.  Most companies in the US are per state.  If you do have larger clients, like AT&T or Boeing, you'll need to figure out how to handle a corporate hierarchy and have an optional Parent field in each company row.",2,1736787050.0
1i0hj62,m6xydoo,"You can always write a query where the join returns null and if that result has more than 0 rows, send an alert somewhere or fill a dashboard or whatever to signal the fact that your mapping is incomplete",1,1736786352.0
1i0hj62,m6xvs5d,Oh Jesus of course lol,1,1736785580.0
1i0hj62,m6yquf9,"lol-worthy response. I use identiy in ref tables also if nothing else was defined.

As far as collisions with MD5 are concerned, usually not an issue with business data like business names. However GUIDs are the better choice for PK, hashing for finding changes without having to compare every single column to every single column.",4,1736794594.0
1i0hj62,m72ex81,"The chance of a hash collions is still very small (check birthday paradox if you want to when the 50% of a hash collion happens)

I know sha256 is the better option to use as a hash but not all db engines have that as a native function, so you have to generate them yourself via python or something like that.",1,1736841573.0
1i0hj62,m6z7xmc,"They are not good surrogate keys, that should be unique everywhere for all time. 

If you truncate the table it starts over. 

Within an OLTP app that only talks to itself, they are ok. 

But connecting it to something else, #101 doesn’t mean anything.",3,1736799567.0
1i0hj62,m6zaieq,"In addition to what Greybush said, in OLAP domains you want to not have a column correlated over the entire table. If you do this, it slows down rowgroup creation because the DB has to check all of the values of the column across all rowgroups before it adds the record. GUIDs are not correlated across all rows, so they make more much quicker inserts.",3,1736800321.0
1i0hj62,m6xzev6,"Yes, what I just typed as this good comment came up.

You use a programming tool like Python only to go from Excel / CSV / JSON into the first staging area.

From that point on, it is all pure SQL management with stored procs called in a sequence.",2,1736786652.0
1i0hj62,m6yrcjo,"Yeah, GUID FTW, especially for web based session caching and validation for OLTP. I use a lot of compound keys too these days, but I do a lot of data lake for reporting dev more than anything else.",3,1736794740.0
1i0hj62,m72wrco,"This sounds very interesting. So far most of my experience is in the OLTP realm and preparing the data for the OLAP section of the platform.
Is this related to the way columnstores work/are created? Could you mention some keywords for further understanding of this? :)",1,1736853068.0
1i1e0eh,m7649li,PySpark,5,1736891708.0
1i1e0eh,m75d3oo,I use R.,3,1736883257.0
1i1e0eh,m76purw,"Does anyone really only use python modules? 

We use only python modules for simple things like reading csv files or whatever, but when it comes time to manipulate data like aggregating it, apply transformation, or whatever business logic do you guys really write everything from scratch? Like write a group-by transformation from scratch?",2,1736898521.0
1i1e0eh,m7679sq,"Thank you for the response and yes, that's another big one.",1,1736892594.0
1i1e0eh,m75j5rb,"No, no. *Production* code.",4,1736885013.0
1i1e0eh,m75ei9u,"I should have added that in the poll, my bad. Thanks for the response.",1,1736883668.0
1i1e0eh,m77o5s4,"So far I have not done group-bys but definitely processed  some raw data which are csv, excel using python.",1,1736910334.0
1i1e0eh,m75v0pf,We use R for production code like most pharma companies.,2,1736888984.0
1i0t15s,m70iaes,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736813875.0
1i0t15s,m70nbym,"First of all, congrats! Both options sound great and worth pursuing.

Regarding what I would do, I think it's difficult to say but I guess, on the one hand, it comes down to personal preference, meaning are you still ""hungry"" and want growth/change in your life, or whether you have already settled down mentally and your priorities are on other things. In this regard, I recently heard an alternative but interesting perspective on ""meaning"" or ""purpose"" which essentially boils down to ""follow your energy"", so if you imagine different scenarios, which are the ones lifting you up and pulling you forward. Maybe this helps to evaluate the less explicit components such as work-life-balance.

The second main aspect seems to be the fear of underperforming. I think it is natural to not feel or even be ready when stepping up into a more advanced position as you often learn on the job and how could one even \*know\* to be ready without doing it.  However, while optimistic, you have to realistically estimate the gap between your current abilities and what is minimally required to have a realistic chance to grow into the new role. You could for example check out online resources adjacent to your expected responsibiliies and briefly work through them to get a better understanding of whether you are at last capable to learn these things in reasonable time. Given your age, I am sure you are able to bring in a lot of complementary experience and skills which might make certain blindspots more forgivable. In doubt, I personally would always go for the more challenging route assuming a potential down side is not too high.",7,1736815554.0
1i0t15s,m70sb34,"I joined a startup at 35, built the dw from the ground up, and years later would do it again in a heartbeat. ",7,1736817202.0
1i0t15s,m70yno0,"Take the higher growth role.

Im a big believer that if you're uncomfortable, you're growing and those experiences are what will propel you in the end.

Everyone wants to feel validated that they made the right choice and you'll only know if it was the right choice if you try it.

Also, Ive chatted with a ton of older data professionals. Something that is actually a downside to management is that you can get super rusty if you lose the individual contributor aspect of things.

I think it would be great to take on a new technology/approach, learn everything from the ground up, and then build a team for it. 

You'll be able to relate more, appreciate more, and those lessons will stick with you for life!

Also, I don't know what the salaries are for both roles, but extra income now and delayed gratification can set you up for life (financially) if you do it right!",3,1736819270.0
1i0t15s,m70tc0z,"What exactly is stopping you from advancing in your current role? Is this referring more to promotions and owning an entire project? Or do they not recognize your abilities and keep you on “easy” tasks? I’d encourage you to first have straightforward discussions with your manager as any good manager would love to help their reports take on more challenging work if they are capable. Your current job seems great and I’d be hesitant to leave without exhausting options especially since you say you’re still learning a lot.

If pay difference is huge it’s probably worth trying out, but definitely tread with caution in jumping to a lead role so quickly if you’re still early in your career. It’s what I kinda did and I wish I had more senior mentorship early on because despite learning a lot and owning a project end to end, I’m still filling in the gaps currently. It was also very stressful and very much a trial by fire. But I did it for less pay (personal reasons/different country) so that didn’t help haha",2,1736817537.0
1i0t15s,m725a88,"I started late in my career so I’ve been where you’re at. I’d recommend you take the risk and always choose the opportunity that offers growth above all else. Data Engineering and I’d argue Data professionals in general is always evolving. And recently it’s been evolving fast. With AI making rapid advancements, the Data Engineering role will be really different 2-5 years from now. If you stay at a comfortable position that doesn’t expose you to new technologies or freedom to discover and use new tech/solutions, you might end up stagnant and behind the eight ball. That’s not a good position to be in as an older less Senior Engineer. You should focus on getting yourself to the level someone at your age would have been had they started earlier.",1,1736835862.0
1i0t15s,m70ros8,"Thanks so much for your thoughtful reply! I really like the idea of following my energy. I’ve always been a really driven person, and the thought of taking on the more challenging role lights up my brain. But when I picture how I want my life configured for my remaining working years (next 10-15), I’d like the latitude to be more relaxed and apportion my time more equally among work, health, recreation, and relationships. I guess it’s true that once I develop enough expertise, my work hours at the new gig will better approximate my current ones (one hopes). To your point, I really need to assess my skill levels to see if it’s even realistic for me to perform sufficiently. Thanks again for your insight.",2,1736817001.0
1i0t15s,m70uwbq,That’s awesome. Were you already highly experienced or did you have to learn a lot in order to execute?,1,1736818049.0
1i0t15s,m7103yt,Those are really good points and some of what I’ve been thinking. I’m excited at the prospect of learning by doing and having a really solid foundation for eventually running a team. And spot on about the income and future finances. I started saving later than I should have but have made good progress. The additional income would get me where I’d like to be so much sooner. I’d love to reach some form of financial independence before typical retirement age so I could focus on more purely enjoying my work rather than worrying so much about how job loss would affect my future.,1,1736819745.0
1i0t15s,m70xz1l,"Your perspective is incredibly helpful. Thank you!

I was referring more to promotions. They would let me develop in whatever direction interests me and have already been giving me more complex work because they are confident in my abilities (their words). My manager is great, as is the engineering director. The whole team really. I’m not unhappy at all. They’re very senior heavy, though, with only a few leads/principals. It seems like it takes a while to move up. But to your point, there are a lot of factors to consider, and I’m aware of how fortunate I am to have transitioned from an adjacent space to DE under these circumstances. This is a great place to learn to my hearts desire while shoring up my skills.  

I just have stars in my eyes because this other position is my dream job, but more so for future me I think. The person I’d be working under is c-suite and has decades of AE/DE experience in my business domain. It would be remarkable to learn from him and become better connected to other leaders in the field. 

A lot to consider for sure, paramount being could I hack it if I took the growth role?",2,1736819046.0
1i0t15s,m71iqj2,I had about seven years of experience at the time and a strong enough handle on the full picture to plan and execute from the get go. I'd do a few things differently on another go but not very different. ,2,1736825882.0
1i0t15s,m70zwd7,"Gotcha and if it feels like an opportunity you’ve been waiting for I think it’s worth trying it out. If you leave your team on a good note there’s always a possibility of boomeranging back. Had a co-worker leave for Google for his dream job and come back half a year later for example when he realized it wasn’t what he thought it’d be. He didn’t regret trying it out at least.

I was wary reading you’d work with a C level exec directly as in my experience that’s been horrible but you did mention they have AE/DE experience so that might be better. I had to work with a non-technical CEO and it was not fun.",2,1736819676.0
1i0t15s,m710v8g,"Good point about boomeranging. I’d definitely make a considerate transition from my current team to keep the door open. Interesting about your friend. We often really don’t know how we’ll actually feel until we do the thing. 

I hear you about c-suite and have had a similar experience. This guy was hired specifically for his technical expertise and building out engineering departments in our field.",1,1736819978.0
1i0t15s,m71184g,Yep I think based on what you shared it’s certainly worth strongly considering then! You seem capable of growing into the role even if it may be a challenging one,2,1736820090.0
1i0t15s,m711rb0,"I appreciate the encouragement! I’ve got a bit of time to weigh my options, so I’m going to all of this into consideration. It’s a lucky choice for sure!",2,1736820264.0
1i0qifq,m6zxnhx,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736807118.0
1i0qifq,m703e7a,"Unlikely to be a legal issue - see LinkedIn vs HiQ for legal precedent. On ethical side - be respectful of servers & relative size of companies when scraping data. Eg don’t degrade other users experience or incur huge server costs with your scraping. What you have stated above seems fine, I wouldn’t think too much about it.",12,1736808913.0
1i0qifq,m70sokf,"Sites will block you if they don't like your scraping. If you're that concerned about security, which imo I don't think you need to be for a personal project scale, try a VPN or a proxy. ",4,1736817323.0
1i0qifq,m733jib,"If you really want to dive deep into this profession, you will have to spin that question around and ask yourself how to do it especially when you are ""not allowed"". Creating pipelines that go through proxies and get the data that you wouldn't normally reach is one of the most exciting things you can do.

To practice this you can find websites where you are normally geoblocked from and try to get their data.",2,1736856703.0
1i0qifq,m7267ae,You can always check the robots.txtfile if they have one.,2,1736836376.0
1i0qifq,m70t21d,"Be aware of this at your own company too, nobody likes big queries",2,1736817446.0
1i0qifq,m72fd8i,"You can ignore robot.txt, that tells nothing.",2,1736841853.0
1i0qifq,m72tohj,Care to explain more?,1,1736851222.0
1i0qifq,m72tuaj,It cannot be used in legal cases. The worst thing that can happen is your ip gets banned from the website.,1,1736851322.0
1i0qtzc,m731yla,"Dataversity, TDAN, TDWI",2,1736855920.0
1i0qtzc,m70jz3p,DMBOK,0,1736814434.0
1i0qtzc,m73z1pa,Thank you so much!,1,1736868568.0
1i0qtzc,m71onih,Wth,1,1736828080.0
1i0qtzc,m72f1vt,"Sorry but I don't agree that's why ny downvote.
It's an important resource for sure, but not to be stay up to date.",1,1736841654.0
1i12i6w,m73heb6,"why can't the semantic layer just be additional objects within the gold layer?  what is a ""semantic layer tool""?",2,1736862531.0
1i12i6w,m754k65,I'll let the users (analytics) handle gold layer totally. It's mostly for ready to use analysis or dashboards. They know what they want. They can't fuck up the lower levels. It's fine for me. If finance complains about query cost I'll look at those gold layer tables.,1,1736880777.0
1i12i6w,m75aypd,"Medallion architecture just renamed stage, core and semantic. **No new concepts here.**  if you use those terms, you will get literally thousands of experiences. (Fucking marketing guys feel they have to dumb down everything.)

How you manage it depends on what your users need. 

* Generic reporting can be handled out of either the semantic or core. Usually, it is both with the appropriate permissions set. 
* If yours are like most I have run into, your data scientists may want access to the stage data. Those folks can be nuts about getting raw, unprocessed data. 
* Your finance people will want the cleanest, scrubbed data they can get with impeccable data lineage. They will make you want to drink.

As an overall thought, the very best warehouses are not constructed with any particular need in mind. They are designed to address all of them and expand over time. This is not as hard to do as many will tell you.",1,1736882633.0
1i0z0bv,m71ylsp,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736832421.0
1i0z0bv,m7257zs,How about you tell first what is your task and what will you do in your job ? Certificates and courses are everywhere,2,1736835828.0
1i0z0bv,m74edyq,"Learn about ETL pipelines and add a cloud technology like AWS to skill set.
Learn SQL and Python
You will be up for the job",1,1736873203.0
1i0p0yh,m6zn8tv,I would bring it into bronze and create a view in gold.,14,1736804018.0
1i0p0yh,m6zo7a9,Bronze. It’s gold today but it might not be tomorrow 😀. Give yourself a layer or two to fix any issues should they pop up.,8,1736804295.0
1i0p0yh,m6zs1og,"Stage to Bronze plus views in gold

If the source data needs some translation / normalization  / standardization to make it joinable with other data best to put it in silver as well",6,1736805416.0
1i0p0yh,m6znrlh,how big is it?,2,1736804168.0
1i0p0yh,m7290ae,"External data requires I/O and are not under your control.  The network may timeout, the structure may change.
This makes it unstable and not suitable for the quality standards of a gold layer.
If you stage it or at least abstract with a view and add quality checks, it will be more reliable.",1,1736837970.0
1i0p0yh,m6zs0fq,"I was wondering something like this. We can do shortcuts (we're building in Fabric), so I thought about doing shortcuts in gold to each table in bronze.",1,1736805405.0
1i0p0yh,m70f9pp,"What's on silver then? Pun intended

Pun aside, genuinely asking as i'm still learning medallion architecture",1,1736812864.0
1i0p0yh,m72nipt,"While I second this approach, OP why do you have to load gold level tables into another platform? In my mind that may be unnecessary, expensive and possibly an anti pattern if many users start doing this. Can you not use federation instead?",1,1736847244.0
1i0p0yh,m6zrupp,"Yea I'm wondering this too. I haven't learned enough about the dataset to know if it's possible it will change, but even if I knew that I can't know that in the future!",1,1736805358.0
1i0p0yh,m706uup,"Makes sense, this sounds like the likely way to pursue it.",1,1736810038.0
1i0p0yh,m6zrpxs,"Not sure yet as far as total GB size, but it's about a dozen tables.",1,1736805320.0
1i0p0yh,m73gl6n,"Interesting point, thank you for this.",1,1736862226.0
1i0p0yh,m70oiu1,I think it's fine to select bronze data right into gold if you don't need to do any intermediate work (yet),2,1736815949.0
1i0p0yh,m73gdh4,"This data is coming from an external procurement software suite, so I assume we need to import it into our lakehouses first before reporting on it. It's gold-level, but it's not yet in a gold lakehouse or anything like that, so we can't use federation as far as I'm aware.",1,1736862147.0
1i0p0yh,m70oebk,"I'd say always land in bronze, and if you can start out with a silver view that's just a straight pass thru from bronze great take the win and be ready for the change requests",1,1736815907.0
1i0p0yh,m715fcz,"My advice, stick with your pattern (load data into lakehouse) unless/until you have a compelling reason not to. Cognitive overhead is a significant cost, make sure the payoff is worth it.",2,1736821455.0
1i0p0yh,m73gine,Yea this is what I'm thinking as well. I'd rather have a standardize ingestion process regardless of the quality of the incoming data.,1,1736862200.0
1i0p0yh,m73jngr,"What’s the other argument for loading directly into the gold layer?

Then come up with criteria (“principles”) for making these kinds of decisions. Advertise it as a “framework”. Make promotions. (At least at big tech, this is how things are done. You demonstrate to leadership that you can use your experience to scale decisions)",2,1736863367.0
1i0p0yh,m73lruw,"Wow, thank you for this. I've been struggling with how to think about these kinds of decisions and have been ending up frustrated when I'm unable to make compelling arguments to support a certain design principle. That said, I was in a meeting yesterday where I was successful in promoting a certain design principle to keep in mind as we migrate our on-prem infrastructure to Fabric. It sounds like I need to be documenting these principles and developing arguments to promote them to leadership. The ones that are accepted can then be shared across the project so everyone can be working towards the same goal.",2,1736864147.0
1i0p0yh,m73ot8o,"It’s easier to get people to agree on principles for how we’re going to do something. Then you put the concrete situation into the machine and an answer comes out. 

When people disagree with the result you have a principled approach to say “hmm which of our previously agreed principles do you want to adjust?” Then you can always take past decisions, run them through that process, see if it would change them.

This is key because people become attached to outcomes but generally are less adamant about processes or frameworks. ",2,1736865223.0
1i0qpxg,m6zzeig,"Are you interested in transitioning into Data Engineering? Read our community guide: https://dataengineering.wiki/FAQ/How+can+I+transition+into+Data+Engineering

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736807658.0
1i0qpxg,m701hda,$35 an hour is decent for someone without relevant professional experience.  What the company you’ll do work for is paying isn’t really relevant because your agency takes a significant cut of that. ,11,1736808305.0
1i0qpxg,m701082,"Having worked with staffing groups and C2H models before, the company is paying probably twice what you are getting yourself. I wouldn't think it diminishes your value too much. In my experience, at the end of the contract there is a new hiring which would involve a new salary. That said your contract may be modeled differently.",6,1736808155.0
1i0qpxg,m7031r2,"Thanks for replying and for the insight! I only have experience related to DS and BI, so passing the interview was definitely a surprise for me. I was just in a ‘why not give it a try’ mindset.",1,1736808801.0
1i0qpxg,m702ex1,"Thank you for your reply! I understand the typical markup involved in staffing arrangements. tbh I'm okay with the agency's high markup. my concern is whether the company is aware of this markup, so they know exactly how much I'm being paid. It's a just bit stressful not knowing if their expectations are aligned with the compensation I'm receiving.",2,1736808600.0
1i0qpxg,m70txkh,"Business is business, and pretty much everyone is aware of this. Make sure your #1 rule is ""look out for #1."" Get some experience and get a better paying role. ",2,1736817735.0
1i0kb85,m6yh00i,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736791752.0
1i0kb85,m6ypv9d,"SSIS is way more expensive (or at least was, some years ago) but if it is only 100K rows, and we are not talking retardedly wide tables, you should be able to do it in less than 5 minutes each day.

Downside is, that SSIS is so 2010.
But it still works and rocks.

If you are also in it for the learning, I suggest looking at CDC, change data capture. You can do it through stored procedures, and basically just keep a live copy of data on your Azure SQL database, instead of a single nightly run. 

There are caveats, like it depends on what your on-prem SQL Server is running of version, and the size of your Azure SQL server, etc, but here is an introction, [https://learn.microsoft.com/en-us/azure/azure-sql/database/change-data-capture-overview?view=azuresql](https://learn.microsoft.com/en-us/azure/azure-sql/database/change-data-capture-overview?view=azuresql)",3,1736794311.0
1i0kb85,m6z0feu,"Use powershell!

Install the SQL and Azure libraries if you need them.",3,1736797375.0
1i0kb85,m70326z,"You possibly could setup an ADF and schedule a pipeline in there pretty simple, and that can happen in few minutes might not cost your company much. But you can do it though open source tooling/scripting I believe to save money and can be a great learning to see CDC.",2,1736808804.0
1i0kb85,m6yqir0,"An easy way to do this is with [sling](https://slingdata.io)

Here is an example replication:

```
source: my_sql_server
target: azure_sql

defaults:
  mode: full-refresh
  object: new_schema.{stream_schema}_{stream_table}

streams:
  dbo.table1:

  dbo.table2:
    disabled: true

  dbo.table3:
    mode: incremental
    primary_key: [id]
    update_key: created_dt
```",3,1736794500.0
1i0kb85,m730h72,100k rows from one SQL db to another should be fairly trivial. A simple script as a cron job should suffice.,1,1736855152.0
1i0kb85,m6ysi7w,"As someone mentioned below, for replication pipelines like this where your source is an OLTP database, the best way to go is change data capture (CDC) - it's the least impact on the source db, doesn't miss any events, captures deletes, etc.

If you are open to tools outside of Azure, Estuary (disclaimer: I work there) can do this for you for pretty cheap and it's a lot easier to manage than SSIS.

Check it out here: [https://estuary.dev/source/sqlserver/](https://estuary.dev/source/sqlserver/)",-3,1736795077.0
1i0kb85,m72qkz8,"Thanks for your insight, I'll check out CDC!",2,1736849257.0
1i0pd6j,m6znv4k,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736804196.0
1i0pd6j,m6zujc4,"Your goal is to make it to senior and then principal 

Look closer at your KPIs and make sure you hit them.

Also make sure you are visible and seen to be the go to person for fixing P1s and helping deliver your jira tickets on time without complaint.  This one takes time.   You only get good at this by doing, reading the docs and listening to the principal data engineers.    Copilot tools can only take you so far.   

Good luck",2,1736806166.0
1i0pd6j,m70qv4j,"> But I want to know if you guys have some tips that I can take with me in my career

This is what I would have liked to be told early on in my career:

* Talk to the guys who have the most fun/complex tasks at lunch, or over the coffee machine, at the bar when you're out drinking or wherever you can. Listen and show interest, and don't try to impress. 
* Get good reading habits. Following this sub can be a basis of finding other blogs and get introduced to different tech/concepts, but never make other peoples opinions your own, as in here are some extremely skewed viewpoints on certain subjects. Get an introduction to them, an idea of how they work. With experience you will find out, what to hate for yourself. Books are not as relevant as some years ago, but I read an old stat, that if you're in IT, and reads 1 book a year, you were reading more than 80%+ of people in this business.
* In general, if you get to choose what to work with or if you get a chance to work with something you haven't touched before, say yes, even though you need to spend a couple of hours tonight to read up on it, so you're have a basic understanding to dive in to the new stuff tomorrow at work. The time is well spent and opens new doors, which you don't always have to enter, but now you know why not.
* If you disagree with a technical direction/solution or something doesn't makes sense, always try to get the business perspective on the matter besides only the technical. Sometimes it actually makes sense.
* Understand concepts so you can use a variety of different tools, for the same tasks, and not lock yourself in with X and Y.",2,1736816728.0
1i0pd6j,m76akm2,"yeah exactly, I am trying to read the docs and stay away from co pilot",1,1736893593.0
1i0pd6j,m76ae5m,Thanks for the tips ! Will have these in mind,2,1736893538.0
1i0tvnm,m70zatc,https://kubernetes.io/docs/concepts/storage/persistent-volumes/,0,1736819479.0
1i0ya7d,m71x2ov,"I would suggest data engineer and ml engineer combination.

So as you grow in data engineering field you need to start learning different tools. Saying this because every year you might see new tools launching market.

Along with this add something related to solution designing. That would be like a solution architect.

I am seeing the shift in last 1 year that companies are hiring ml+data engineer combination rather than data scientist. So they are hiring one solution architect in data science with 10+ years and then hire few ml+data engineers who can shape the project as per the solution design.",2,1736831700.0
1i0ya7d,m71ubbt,Data Automation Specialist? Can you elaborate a bit more on this,1,1736830443.0
1i0ya7d,m71yt0z,"This is so incredibly insightful! Thank you so much!! I definitely want to keep up to tabs on all of the new data science tools out on the market, thankfully I have some non traditional student friends that are going for the same degree I graduated in and are updating me with whats new at the university :P

  
checking out what places are hiring a 'solution architect' near me, sounds like something I would be interested in. Again this is so appreciated thank you!",1,1736832519.0
1i0ya7d,m71wa6b,"I saw a job posting that had 'Data Automation' as the title. Reading further into it, seemed to tie into the auto extraction of data within the whole ETL process. So I'm guessing doing some linkning between databases and POS systems to pull in data and then manage that whole process. 

I am still fairly ""new"" to data sciences at an enterprise level, so this may not be the exact title used. But it was a title I found while browsing for positions the other day. I've found that there is still some 'greyness' when it comes to companies determining what a ""data \_\_\_\_\_"" is. sometimes what one company calls a 'data sciencist' would be a 'data specialist' at another company. 

Definitely have been struggling with the amount of titles that exist now. I enjoy developing data pipelines, databases, I have loads of experience in snowflake, python and other etl tools like snaplogic, power automate, data visualization through tableau and qlik, the whole lot. I definitely think I could be doing more than what is expected at a 'junior' level now. Just don't know where to start.",1,1736831334.0
1i0ya7d,m73prcv,"Thats pretty informative. Unfortunately this new title is quite mapped only to that respective organisation. It is very rare I came across a title other than data engineer.

Thanks for clearing that up.",2,1736865552.0
1i0cpuy,m6wt9pi,"Question 1 says you might be a bit out of your depth here. You just asked if we should eat an apple or a fork. 

Data warehousing is one thing but you're dealing with a bank's data. That's data about real people and their finances. I wouldn't turn to reddit for the complete solution. Come here for some fact checking and ideas. If you fail here, the breach will be catastrophic to real people's lives.",76,1736771908.0
1i0cpuy,m6x893p,"I work in the financial sector.

Your questions are so broad, they are impossible to answer. 

They basically tell me you haven't a clue what you are supposed to do. 

Personally, I'd walk. You can't pick up this information on the job as you go along.",33,1736777977.0
1i0cpuy,m6wswm3,You seemed to have left off any concern for data governance.,10,1736771736.0
1i0cpuy,m6wus2y,">Should we use a traditional star or snowflake schema, or is a modern cloud-native solution like Snowflake or BigQuery better?

Star or snowflake are data warehouse architectures, Snowflake or BigQuery are two cloud products that offers you a scalable query engine plus a lot of other things. Just want to point you're comparing two completely different things.

>Best practices for secure ETL processes in the banking sector?

Banking sector, depending on the country where it operates, has usually very strict rules about secure data access. That's why it's pretty rare to find Cloud data warehouse in banking sector, but recently cloud providers have prepared packages to access that market too.

>Tools/architectures for handling real-time data, especially for fraud detection and customer behavior?

Your client should define SLA for data refresh; real-time, near-real time are just project management jargon that actually has no tech meaning. Fraud detection usually needs fast alerting (less than 5 minutes perhaps?) but customer behaviour in my opinion doesn't need real time data. ""How many **business relevant** operation does a customer on a daily basis?"" you should ask youself. Depending on the approach even a 7 days report creation schedule can be enough. Basically you don't want to overload your database with worthless processing if your data has not a high frequency of update.

>Should we use open-source tools like Kafka, PySpark, Postgres, etc., or stick with enterprise solutions?

Same as for security, banks usually prefer to stick with ""their own"" tools.

>How to ensure compliance and data security (GDPR, PCI DSS)?

Too generic question sorry, try to search on this sub because a proper answer might be too long.

>Strategies for scaling the warehouse as data grows?

You should ask yourself the volumes of the historical load of data and a proper estimate of the scheduled loads from the operational systems, based on that you design your solution. A lot of databases offer horizontally scalable solutions, if you want to do on-premise is a very big burden because you need a lot of very expert DBA to handle that; cloud providers offer more ""plug-n-play"" solutions but for what I said before it's pretty difficult to implement cloud data warehouse in banking sector.",10,1736772595.0
1i0cpuy,m6y65qr,"I think you are getting good advice from some of the people here. Let me see if I can put some structure around it.

As many people have mentioned, you are starting at the wrong place. The first questions you should be asking are not the technical ones. Those are the last ones you need to ask. (BTW, I often live in this space (greenfield and migrations) for enormous warehouses. Think multi-petabyte and above.) I have a semi-methodology based on some of the thoughts of Simon Sinek. It has served me well.

**First, find out what the business wants to accomplish**. These are your **WHYs** and are always business reasons, never technical. This will become the criteria for your success. Did you achieve the business goals? These are hard to dig out as not many people in an organization know why they are doing what they are doing. Strange but true. This will take some time but be very clear about it before you do anything. Write these down and make sure the business owners agree.

Being in the finance sector, security will be a big why. It is so engrained in the business that they often take it for granted that you know it. If you are non-US or have non-US customers, it gets even more complicated. Security and compliance to the laws and regulation are not optional. 

**Second, understand WHAT you are going to do to achieve those business goals.** Is it reporting, extracts, SOA? Is it a dashboard. This is still not technical yet. This stage focuses in on the usage and patterns of the data. *Data warehouses have zero value until they are queried.* For all the talk on it, ETL/ELT is just the homework you do in order to query the data. These will become input to determine the ROI of the warehouse and to prioritize the deliverables. Every single thing you list at this level should support the WHY level. If it doesn't don't do it.

These first two steps will take you from several months to a year. 

**Last, think about HOW you are going to achieve those.** Finally, you are getting to the technical questions. They way you answer some of your questions you are asking. You should continually be asking how well various products, practices, architectures address you delivering the WHATs. This approach gives you a way to judge what works best. You struggle here to keep the noise at bay. Everyone and their brother will have an opinion on what works best. 90% of the time it them re-solving their last problem.

When you do get to this step, remember to design for success. Don't play too much defense. It will be tempting but ultimately causes more problems.",8,1736788623.0
1i0cpuy,m6wsv7w,Are you an internal developer or a consultant?,4,1736771717.0
1i0cpuy,m6ybqak,savage thread - which bank is this,3,1736790236.0
1i0cpuy,m6wscbj,RemindMe! 3 days,3,1736771466.0
1i0cpuy,m6xnb5r,"Usually WH apps don't touch the actual transactional tables.  First replicate the tables of interest by CDC or QRep

Database choices - 
* Db2 IDAA - For near to source quicker response, real timeanalytics,  fraud analysis. Similar ops can be done in bq as well. 

* Postgres for reference tables",3,1736783016.0
1i0cpuy,m6yiqw7,Is this like an interview question or something? There’s so much nuance that can only come from internal domain expertise working at said bank. What bank is this lol? I don’t want to be banking with these guys.,3,1736792255.0
1i0cpuy,m6zzelk,Look up this swissknife: Databricks,3,1736807659.0
1i0cpuy,m70pwa6,"I have built/am building a very similar large generic thing for a financial services company. I am using this stack:

1) Airflow
2) Airbyte
3) DBT
4) Postgres (OLTP)
5) Snowflake (some data providers distribute their data there)
6) Databricks with Delta Tables
7) BI: Metabase

Basically:

WebAPP -> Postgres -> Data Warehouse -> BI


I have been working on this for 1 year, every day with maximun productivity, but it is an endless task and I am just getting started.


The most important things:

1) You need to think with a “product” mindset: solve a specific issue for a specific important person.

2) do not let senior management tell you what to build first, they will always ask first for something big hard and not important, mostly because they think in waterfall projects with clear steps

3) Spend significant time alligning expectations and thinking on what to do first.

4) build it in a way that you can easily modify over time, in my case I was VERY careful to make things very modular, very “changeable” and to defer architecture and data modelling choices as most as I could.

I am willing to help you for USD 1.5mn/year

😂",3,1736816405.0
1i0cpuy,m6xse7r,"Just ask TI what are the rules and cross check with Cybersecurity for procedures.

It's like you're trying to sell something most likely will fail because there are risks that you're not considering",2,1736784568.0
1i0cpuy,m6zjjw5,"I work for a bank. We have built on Google with dbt using data vault. It's expensive to run as we went with a simple solution. We are working on optimisation to improve the cost.

Most of the security and data governance is build in to google. You obviously need to set it up. 

Real time is problematic as you want data to oltp speeds but you are dealing with high volume. We have realised although real is desirable and possible it is too expensive. It also gets hard with the speed of data coming into the platform out of order data becomes a problem.",2,1736802942.0
1i0cpuy,m6zvwv8,"Hi

1) these are not mutually exclusive choices.   You can user Snowflake Cloud DBMS and have a star, snowflake, data vault...whatever works best in your situation.

2) can't help you there

3) Too hard to answer that.  There are many choices available

4) I would guess that since this is a bank they would insist on enterprise solutions but depends on the bank I guess.

5/6). these are large topics.  Too large to address here.",2,1736806585.0
1i0cpuy,m6x7mfe,"For banking, Snowflake is solid. Handles compliance well and scales nicely. 

Mix it with Kafka for real-time + Azure/AWS services for security. Keep sensitive data encrypted at rest.

Been there - strict security beats fancy open source every time in finance.",2,1736777746.0
1i0cpuy,m6z6slh,"I did a banking sector DW about 8 years ago.

I understand that the landscape has changed a lot since then.  But I'll add my 2 C worth.

* Do you need to store it in the cloud?
* Will there be any analytical benefit storing account and card numbers?  If the actual card numbers are not stored, or cannot be derived then maybe PCI compliance is automatically met?
* Same for account holder details.  Why store names and addresses at all.  Maybe a locale is good enough.
* Get your security, cyber sec and compliance team onboard from the beginning of the project.  Run everything, I mean EVERYTHING by them before doing anything. 

The project I started was an on prem SQL server stack DW.

When I left, they were pivoting to cloud.  I never saw the completion of that part of the system, but getting compliance right was slow and laborious, but extremely necessary",1,1736799230.0
1i0cpuy,m70m2t6,Use the one that is easiest to transition to,1,1736815136.0
1i0cpuy,m6xbpe3,"use best design , normailzed table and good naming",-1,1736779220.0
1i0cpuy,m6wtoc1,My first thought too..star schema or bq??,18,1736772095.0
1i0cpuy,m6wutbl,"
I have worked on other data warehousing projects, and the bank one is the first. So wanted to hear what people have to say about data warehousing in the financial world.",-9,1736772610.0
1i0cpuy,m6zf1yx,"Yeah I was gonna say similar. 

I've been part of a team that handled financial data with similar requirements to above. It probably spanned 100 direct professionals getting it setup and managing operations. Legal, audit, engineers, etc.",2,1736801645.0
1i0cpuy,m6wxnrj,Thanks for the reminder,1,1736773846.0
1i0cpuy,m6wuwnn,I am an internal dev,3,1736772652.0
1i0cpuy,m6ysvgm,"Probably a small regional or local, there’s tons and tons of banks",2,1736795185.0
1i0cpuy,m6wsft1,"I will be messaging you in 3 days on [**2025-01-16 12:31:06 UTC**](http://www.wolframalpha.com/input/?i=2025-01-16%2012:31:06%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1i0cpuy/data_warehousing_architecture_for_a_banks_data/m6wscbj/?context=3)

[**3 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1i0cpuy%2Fdata_warehousing_architecture_for_a_banks_data%2Fm6wscbj%2F%5D%0A%0ARemindMe%21%202025-01-16%2012%3A31%3A06%20UTC) to send a PM to also be reminded and to reduce spam.

^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201i0cpuy)

*****

|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|
|-|-|-|-|",1,1736771513.0
1i0cpuy,m70qdku,"Using databricks, very good swissknife",2,1736816566.0
1i0cpuy,m70q58b,"Also a good tip, this one is free.
This is a HARD topic, with many nuances. Instead of reddit try to find answers on udemy courses. Very good, cheap, all technologies are there.",2,1736816489.0
1i0cpuy,m6xfnhh,"Are there any issues for data residency in the cloud, and PII data in the cloud?  Some data privacy CIOs go crazy when things like social insurance numbers start showing up in queries.",1,1736780562.0
1i0cpuy,m6xnl5a,🙂,5,1736783101.0
1i0cpuy,m6wvwyk,"I work in financial services. Data protection is the biggest thing. Use tools with end to end encryption. Employ your own encryption practices for highly sensitive data (like SSN), design access controls and review practices day 1.

Outside of that, building a warehouse is very business driven. Modeling, what data you need, frequency of it, etc all depend on the business needs. Are you starting with exploration or have reporting requirements? Do you have an AI/ML group?

Ideally you start with a cloud based solution given the apparent size of your data to solve scalability and flexibility but it's more challenging because of the sensitivity of the data.

Try posing your same question to ChatGPT. You'll probably get as good of an answer as you will from reddit.

Good luck.",18,1736773095.0
1i0cpuy,m6wwu95,"Star schema and snowflake schema are platform agnostic patterns for how data is structured. Big Query and capital S Snowflake are platforms for implementing a data warehouse (or other database product), and only two of many, many out there. There are a lot of architectures to consider as well which combine data lakes and relational databases, among other things. 

This is a big undertaking. The kind of security you need to consider is a specialist’s domain. There are more people than just you planning this whole thing out, right? Some of your choices are going to be constrained by the decisions/needs of other parts of the company. Good luck",7,1736773497.0
1i0cpuy,m72i7zp,"Yep, I think it has all integrated that the post writer needs.",2,1736843706.0
1i0cpuy,m70vet6,"Can’t speak for banking specifically, but our company uses cloud resources to store data with PII. Assuming you’re using one of the big three (Azure, Google, AWS), at least as far as I can tell, the issue isn’t the technology itself. The tech is certified for most applicable regulations (SOX, GDRP (?)). The issues arise with how the user/customer limits (or fails to limit) access.",2,1736818217.0
1i0cpuy,m6wwhj9,Hell I've seen individual field encryption within a table. Make sure nobody gets data without approval,7,1736773347.0
1i0cpuy,m6wxkhq,Thanks a lot for your insights.,3,1736773808.0
1i0cpuy,m6wwsyn,"That's how we have it set up. Disk level encryption for everything, dynamic masking for PII, field level encryption for the highly sensitive.

Security is requirement number 1 for anything financial services.",6,1736773482.0
1i0cpuy,m6x1goo,"Ehh, I can still get the data, I'm just an asshole when it comes to independently sourcing and testing data.

So much easier to see mistakes when they can't hide behind stupid privacy, obstruction, or debt ridden data that they have me here in the first place....",1,1736775407.0
1i0mkm3,m6z6b13,"Our project is coming up on 2000 models and we don’t have this issue. However it’s really rare that the whole project gets run. Even our CICD and jobs use selectors.

My advice would be to get better at doing things like ‘dbt run —model 2+model_that_im_working_on+’",6,1736799085.0
1i0mkm3,m70q3lh,"My team had some sh files to split the dbt project into smaller dbt projects in the same repo to save time compiling. But this was too messy. We ended up completely splitting out models into different repos and everything works out fine now. Specifically since we started using terraform, we could use the same code and spin up other instance of airflow/dbt in seconds and create a new repo and dbt project without wasting time setting things up.",1,1736816473.0
1i0mkm3,m77ooyc,"If you using dbt-core, make sure that you are using at least Python 3.11. There were some big changes in efficiency in dbt when moving to Python 3.11. 

https://docs.getdbt.com/faqs/Core/install-python-compatibility",1,1736910530.0
1i0mkm3,m6z3k14,"Are you using CLI selectors when developing? Or just dbt build each time.

Are you using incremental models? Staging tables/queries correctly? Optimizing queries? Tagging models or using state tracking so you can run chunks of models when they need to vs every time?

Can you spread out tests so that they don’t run every time if you have rapidly changing data? (I did something where I used an evrionment variable you can alter in CLI, certain terribly taxing tests will only run when the variable is set explicitly to true)

Splitting a project into separate ones purely for performance issues seems like a bad idea, unless it’s departmental driven or you’re trying to achieve a certain design pattern. Most of the time you actually want to consolidate to a single project if possible. (There was a thread not too long ago here discussing 1 large project vs a bunch of smaller ones)",0,1736798275.0
1i0mkm3,m6zdube,"While developing, most of the time it's a single model being run at time (no tests). This project is also expected to grown a lot as more teams are expected to start working on this project.    
  
My goal is to to shave time from the dbt compile step. Right now it's taking about 4 minutes from the moment we start a run to the moment the first query start to run. This can have some variation depending on if it's a full parse or if dbt is reusing the manifest but it feels negligible. 

I'm intrigued about your comment. I thought the main reason why the project was slowing down was because of the model quantity. But if you are working with 2000 without problem there must be something more we are not realising",1,1736801294.0
1i0mkm3,m77peto,"""Python support: Python 3.11 was released in October 2022. It is officially supported in dbt-core v1.4, although full support depends also on the adapter plugin for your data platform. According to the Python maintainers, ""Python 3.11 is between 10-60% faster than Python 3.10."" We encourage you to try dbt parse with dbt Core v1.4 + Python 3.11, and compare the timing with dbt Core v1.3 + Python 3.10. Let us know what you find!""

https://docs.getdbt.com/docs/dbt-versions/core-upgrade/Older%20versions/upgrading-to-v1.4",1,1736910793.0
1i0mkm3,m6zdi07,"While developing, most of the time it's a single model being run at time (no tests). This project is also expected to grown a lot as more teams are expected to start working on this project.    
  
My goal is to to shave time from the dbt compile step. Right now it's taking about 4 minutes from the moment we start a run to the moment the first query start to run. This can have some variation depending on if it's a full parse or if dbt is reusing the manifest but it feels negligible.",1,1736801195.0
1i0mkm3,m6zihxs,"Ah, my bad, I misunderstood you. Our compile runs in about 45 seconds. One of the things you could look at are the introspection queries that dbt is running, if your warehouse is slow to respond that could be causing long compile times.",2,1736802641.0
1i0mkm3,m70cle6,"Wait, your model sits for 4 minutes before the first model runs or finishes running? If it’s 4 minutes to finish then it’s a poorly written root model or you don’t have parallelization setup or…does your entire project build off a single model as its root

For reference I have a 600 model project and parse takes like 5 second and first models build shortly after. Parse also doesn’t hit the database at all. How many threads are you using? What kind of hardware is running the dbt project?

Can you provide the first couple lines from a dbt build step? And maybe the query for the very first model that’s taking 4 minutes?",2,1736811962.0
1i0mkm3,m70juao,"We always run an specific model, so something like `dbt run --select ""my_dbt_model""` 

Lets suppose this query takes about 30 seconds. 

dbt will run on my laptop for about 4m, them it will start the query and finish at 4m30s. 

Parse does not hit the database, but compile does. If I understand correctly, under de hood dbt does something like

Parse -> compile -> run 

Some optimizations may take place to make an parcial or skip some stages.",1,1736814390.0
1i0mkm3,m71szse,"So something is causing your manifest and target files to take forever. 

So to answer my question, you’re compiling the project locally. What kind of CPU and threads do you have? Have you set the thread setting in the profile.yml?

I would consider looking into the build artifacts/state recognition. It should only compile files changed since last run.

I find it extremely unusual that compilation itself takes that long barring poor hardware. Or some queries that are making calls to the database to build the scripts.

Do you have any project on-starts or dynamically building column names/using dbt macros to construct the scripts?

It sounds like there could be other queries running in compilation that are poorly optimized.",2,1736829863.0
1i0mklp,m70ic1n,"Our daily runs take about 50 minutes with 1k+ models, but my development experience isn’t hindered by that at all as I just run with —select the models I’m working on (with upstream or downstream as needed).",2,1736813891.0
1i0mklp,m6zbvdv,"Some ideas are:


- Careful combinations of incremental materializations and views.

- Use the --state or --defer flags in development for more efficient runs.

- Use tags to run only parts of the pipeline.",1,1736800717.0
1i0mklp,m71b6xd,Use tags to break up your project into different parts. That and use the —select modifier to only run the necessary parts of your project.,1,1736823281.0
1i0j47l,m6y6tzy,"You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources

*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",1,1736788820.0
1i0j47l,m6y8m4i,"Never heard of informatica that much in this space and actually surprised to hear it - if the choice is between one or the other, I would go with databricks. Fully integrated pipelines and features to cater to AI needs with the mosaic AI stack. That said, I believe most data scientists and ml engineers would go with a combination of open source tools but the databricks infra makes it easier as it’s all packaged together for you",9,1736789335.0
1i0j47l,m6yy2fv,"\> And why is Informatica gaining more traction lately in the AI/ML space? Is it just marketing, or does it have an edge for things like compliance and data governance?

This is almost certainly marketing - search this sub and you'll find tons of posts asking for help migrating from Informatica to Databricks.  I'd be a bit surprised to see year-over-year subscription growth for Informatica, and would be shocked if its subscription growth is anywhere near Databricks'. Informatica is one of those tools that sells great to non-technical C-suites as an all-in-one solution, and once entrenched in a company becomes extraordinarily difficult to get off of due to how much vendor-lock is built into the platform. Databricks is built on open source tech and is relatively trivial to integrate with other industry tools, and is easier to start small with and slowly expand as your org learns how to integrate it better. However Databricks arguably requires quite a bit more technical expertise in your org (though they're trying to reduce this overhead with all the managed and serverless stuff they have now), whereas Informatica supports more drag-and-drop stuff that might be useful if you have Excel jockeys that do most of your transformations but don't know much about coding.

Starting an Informatica subscription today is basically paying for a rigid, try-to-do-everything tool that is a decade past its prime instead of a flexible, modern solution that is likely to cost a significant amount less. The only reason to consider Informatica today is if you need to enable pretty non-technical users to do transformations / reporting.",5,1736796693.0
1i0j47l,m6yfrpy,"It has been my experience, across several very large companies, that data scientists don't want thier data scrubbed. Just straight from the faucet, so to speak. They don't want it cleansed or touched (or delayed) at all. 

I think you should talk to your quants and see what they want. Their use cases can be quite different from anyone else in your company. You pipeline may just reduce down to a copy or an extra grant statement in staging.",3,1736791393.0
1i0j47l,m6yr1vl,I don't have experience with databricks however I can tell you that I detest everything that informatica is. Disclaimer: this could be user error lol.,2,1736794655.0
1i0j47l,m6ysw4t,"Essentially their ETL tools but surely you just need raw data rather than transforming/scrubbing it?

Informatica is so expensive nobody uses it.",2,1736795190.0
1i0j47l,m6zeaxb,"Databricks is way better suited for AI/ML pipelines. Native integration with MLflow, easy scaling of compute, and seamless transitions between notebooks and production code.

Informatica is solid for ETL but feels like they're just slapping ""AI"" on traditional data integration.",2,1736801428.0
1i0j47l,m6zt0e2,Neither. I’d use airflow :),2,1736805702.0
1i0j47l,m6zusfe,"Databricks way better than Informatica for AI and workflows if you have the choice. Informatica great technology but getting old. It’s a good choice for their non-code approach. But if you know how to code a little bit Databricks is faster and most of the time cheaper. 
Also Informatica is lock-in, it’s a bit hard to migrate away your workflows.",2,1736806242.0
1i0j47l,m70y67j,Do not touch informatica with a 10 ft pole,2,1736819110.0
1i0j47l,m7104f1,Informatica is the second worst.  Drop it like a dead body.,2,1736819749.0
1i0j47l,m6ys97v,"Just curious: Informática, Powercenter informática?",1,1736795004.0
1i0j47l,m6z5qah,I'm not sure why informatica is even on your list. Just don't. It's a huge pain and not even fit for the ML purpose. If someone at informatica told you it does ML they are trying to close a new contract.,1,1736798916.0
1i0j47l,m77z9nv,"As for informatica gaining more traction in the AI/ML, it's all aggressive marketing so they don't look like the fossil they are. And for Databricks, I'm assuming you're using their lakehouse or data warehouse? Otherwise, there are lot more lightweight approaches to building ML pipelines.",1,1736914632.0
1i0j47l,m6ybxjs,"Hey, check out langchian-beam, Its a langchain and apache beam integration to use langchain's components like LLM interface in apache beam ETL pipeline and leverage LLM's capabilities for data processing, transformations and provide a way to create RAG based ETL pipelines.

recently I've added a feature to integrate embedding models into beam pipeline and generate vector embeddings for text in pipeline using the models so that embedding generation activity can be a part of the data pipeline instead of separate service.

Would like to hear your thoughts. Repo -  [https://github.com/Ganeshsivakumar/langchain-beam](https://github.com/Ganeshsivakumar/langchain-beam)",0,1736790294.0
1i0j47l,m6yxxan,"Thanks! why do you think a combo of OS tools with Databricks works better? Is it mostly about the flexibility to customize workflows, or is it more of a cost-saving move (assuming you’ve got the team with the right skills)?",1,1736796652.0
1i0j47l,m6z5x80,">search this sub and you'll find tons of posts asking for help migrating from Informatica to Databricks

I’ll definitely check it out, thanks so much! Your comment was super helpful and cleared up almost all my doubts.",1,1736798973.0
1i0j47l,m6yxv14,"This is very bad. 

There should be standard ways that features are calculated and standard ways that data problems are treated. Any other approach is just going to create noise as different teams argue about why their numbers are different.",3,1736796634.0
1i0j47l,m6ysh35,"Prof. Hubert J. Farnsworth vibes right there. And I respect that.
Edited: correcting autocorrect",1,1736795068.0
1i0j47l,m6yzxxw,"Thanks for your input! The raw vs. transformed data debate is definitely something I’m still figuring out, especially in terms of how much pre-processing might actually hinder a model’s ability to learn.

As for Informatica being so expensive, I’m curious—do you think that’s purely a commercial thing, or is there a technical aspect that drives up the cost?",1,1736797235.0
1i0j47l,m73c6fi,Thanks!,1,1736860520.0
1i0j47l,m6yy7z2,Yep,1,1736796737.0
1i0j47l,m6zad8q,"Thanks for the comment! I’ve read a bit about how they help ‘get data ready for AI,’ but I’m still not totally clear on why it’s not fit for ML. From what I get, it’s mostly an ETL tool, and advanced models seem to work better with raw data. I understand there are tools like Databricks that are optimized for ML with features like distributed processing, built-in machine learning frameworks (e.g., TensorFlow, PyTorch), and support for real-time data pipelines. Is there more I’m missing about why Informatica struggles with ML workflows?",1,1736800279.0
1i0j47l,m6z0lpt,"It’s flexibility - data scientists / MLE like having options and are generally not too concerned about costs. That said never underestimate the cost of building a fully OS based architecture, it might be cheaper to run but expensive to stitch together and maintain. Databricks integrates well with many os solutions and often core packages, libraries etc come already pre-installed in the databricks runtime. You can also use databricks just as a compute engine if thats all you need it for.",1,1736797425.0
1i0j47l,m6zn75c,"I'm just delivering the message. Statistical problems rarely have the same sort of results that other data problems have. There are standard methods (think calculating a standard deviation) but not standard ways of applying it.

What DS are more concerned about is injecting bias during the data cleanup. It is a matter of what you perceive to be the bigger risk.",3,1736804003.0
1i0j47l,m6yyuw0,"haha, what went wrong?",1,1736796920.0
1i0j47l,m6z2o4g,">expensive to stitch together and maintain. 

Agree.

>Databricks integrates well with many os solutions and often core packages, libraries etc come already pre-installed in the databricks runtime. 

That's an important factor; thanks for the clear explanation! ",2,1736798020.0
